{
  "bill_id": "MA2025000S51",
  "source_url": "http://custom.statenet.com/public/resources.cgi?id=ID:bill:MA2025000S51&cuiq=93d84396-c63b-526a-b152-38b7f79b4cfd&client_md=e4f6fea4-27b4-5d41-b7d3-766fe52569f0",
  "versions": [
    {
      "date": "02/27/2025",
      "label": "Introduced",
      "url": "https://custom.statenet.com/public/resources.cgi?mode=show_text&id=ID:bill:MA2025000S51&verid=MA2025000S51_20250227_0_I&",
      "raw_html": "<html>\n<head>\n<title>Bill Resource</title>\n\n<!--   <link href=\"https://custom.statenet.com/network/Common/css/extregtext.css\" rel=\"stylesheet\" type=\"text/css\" />-->\n   <link href=\"https://custom.statenet.com/network/Common/css/xmltext-2.0.css\" rel=\"stylesheet\" type=\"text/css\" />\n   <link href=\"https://custom.statenet.com/network/Common/css/additional-text.css\" rel=\"stylesheet\" type=\"text/css\" />\n\n\t<style type=\"text/css\">\n<!--\n\ntd, body {\n     background-color: white;\n\tfont-family: Verdana, Arial, Helvetica, sans-serif;\n\tfont-size: 12px;\n}\n\n.resourceContainer {\n   border: 1px solid black;\n}\n-->\n</style>\n</head>\n<body>\n\n    <div style=\"width: 750px; margin: auto\">\n       <div style=\"font-size: .8em;margin-bottom: 10px\"><table width=\"100%\"><tr><td align=\"left\" style=\"font-size: .8em;\"><div>The following has special meaning:</div>\n<div><u class=\"amendmentInsertedText\">green underline denotes added text</u></div>\n<div><strike class=\"amendmentDeletedText\">red struck out text denotes deleted text</strike></div></td> <td align=\"right\"><a href=\"https://www.lexisnexis.com/statenet/\"><img alt=\"Powered by State Net\" src=\"https://custom.statenet.com/network/poweredby.gif\" /></a></td></tr></table></div><table id=\"text-identifier\"><tr><td class=\"key\">2025 MA S 51</td> <td><table><tr><td class=\"label\">Author:</td> <td>Velis</td></tr> <tr><td class=\"label\">Version:</td> <td>Introduced</td></tr> <tr><td class=\"label\">Version Date:</td> <td>02/27/2025</td></tr></table></td></tr></table><div class=\"documentBody\">\n  <a name=\"head_document_section\"></a><div class=\"head\">\n   <p class=\"left\">SENATE No. 51</p>\n   <p class=\"center\">The Commonwealth of Massachusetts</p>\n   <p class=\"center\">In the One Hundred and Ninety-Fourth General Court</p>\n   <p class=\"center\">(2025-2026)</p>\n  </div>\n  <a name=\"title_document_section\"></a><div class=\"title\">\n   <p class=\"left\">AN ACT RELATIVE TO SOCIAL MEDIA, ALGORITHM ACCOUNTABILITY, AND TRANSPARENCY.</p>\n  </div>\n  <a name=\"text_document_section\"></a><div class=\"text\">\n   <span>\n    <p class=\"indent\">Be it enacted by the Senate and House of Representatives in General Court assembled, and by the authority of the same, as follows: </p>\n   </span>\n   <p class=\"indent\">SECTION 1. Chapter 12 of the General Laws, as so appearing, is hereby amended by inserting after section 35 the following section:- </p>\n   <p class=\"indent\">Section 36. (a) As used in this section the following words shall, unless the context clearly requires otherwise, have the following meanings:- </p>\n   <p class=\"indent\">&ldquo;Algorithm&rdquo;, computational process that uses machine learning, natural language processing, artificial intelligence techniques, or other computational processing techniques of similar or greater complexity and that makes a decision or facilitates human decision-making with respect to users personal information, including to determine the provision of products or services or to rank, order, promote, recommend, amplify or similarly determine the delivery or display of information to an individual. For purposes of this section, an algorithm will refer to recommendation algorithms, also known as engagement-based algorithms, which passively populate a user&rsquo;s feed or experience with content without any direct action or request by the user. </p>\n   <p class=\"indent\">&ldquo;Children&rdquo;, consumers under 18 years of age. </p>\n   <p class=\"indent\">&ldquo;Covered platform&rdquo;, an internet website, online service, online application, or mobile application, including, but not limited to, a social media platform that conducts business in this state or that produces products or services that is accessed by residents and that during the preceding calendar year: (1) controlled or processed the personal information of not less than one hundred thousand consumers, excluding personal information controlled or processed solely for the purpose of completing a payment transaction; or (2) controlled or processed the personal information of not less than twenty-five thousand consumers and derived more than twenty-five per cent of their gross revenue from the sale of personal data. </p>\n   <p class=\"indent\">&ldquo;Consumer&rdquo;, a natural person who is a Massachusetts resident, however identified, including by any unique identifier. </p>\n   <p class=\"indent\">&ldquo;Independent third-party auditor&rdquo;, auditing organization that has no affiliation with a covered platform as defined by this section. </p>\n   <p class=\"indent\">&ldquo;Likely to be accessed&rdquo;, reasonable expectation, based on the following factors, that a covered platform would be accessed by children: (1) the covered platform is directed to children as defined by the Children&rsquo;s Online Privacy Protection Act (15 U.S.C. Sec. 6501 et seq.); (2) the covered platform is determined based on audience composition where children comprise at least 10% of its audience; (3) the covered platform is paid for advertisements on its platform that are marketed to children; (4) the covered platform is substantially similar or the same as a covered platform that satisfies subsection (2); and (5) a significant amount of the audience of the covered platform, 10% or more, is determined, based on internal company research, to be children. </p>\n   <p class=\"indent\">&quot;Process&quot; or &quot;processing&quot;, any operation or set of operations performed, whether by manual or automated means, on personal information or on sets of personal information, such as the collection, use, storage, disclosure, analysis, deletion or modification of personal information. </p>\n   <p class=\"indent\">&ldquo;Personal information&rdquo;, information linked or reasonably linkable to an identified or identifiable individual. </p>\n   <p class=\"indent\">&ldquo;Social media platform&rdquo;, public or semipublic internet-based service or application that has users in Massachusetts and that meets both of the following criteria: (1) a substantial function of the service or application is to connect users and allow users to interact socially with each other within the service or application; provided further, that an internet-based service or application that provides email or direct messaging services shall not be considered to meet this criterion on this function alone; provided further that a service or application that is an internet search engine or website whose primary focus is e-commerce, which would include the buying, selling, or exchange of goods or services over the internet, including business-to-business, business-to-consumer, and consumer-to-consumer transactions shall not be considered to meet this criterion on the basis of that function alone; and (2) the application allows users to: (i) construct a public or semipublic profile for purposes of signing into and using the service or application; (ii) populate a list of other users with whom an individual shares a social connection within the system; and (iii) create or post content viewable by other users, including, but not limited to, on message boards, in chat rooms, or through a landing page or main feed that presents the user with content generated by other users. </p>\n   <p class=\"indent\">&ldquo;Experts in the mental health and public policy fields&rdquo;, (1) academic experts, health professionals, and members of civil society with expertise in mental health, substance use disorders, and the prevention of harms to minors; (2) representatives in academia and civil society with specific expertise in privacy and civil liberties; (3) parents and youth representation; (4) representatives of the national telecommunications and information administration, the national institute of standards and technology, the federal trade commission, the office of the attorney general of Massachusetts, and the Massachusetts executive office of health and human services; (5) state attorneys general or their designees acting in State or local government; and (6) representatives of communities of socially disadvantaged individuals as defined in section 8 of the Small Business Act, 15 U.S.C. 637. </p>\n   <p class=\"indent\">(b) There shall be an office of social media transparency and accountability, which shall be supervised and controlled by the office of the attorney general. The office shall receive, review and maintain the reports from covered platforms, to enforce this section, and to adopt regulations to clarify the requirements of this section. </p>\n   <p class=\"indent\">(c) Annually before January 1, covered platforms shall register with the office by providing: (i) a registration fee, determined by the office of the attorney general; (ii) the platform&rsquo;s name; (iii) physical address; (iv) email; and (v) internet address. </p>\n   <p class=\"indent\">(d) The office shall compile a list of approved, independent third-party auditors and shall assign independent third-party auditors to conduct algorithm risk audits of covered platforms. Risk audits shall be conducted monthly by third-party auditors, unless specified otherwise by the office. Audits and associated costs shall be paid for by covered platforms. The algorithm risk audits shall focus on harms to children, including but not limited to: (i) mental health disorders including anxiety, depression, eating disorders, substance abuse disorders, and suicidal behaviors; (ii) patterns of use that indicate or encourage addiction-like behaviors; (iii) physical violence, online bullying, and harassment of the minor; (iv) sexual exploitation and abuse; (v) promoting and market of narcotic drugs as defined in section 102 of the Controlled Substances Act, 21 U.S.C. 802, tobacco products, gambling, or alcohol; and (vi) predatory, unfair or deceptive marketing practices, or other financial harms. </p>\n   <p class=\"indent\">(e) Annually before January 1, the office shall empanel an Advisory Council of experts in the mental health and public policy fields as defined in this section to review these harms and identify additional ways covered platforms cause harms to children. </p>\n   <p class=\"indent\">(f) Annually before July 1, the office shall promulgate regulations based on the cumulation of the potential harms identified by the Advisory Council that update the specific harms that must be examined by the algorithm risk audits required under this section. </p>\n   <p class=\"indent\">(g) Beginning on January 1, 2026, covered platforms shall annually submit transparency reports to the office containing, but not limited to: (i) assessment of whether the covered platform is likely to be accessed by children; (ii) description of the covered platform&rsquo;s commercial interests in use of the platform by children; (iii) number of individuals using the covered platform reasonably believed to be children in the United States, disaggregated by the age ranges of 0-5, 6-9, 10-12, 13-15 and 16-17 years; (iv) median and mean amounts of time spent on the covered platform by children in the United States who have accessed the platform during the reporting year on a daily, weekly and monthly basis, disaggregated by the age ranges of 0-5, 6-9, 10-12, 13-15 and 16-17 years; (v) description of whether and how the covered platform uses system design features to increase, sustain, or extend use of a product or service by users, including automatic playing of media, rewards for time spent and notifications; (vi) description of whether, how and for what purpose the covered platform collects or processes personal information that may cause reasonably foreseeable risk of harm to children; (vii) total number of complaints received regarding, and the prevalence of issues related to, the harms described in section 1, disaggregated by category of harm; (viii) description of the mechanism by which the public may submit complaints, the internal processes for handling complaints, and any automated detection mechanisms for harms to children, including the rate, timeliness, and effectiveness of responses. </p>\n   <p class=\"indent\">(h) By January 1, 2027, covered platforms shall submit preliminary reports to the office. The preliminary report must measure the incidence of each of the specific harms identified in subsection (d) that occur on the covered platform. The office must consult with independent third-party auditors and covered platforms to determine what data shall be used to produce the preliminary reports. </p>\n   <p class=\"indent\">After a covered platform has submitted a preliminary report, the covered platform may agree that the office will consult with independent third-party auditors and the covered platform to set benchmarks the covered platform must meet to reduce the harms, identified in subsection (d) on its platform as indicated in the preliminary reports required under this section. Upon agreement, each covered platform shall thereafter produce biannual reports containing, but not limited to: (i) steps taken to mitigate harm on its platform, including implementation of any systems used to meet benchmarks; and (ii) measurements indicating the redaction in harm as a result of these systems. </p>\n   <p class=\"indent\">In the case the covered platform has failed meet the benchmarks, upon agreement its annual report must also contain: (1) a mitigation plan detailing changes the platform intends to take to ensure future compliance with benchmarks; and (2) a written explanation regarding the reasons the benchmarks were not met. </p>\n   <p class=\"indent\">If a covered platform should choose not to consult with independent third-party auditors to set benchmarks it must meet to reduce the harms, identified in subsection (d), on its platform as indicated in the preliminary reports required under this subsection, the attorney general is not precluded from pursuing any other legal remedy available at law to mitigate harms. </p>\n   <p class=\"indent\">(i) The records generated by this section shall be subject to chapter 66 of the General Laws and shall be made accessible to the public on the attorney general&rsquo;s website. However, to the extent any information contained within a report required by this section is trade secret, proprietary or privileged, covered platforms may request such information be redacted from the copy of the report that is obtainable under the public records law and on the attorney general&rsquo;s website. The office will conduct a confidential, in-camera review of requested redactions to determine whether the information is trade secret, proprietary or privileged information that should not be made accessible for public review. All information from the copy of the report submitted to the office, including redactions, will be maintained by a covered platform in their internal records. </p>\n   <p class=\"indent\">(j) A covered platform shall be considered in violation of this section for the following: (i) fails to register with the office; (ii) materially omits or misrepresents required information in a submitted report; or (iii) fails to timely submit a report to the office. </p>\n   <p class=\"indent\">(1) A covered platform in violation of this section is subject to an injunction and liable for a civil penalty not to exceed $500,000 per violation, which shall be assessed and recovered in a civil action brought by the attorney general. In assessing the amount of a civil penalty pursuant to this section, the court shall consider whether the covered platform made a reasonable, good faith attempt to comply with the provisions of this section. Any penalties, fees, and expenses recovered in an action brought under this section shall be collected by the office of the attorney general with the intent that they be used to fully offset costs in connection with the enforcement of this section and to promote the positive mental health outcomes of the children of Massachusetts. </p>\n   <p class=\"indent\">(k) If any provision of this section, or any application of such provision to any person or circumstance, is held to be unconstitutional, the remainder of this section and the application of this section to any other person or circumstance shall not be affected. </p>\n  </div>\n </div>\n    </div>\t\n<table cellpadding=0 cellspacing=0 width=\"100%\">\n   <tr>\n      <td>\n          Copyright &copy; 2025 State Net\n      </td>\n<BR>\n<!--???MOVED INTO resources.cgi      <td align=\"right\">\n          <img src=\"https://custom.statenet.com/network/poweredby.gif\" alt=\"Powered by State Net\">\n      </td>-->\n\n    </tr>\n</table>\n</body></html>\n",
      "markdown": "The following has special meaning: _green underline denotes added text_ ~~red struck out text denotes deleted text~~ | [![Powered by State Net](https://custom.statenet.com/network/poweredby.gif)](https://www.lexisnexis.com/statenet/)  \n---|---  \n  \n2025 MA S 51 | | Author: | Velis  \n---|---  \nVersion: | Introduced  \nVersion Date: | 02/27/2025  \n  \nSENATE No. 51\n\nThe Commonwealth of Massachusetts\n\nIn the One Hundred and Ninety-Fourth General Court\n\n(2025-2026)\n\nAN ACT RELATIVE TO SOCIAL MEDIA, ALGORITHM ACCOUNTABILITY, AND TRANSPARENCY.\n\nBe it enacted by the Senate and House of Representatives in General Court\nassembled, and by the authority of the same, as follows:\n\nSECTION 1. Chapter 12 of the General Laws, as so appearing, is hereby amended\nby inserting after section 35 the following section:-\n\nSection 36. (a) As used in this section the following words shall, unless the\ncontext clearly requires otherwise, have the following meanings:-\n\n\"Algorithm\", computational process that uses machine learning, natural\nlanguage processing, artificial intelligence techniques, or other\ncomputational processing techniques of similar or greater complexity and that\nmakes a decision or facilitates human decision-making with respect to users\npersonal information, including to determine the provision of products or\nservices or to rank, order, promote, recommend, amplify or similarly determine\nthe delivery or display of information to an individual. For purposes of this\nsection, an algorithm will refer to recommendation algorithms, also known as\nengagement-based algorithms, which passively populate a user's feed or\nexperience with content without any direct action or request by the user.\n\n\"Children\", consumers under 18 years of age.\n\n\"Covered platform\", an internet website, online service, online application,\nor mobile application, including, but not limited to, a social media platform\nthat conducts business in this state or that produces products or services\nthat is accessed by residents and that during the preceding calendar year: (1)\ncontrolled or processed the personal information of not less than one hundred\nthousand consumers, excluding personal information controlled or processed\nsolely for the purpose of completing a payment transaction; or (2) controlled\nor processed the personal information of not less than twenty-five thousand\nconsumers and derived more than twenty-five per cent of their gross revenue\nfrom the sale of personal data.\n\n\"Consumer\", a natural person who is a Massachusetts resident, however\nidentified, including by any unique identifier.\n\n\"Independent third-party auditor\", auditing organization that has no\naffiliation with a covered platform as defined by this section.\n\n\"Likely to be accessed\", reasonable expectation, based on the following\nfactors, that a covered platform would be accessed by children: (1) the\ncovered platform is directed to children as defined by the Children's Online\nPrivacy Protection Act (15 U.S.C. Sec. 6501 et seq.); (2) the covered platform\nis determined based on audience composition where children comprise at least\n10% of its audience; (3) the covered platform is paid for advertisements on\nits platform that are marketed to children; (4) the covered platform is\nsubstantially similar or the same as a covered platform that satisfies\nsubsection (2); and (5) a significant amount of the audience of the covered\nplatform, 10% or more, is determined, based on internal company research, to\nbe children.\n\n\"Process\" or \"processing\", any operation or set of operations performed,\nwhether by manual or automated means, on personal information or on sets of\npersonal information, such as the collection, use, storage, disclosure,\nanalysis, deletion or modification of personal information.\n\n\"Personal information\", information linked or reasonably linkable to an\nidentified or identifiable individual.\n\n\"Social media platform\", public or semipublic internet-based service or\napplication that has users in Massachusetts and that meets both of the\nfollowing criteria: (1) a substantial function of the service or application\nis to connect users and allow users to interact socially with each other\nwithin the service or application; provided further, that an internet-based\nservice or application that provides email or direct messaging services shall\nnot be considered to meet this criterion on this function alone; provided\nfurther that a service or application that is an internet search engine or\nwebsite whose primary focus is e-commerce, which would include the buying,\nselling, or exchange of goods or services over the internet, including\nbusiness-to-business, business-to-consumer, and consumer-to-consumer\ntransactions shall not be considered to meet this criterion on the basis of\nthat function alone; and (2) the application allows users to: (i) construct a\npublic or semipublic profile for purposes of signing into and using the\nservice or application; (ii) populate a list of other users with whom an\nindividual shares a social connection within the system; and (iii) create or\npost content viewable by other users, including, but not limited to, on\nmessage boards, in chat rooms, or through a landing page or main feed that\npresents the user with content generated by other users.\n\n\"Experts in the mental health and public policy fields\", (1) academic experts,\nhealth professionals, and members of civil society with expertise in mental\nhealth, substance use disorders, and the prevention of harms to minors; (2)\nrepresentatives in academia and civil society with specific expertise in\nprivacy and civil liberties; (3) parents and youth representation; (4)\nrepresentatives of the national telecommunications and information\nadministration, the national institute of standards and technology, the\nfederal trade commission, the office of the attorney general of Massachusetts,\nand the Massachusetts executive office of health and human services; (5) state\nattorneys general or their designees acting in State or local government; and\n(6) representatives of communities of socially disadvantaged individuals as\ndefined in section 8 of the Small Business Act, 15 U.S.C. 637.\n\n(b) There shall be an office of social media transparency and accountability,\nwhich shall be supervised and controlled by the office of the attorney\ngeneral. The office shall receive, review and maintain the reports from\ncovered platforms, to enforce this section, and to adopt regulations to\nclarify the requirements of this section.\n\n(c) Annually before January 1, covered platforms shall register with the\noffice by providing: (i) a registration fee, determined by the office of the\nattorney general; (ii) the platform's name; (iii) physical address; (iv)\nemail; and (v) internet address.\n\n(d) The office shall compile a list of approved, independent third-party\nauditors and shall assign independent third-party auditors to conduct\nalgorithm risk audits of covered platforms. Risk audits shall be conducted\nmonthly by third-party auditors, unless specified otherwise by the office.\nAudits and associated costs shall be paid for by covered platforms. The\nalgorithm risk audits shall focus on harms to children, including but not\nlimited to: (i) mental health disorders including anxiety, depression, eating\ndisorders, substance abuse disorders, and suicidal behaviors; (ii) patterns of\nuse that indicate or encourage addiction-like behaviors; (iii) physical\nviolence, online bullying, and harassment of the minor; (iv) sexual\nexploitation and abuse; (v) promoting and market of narcotic drugs as defined\nin section 102 of the Controlled Substances Act, 21 U.S.C. 802, tobacco\nproducts, gambling, or alcohol; and (vi) predatory, unfair or deceptive\nmarketing practices, or other financial harms.\n\n(e) Annually before January 1, the office shall empanel an Advisory Council of\nexperts in the mental health and public policy fields as defined in this\nsection to review these harms and identify additional ways covered platforms\ncause harms to children.\n\n(f) Annually before July 1, the office shall promulgate regulations based on\nthe cumulation of the potential harms identified by the Advisory Council that\nupdate the specific harms that must be examined by the algorithm risk audits\nrequired under this section.\n\n(g) Beginning on January 1, 2026, covered platforms shall annually submit\ntransparency reports to the office containing, but not limited to: (i)\nassessment of whether the covered platform is likely to be accessed by\nchildren; (ii) description of the covered platform's commercial interests in\nuse of the platform by children; (iii) number of individuals using the covered\nplatform reasonably believed to be children in the United States,\ndisaggregated by the age ranges of 0-5, 6-9, 10-12, 13-15 and 16-17 years;\n(iv) median and mean amounts of time spent on the covered platform by children\nin the United States who have accessed the platform during the reporting year\non a daily, weekly and monthly basis, disaggregated by the age ranges of 0-5,\n6-9, 10-12, 13-15 and 16-17 years; (v) description of whether and how the\ncovered platform uses system design features to increase, sustain, or extend\nuse of a product or service by users, including automatic playing of media,\nrewards for time spent and notifications; (vi) description of whether, how and\nfor what purpose the covered platform collects or processes personal\ninformation that may cause reasonably foreseeable risk of harm to children;\n(vii) total number of complaints received regarding, and the prevalence of\nissues related to, the harms described in section 1, disaggregated by category\nof harm; (viii) description of the mechanism by which the public may submit\ncomplaints, the internal processes for handling complaints, and any automated\ndetection mechanisms for harms to children, including the rate, timeliness,\nand effectiveness of responses.\n\n(h) By January 1, 2027, covered platforms shall submit preliminary reports to\nthe office. The preliminary report must measure the incidence of each of the\nspecific harms identified in subsection (d) that occur on the covered\nplatform. The office must consult with independent third-party auditors and\ncovered platforms to determine what data shall be used to produce the\npreliminary reports.\n\nAfter a covered platform has submitted a preliminary report, the covered\nplatform may agree that the office will consult with independent third-party\nauditors and the covered platform to set benchmarks the covered platform must\nmeet to reduce the harms, identified in subsection (d) on its platform as\nindicated in the preliminary reports required under this section. Upon\nagreement, each covered platform shall thereafter produce biannual reports\ncontaining, but not limited to: (i) steps taken to mitigate harm on its\nplatform, including implementation of any systems used to meet benchmarks; and\n(ii) measurements indicating the redaction in harm as a result of these\nsystems.\n\nIn the case the covered platform has failed meet the benchmarks, upon\nagreement its annual report must also contain: (1) a mitigation plan detailing\nchanges the platform intends to take to ensure future compliance with\nbenchmarks; and (2) a written explanation regarding the reasons the benchmarks\nwere not met.\n\nIf a covered platform should choose not to consult with independent third-\nparty auditors to set benchmarks it must meet to reduce the harms, identified\nin subsection (d), on its platform as indicated in the preliminary reports\nrequired under this subsection, the attorney general is not precluded from\npursuing any other legal remedy available at law to mitigate harms.\n\n(i) The records generated by this section shall be subject to chapter 66 of\nthe General Laws and shall be made accessible to the public on the attorney\ngeneral's website. However, to the extent any information contained within a\nreport required by this section is trade secret, proprietary or privileged,\ncovered platforms may request such information be redacted from the copy of\nthe report that is obtainable under the public records law and on the attorney\ngeneral's website. The office will conduct a confidential, in-camera review of\nrequested redactions to determine whether the information is trade secret,\nproprietary or privileged information that should not be made accessible for\npublic review. All information from the copy of the report submitted to the\noffice, including redactions, will be maintained by a covered platform in\ntheir internal records.\n\n(j) A covered platform shall be considered in violation of this section for\nthe following: (i) fails to register with the office; (ii) materially omits or\nmisrepresents required information in a submitted report; or (iii) fails to\ntimely submit a report to the office.\n\n(1) A covered platform in violation of this section is subject to an\ninjunction and liable for a civil penalty not to exceed $500,000 per\nviolation, which shall be assessed and recovered in a civil action brought by\nthe attorney general. In assessing the amount of a civil penalty pursuant to\nthis section, the court shall consider whether the covered platform made a\nreasonable, good faith attempt to comply with the provisions of this section.\nAny penalties, fees, and expenses recovered in an action brought under this\nsection shall be collected by the office of the attorney general with the\nintent that they be used to fully offset costs in connection with the\nenforcement of this section and to promote the positive mental health outcomes\nof the children of Massachusetts.\n\n(k) If any provision of this section, or any application of such provision to\nany person or circumstance, is held to be unconstitutional, the remainder of\nthis section and the application of this section to any other person or\ncircumstance shall not be affected.\n\nCopyright (C) 2025 State Net  \n  \n---\n\n",
      "latest_version": true
    }
  ]
}