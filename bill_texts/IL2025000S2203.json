{
  "bill_id": "IL2025000S2203",
  "source_url": "http://custom.statenet.com/public/resources.cgi?id=ID:bill:IL2025000S2203&cuiq=93d84396-c63b-526a-b152-38b7f79b4cfd&client_md=e4f6fea4-27b4-5d41-b7d3-766fe52569f0",
  "versions": [
    {
      "date": "02/07/2025",
      "label": "Introduced",
      "url": "https://custom.statenet.com/public/resources.cgi?mode=show_text&id=ID:bill:IL2025000S2203&verid=IL2025000S2203_20250207_0_I&",
      "raw_html": "<html>\n<head>\n<title>Bill Resource</title>\n\n<!--   <link href=\"https://custom.statenet.com/network/Common/css/extregtext.css\" rel=\"stylesheet\" type=\"text/css\" />-->\n   <link href=\"https://custom.statenet.com/network/Common/css/xmltext-2.0.css\" rel=\"stylesheet\" type=\"text/css\" />\n   <link href=\"https://custom.statenet.com/network/Common/css/additional-text.css\" rel=\"stylesheet\" type=\"text/css\" />\n\n\t<style type=\"text/css\">\n<!--\n\ntd, body {\n     background-color: white;\n\tfont-family: Verdana, Arial, Helvetica, sans-serif;\n\tfont-size: 12px;\n}\n\n.resourceContainer {\n   border: 1px solid black;\n}\n-->\n</style>\n</head>\n<body>\n\n    <div style=\"width: 750px; margin: auto\">\n       <div style=\"font-size: .8em;margin-bottom: 10px\"><table width=\"100%\"><tr><td align=\"left\" style=\"font-size: .8em;\"><div>The following has special meaning:</div>\n<div><u class=\"amendmentInsertedText\">green underline denotes added text</u></div>\n<div><strike class=\"amendmentDeletedText\">red struck out text denotes deleted text</strike></div></td> <td align=\"right\"><a href=\"https://www.lexisnexis.com/statenet/\"><img alt=\"Powered by State Net\" src=\"https://custom.statenet.com/network/poweredby.gif\" /></a></td></tr></table></div><table id=\"text-identifier\"><tr><td class=\"key\">2025 IL S 2203</td> <td><table><tr><td class=\"label\">Author:</td> <td>Guzman</td></tr> <tr><td class=\"label\">Version:</td> <td>Introduced</td></tr> <tr><td class=\"label\">Version Date:</td> <td>02/07/2025</td></tr></table></td></tr></table><div class=\"documentBody\">\n  <a name=\"head_document_section\"></a><div class=\"head\">\n   <p class=\"center\">\n    <b>104TH GENERAL ASSEMBLY</b>\n   </p>\n   <p class=\"center\">\n    <b>State of Illinois</b>\n   </p>\n   <p class=\"center\">\n    <b>2025 and 2026</b>\n   </p>\n   <p class=\"center\">\n    <b>SB2203</b>\n   </p>\n   <p class=\"left\">Introduced 2/7/2025, by Sen. Graciela Guzm&aacute;n</p>\n   <p class=\"left\">\n    <b>SYNOPSIS AS INTRODUCED:</b>\n   </p>\n   <p class=\"left\">New Act</p>\n   <p class=\"left\">815 ILCS 505/2HHHH new</p>\n   <p class=\"indent\">Creates the Preventing Algorithmic Discrimination Act. Provides that, on or before January 1, 2027, and annually thereafter, a deployer of an automated decision tool shall perform an impact assessment for any automated decision tool the deployer uses or designs, codes, or produces that includes specified information. Provides that a deployer shall, at or before the time an automated decision tool is used to make a consequential decision, notify any natural person who is the subject of the consequential decision that an automated decision tool is being used to make, or be a controlling factor in making, the consequential decision and provide specified information. Provides that a deployer shall establish, document, implement, and maintain a governance program that contains reasonable administrative and technical safeguards to map, measure, manage, and govern the reasonably foreseeable risks of algorithmic discrimination associated with the use or intended use of an automated decision tool. Provides that, within 60 days after completing an impact assessment required by the Act, a deployer shall provide the impact assessment to the Attorney General. Amends the Consumer Fraud and Deceptive Business Practices Act to make conforming changes.</p>\n   <p class=\"center\">\n    <b>A BILL FOR</b>\n   </p>\n  </div>\n  <a name=\"title_document_section\"></a><div class=\"title\">\n   <p class=\"indent\">AN ACT concerning business.</p>\n  </div>\n  <a name=\"text_document_section\"></a><div class=\"text\">\n   <span>\n    <p class=\"indent\">\n     <b>Be it enacted by the People of the State of Illinois, represented in the General Assembly:</b>\n    </p>\n   </span>\n   <p class=\"indent\">Section 1. Short title. This Act may be cited as the Preventing Algorithmic Discrimination Act.</p>\n   <p class=\"indent\">Section 5. Definitions. As used in this Act:</p>\n   <p class=\"indent\">&quot;Algorithmic discrimination&quot; means the condition in which an automated decision tool contributes to unjustified differential treatment or impacts disfavoring people based on their actual or perceived race, color, ethnicity, sex, religion, age, national origin, limited English proficiency, disability, veteran status, genetic information, reproductive health, or any other classification protected by State law. &quot;Algorithmic discrimination&quot; does not include:</p>\n   <p class=\"indent\">(1) the offer, license, or use of a high-risk artificial intelligence system by a deployer for the sole purpose of:</p>\n   <p class=\"indent\">(A) the deployer&#39;s self-testing to identify, mitigate, or prevent discrimination or otherwise ensure compliance with state and federal law; or</p>\n   <p class=\"indent\">(B) expanding an applicant, customer, or participant pool to increase diversity or redress historical discrimination; or</p>\n   <p class=\"indent\">(2) an act or omission by or on behalf of a private club or other establishment that is not in fact open to the public, as set forth in the Civil Rights Act of 1964.</p>\n   <p class=\"indent\">&quot;Artificial intelligence system&quot; means a machine-based system that, for explicit or implicit objectives, infers, from the input it receives, how to generate outputs such as predictions, content, recommendations, or decisions that can influence physical or virtual environments. &quot;Artificial intelligence system&quot; includes a generative artificial intelligence system. For the purposes of this definition, &quot;generative artificial intelligence system&quot; means an automated computing system that, when prompted with human prompts, descriptions, or queries, can produce outputs that simulate human-produced content, including, but not limited to:</p>\n   <p class=\"indent\">(1) textual outputs, such as short answers, essays, poetry, or longer compositions or answers;</p>\n   <p class=\"indent\">(2) image outputs, such as fine art, photographs, conceptual art, diagrams, and other images;</p>\n   <p class=\"indent\">(3) multimedia outputs, such as audio or video in the form of compositions, songs, or short-form or long-form audio or video; and</p>\n   <p class=\"indent\">(4) other content that would otherwise be produced by human means</p>\n   <p class=\"indent\">&quot;Automated decision tool&quot; means a system or service that uses artificial intelligence and has been specifically developed and marketed to, or specifically modified to, make, or be a controlling factor in making, consequential decisions.</p>\n   <p class=\"indent\">&quot;Consequential decision&quot; means a decision or judgment that has a legal, material, or similarly significant effect on an individual&#39;s life relating to the impact of, access to, or the cost, terms, or availability of, any of the following:</p>\n   <p class=\"indent\">(1) employment, worker management, or self-employment, including, but not limited to, all of the following:</p>\n   <p class=\"indent\">(A) pay or promotion;</p>\n   <p class=\"indent\">(B) hiring or termination; and</p>\n   <p class=\"indent\">(C) automated task allocation;</p>\n   <p class=\"indent\">(2) education and vocational training, including, but not limited to, all of the following:</p>\n   <p class=\"indent\">(A) assessment, including, but not limited to, detecting student cheating or plagiarism;</p>\n   <p class=\"indent\">(B) accreditation;</p>\n   <p class=\"indent\">(C) certification;</p>\n   <p class=\"indent\">(D) admissions; and</p>\n   <p class=\"indent\">(E) financial aid or scholarships;</p>\n   <p class=\"indent\">(3) housing or lodging, including rental or short-term housing or lodging;</p>\n   <p class=\"indent\">(4) essential utilities, including electricity, heat, water, Internet or telecommunications access, or transportation;</p>\n   <p class=\"indent\">(5) family planning, including adoption services or reproductive services, as well as assessments related to child protective services;</p>\n   <p class=\"indent\">(6) healthcare or health insurance, including mental health care, dental, or vision;</p>\n   <p class=\"indent\">(7) financial services, including a financial service provided by a mortgage company, mortgage broker, or creditor;</p>\n   <p class=\"indent\">(8) the criminal justice system, including, but not limited to, all of the following:</p>\n   <p class=\"indent\">(A) risk assessments for pretrial hearings;</p>\n   <p class=\"indent\">(B) sentencing; and</p>\n   <p class=\"indent\">(C) parole;</p>\n   <p class=\"indent\">(9) legal services, including private arbitration or mediation;</p>\n   <p class=\"indent\">(10) voting; and</p>\n   <p class=\"indent\">(11) access to benefits or services or assignment of penalties.</p>\n   <p class=\"indent\">&quot;Deployer&quot; means a person, partnership, State or local government agency, or corporation that uses an automated decision tool to make a consequential decision.</p>\n   <p class=\"indent\">&quot;Impact assessment&quot; means a documented risk-based evaluation of an automated decision tool that meets the criteria of Section 10.</p>\n   <p class=\"indent\">&quot;Sex&quot; includes pregnancy, childbirth, and related conditions, gender identity, intersex status, and sexual orientation.</p>\n   <p class=\"indent\">&quot;Significant update&quot; means a new version, new release, or other update to an automated decision tool that includes changes to its use case, key functionality, or expected outcomes.</p>\n   <p class=\"indent\">Section 10. Impact assessment.</p>\n   <p class=\"indent\">(a) On or before January 1, 2027, and annually thereafter, a deployer of an automated decision tool shall perform an impact assessment for any automated decision tool the deployer uses that includes all of the following:</p>\n   <p class=\"indent\">(1) a statement of the purpose of the automated decision tool and its intended benefits, uses, and deployment contexts;</p>\n   <p class=\"indent\">(2) a description of the automated decision tool&#39;s outputs and how they are used to make, or be a controlling factor in making, a consequential decision;</p>\n   <p class=\"indent\">(3) a summary of the type of data collected from natural persons and processed by the automated decision tool when it is used to make, or be a controlling factor in making, a consequential decision;</p>\n   <p class=\"indent\">(4) an analysis of potential adverse impacts on the basis of sex, race, color, ethnicity, religion, age, national origin, limited English proficiency, disability, veteran status, or genetic information from the deployer&#39;s use of the automated decision tool;</p>\n   <p class=\"indent\">(5) a description of the safeguards implemented, or that will be implemented, by the deployer to address any reasonably foreseeable risks of algorithmic discrimination arising from the use of the automated decision tool known to the deployer at the time of the impact assessment;</p>\n   <p class=\"indent\">(6) a description of how the automated decision tool will be used by a natural person, or monitored when it is used, to make, or be a controlling factor in making, a consequential decision; and</p>\n   <p class=\"indent\">(7) a description of how the automated decision tool has been or will be evaluated for validity or relevance.</p>\n   <p class=\"indent\">(b) A deployer shall, in addition to the impact assessment required by subsection (a), perform, as soon as feasible, an impact assessment with respect to any significant update.</p>\n   <p class=\"indent\">(c) This Section does not apply to a deployer with fewer than 25 employees unless, as of the end of the prior calendar year, the deployer deployed an automated decision tool that impacted more than 999 people per year.</p>\n   <p class=\"indent\">Section 15. Notification and accommodations.</p>\n   <p class=\"indent\">(a) A deployer shall, at or before the time an automated decision tool is used to make a consequential decision, notify any natural person who is the subject of the consequential decision that an automated decision tool is being used to make, or be a controlling factor in making, the consequential decision. A deployer shall provide to a natural person notified under this subsection all of the following:</p>\n   <p class=\"indent\">(1) a statement of the purpose of the automated decision tool;</p>\n   <p class=\"indent\">(2) the contact information for the deployer; and</p>\n   <p class=\"indent\">(3) a plain language description of the automated decision tool that includes a description of any human components and how any automated component is used to inform a consequential decision.</p>\n   <p class=\"indent\">(b) If a consequential decision is made solely based on the output of an automated decision tool, a deployer shall, if technically feasible, accommodate a natural person&#39;s request to not be subject to the automated decision tool and to be subject to an alternative selection process or accommodation. After a request is made under this subsection, a deployer may reasonably request, collect, and process information from a natural person for the purposes of identifying the person and the associated consequential decision. If the person does not provide that information, the deployer shall not be obligated to provide an alternative selection process or accommodation.</p>\n   <p class=\"indent\">Section 20. Governance program.</p>\n   <p class=\"indent\">(a) A deployer shall establish, document, implement, and maintain a governance program that contains reasonable administrative and technical safeguards to map, measure, manage, and govern the reasonably foreseeable risks of algorithmic discrimination associated with the use or intended use of an automated decision tool. The safeguards required by this subsection shall be appropriate to all of the following:</p>\n   <p class=\"indent\">(1) the use or intended use of the automated decision tool;</p>\n   <p class=\"indent\">(2) the deployer&#39;s role as a deployer;</p>\n   <p class=\"indent\">(3) the size, complexity, and resources of the deployer;</p>\n   <p class=\"indent\">(4) the nature, context, and scope of the activities of the deployer in connection with the automated decision tool; and</p>\n   <p class=\"indent\">(5) the technical feasibility and cost of available tools, assessments, and other means used by a deployer to map, measure, manage, and govern the risks associated with an automated decision tool.</p>\n   <p class=\"indent\">(b) The governance program required by this Section shall be designed to do all of the following:</p>\n   <p class=\"indent\">(1) identify and implement safeguards to address reasonably foreseeable risks of algorithmic discrimination resulting from the use or intended use of an automated decision tool;</p>\n   <p class=\"indent\">(2) if established by a deployer, provide for the performance of impact assessments as required by Section 10;</p>\n   <p class=\"indent\">(3) conduct an annual and comprehensive review of policies, practices, and procedures to ensure compliance with this Act;</p>\n   <p class=\"indent\">(4) maintain for 2 years after completion the results of an impact assessment; and</p>\n   <p class=\"indent\">(5) evaluate and make reasonable adjustments to administrative and technical safeguards in light of material changes in technology, the risks associated with the automated decision tool, the state of technical standards, and changes in business arrangements or operations of the deployer.</p>\n   <p class=\"indent\">(c) A deployer shall designate at least one employee to be responsible for overseeing and maintaining the governance program and compliance with this Act. An employee designated under this subsection shall have the authority to assert to the employee&#39;s employer a good faith belief that the design, production, or use of an automated decision tool fails to comply with the requirements of this Act. An employer of an employee designated under this subsection shall conduct a prompt and complete assessment of any compliance issue raised by that employee.</p>\n   <p class=\"indent\">(d) This Section does not apply to a deployer with fewer than 25 employees unless, as of the end of the prior calendar year, the deployer deployed an automated decision tool that impacted more than 999 people per year.</p>\n   <p class=\"indent\">Section 25. Public statement of policy. A deployer shall make publicly available, in a readily accessible manner, a clear policy that provides a summary of both of the following:</p>\n   <p class=\"indent\">(1) the types of automated decision tools currently in use or made available to others by the deployer; and</p>\n   <p class=\"indent\">(2) how the deployer manages the reasonably foreseeable risks of algorithmic discrimination that may arise from the use of the automated decision tools it currently uses or makes available to others.</p>\n   <p class=\"indent\">Section 30. Algorithmic discrimination.</p>\n   <p class=\"indent\">(a) A deployer shall not use an automated decision tool that results in algorithmic discrimination.</p>\n   <p class=\"indent\">(b) On and after January 1, 2028, a person may bring a civil action against a deployer for violation of this Section. In an action brought under this subsection, the plaintiff shall have the burden of proof to demonstrate that the deployer&#39;s use of the automated decision tool resulted in algorithmic discrimination that caused actual harm to the person bringing the civil action.</p>\n   <p class=\"indent\">(c) In addition to any other remedy at law, a deployer that violates this Section shall be liable to a prevailing plaintiff for any of the following:</p>\n   <p class=\"indent\">(1) compensatory damages;</p>\n   <p class=\"indent\">(2) declaratory relief; and</p>\n   <p class=\"indent\">(3) reasonable attorney&#39;s fees and costs.</p>\n   <p class=\"indent\">Section 35. Impact assessment.</p>\n   <p class=\"indent\">(a) Within 60 days after completing an impact assessment required by this Act, a deployer shall provide the impact assessment to the Attorney General.</p>\n   <p class=\"indent\">(b) A deployer who knowingly violates this Section shall be liable for an administrative fine of not more than $10,000 per violation in an administrative enforcement action brought by the Attorney General. Each day on which an automated decision tool is used for which an impact assessment has not been submitted as required under this Section shall give rise to a distinct violation of this Section.</p>\n   <p class=\"indent\">(c) The Attorney General may share impact assessments with other State entities as appropriate.</p>\n   <p class=\"indent\">Section 40. Enforcement. A violation of this Act constitutes an unlawful practice under the Consumer Fraud and Deceptive Business Practices Act. All remedies, penalties, and authority granted to the Attorney General by the Consumer Fraud and Deceptive Business Practices Act shall be available to him or her for the enforcement of this Act.</p>\n   <p class=\"indent\">Section 95. The Consumer Fraud and Deceptive Business Practices Act is amended by adding Section 2HHHH as follows:</p>\n   <p class=\"indent\">(815 ILCS 505/2HHHH new)</p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">Sec. 2HHHH. Violations of the Preventing Algorithmic Discrimination Act. A person who violates the Preventing Algorithmic Discrimination Act commits an unlawful practice within the meaning of this Act.</u>\n   </p>\n  </div>\n </div>\n    </div>\t\n<table cellpadding=0 cellspacing=0 width=\"100%\">\n   <tr>\n      <td>\n          Copyright &copy; 2025 State Net\n      </td>\n<BR>\n<!--???MOVED INTO resources.cgi      <td align=\"right\">\n          <img src=\"https://custom.statenet.com/network/poweredby.gif\" alt=\"Powered by State Net\">\n      </td>-->\n\n    </tr>\n</table>\n</body></html>\n",
      "markdown": "The following has special meaning: _green underline denotes added text_ ~~red struck out text denotes deleted text~~ | [![Powered by State Net](https://custom.statenet.com/network/poweredby.gif)](https://www.lexisnexis.com/statenet/)  \n---|---  \n  \n2025 IL S 2203 | | Author: | Guzman  \n---|---  \nVersion: | Introduced  \nVersion Date: | 02/07/2025  \n  \n**104TH GENERAL ASSEMBLY**\n\n**State of Illinois**\n\n**2025 and 2026**\n\n**SB2203**\n\nIntroduced 2/7/2025, by Sen. Graciela Guzman\n\n**SYNOPSIS AS INTRODUCED:**\n\nNew Act\n\n815 ILCS 505/2HHHH new\n\nCreates the Preventing Algorithmic Discrimination Act. Provides that, on or\nbefore January 1, 2027, and annually thereafter, a deployer of an automated\ndecision tool shall perform an impact assessment for any automated decision\ntool the deployer uses or designs, codes, or produces that includes specified\ninformation. Provides that a deployer shall, at or before the time an\nautomated decision tool is used to make a consequential decision, notify any\nnatural person who is the subject of the consequential decision that an\nautomated decision tool is being used to make, or be a controlling factor in\nmaking, the consequential decision and provide specified information. Provides\nthat a deployer shall establish, document, implement, and maintain a\ngovernance program that contains reasonable administrative and technical\nsafeguards to map, measure, manage, and govern the reasonably foreseeable\nrisks of algorithmic discrimination associated with the use or intended use of\nan automated decision tool. Provides that, within 60 days after completing an\nimpact assessment required by the Act, a deployer shall provide the impact\nassessment to the Attorney General. Amends the Consumer Fraud and Deceptive\nBusiness Practices Act to make conforming changes.\n\n**A BILL FOR**\n\nAN ACT concerning business.\n\n**Be it enacted by the People of the State of Illinois, represented in the\nGeneral Assembly:**\n\nSection 1. Short title. This Act may be cited as the Preventing Algorithmic\nDiscrimination Act.\n\nSection 5. Definitions. As used in this Act:\n\n\"Algorithmic discrimination\" means the condition in which an automated\ndecision tool contributes to unjustified differential treatment or impacts\ndisfavoring people based on their actual or perceived race, color, ethnicity,\nsex, religion, age, national origin, limited English proficiency, disability,\nveteran status, genetic information, reproductive health, or any other\nclassification protected by State law. \"Algorithmic discrimination\" does not\ninclude:\n\n(1) the offer, license, or use of a high-risk artificial intelligence system\nby a deployer for the sole purpose of:\n\n(A) the deployer's self-testing to identify, mitigate, or prevent\ndiscrimination or otherwise ensure compliance with state and federal law; or\n\n(B) expanding an applicant, customer, or participant pool to increase\ndiversity or redress historical discrimination; or\n\n(2) an act or omission by or on behalf of a private club or other\nestablishment that is not in fact open to the public, as set forth in the\nCivil Rights Act of 1964.\n\n\"Artificial intelligence system\" means a machine-based system that, for\nexplicit or implicit objectives, infers, from the input it receives, how to\ngenerate outputs such as predictions, content, recommendations, or decisions\nthat can influence physical or virtual environments. \"Artificial intelligence\nsystem\" includes a generative artificial intelligence system. For the purposes\nof this definition, \"generative artificial intelligence system\" means an\nautomated computing system that, when prompted with human prompts,\ndescriptions, or queries, can produce outputs that simulate human-produced\ncontent, including, but not limited to:\n\n(1) textual outputs, such as short answers, essays, poetry, or longer\ncompositions or answers;\n\n(2) image outputs, such as fine art, photographs, conceptual art, diagrams,\nand other images;\n\n(3) multimedia outputs, such as audio or video in the form of compositions,\nsongs, or short-form or long-form audio or video; and\n\n(4) other content that would otherwise be produced by human means\n\n\"Automated decision tool\" means a system or service that uses artificial\nintelligence and has been specifically developed and marketed to, or\nspecifically modified to, make, or be a controlling factor in making,\nconsequential decisions.\n\n\"Consequential decision\" means a decision or judgment that has a legal,\nmaterial, or similarly significant effect on an individual's life relating to\nthe impact of, access to, or the cost, terms, or availability of, any of the\nfollowing:\n\n(1) employment, worker management, or self-employment, including, but not\nlimited to, all of the following:\n\n(A) pay or promotion;\n\n(B) hiring or termination; and\n\n(C) automated task allocation;\n\n(2) education and vocational training, including, but not limited to, all of\nthe following:\n\n(A) assessment, including, but not limited to, detecting student cheating or\nplagiarism;\n\n(B) accreditation;\n\n(C) certification;\n\n(D) admissions; and\n\n(E) financial aid or scholarships;\n\n(3) housing or lodging, including rental or short-term housing or lodging;\n\n(4) essential utilities, including electricity, heat, water, Internet or\ntelecommunications access, or transportation;\n\n(5) family planning, including adoption services or reproductive services, as\nwell as assessments related to child protective services;\n\n(6) healthcare or health insurance, including mental health care, dental, or\nvision;\n\n(7) financial services, including a financial service provided by a mortgage\ncompany, mortgage broker, or creditor;\n\n(8) the criminal justice system, including, but not limited to, all of the\nfollowing:\n\n(A) risk assessments for pretrial hearings;\n\n(B) sentencing; and\n\n(C) parole;\n\n(9) legal services, including private arbitration or mediation;\n\n(10) voting; and\n\n(11) access to benefits or services or assignment of penalties.\n\n\"Deployer\" means a person, partnership, State or local government agency, or\ncorporation that uses an automated decision tool to make a consequential\ndecision.\n\n\"Impact assessment\" means a documented risk-based evaluation of an automated\ndecision tool that meets the criteria of Section 10.\n\n\"Sex\" includes pregnancy, childbirth, and related conditions, gender identity,\nintersex status, and sexual orientation.\n\n\"Significant update\" means a new version, new release, or other update to an\nautomated decision tool that includes changes to its use case, key\nfunctionality, or expected outcomes.\n\nSection 10. Impact assessment.\n\n(a) On or before January 1, 2027, and annually thereafter, a deployer of an\nautomated decision tool shall perform an impact assessment for any automated\ndecision tool the deployer uses that includes all of the following:\n\n(1) a statement of the purpose of the automated decision tool and its intended\nbenefits, uses, and deployment contexts;\n\n(2) a description of the automated decision tool's outputs and how they are\nused to make, or be a controlling factor in making, a consequential decision;\n\n(3) a summary of the type of data collected from natural persons and processed\nby the automated decision tool when it is used to make, or be a controlling\nfactor in making, a consequential decision;\n\n(4) an analysis of potential adverse impacts on the basis of sex, race, color,\nethnicity, religion, age, national origin, limited English proficiency,\ndisability, veteran status, or genetic information from the deployer's use of\nthe automated decision tool;\n\n(5) a description of the safeguards implemented, or that will be implemented,\nby the deployer to address any reasonably foreseeable risks of algorithmic\ndiscrimination arising from the use of the automated decision tool known to\nthe deployer at the time of the impact assessment;\n\n(6) a description of how the automated decision tool will be used by a natural\nperson, or monitored when it is used, to make, or be a controlling factor in\nmaking, a consequential decision; and\n\n(7) a description of how the automated decision tool has been or will be\nevaluated for validity or relevance.\n\n(b) A deployer shall, in addition to the impact assessment required by\nsubsection (a), perform, as soon as feasible, an impact assessment with\nrespect to any significant update.\n\n(c) This Section does not apply to a deployer with fewer than 25 employees\nunless, as of the end of the prior calendar year, the deployer deployed an\nautomated decision tool that impacted more than 999 people per year.\n\nSection 15. Notification and accommodations.\n\n(a) A deployer shall, at or before the time an automated decision tool is used\nto make a consequential decision, notify any natural person who is the subject\nof the consequential decision that an automated decision tool is being used to\nmake, or be a controlling factor in making, the consequential decision. A\ndeployer shall provide to a natural person notified under this subsection all\nof the following:\n\n(1) a statement of the purpose of the automated decision tool;\n\n(2) the contact information for the deployer; and\n\n(3) a plain language description of the automated decision tool that includes\na description of any human components and how any automated component is used\nto inform a consequential decision.\n\n(b) If a consequential decision is made solely based on the output of an\nautomated decision tool, a deployer shall, if technically feasible,\naccommodate a natural person's request to not be subject to the automated\ndecision tool and to be subject to an alternative selection process or\naccommodation. After a request is made under this subsection, a deployer may\nreasonably request, collect, and process information from a natural person for\nthe purposes of identifying the person and the associated consequential\ndecision. If the person does not provide that information, the deployer shall\nnot be obligated to provide an alternative selection process or accommodation.\n\nSection 20. Governance program.\n\n(a) A deployer shall establish, document, implement, and maintain a governance\nprogram that contains reasonable administrative and technical safeguards to\nmap, measure, manage, and govern the reasonably foreseeable risks of\nalgorithmic discrimination associated with the use or intended use of an\nautomated decision tool. The safeguards required by this subsection shall be\nappropriate to all of the following:\n\n(1) the use or intended use of the automated decision tool;\n\n(2) the deployer's role as a deployer;\n\n(3) the size, complexity, and resources of the deployer;\n\n(4) the nature, context, and scope of the activities of the deployer in\nconnection with the automated decision tool; and\n\n(5) the technical feasibility and cost of available tools, assessments, and\nother means used by a deployer to map, measure, manage, and govern the risks\nassociated with an automated decision tool.\n\n(b) The governance program required by this Section shall be designed to do\nall of the following:\n\n(1) identify and implement safeguards to address reasonably foreseeable risks\nof algorithmic discrimination resulting from the use or intended use of an\nautomated decision tool;\n\n(2) if established by a deployer, provide for the performance of impact\nassessments as required by Section 10;\n\n(3) conduct an annual and comprehensive review of policies, practices, and\nprocedures to ensure compliance with this Act;\n\n(4) maintain for 2 years after completion the results of an impact assessment;\nand\n\n(5) evaluate and make reasonable adjustments to administrative and technical\nsafeguards in light of material changes in technology, the risks associated\nwith the automated decision tool, the state of technical standards, and\nchanges in business arrangements or operations of the deployer.\n\n(c) A deployer shall designate at least one employee to be responsible for\noverseeing and maintaining the governance program and compliance with this\nAct. An employee designated under this subsection shall have the authority to\nassert to the employee's employer a good faith belief that the design,\nproduction, or use of an automated decision tool fails to comply with the\nrequirements of this Act. An employer of an employee designated under this\nsubsection shall conduct a prompt and complete assessment of any compliance\nissue raised by that employee.\n\n(d) This Section does not apply to a deployer with fewer than 25 employees\nunless, as of the end of the prior calendar year, the deployer deployed an\nautomated decision tool that impacted more than 999 people per year.\n\nSection 25. Public statement of policy. A deployer shall make publicly\navailable, in a readily accessible manner, a clear policy that provides a\nsummary of both of the following:\n\n(1) the types of automated decision tools currently in use or made available\nto others by the deployer; and\n\n(2) how the deployer manages the reasonably foreseeable risks of algorithmic\ndiscrimination that may arise from the use of the automated decision tools it\ncurrently uses or makes available to others.\n\nSection 30. Algorithmic discrimination.\n\n(a) A deployer shall not use an automated decision tool that results in\nalgorithmic discrimination.\n\n(b) On and after January 1, 2028, a person may bring a civil action against a\ndeployer for violation of this Section. In an action brought under this\nsubsection, the plaintiff shall have the burden of proof to demonstrate that\nthe deployer's use of the automated decision tool resulted in algorithmic\ndiscrimination that caused actual harm to the person bringing the civil\naction.\n\n(c) In addition to any other remedy at law, a deployer that violates this\nSection shall be liable to a prevailing plaintiff for any of the following:\n\n(1) compensatory damages;\n\n(2) declaratory relief; and\n\n(3) reasonable attorney's fees and costs.\n\nSection 35. Impact assessment.\n\n(a) Within 60 days after completing an impact assessment required by this Act,\na deployer shall provide the impact assessment to the Attorney General.\n\n(b) A deployer who knowingly violates this Section shall be liable for an\nadministrative fine of not more than $10,000 per violation in an\nadministrative enforcement action brought by the Attorney General. Each day on\nwhich an automated decision tool is used for which an impact assessment has\nnot been submitted as required under this Section shall give rise to a\ndistinct violation of this Section.\n\n(c) The Attorney General may share impact assessments with other State\nentities as appropriate.\n\nSection 40. Enforcement. A violation of this Act constitutes an unlawful\npractice under the Consumer Fraud and Deceptive Business Practices Act. All\nremedies, penalties, and authority granted to the Attorney General by the\nConsumer Fraud and Deceptive Business Practices Act shall be available to him\nor her for the enforcement of this Act.\n\nSection 95. The Consumer Fraud and Deceptive Business Practices Act is amended\nby adding Section 2HHHH as follows:\n\n(815 ILCS 505/2HHHH new)\n\n_Sec. 2HHHH. Violations of the Preventing Algorithmic Discrimination Act. A\nperson who violates the Preventing Algorithmic Discrimination Act commits an\nunlawful practice within the meaning of this Act._\n\nCopyright (C) 2025 State Net  \n  \n---\n\n",
      "latest_version": true
    }
  ]
}