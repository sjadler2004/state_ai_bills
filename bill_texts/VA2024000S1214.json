{
  "bill_id": "VA2024000S1214",
  "source_url": "http://custom.statenet.com/public/resources.cgi?id=ID:bill:VA2024000S1214&cuiq=93d84396-c63b-526a-b152-38b7f79b4cfd&client_md=e4f6fea4-27b4-5d41-b7d3-766fe52569f0",
  "versions": [
    {
      "date": "01/08/2025",
      "label": "Introduced",
      "url": "https://custom.statenet.com/public/resources.cgi?mode=show_text&id=ID:bill:VA2024000S1214&verid=VA2024000S1214_20250108_0_I&",
      "raw_html": "<html>\n<head>\n<title>Bill Resource</title>\n\n<!--   <link href=\"https://custom.statenet.com/network/Common/css/extregtext.css\" rel=\"stylesheet\" type=\"text/css\" />-->\n   <link href=\"https://custom.statenet.com/network/Common/css/xmltext-2.0.css\" rel=\"stylesheet\" type=\"text/css\" />\n   <link href=\"https://custom.statenet.com/network/Common/css/additional-text.css\" rel=\"stylesheet\" type=\"text/css\" />\n\n\t<style type=\"text/css\">\n<!--\n\ntd, body {\n     background-color: white;\n\tfont-family: Verdana, Arial, Helvetica, sans-serif;\n\tfont-size: 12px;\n}\n\n.resourceContainer {\n   border: 1px solid black;\n}\n-->\n</style>\n</head>\n<body>\n\n    <div style=\"width: 750px; margin: auto\">\n       <div style=\"font-size: .8em;margin-bottom: 10px\"><table width=\"100%\"><tr><td align=\"left\" style=\"font-size: .8em;\"><div>The following has special meaning:</div>\n<div><u class=\"amendmentInsertedText\">green underline denotes added text</u></div>\n<div><strike class=\"amendmentDeletedText\">red struck out text denotes deleted text</strike></div></td> <td align=\"right\"><a href=\"https://www.lexisnexis.com/statenet/\"><img alt=\"Powered by State Net\" src=\"https://custom.statenet.com/network/poweredby.gif\" /></a></td></tr></table></div><table id=\"text-identifier\"><tr><td class=\"key\">2024 VA S 1214</td> <td><table><tr><td class=\"label\">Author:</td> <td>Aird</td></tr> <tr><td class=\"label\">Version:</td> <td>Introduced</td></tr> <tr><td class=\"label\">Version Date:</td> <td>01/08/2025</td></tr></table></td></tr></table><div class=\"documentBody\">\n  <a name=\"head_document_section\"></a><div class=\"head\">\n   <p class=\"center\">\n    <b>SENATE BILL NO. 1214</b>\n   </p>\n   <p class=\"center\">Offered January 8, 2025</p>\n   <p class=\"center\">Prefiled January 8, 2025</p>\n  </div>\n  <a name=\"code_document_section\"></a><div class=\"code\">\n   <p class=\"indent\">\n    <i>A BILL to amend and reenact &sect; 2.2-2007 of the Code of Virginia and to amend the Code of Virginia by adding in Title 2.2 a chapter numbered 55.6, consisting of sections numbered 2.2-5517 through 2.2-5522, relating to high-risk artificial intelligence; development, deployment, and use by public bodies; work group; report.</i>\n   </p>\n   <p class=\"center\">Patron--Aird</p>\n   <p class=\"center\">Referred to Committee on General Laws and Technology</p>\n  </div>\n  <a name=\"text_document_section\"></a><div class=\"text\">\n   <span>\n    <p class=\"indent\">\n     <b>Be it enacted by the General Assembly of Virginia:</b>\n    </p>\n   </span>\n   <p class=\"indent\">\n    <b>1. That &sect; 2.2-2007 of the Code of Virginia is amended and reenacted and that the Code of Virginia is amended by adding in Title 2.2 a chapter numbered 55.6, consisting of sections numbered 2.2-5517 through 2.2-5522, as follows:</b>\n   </p>\n   <p class=\"indent\">\n    <b>&sect; 2.2-2007. Powers of the CIO.</b>\n   </p>\n   <p class=\"indent\">A. The CIO shall promulgate regulations necessary or incidental to the performance of duties or execution of powers conferred under this chapter. The CIO shall also develop policies, standards, and guidelines for the planning, budgeting, procurement, development, maintenance, security, and operations of information technology for executive branch agencies. Such policies, standards, and guidelines shall include those necessary to:</p>\n   <p class=\"indent\">1. Support state and local government exchange, acquisition, storage, use, sharing, and distribution of data and related technologies.</p>\n   <p class=\"indent\">2. Support the development of electronic transactions<u class=\"amendmentInsertedText\">,</u> including the use of electronic signatures as provided in &sect; 59.1-496.</p>\n   <p class=\"indent\">3. Support a unified approach to information technology across the totality of state government, thereby assuring that the citizens and businesses of the Commonwealth receive the greatest possible security, value, and convenience from investments made in technology.</p>\n   <p class=\"indent\">4. Ensure that the costs of information technology systems, products, data, and services are contained through the shared use of existing or planned equipment, data, or services.</p>\n   <p class=\"indent\">5. Provide for the effective management of information technology investments through their entire life cycles, including identification, business case development, selection, procurement, implementation, operation, performance evaluation, and enhancement or retirement. Such policies, standards, and guidelines shall include, at a minimum, the periodic review by the CIO of agency Commonwealth information technology projects.</p>\n   <p class=\"indent\">6. Establish an Information Technology Investment Management Standard based on acceptable technology investment methods to ensure that all executive branch agency technology expenditures are an integral part of the Commonwealth&#39;s performance management system, produce value for the agency and the Commonwealth, and are aligned with (i) agency strategic plans, (ii) the Governor&#39;s policy objectives, and (iii) the long-term objectives of the Council on Virginia&#39;s Future.</p>\n   <p class=\"indent\">B. In addition to other such duties as the Secretary may assign, the CIO shall:</p>\n   <p class=\"indent\">1. Oversee and administer the Virginia Technology Infrastructure Fund created pursuant to &sect; 2.2-2023.</p>\n   <p class=\"indent\">2. Report annually to the Governor, the Secretary, and the Joint Commission on Technology and Science created pursuant to &sect; 30-85 on the use and application of information technology by executive branch agencies to increase economic efficiency, citizen convenience, and public access to state government.</p>\n   <p class=\"indent\">3. Prepare annually a report for submission to the Secretary, the Information Technology Advisory Council, and the Joint Commission on Technology and Science on a prioritized list of Recommended Technology Investment Projects (RTIP Report) based upon major information technology projects submitted for business case approval pursuant to this chapter. As part of the RTIP Report, the CIO shall develop and regularly update a methodology for prioritizing projects based upon the allocation of points to defined criteria. The criteria and their definitions shall be presented in the RTIP Report. For each project recommended for funding in the RTIP Report, the CIO shall indicate the number of points and how they were awarded. For each listed project, the CIO shall also report (i) all projected costs of ongoing operations and maintenance activities of the project for the next three biennia following project implementation; (ii) a justification and description for each project baseline change; and (iii) whether the project fails to incorporate existing standards for the maintenance, exchange, and security of data. This report shall also include trends in current projected information technology spending by executive branch agencies and secretariats, including spending on projects, operations and maintenance, and payments to VITA. Agencies shall provide all project and cost information required to complete the RTIP Report to the CIO prior to May 31 immediately preceding any budget biennium in which the project appears in the Governor&#39;s budget bill.</p>\n   <p class=\"indent\">4. Provide oversight for executive branch agency efforts to modernize the planning, development, implementation, improvement, operations and maintenance, and retirement of Commonwealth information technology, including oversight for the selection, development and management of enterprise information technology.</p>\n   <p class=\"indent\">5. Develop statewide technical and data standards and specifications for information technology and related systems, including (i) the efficient exchange of electronic information and technology, including infrastructure, between the public and private sectors in the Commonwealth and (ii) the utilization of nationally recognized technical and data standards for health information technology systems or software purchased by an executive branch agency.</p>\n   <p class=\"indent\">6. Direct the compilation and maintenance of an inventory of information technology, including but not limited to personnel, facilities, equipment, goods, and contracts for services.</p>\n   <p class=\"indent\">7. Provide for the centralized marketing, provision, leasing, and executing of licensing agreements for electronic access to public information and government services through the Internet, wireless devices, personal digital assistants, kiosks, or other such related media on terms and conditions as may be determined to be in the best interest of the Commonwealth. VITA may fix and collect fees and charges for (i) public information, media, and other incidental services furnished by it to any private individual or entity, notwithstanding the charges set forth in &sect; 2.2-3704, and (ii) such use and services it provides to any executive branch agency or local government. Nothing in this subdivision authorizing VITA to fix and collect fees for providing information services shall be construed to prevent access to the public records of any public body pursuant to the provisions of the Virginia Freedom of Information Act (&sect; 2.2-3700 et seq.). VITA is authorized, subject to the approval by the Secretary of Administration and any other affected Secretariat, to delegate the powers and responsibilities granted in this subdivision to any agency within the executive branch.</p>\n   <p class=\"indent\">8. Periodically evaluate the feasibility of outsourcing information technology resources and services, and outsource those resources and services that are feasible and beneficial to the Commonwealth.</p>\n   <p class=\"indent\">9. Have the authority to enter into and amend contracts, including contracts with one or more other public bodies, or public agencies or institutions or localities of the several states, of the United States or its territories, or the District of Columbia, for the provision of information technology services.</p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">10. Develop, publish, and maintain policies and procedures concerning the development, procurement, implementation, utilization, and ongoing assessment of systems that employ high-risk artificial intelligence systems, as defined in &sect; 2.2-5517, and are in use by public bodies, consistent with the provisions of Chapter 55.6 (&sect; 2.2-5517 et seq.). Such policies and procedures shall, at a minimum, (i) govern the procurement, implementation, and ongoing assessment of any such system by a public body; (ii) address and provide resources regarding data security and privacy issues that may arise from the development and deployment of high-risk artificial intelligence systems by public bodies; (iii) be sufficient to ensure that no such system results in any algorithmic discrimination, as defined in &sect; 2.2-5517; (iv) create guidelines for acceptable use policies for public bodies integrating high-risk artificial intelligence systems pursuant to &sect; 2.2-5520; and (v) require a public body to assess the likely impact of any such system before implementing such system and perform ongoing assessments of such system to ensure that no such system results in any such algorithmic discrimination, as defined in &sect; 2.2-5517. Such policies and procedures shall include a requirement that a high-risk artificial intelligence system compliance clause be included in procurement contracts for systems that use a high-risk artificial intelligence system for which negotiation or renegotiation is begun on or after July 1, 2026, requiring compliance with the provisions of Chapter 55.6 (&sect; 2.2-5517 et seq.) and any other applicable state law governing the development or deployment of high-risk artificial intelligence systems, as applicable.</u>\n   </p>\n   <p class=\"indent\">C. Consistent with &sect; 2.2-2012, the CIO may enter into public-private partnership contracts to finance or implement information technology programs and projects. The CIO may issue a request for information to seek out potential private partners interested in providing programs or projects pursuant to an agreement under this subsection. The compensation for such services shall be computed with reference to and paid from the increased revenue or cost savings attributable to the successful implementation of the program or project for the period specified in the contract. The CIO shall be responsible for reviewing and approving the programs and projects and the terms of contracts for same under this subsection. The CIO shall determine annually the total amount of increased revenue or cost savings attributable to the successful implementation of a program or project under this subsection and such amount shall be deposited in the Virginia Technology Infrastructure Fund created in &sect; 2.2-2023. The CIO is authorized to use moneys deposited in the Fund to pay private partners pursuant to the terms of contracts under this subsection. All moneys in excess of that required to be paid to private partners, as determined by the CIO, shall be reported to the Comptroller and retained in the Fund. The CIO shall prepare an annual report to the Governor, the Secretary, and General Assembly on all contracts under this subsection, describing each information technology program or project, its progress, revenue impact, and such other information as may be relevant.</p>\n   <p class=\"indent\">D. Executive branch agencies shall cooperate with VITA in identifying the development and operational requirements of proposed information technology systems, products, data, and services, including the proposed use, functionality, and capacity, and the total cost of acquisition, operation, and maintenance.</p>\n   <p class=\"center\">\n    <u class=\"amendmentInsertedText\">CHAPTER 55.6.</u>\n   </p>\n   <p class=\"center\">\n    <u class=\"amendmentInsertedText\">USE OF HIGH-RISK ARTIFICIAL INTELLIGENCE SYSTEMS.</u>\n   </p>\n   <p class=\"indent\">\n    <b>\n     <u class=\"amendmentInsertedText\">&sect; 2.2-5517. Definitions.</u>\n    </b>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">As used in this chapter, unless the context requires a different meaning:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Algorithmic discrimination&quot; means any discrimination that results in an unlawful differential treatment or impact that disfavors an individual or group of individuals on the basis of their actual or perceived age, color, disability, ethnicity, genetic information, limited proficiency in the English language, national origin, race, religion, reproductive health, sex, sexual orientation, veteran status, or other classification protected under state or federal law. &quot;Algorithmic discrimination&quot; does not include (i) the offer, license, or use of a high-risk artificial intelligence system by a developer, integrator, or deployer for the sole purpose of the developer&#39;s, integrator&#39;s, or deployer&#39;s self-testing to identify, mitigate, or prevent discrimination or otherwise ensure compliance with state and federal law or (ii) the expansion of an applicant, customer, or participant pool to increase diversity or redress historical discrimination.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Artificial intelligence&quot; means a set of technologies that enables machines to perform tasks under varying and unpredictable circumstances that typically require human oversight or intelligence, or that can learn from experience and improve performance when exposed to data set</u>\n    <strike class=\"amendmentDeletedText\">s</strike>\n    <u class=\"amendmentInsertedText\">.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Artificial intelligence system&quot; means any machine-based system that, for any explicit or implicit objective, infers from the inputs such system receives how to generate outputs, including content, decisions, predictions, and recommendations, that can influence physical or virtual environments.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Consequential decision&quot; means any decision that has a material legal, or similarly significant, effect on the provision or denial to any consumer of, or the cost or terms of, (i) education enrollment or an education opportunity, (ii) employment or an employment opportunity, (iii) a financial or lending service, (iv) an essential government service, (v) health care services, (vi) housing, (vii) insurance, or (viii) a legal service.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Consumer&quot; means a natural person acting only in an individual or household context. &quot;Consumer&quot; does not include a natural person acting in a commercial or employment context.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Deployer&quot; means any public body that deploys or uses a high-risk artificial intelligence system to make a consequential decision.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Developer&quot; means any public body that develops or intentionally and substantially modifies a high-risk artificial intelligence system that is offered, sold, leased, given, or otherwise provided to consumers in the Commonwealth.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Foundation model&quot; means a machine learning model that (i) is trained on broad data at scale, (ii) is designed for generality of output, and (iii) can be adapted to a wide range of distinctive tasks.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;General-purpose artificial intelligence model&quot; means any form of artificial intelligence system that (i) displays significant generality, (ii) is capable of competently performing a wide range of distinct tasks, and (iii) can be integrated into a variety of downstream applications or systems. &quot;General-purpose artificial intelligence model&quot; does not include any artificial intelligence model that is used for development, prototyping, or research activities before such artificial intelligence model is released on the market.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Generative artificial intelligence&quot; means artificial intelligence based on a foundation model that is capable of and used to produce synthetic digital content, including audio, images, text, and videos.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Generative artificial intelligence system&quot; means any artificial intelligence system or service that incorporates generative artificial intelligence.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;High-risk artificial intelligence system&quot; means any artificial intelligence system that is specifically intended to autonomously make, or be a substantial factor in making, a consequential decision. A system or service is not a &quot;high-risk artificial intelligence system&quot; if it is intended to (i) perform a narrow procedural task, (ii) improve the result of a previously completed human activity, (iii) detect decision-making patterns or deviations from prior decision-making patterns and is not meant to replace or influence the previously completed human assessment without sufficient human review, or (iv) perform a preparatory task to an assessment relevant to a consequential decision. There is a rebuttable presumption that &quot;high-risk artificial intelligence system&quot; does not include any of the following technologies:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">1. Anti-fraud technology that does not use facial recognition technology;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">2. Anti-malware technology;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">3. Anti-virus technology;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">4. Artificial intelligence-enabled video games;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">5. Calculators;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">6. Cybersecurity technology;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">7. Databases;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">8. Data storage;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">9. Firewall technology;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">10. Internet domain registration;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">11. Internet website loading;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">12. Networking;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">13. Spam and robocall filtering;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">14. Spell-checking technology;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">15. Spreadsheets;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">16. Web caching;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">17. Web hosting or any similar technology; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">18. Technology that communicates with consumers in natural language for the purpose of providing users with information, making referrals or recommendations, and answering questions and is subject to an accepted use policy that prohibits generating content that is discriminatory or harmful.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Integrator&quot; means a public body that knowingly integrates an artificial intelligence system into a software application and places such software application on the market or makes such software application available for public use. An &quot;integrator&quot; does not include a public body offering information technology infrastructure.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Intentional and substantial modification&quot; means any deliberate change made to (i) an artificial intelligence system that results in any new reasonably foreseeable risk of algorithmic discrimination or (ii) a general-purpose artificial intelligence model that affects compliance of the general-purpose artificial intelligence model, materially changes the purpose of the general-purpose artificial intelligence model, or results in any new reasonably foreseeable risk of algorithmic discrimination. &quot;Intentional and substantial modification&quot; does not include any change made to a high-risk artificial intelligence system, or the performance of a high-risk artificial intelligence system, if (a) the high-risk artificial intelligence system continues to learn after such high-risk artificial intelligence system is offered, sold, leased, licensed, given, or otherwise made available to a deployer, or deployed, and (b) such change (1) is made to such high-risk artificial intelligence system as a result of any learning described in clause (a), and (2) was predetermined by the deployer or the third party contracted by the deployer when such deployer or third party completed the initial impact assessment of such high-risk artificial intelligence system as required in &sect; 2.2-5519.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Machine learning&quot; means the development of algorithms to build data-derived statistical models that are capable of drawing inferences from previously unseen data without explicit human instruction.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Public body&quot; means any authority, board, department, instrumentality, agency, or other unit of state government. &quot;Public body&quot; does not include any county, city, or town; or any local or regional governmental authority.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Significant update&quot; means any new version, new release, or other update to a high-risk artificial intelligence system that results in significant changes to such high-risk artificial intelligence system&#39;s use case or key functionality and that results in any new or reasonably foreseeable risk of algorithmic discrimination.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Substantial factor&quot; means a factor that (i) assists in making a consequential decision, (ii) is capable of altering the outcome of a consequential decision, and (iii) is generated by an artificial intelligence system. &quot;Substantial factor&quot; includes any use of an artificial intelligence system to generate any content, decision, prediction, or recommendation concerning a consumer that is used as a basis to make a consequential decision concerning the consumer.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Synthetic digital content&quot; means any digital content, including any audio, image, text, or video, that is produced or manipulated by a generative artificial intelligence system, including a general-purpose artificial intelligence model.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Trade secret&quot; means information, including a formula, pattern, compilation, program, device, method, technique, or process, that (i) derives independent economic value, actual or potential, from not being generally known to, and not being readily ascertainable by proper means by, other persons who can obtain economic value from its disclosure or use and (ii) is the subject of efforts that are reasonable under the circumstances to maintain its secrecy.</u>\n   </p>\n   <p class=\"indent\">\n    <b>\n     <u class=\"amendmentInsertedText\">&sect; 2.2-5518. Operating standards for public bodies developing high-risk artificial intelligence systems.</u>\n    </b>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">A. No developer of a high-risk artificial intelligence system shall offer, sell, lease, give, or otherwise provide to a deployer a high-risk artificial intelligence system unless the developer makes available to the deployer:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">1. A statement disclosing the intended uses of such high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">2. Documentation disclosing the following:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">a. The known or reasonably known limitations of such high-risk artificial intelligence system, including any and all known or reasonably foreseeable risks of algorithmic discrimination arising from the intended uses of such high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">b. The purpose of such high-risk artificial intelligence system and the intended benefits and uses of such high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">c. A summary describing how such high-risk artificial intelligence system was evaluated for performance and relevant information related to explainability before such high-risk artificial intelligence system was licensed, sold, given, or otherwise made available to a developer;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">d. The measures the developer has taken to mitigate reasonable foreseeable risks of algorithmic discrimination that the developer knows arises from deployment or use of such high-risk artificial intelligence system; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">e. How an individual can use such high-risk artificial intelligence system to make, or monitor such high-risk artificial intelligence system when such high-risk artificial intelligence system is deployed or used to make, a consequential decision;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">3. Documentation describing (i) how the high-risk artificial intelligence system was evaluated for performance and for mitigation of algorithmic discrimination before such system was made available to the deployer; (ii) the data governance measures used to cover the training data sets and the measures used to examine the suitability of data sources, possible biases of data sources, and appropriate mitigation; (iii) the intended outputs of the high-risk artificial intelligence system; (iv) the measures the developer has taken to mitigate known or reasonably foreseeable risks of algorithmic discrimination that may arise from the reasonably foreseeable deployment of the high-risk artificial intelligence system; and (v) how the high-risk artificial intelligence system should be used, not be used, and be monitored by an individual when such system is used to make, or is a substantial factor in making, a consequential decision; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">4. Any additional documentation that is reasonably necessary to assist the deployer in understanding the outputs and monitoring performance of the high-risk artificial intelligence system for risks of algorithmic discrimination.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">B. Each developer that offers, sells, leases, gives, or otherwise makes available to a deployer a high-risk artificial intelligence system shall make available to the deployer information and documentation in the developer&#39;s possession, custody, or control that is reasonably required to complete an impact assessment as required in &sect; 2.2-5519.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">C. A developer that also serves as a deployer for any high-risk artificial intelligence system shall not be required to generate the documentation required by this section unless such high-risk artificial intelligence system is provided to an unaffiliated entity acting as a deployer or as otherwise required by law.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">D. Nothing in this section shall be construed to require a developer to disclose any trade secret.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">E. High-risk artificial intelligence systems that are in conformity with the latest version of the Artificial Intelligence Risk Management Framework published by the National Institute of Standards and Technology, Standard ISO/IEC 42001 of the International Organization for Standardization, or another nationally or internationally recognized risk management framework for artificial intelligence systems, or parts thereof, shall be presumed to be in conformity with related requirements set out in this section and in associated regulations.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">F. For any disclosure required pursuant to this section, each developer shall, no later than 90 days after the developer performs an intentional and substantial modification to any high-risk artificial intelligence system, update such disclosure as necessary to ensure that such disclosure remains accurate.</u>\n   </p>\n   <p class=\"indent\">\n    <b>\n     <u class=\"amendmentInsertedText\">&sect; 2.2-5519. Operating standards for public bodies deploying high-risk artificial intelligence systems.</u>\n    </b>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">A. No deployer shall deploy or use a high-risk artificial intelligence system to make a consequential decision unless the deployer has designed and implemented a risk management policy and program for such high-risk artificial intelligence system. The risk management policy shall specify the principles, processes, and personnel that the deployer shall use in maintaining the risk management program to identify, mitigate, and document any risk of algorithmic discrimination that is a reasonably foreseeable consequence of deploying or using such high-risk artificial intelligence system to make a consequential decision. Each risk management policy and program designed, implemented, and maintained pursuant to this subsection shall be (i) at least as stringent as the latest version of the Artificial Intelligence Risk Management Framework published by the National Institute of Standards and Technology, Standard ISO/IEC 42001 of the International Organization for Standardization, or another nationally or internationally recognized risk management framework for artificial intelligence systems and (ii) reasonable considering (a) the size and complexity of the deployer; (b) the nature and scope of the high-risk artificial intelligence systems deployed and used by the deployer, including the intended uses of such high-risk artificial intelligence systems; (c) the sensitivity and volume of data processed in connection with the high-risk artificial intelligence systems deployed and used by the deployer; and (d) the cost to the deployer to implement and maintain such risk management program.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">B. Except as provided in this subsection, no deployer shall deploy or use a high-risk artificial intelligence system to make a consequential decision unless the deployer has completed an impact assessment for such high-risk artificial intelligence system. The deployer shall complete an impact assessment for a high-risk artificial intelligence system (i) before the deployer initially deploys such high-risk artificial intelligence system and (ii) not later than 90 days after each significant update to such high-risk artificial intelligence system is made available.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">Each impact assessment completed pursuant to this subsection shall include, at a minimum:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">1. A statement by the deployer disclosing (i) the purpose, intended use cases and deployment context of, and benefits afforded by the high-risk artificial intelligence system and (ii) whether the deployment or use of the high-risk artificial intelligence system poses a reasonably foreseeable risk of algorithmic discrimination and, if so, (a) the nature of such algorithmic discrimination and (b) the steps that have been taken, to the extent feasible, to mitigate such risk;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">2. For each post-deployment impact assessment completed pursuant to this subsection, whether the intended use cases of the high-risk artificial intelligence system as updated were consistent with, or varied from, the developer&#39;s intended uses of such high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">3. A description of (i) the categories of data the high-risk artificial intelligence system processes as inputs and (ii) the outputs such high-risk artificial intelligence system produces;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">4. If the deployer used data to customize the high-risk artificial intelligence system, an overview of the categories of data the deployer used to customize such high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">5. A list of any metrics used to evaluate the performance and known limitations of the high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">6. A description of any transparency measures taken concerning the high-risk artificial intelligence system, including any measures taken to disclose to a consumer that such high-risk artificial intelligence system is in use when such high-risk artificial intelligence system is in use; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">7. A description of any post-deployment monitoring performed and user safeguards provided concerning such high-risk artificial intelligence system, including any oversight process established by the deployer to address issues arising from deployment or use of such high-risk artificial intelligence system as such issues arise.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">A single impact assessment may address a comparable set of high-risk artificial intelligence systems deployed or used by a deployer. High-risk artificial intelligence systems that are in conformity with the latest version of the Artificial Intelligence Risk Management Framework published by the National Institute of Standards and Technology, Standard ISO/IEC 42001 of the International Organization for Standardization, or another nationally or internationally recognized risk management framework for artificial intelligence systems, or parts thereof, shall be presumed to be in conformity with related requirements set out in this section and in associated regulations. If a deployer completes an impact assessment for the purpose of complying with another applicable law or regulation, such impact assessment shall be deemed to satisfy the requirements established in this subsection if such impact assessment is reasonably similar in scope and effect to the impact assessment that would otherwise be completed pursuant to this subsection. A deployer that completes an impact assessment pursuant to this subsection shall maintain such impact assessment and all records concerning such impact assessment for five years.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">C. Not later than the time that a deployer uses a high-risk artificial intelligence system to make a consequential decision concerning a consumer, the deployer shall notify the consumer that the deployer is using a high-risk artificial intelligence system to make such consequential decision concerning such consumer and provide to the consumer a statement disclosing (i) the purpose of such high-risk artificial intelligence system, (ii) the nature of such system, (iii) the nature of the consequential decision, (iv) the contact information for the deployer, and (v) a description in plain language of such system.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">If such consequential decision is adverse to such consumer, the deployer shall provide to the consumer (a) a statement disclosing the principal reason or reasons for the consequential decision, including (1) the degree to which and manner in which the high-risk artificial intelligence system contributed to the consequential decision, (2) the type of data that was processed by such system in making the consequential decision, and (3) the sources of such data; (b) an opportunity to correct any incorrect personal data that the high-risk artificial intelligence system processed in making, or as a substantial factor in making, the consequential decision; and (c) an opportunity to appeal such adverse consequential decision concerning the consumer arising from the deployment of such system. Any such appeal shall allow for human review, if technically feasible, unless providing the opportunity for appeal is not in the best interest of the consumer, including instances in which any delay might pose a risk to the life or safety of such consumer.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">D. Each deployer shall make available, in a manner that is clear and readily available, a statement summarizing how such deployer manages any reasonably foreseeable risk of algorithmic discrimination that may arise from the use or deployment of the high-risk artificial intelligence system.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">E. For any disclosure required pursuant to this section, each deployer shall, no later than 90 days after the developer performs an intentional and substantial modification to any high-risk artificial intelligence system, update such disclosure as necessary to ensure that such disclosure remains accurate.</u>\n   </p>\n   <p class=\"indent\">\n    <b>\n     <u class=\"amendmentInsertedText\">&sect; 2.2-5520. Operating standards for public bodies integrating high-risk artificial intelligence systems.</u>\n    </b>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">Each integrator of a high-risk artificial intelligence system shall develop and adopt an acceptable use policy, which shall limit the use of the high-risk artificial intelligence system to mitigate known risks of algorithmic discrimination.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">Each integrator of a high-risk artificial intelligence system shall provide to the deployer clear, conspicuous notice of (i) the name or other identifier of the high-risk artificial intelligence system integrated into a software application provided to the deployer; (ii) the name and contact information of the developer of the high-risk artificial intelligence system integrated into a software application provided to the deployer; (iii) whether the integrator has adjusted the model weights of the high-risk artificial intelligence system integrated into the software application by exposing it to additional data, a summary of the adjustment process, and how such process and the resulting system were evaluated for risk of algorithmic discrimination; (iv) a summary of any other non-substantial modifications made by the integrator; and (v) the integrator&#39;s acceptable use policy.</u>\n   </p>\n   <p class=\"indent\">\n    <b>\n     <u class=\"amendmentInsertedText\">&sect; 2.2-5521. Exemptions.</u>\n    </b>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">A. Nothing in this chapter shall be construed to restrict a developer&#39;s, integrator&#39;s, or deployer&#39;s ability to (i) comply with federal, state, or municipal ordinances or regulations; (ii) comply with a civil, criminal, or regulatory inquiry, investigation, subpoena, or summons by federal, state, local, or other governmental authorities; (iii) cooperate with law-enforcement agencies concerning conduct or activity that the developer, integrator, or deployer reasonably and in good faith believes may violate federal, state, or local law, ordinances, or regulations; (iv) investigate, establish, exercise, prepare for, or defend legal claims; (v) provide a product or service specifically requested by a consumer; (vi) perform under a contract to which a consumer is a party, including fulfilling the terms of a written warranty; (vii) take steps at the request of a consumer prior to entering into a contract; (viii) take immediate steps to protect an interest that is essential for the life or physical safety of the consumer or another individual; (ix) prevent, detect, protect against, or respond to security incidents, identity theft, fraud, harassment, or malicious or deceptive activities; (x) take actions to prevent, detect, protect against, report, or respond to the production, generation, incorporation, or synthesization of child sex abuse material, or any illegal activity, preserve the integrity or security of systems, or investigate, report, or prosecute those responsible for any such action; (xi) engage in public or peer-reviewed scientific or statistical research in the public interest that adheres to all other applicable ethics and privacy laws and is approved, monitored, and governed by an institutional review board that determines, or similar independent oversight entities that determine, (a) that the expected benefits of the research outweigh the risks associated with such research and (b) whether the developer, integrator, or deployer has implemented reasonable safeguards to mitigate the risks associated with such research; (xii) assist another developer, integrator, or deployer with any of the obligations imposed by this chapter; or (xiii) take any action that is in the public interest in the areas of public health, community health, or population health, but solely to the extent that such action is subject to suitable and specific measures to safeguard the public.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">B. The obligations imposed on developers, integrators, or deployers by this chapter shall not restrict a developer&#39;s, integrator&#39;s, or deployer&#39;s ability to (i) conduct internal research to develop, improve, or repair products, services, or technologies; (ii) effectuate a product recall; (iii) identify and repair technical errors that impair existing or intended functionality; or (iv) perform internal operations that are reasonably aligned with the expectations of the consumer or reasonably anticipated based on the consumer&#39;s existing relationship with the developer, integrator, or deployer.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">C. Nothing in this chapter shall be construed to impose any obligation on a developer, integrator, or deployer to disclose trade secrets.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">D. The obligations imposed on developers, integrators, or deployers by this chapter shall not apply where compliance by the developer, integrator, or deployer with such obligations would violate an evidentiary privilege under the laws of the Commonwealth.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">E. Nothing in this chapter shall be construed to impose any obligation on a developer, integrator, or deployer that adversely affects the legally protected rights or freedoms of any person, including the rights of any person to freedom of speech or freedom of the press guaranteed in the First Amendment to the Constitution of the United States or under the Virginia Human Rights Act (&sect; 2.2-3900 et seq.).</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">F. If a developer, integrator, or deployer engages in any action authorized by an exemption set forth in this section, the developer, integrator, or deployer bears the burden of demonstrating that such action qualifies for such exemption.</u>\n   </p>\n   <p class=\"indent\">\n    <b>\n     <u class=\"amendmentInsertedText\">&sect; 2.2-5522. Additional requirements.</u>\n    </b>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">A. A public body shall not implement any system that employs high-risk artificial intelligence systems unless it has fulfilled the requirements of this section and complied with the provisions of this chapter and the high-risk artificial intelligence policies and procedures developed by the Chief Information Officer of the Commonwealth pursuant to subdivision B 10 of &sect; 2.2-2007.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">B. A public body procuring any system that employs high-risk artificial intelligence systems shall in all future contracts for the procurement of such systems for which negotiation or renegotiation is begun on or after July 1, 2026, include a high-risk artificial intelligence system compliance clause, as developed by the Chief Information Officer of the Commonwealth pursuant to &sect; 2.2-2007.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">C. Prior to implementing any system that employs high-risk artificial intelligence systems, the public body shall comply with the impact assessment requirements of &sect; 2.2-5519. A public body shall additionally perform ongoing assessments of such system after implementation. If the public body, or the head of the public body, determines, in its discretion, that such system does not comply with such requirements, the public body shall not implement such system or shall cease to use such system to the extent such system does not comply with such requirements.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">D. All public bodies that implement high-risk artificial intelligence systems shall annually report on initial and ongoing system assessments and provide an inventory of such systems used. Public bodies in the legislative branch shall submit such report and inventory to the General Assembly. Public bodies in the judicial branch shall submit such report and inventory to the Executive Secretary of the Supreme Court of Virginia. Public bodies in the executive branch and any other public bodies not specified in this subsection shall submit such report and inventory to the Chief Information Officer of the Commonwealth. Such report and inventory shall be transmitted to the appropriate entity annually.</u>\n   </p>\n   <p class=\"indent\">\n    <b>2. That the Chief Information Officer of the Commonwealth (CIO) shall convene a work group to examine the impact on and the ability of local governments to comply with the requirements of this act. The work group shall consist of a representative from the Virginia Association of Counties who is also a representative of a member county, a representative from the Virginia Municipal League who is also a representative of a member locality, a representative of the Virginia Association of Chiefs of Police, a representative from the Virginia Association of Commonwealth&#39;s Attorneys, the chief information officer of a school division, the chief information officer of a county, the chief information officer of a city, a representative from the Department of Human Resource Management, a representative of a regional technology council, a member of the Joint Commission on Technology and Science (JCOTS) who is a member of the House of Delegates, and a member of JCOTS who is a member of the Senate. The CIO shall submit a report of the work group&#39;s findings to JCOTS no later than December 1, 2025.</b>\n   </p>\n   <p class=\"indent\">\n    <b>3. That the provisions of the first enactment of this act shall become effective on July 1, 2026.</b>\n   </p>\n  </div>\n </div>\n    </div>\t\n<table cellpadding=0 cellspacing=0 width=\"100%\">\n   <tr>\n      <td>\n          Copyright &copy; 2025 State Net\n      </td>\n<BR>\n<!--???MOVED INTO resources.cgi      <td align=\"right\">\n          <img src=\"https://custom.statenet.com/network/poweredby.gif\" alt=\"Powered by State Net\">\n      </td>-->\n\n    </tr>\n</table>\n</body></html>\n",
      "markdown": "The following has special meaning: _green underline denotes added text_ ~~red struck out text denotes deleted text~~ | [![Powered by State Net](https://custom.statenet.com/network/poweredby.gif)](https://www.lexisnexis.com/statenet/)  \n---|---  \n  \n2024 VA S 1214 | | Author: | Aird  \n---|---  \nVersion: | Introduced  \nVersion Date: | 01/08/2025  \n  \n**SENATE BILL NO. 1214**\n\nOffered January 8, 2025\n\nPrefiled January 8, 2025\n\n_A BILL to amend and reenact  2.2-2007 of the Code of Virginia and to amend\nthe Code of Virginia by adding in Title 2.2 a chapter numbered 55.6,\nconsisting of sections numbered 2.2-5517 through 2.2-5522, relating to high-\nrisk artificial intelligence; development, deployment, and use by public\nbodies; work group; report._\n\nPatron--Aird\n\nReferred to Committee on General Laws and Technology\n\n**Be it enacted by the General Assembly of Virginia:**\n\n**1\\. That  2.2-2007 of the Code of Virginia is amended and reenacted and\nthat the Code of Virginia is amended by adding in Title 2.2 a chapter numbered\n55.6, consisting of sections numbered 2.2-5517 through 2.2-5522, as follows:**\n\n** 2.2-2007. Powers of the CIO.**\n\nA. The CIO shall promulgate regulations necessary or incidental to the\nperformance of duties or execution of powers conferred under this chapter. The\nCIO shall also develop policies, standards, and guidelines for the planning,\nbudgeting, procurement, development, maintenance, security, and operations of\ninformation technology for executive branch agencies. Such policies,\nstandards, and guidelines shall include those necessary to:\n\n1\\. Support state and local government exchange, acquisition, storage, use,\nsharing, and distribution of data and related technologies.\n\n2\\. Support the development of electronic transactions _,_ including the use\nof electronic signatures as provided in  59.1-496.\n\n3\\. Support a unified approach to information technology across the totality\nof state government, thereby assuring that the citizens and businesses of the\nCommonwealth receive the greatest possible security, value, and convenience\nfrom investments made in technology.\n\n4\\. Ensure that the costs of information technology systems, products, data,\nand services are contained through the shared use of existing or planned\nequipment, data, or services.\n\n5\\. Provide for the effective management of information technology investments\nthrough their entire life cycles, including identification, business case\ndevelopment, selection, procurement, implementation, operation, performance\nevaluation, and enhancement or retirement. Such policies, standards, and\nguidelines shall include, at a minimum, the periodic review by the CIO of\nagency Commonwealth information technology projects.\n\n6\\. Establish an Information Technology Investment Management Standard based\non acceptable technology investment methods to ensure that all executive\nbranch agency technology expenditures are an integral part of the\nCommonwealth's performance management system, produce value for the agency and\nthe Commonwealth, and are aligned with (i) agency strategic plans, (ii) the\nGovernor's policy objectives, and (iii) the long-term objectives of the\nCouncil on Virginia's Future.\n\nB. In addition to other such duties as the Secretary may assign, the CIO\nshall:\n\n1\\. Oversee and administer the Virginia Technology Infrastructure Fund created\npursuant to  2.2-2023.\n\n2\\. Report annually to the Governor, the Secretary, and the Joint Commission\non Technology and Science created pursuant to  30-85 on the use and\napplication of information technology by executive branch agencies to increase\neconomic efficiency, citizen convenience, and public access to state\ngovernment.\n\n3\\. Prepare annually a report for submission to the Secretary, the Information\nTechnology Advisory Council, and the Joint Commission on Technology and\nScience on a prioritized list of Recommended Technology Investment Projects\n(RTIP Report) based upon major information technology projects submitted for\nbusiness case approval pursuant to this chapter. As part of the RTIP Report,\nthe CIO shall develop and regularly update a methodology for prioritizing\nprojects based upon the allocation of points to defined criteria. The criteria\nand their definitions shall be presented in the RTIP Report. For each project\nrecommended for funding in the RTIP Report, the CIO shall indicate the number\nof points and how they were awarded. For each listed project, the CIO shall\nalso report (i) all projected costs of ongoing operations and maintenance\nactivities of the project for the next three biennia following project\nimplementation; (ii) a justification and description for each project baseline\nchange; and (iii) whether the project fails to incorporate existing standards\nfor the maintenance, exchange, and security of data. This report shall also\ninclude trends in current projected information technology spending by\nexecutive branch agencies and secretariats, including spending on projects,\noperations and maintenance, and payments to VITA. Agencies shall provide all\nproject and cost information required to complete the RTIP Report to the CIO\nprior to May 31 immediately preceding any budget biennium in which the project\nappears in the Governor's budget bill.\n\n4\\. Provide oversight for executive branch agency efforts to modernize the\nplanning, development, implementation, improvement, operations and\nmaintenance, and retirement of Commonwealth information technology, including\noversight for the selection, development and management of enterprise\ninformation technology.\n\n5\\. Develop statewide technical and data standards and specifications for\ninformation technology and related systems, including (i) the efficient\nexchange of electronic information and technology, including infrastructure,\nbetween the public and private sectors in the Commonwealth and (ii) the\nutilization of nationally recognized technical and data standards for health\ninformation technology systems or software purchased by an executive branch\nagency.\n\n6\\. Direct the compilation and maintenance of an inventory of information\ntechnology, including but not limited to personnel, facilities, equipment,\ngoods, and contracts for services.\n\n7\\. Provide for the centralized marketing, provision, leasing, and executing\nof licensing agreements for electronic access to public information and\ngovernment services through the Internet, wireless devices, personal digital\nassistants, kiosks, or other such related media on terms and conditions as may\nbe determined to be in the best interest of the Commonwealth. VITA may fix and\ncollect fees and charges for (i) public information, media, and other\nincidental services furnished by it to any private individual or entity,\nnotwithstanding the charges set forth in  2.2-3704, and (ii) such use and\nservices it provides to any executive branch agency or local government.\nNothing in this subdivision authorizing VITA to fix and collect fees for\nproviding information services shall be construed to prevent access to the\npublic records of any public body pursuant to the provisions of the Virginia\nFreedom of Information Act ( 2.2-3700 et seq.). VITA is authorized, subject\nto the approval by the Secretary of Administration and any other affected\nSecretariat, to delegate the powers and responsibilities granted in this\nsubdivision to any agency within the executive branch.\n\n8\\. Periodically evaluate the feasibility of outsourcing information\ntechnology resources and services, and outsource those resources and services\nthat are feasible and beneficial to the Commonwealth.\n\n9\\. Have the authority to enter into and amend contracts, including contracts\nwith one or more other public bodies, or public agencies or institutions or\nlocalities of the several states, of the United States or its territories, or\nthe District of Columbia, for the provision of information technology\nservices.\n\n_10\\. Develop, publish, and maintain policies and procedures concerning the\ndevelopment, procurement, implementation, utilization, and ongoing assessment\nof systems that employ high-risk artificial intelligence systems, as defined\nin  2.2-5517, and are in use by public bodies, consistent with the provisions\nof Chapter 55.6 ( 2.2-5517 et seq.). Such policies and procedures shall, at a\nminimum, (i) govern the procurement, implementation, and ongoing assessment of\nany such system by a public body; (ii) address and provide resources regarding\ndata security and privacy issues that may arise from the development and\ndeployment of high-risk artificial intelligence systems by public bodies;\n(iii) be sufficient to ensure that no such system results in any algorithmic\ndiscrimination, as defined in  2.2-5517; (iv) create guidelines for\nacceptable use policies for public bodies integrating high-risk artificial\nintelligence systems pursuant to  2.2-5520; and (v) require a public body to\nassess the likely impact of any such system before implementing such system\nand perform ongoing assessments of such system to ensure that no such system\nresults in any such algorithmic discrimination, as defined in  2.2-5517. Such\npolicies and procedures shall include a requirement that a high-risk\nartificial intelligence system compliance clause be included in procurement\ncontracts for systems that use a high-risk artificial intelligence system for\nwhich negotiation or renegotiation is begun on or after July 1, 2026,\nrequiring compliance with the provisions of Chapter 55.6 ( 2.2-5517 et seq.)\nand any other applicable state law governing the development or deployment of\nhigh-risk artificial intelligence systems, as applicable._\n\nC. Consistent with  2.2-2012, the CIO may enter into public-private\npartnership contracts to finance or implement information technology programs\nand projects. The CIO may issue a request for information to seek out\npotential private partners interested in providing programs or projects\npursuant to an agreement under this subsection. The compensation for such\nservices shall be computed with reference to and paid from the increased\nrevenue or cost savings attributable to the successful implementation of the\nprogram or project for the period specified in the contract. The CIO shall be\nresponsible for reviewing and approving the programs and projects and the\nterms of contracts for same under this subsection. The CIO shall determine\nannually the total amount of increased revenue or cost savings attributable to\nthe successful implementation of a program or project under this subsection\nand such amount shall be deposited in the Virginia Technology Infrastructure\nFund created in  2.2-2023. The CIO is authorized to use moneys deposited in\nthe Fund to pay private partners pursuant to the terms of contracts under this\nsubsection. All moneys in excess of that required to be paid to private\npartners, as determined by the CIO, shall be reported to the Comptroller and\nretained in the Fund. The CIO shall prepare an annual report to the Governor,\nthe Secretary, and General Assembly on all contracts under this subsection,\ndescribing each information technology program or project, its progress,\nrevenue impact, and such other information as may be relevant.\n\nD. Executive branch agencies shall cooperate with VITA in identifying the\ndevelopment and operational requirements of proposed information technology\nsystems, products, data, and services, including the proposed use,\nfunctionality, and capacity, and the total cost of acquisition, operation, and\nmaintenance.\n\n_CHAPTER 55.6._\n\n_USE OF HIGH-RISK ARTIFICIAL INTELLIGENCE SYSTEMS._\n\n**_ 2.2-5517. Definitions._ **\n\n_As used in this chapter, unless the context requires a different meaning:_\n\n_\" Algorithmic discrimination\" means any discrimination that results in an\nunlawful differential treatment or impact that disfavors an individual or\ngroup of individuals on the basis of their actual or perceived age, color,\ndisability, ethnicity, genetic information, limited proficiency in the English\nlanguage, national origin, race, religion, reproductive health, sex, sexual\norientation, veteran status, or other classification protected under state or\nfederal law. \"Algorithmic discrimination\" does not include (i) the offer,\nlicense, or use of a high-risk artificial intelligence system by a developer,\nintegrator, or deployer for the sole purpose of the developer's, integrator's,\nor deployer's self-testing to identify, mitigate, or prevent discrimination or\notherwise ensure compliance with state and federal law or (ii) the expansion\nof an applicant, customer, or participant pool to increase diversity or\nredress historical discrimination._\n\n_\" Artificial intelligence\" means a set of technologies that enables machines\nto perform tasks under varying and unpredictable circumstances that typically\nrequire human oversight or intelligence, or that can learn from experience and\nimprove performance when exposed to data set_ ~~s~~ _._\n\n_\" Artificial intelligence system\" means any machine-based system that, for\nany explicit or implicit objective, infers from the inputs such system\nreceives how to generate outputs, including content, decisions, predictions,\nand recommendations, that can influence physical or virtual environments._\n\n_\" Consequential decision\" means any decision that has a material legal, or\nsimilarly significant, effect on the provision or denial to any consumer of,\nor the cost or terms of, (i) education enrollment or an education opportunity,\n(ii) employment or an employment opportunity, (iii) a financial or lending\nservice, (iv) an essential government service, (v) health care services, (vi)\nhousing, (vii) insurance, or (viii) a legal service._\n\n_\" Consumer\" means a natural person acting only in an individual or household\ncontext. \"Consumer\" does not include a natural person acting in a commercial\nor employment context._\n\n_\" Deployer\" means any public body that deploys or uses a high-risk artificial\nintelligence system to make a consequential decision._\n\n_\" Developer\" means any public body that develops or intentionally and\nsubstantially modifies a high-risk artificial intelligence system that is\noffered, sold, leased, given, or otherwise provided to consumers in the\nCommonwealth._\n\n_\" Foundation model\" means a machine learning model that (i) is trained on\nbroad data at scale, (ii) is designed for generality of output, and (iii) can\nbe adapted to a wide range of distinctive tasks._\n\n_\" General-purpose artificial intelligence model\" means any form of artificial\nintelligence system that (i) displays significant generality, (ii) is capable\nof competently performing a wide range of distinct tasks, and (iii) can be\nintegrated into a variety of downstream applications or systems. \"General-\npurpose artificial intelligence model\" does not include any artificial\nintelligence model that is used for development, prototyping, or research\nactivities before such artificial intelligence model is released on the\nmarket._\n\n_\" Generative artificial intelligence\" means artificial intelligence based on\na foundation model that is capable of and used to produce synthetic digital\ncontent, including audio, images, text, and videos._\n\n_\" Generative artificial intelligence system\" means any artificial\nintelligence system or service that incorporates generative artificial\nintelligence._\n\n_\" High-risk artificial intelligence system\" means any artificial intelligence\nsystem that is specifically intended to autonomously make, or be a substantial\nfactor in making, a consequential decision. A system or service is not a\n\"high-risk artificial intelligence system\" if it is intended to (i) perform a\nnarrow procedural task, (ii) improve the result of a previously completed\nhuman activity, (iii) detect decision-making patterns or deviations from prior\ndecision-making patterns and is not meant to replace or influence the\npreviously completed human assessment without sufficient human review, or (iv)\nperform a preparatory task to an assessment relevant to a consequential\ndecision. There is a rebuttable presumption that \"high-risk artificial\nintelligence system\" does not include any of the following technologies:_\n\n_1\\. Anti-fraud technology that does not use facial recognition technology;_\n\n_2\\. Anti-malware technology;_\n\n_3\\. Anti-virus technology;_\n\n_4\\. Artificial intelligence-enabled video games;_\n\n_5\\. Calculators;_\n\n_6\\. Cybersecurity technology;_\n\n_7\\. Databases;_\n\n_8\\. Data storage;_\n\n_9\\. Firewall technology;_\n\n_10\\. Internet domain registration;_\n\n_11\\. Internet website loading;_\n\n_12\\. Networking;_\n\n_13\\. Spam and robocall filtering;_\n\n_14\\. Spell-checking technology;_\n\n_15\\. Spreadsheets;_\n\n_16\\. Web caching;_\n\n_17\\. Web hosting or any similar technology; or_\n\n_18\\. Technology that communicates with consumers in natural language for the\npurpose of providing users with information, making referrals or\nrecommendations, and answering questions and is subject to an accepted use\npolicy that prohibits generating content that is discriminatory or harmful._\n\n_\" Integrator\" means a public body that knowingly integrates an artificial\nintelligence system into a software application and places such software\napplication on the market or makes such software application available for\npublic use. An \"integrator\" does not include a public body offering\ninformation technology infrastructure._\n\n_\" Intentional and substantial modification\" means any deliberate change made\nto (i) an artificial intelligence system that results in any new reasonably\nforeseeable risk of algorithmic discrimination or (ii) a general-purpose\nartificial intelligence model that affects compliance of the general-purpose\nartificial intelligence model, materially changes the purpose of the general-\npurpose artificial intelligence model, or results in any new reasonably\nforeseeable risk of algorithmic discrimination. \"Intentional and substantial\nmodification\" does not include any change made to a high-risk artificial\nintelligence system, or the performance of a high-risk artificial intelligence\nsystem, if (a) the high-risk artificial intelligence system continues to learn\nafter such high-risk artificial intelligence system is offered, sold, leased,\nlicensed, given, or otherwise made available to a deployer, or deployed, and\n(b) such change (1) is made to such high-risk artificial intelligence system\nas a result of any learning described in clause (a), and (2) was predetermined\nby the deployer or the third party contracted by the deployer when such\ndeployer or third party completed the initial impact assessment of such high-\nrisk artificial intelligence system as required in  2.2-5519._\n\n_\" Machine learning\" means the development of algorithms to build data-derived\nstatistical models that are capable of drawing inferences from previously\nunseen data without explicit human instruction._\n\n_\" Public body\" means any authority, board, department, instrumentality,\nagency, or other unit of state government. \"Public body\" does not include any\ncounty, city, or town; or any local or regional governmental authority._\n\n_\" Significant update\" means any new version, new release, or other update to\na high-risk artificial intelligence system that results in significant changes\nto such high-risk artificial intelligence system's use case or key\nfunctionality and that results in any new or reasonably foreseeable risk of\nalgorithmic discrimination._\n\n_\" Substantial factor\" means a factor that (i) assists in making a\nconsequential decision, (ii) is capable of altering the outcome of a\nconsequential decision, and (iii) is generated by an artificial intelligence\nsystem. \"Substantial factor\" includes any use of an artificial intelligence\nsystem to generate any content, decision, prediction, or recommendation\nconcerning a consumer that is used as a basis to make a consequential decision\nconcerning the consumer._\n\n_\" Synthetic digital content\" means any digital content, including any audio,\nimage, text, or video, that is produced or manipulated by a generative\nartificial intelligence system, including a general-purpose artificial\nintelligence model._\n\n_\" Trade secret\" means information, including a formula, pattern, compilation,\nprogram, device, method, technique, or process, that (i) derives independent\neconomic value, actual or potential, from not being generally known to, and\nnot being readily ascertainable by proper means by, other persons who can\nobtain economic value from its disclosure or use and (ii) is the subject of\nefforts that are reasonable under the circumstances to maintain its secrecy._\n\n**_ 2.2-5518. Operating standards for public bodies developing high-risk\nartificial intelligence systems._ **\n\n_A. No developer of a high-risk artificial intelligence system shall offer,\nsell, lease, give, or otherwise provide to a deployer a high-risk artificial\nintelligence system unless the developer makes available to the deployer:_\n\n_1\\. A statement disclosing the intended uses of such high-risk artificial\nintelligence system;_\n\n_2\\. Documentation disclosing the following:_\n\n_a. The known or reasonably known limitations of such high-risk artificial\nintelligence system, including any and all known or reasonably foreseeable\nrisks of algorithmic discrimination arising from the intended uses of such\nhigh-risk artificial intelligence system;_\n\n_b. The purpose of such high-risk artificial intelligence system and the\nintended benefits and uses of such high-risk artificial intelligence system;_\n\n_c. A summary describing how such high-risk artificial intelligence system was\nevaluated for performance and relevant information related to explainability\nbefore such high-risk artificial intelligence system was licensed, sold,\ngiven, or otherwise made available to a developer;_\n\n_d. The measures the developer has taken to mitigate reasonable foreseeable\nrisks of algorithmic discrimination that the developer knows arises from\ndeployment or use of such high-risk artificial intelligence system; and_\n\n_e. How an individual can use such high-risk artificial intelligence system to\nmake, or monitor such high-risk artificial intelligence system when such high-\nrisk artificial intelligence system is deployed or used to make, a\nconsequential decision;_\n\n_3\\. Documentation describing (i) how the high-risk artificial intelligence\nsystem was evaluated for performance and for mitigation of algorithmic\ndiscrimination before such system was made available to the deployer; (ii) the\ndata governance measures used to cover the training data sets and the measures\nused to examine the suitability of data sources, possible biases of data\nsources, and appropriate mitigation; (iii) the intended outputs of the high-\nrisk artificial intelligence system; (iv) the measures the developer has taken\nto mitigate known or reasonably foreseeable risks of algorithmic\ndiscrimination that may arise from the reasonably foreseeable deployment of\nthe high-risk artificial intelligence system; and (v) how the high-risk\nartificial intelligence system should be used, not be used, and be monitored\nby an individual when such system is used to make, or is a substantial factor\nin making, a consequential decision; and_\n\n_4\\. Any additional documentation that is reasonably necessary to assist the\ndeployer in understanding the outputs and monitoring performance of the high-\nrisk artificial intelligence system for risks of algorithmic discrimination._\n\n_B. Each developer that offers, sells, leases, gives, or otherwise makes\navailable to a deployer a high-risk artificial intelligence system shall make\navailable to the deployer information and documentation in the developer 's\npossession, custody, or control that is reasonably required to complete an\nimpact assessment as required in  2.2-5519._\n\n_C. A developer that also serves as a deployer for any high-risk artificial\nintelligence system shall not be required to generate the documentation\nrequired by this section unless such high-risk artificial intelligence system\nis provided to an unaffiliated entity acting as a deployer or as otherwise\nrequired by law._\n\n_D. Nothing in this section shall be construed to require a developer to\ndisclose any trade secret._\n\n_E. High-risk artificial intelligence systems that are in conformity with the\nlatest version of the Artificial Intelligence Risk Management Framework\npublished by the National Institute of Standards and Technology, Standard\nISO/IEC 42001 of the International Organization for Standardization, or\nanother nationally or internationally recognized risk management framework for\nartificial intelligence systems, or parts thereof, shall be presumed to be in\nconformity with related requirements set out in this section and in associated\nregulations._\n\n_F. For any disclosure required pursuant to this section, each developer\nshall, no later than 90 days after the developer performs an intentional and\nsubstantial modification to any high-risk artificial intelligence system,\nupdate such disclosure as necessary to ensure that such disclosure remains\naccurate._\n\n**_ 2.2-5519. Operating standards for public bodies deploying high-risk\nartificial intelligence systems._ **\n\n_A. No deployer shall deploy or use a high-risk artificial intelligence system\nto make a consequential decision unless the deployer has designed and\nimplemented a risk management policy and program for such high-risk artificial\nintelligence system. The risk management policy shall specify the principles,\nprocesses, and personnel that the deployer shall use in maintaining the risk\nmanagement program to identify, mitigate, and document any risk of algorithmic\ndiscrimination that is a reasonably foreseeable consequence of deploying or\nusing such high-risk artificial intelligence system to make a consequential\ndecision. Each risk management policy and program designed, implemented, and\nmaintained pursuant to this subsection shall be (i) at least as stringent as\nthe latest version of the Artificial Intelligence Risk Management Framework\npublished by the National Institute of Standards and Technology, Standard\nISO/IEC 42001 of the International Organization for Standardization, or\nanother nationally or internationally recognized risk management framework for\nartificial intelligence systems and (ii) reasonable considering (a) the size\nand complexity of the deployer; (b) the nature and scope of the high-risk\nartificial intelligence systems deployed and used by the deployer, including\nthe intended uses of such high-risk artificial intelligence systems; (c) the\nsensitivity and volume of data processed in connection with the high-risk\nartificial intelligence systems deployed and used by the deployer; and (d) the\ncost to the deployer to implement and maintain such risk management program._\n\n_B. Except as provided in this subsection, no deployer shall deploy or use a\nhigh-risk artificial intelligence system to make a consequential decision\nunless the deployer has completed an impact assessment for such high-risk\nartificial intelligence system. The deployer shall complete an impact\nassessment for a high-risk artificial intelligence system (i) before the\ndeployer initially deploys such high-risk artificial intelligence system and\n(ii) not later than 90 days after each significant update to such high-risk\nartificial intelligence system is made available._\n\n_Each impact assessment completed pursuant to this subsection shall include,\nat a minimum:_\n\n_1\\. A statement by the deployer disclosing (i) the purpose, intended use\ncases and deployment context of, and benefits afforded by the high-risk\nartificial intelligence system and (ii) whether the deployment or use of the\nhigh-risk artificial intelligence system poses a reasonably foreseeable risk\nof algorithmic discrimination and, if so, (a) the nature of such algorithmic\ndiscrimination and (b) the steps that have been taken, to the extent feasible,\nto mitigate such risk;_\n\n_2\\. For each post-deployment impact assessment completed pursuant to this\nsubsection, whether the intended use cases of the high-risk artificial\nintelligence system as updated were consistent with, or varied from, the\ndeveloper 's intended uses of such high-risk artificial intelligence system;_\n\n_3\\. A description of (i) the categories of data the high-risk artificial\nintelligence system processes as inputs and (ii) the outputs such high-risk\nartificial intelligence system produces;_\n\n_4\\. If the deployer used data to customize the high-risk artificial\nintelligence system, an overview of the categories of data the deployer used\nto customize such high-risk artificial intelligence system;_\n\n_5\\. A list of any metrics used to evaluate the performance and known\nlimitations of the high-risk artificial intelligence system;_\n\n_6\\. A description of any transparency measures taken concerning the high-risk\nartificial intelligence system, including any measures taken to disclose to a\nconsumer that such high-risk artificial intelligence system is in use when\nsuch high-risk artificial intelligence system is in use; and_\n\n_7\\. A description of any post-deployment monitoring performed and user\nsafeguards provided concerning such high-risk artificial intelligence system,\nincluding any oversight process established by the deployer to address issues\narising from deployment or use of such high-risk artificial intelligence\nsystem as such issues arise._\n\n_A single impact assessment may address a comparable set of high-risk\nartificial intelligence systems deployed or used by a deployer. High-risk\nartificial intelligence systems that are in conformity with the latest version\nof the Artificial Intelligence Risk Management Framework published by the\nNational Institute of Standards and Technology, Standard ISO/IEC 42001 of the\nInternational Organization for Standardization, or another nationally or\ninternationally recognized risk management framework for artificial\nintelligence systems, or parts thereof, shall be presumed to be in conformity\nwith related requirements set out in this section and in associated\nregulations. If a deployer completes an impact assessment for the purpose of\ncomplying with another applicable law or regulation, such impact assessment\nshall be deemed to satisfy the requirements established in this subsection if\nsuch impact assessment is reasonably similar in scope and effect to the impact\nassessment that would otherwise be completed pursuant to this subsection. A\ndeployer that completes an impact assessment pursuant to this subsection shall\nmaintain such impact assessment and all records concerning such impact\nassessment for five years._\n\n_C. Not later than the time that a deployer uses a high-risk artificial\nintelligence system to make a consequential decision concerning a consumer,\nthe deployer shall notify the consumer that the deployer is using a high-risk\nartificial intelligence system to make such consequential decision concerning\nsuch consumer and provide to the consumer a statement disclosing (i) the\npurpose of such high-risk artificial intelligence system, (ii) the nature of\nsuch system, (iii) the nature of the consequential decision, (iv) the contact\ninformation for the deployer, and (v) a description in plain language of such\nsystem._\n\n_If such consequential decision is adverse to such consumer, the deployer\nshall provide to the consumer (a) a statement disclosing the principal reason\nor reasons for the consequential decision, including (1) the degree to which\nand manner in which the high-risk artificial intelligence system contributed\nto the consequential decision, (2) the type of data that was processed by such\nsystem in making the consequential decision, and (3) the sources of such data;\n(b) an opportunity to correct any incorrect personal data that the high-risk\nartificial intelligence system processed in making, or as a substantial factor\nin making, the consequential decision; and (c) an opportunity to appeal such\nadverse consequential decision concerning the consumer arising from the\ndeployment of such system. Any such appeal shall allow for human review, if\ntechnically feasible, unless providing the opportunity for appeal is not in\nthe best interest of the consumer, including instances in which any delay\nmight pose a risk to the life or safety of such consumer._\n\n_D. Each deployer shall make available, in a manner that is clear and readily\navailable, a statement summarizing how such deployer manages any reasonably\nforeseeable risk of algorithmic discrimination that may arise from the use or\ndeployment of the high-risk artificial intelligence system._\n\n_E. For any disclosure required pursuant to this section, each deployer shall,\nno later than 90 days after the developer performs an intentional and\nsubstantial modification to any high-risk artificial intelligence system,\nupdate such disclosure as necessary to ensure that such disclosure remains\naccurate._\n\n**_ 2.2-5520. Operating standards for public bodies integrating high-risk\nartificial intelligence systems._ **\n\n_Each integrator of a high-risk artificial intelligence system shall develop\nand adopt an acceptable use policy, which shall limit the use of the high-risk\nartificial intelligence system to mitigate known risks of algorithmic\ndiscrimination._\n\n_Each integrator of a high-risk artificial intelligence system shall provide\nto the deployer clear, conspicuous notice of (i) the name or other identifier\nof the high-risk artificial intelligence system integrated into a software\napplication provided to the deployer; (ii) the name and contact information of\nthe developer of the high-risk artificial intelligence system integrated into\na software application provided to the deployer; (iii) whether the integrator\nhas adjusted the model weights of the high-risk artificial intelligence system\nintegrated into the software application by exposing it to additional data, a\nsummary of the adjustment process, and how such process and the resulting\nsystem were evaluated for risk of algorithmic discrimination; (iv) a summary\nof any other non-substantial modifications made by the integrator; and (v) the\nintegrator 's acceptable use policy._\n\n**_ 2.2-5521. Exemptions._ **\n\n_A. Nothing in this chapter shall be construed to restrict a developer 's,\nintegrator's, or deployer's ability to (i) comply with federal, state, or\nmunicipal ordinances or regulations; (ii) comply with a civil, criminal, or\nregulatory inquiry, investigation, subpoena, or summons by federal, state,\nlocal, or other governmental authorities; (iii) cooperate with law-enforcement\nagencies concerning conduct or activity that the developer, integrator, or\ndeployer reasonably and in good faith believes may violate federal, state, or\nlocal law, ordinances, or regulations; (iv) investigate, establish, exercise,\nprepare for, or defend legal claims; (v) provide a product or service\nspecifically requested by a consumer; (vi) perform under a contract to which a\nconsumer is a party, including fulfilling the terms of a written warranty;\n(vii) take steps at the request of a consumer prior to entering into a\ncontract; (viii) take immediate steps to protect an interest that is essential\nfor the life or physical safety of the consumer or another individual; (ix)\nprevent, detect, protect against, or respond to security incidents, identity\ntheft, fraud, harassment, or malicious or deceptive activities; (x) take\nactions to prevent, detect, protect against, report, or respond to the\nproduction, generation, incorporation, or synthesization of child sex abuse\nmaterial, or any illegal activity, preserve the integrity or security of\nsystems, or investigate, report, or prosecute those responsible for any such\naction; (xi) engage in public or peer-reviewed scientific or statistical\nresearch in the public interest that adheres to all other applicable ethics\nand privacy laws and is approved, monitored, and governed by an institutional\nreview board that determines, or similar independent oversight entities that\ndetermine, (a) that the expected benefits of the research outweigh the risks\nassociated with such research and (b) whether the developer, integrator, or\ndeployer has implemented reasonable safeguards to mitigate the risks\nassociated with such research; (xii) assist another developer, integrator, or\ndeployer with any of the obligations imposed by this chapter; or (xiii) take\nany action that is in the public interest in the areas of public health,\ncommunity health, or population health, but solely to the extent that such\naction is subject to suitable and specific measures to safeguard the public._\n\n_B. The obligations imposed on developers, integrators, or deployers by this\nchapter shall not restrict a developer 's, integrator's, or deployer's ability\nto (i) conduct internal research to develop, improve, or repair products,\nservices, or technologies; (ii) effectuate a product recall; (iii) identify\nand repair technical errors that impair existing or intended functionality; or\n(iv) perform internal operations that are reasonably aligned with the\nexpectations of the consumer or reasonably anticipated based on the consumer's\nexisting relationship with the developer, integrator, or deployer._\n\n_C. Nothing in this chapter shall be construed to impose any obligation on a\ndeveloper, integrator, or deployer to disclose trade secrets._\n\n_D. The obligations imposed on developers, integrators, or deployers by this\nchapter shall not apply where compliance by the developer, integrator, or\ndeployer with such obligations would violate an evidentiary privilege under\nthe laws of the Commonwealth._\n\n_E. Nothing in this chapter shall be construed to impose any obligation on a\ndeveloper, integrator, or deployer that adversely affects the legally\nprotected rights or freedoms of any person, including the rights of any person\nto freedom of speech or freedom of the press guaranteed in the First Amendment\nto the Constitution of the United States or under the Virginia Human Rights\nAct (  2.2-3900 et seq.)._\n\n_F. If a developer, integrator, or deployer engages in any action authorized\nby an exemption set forth in this section, the developer, integrator, or\ndeployer bears the burden of demonstrating that such action qualifies for such\nexemption._\n\n**_ 2.2-5522. Additional requirements._ **\n\n_A. A public body shall not implement any system that employs high-risk\nartificial intelligence systems unless it has fulfilled the requirements of\nthis section and complied with the provisions of this chapter and the high-\nrisk artificial intelligence policies and procedures developed by the Chief\nInformation Officer of the Commonwealth pursuant to subdivision B 10 of \n2.2-2007._\n\n_B. A public body procuring any system that employs high-risk artificial\nintelligence systems shall in all future contracts for the procurement of such\nsystems for which negotiation or renegotiation is begun on or after July 1,\n2026, include a high-risk artificial intelligence system compliance clause, as\ndeveloped by the Chief Information Officer of the Commonwealth pursuant to \n2.2-2007._\n\n_C. Prior to implementing any system that employs high-risk artificial\nintelligence systems, the public body shall comply with the impact assessment\nrequirements of  2.2-5519. A public body shall additionally perform ongoing\nassessments of such system after implementation. If the public body, or the\nhead of the public body, determines, in its discretion, that such system does\nnot comply with such requirements, the public body shall not implement such\nsystem or shall cease to use such system to the extent such system does not\ncomply with such requirements._\n\n_D. All public bodies that implement high-risk artificial intelligence systems\nshall annually report on initial and ongoing system assessments and provide an\ninventory of such systems used. Public bodies in the legislative branch shall\nsubmit such report and inventory to the General Assembly. Public bodies in the\njudicial branch shall submit such report and inventory to the Executive\nSecretary of the Supreme Court of Virginia. Public bodies in the executive\nbranch and any other public bodies not specified in this subsection shall\nsubmit such report and inventory to the Chief Information Officer of the\nCommonwealth. Such report and inventory shall be transmitted to the\nappropriate entity annually._\n\n**2\\. That the Chief Information Officer of the Commonwealth (CIO) shall\nconvene a work group to examine the impact on and the ability of local\ngovernments to comply with the requirements of this act. The work group shall\nconsist of a representative from the Virginia Association of Counties who is\nalso a representative of a member county, a representative from the Virginia\nMunicipal League who is also a representative of a member locality, a\nrepresentative of the Virginia Association of Chiefs of Police, a\nrepresentative from the Virginia Association of Commonwealth 's Attorneys, the\nchief information officer of a school division, the chief information officer\nof a county, the chief information officer of a city, a representative from\nthe Department of Human Resource Management, a representative of a regional\ntechnology council, a member of the Joint Commission on Technology and Science\n(JCOTS) who is a member of the House of Delegates, and a member of JCOTS who\nis a member of the Senate. The CIO shall submit a report of the work group's\nfindings to JCOTS no later than December 1, 2025.**\n\n**3\\. That the provisions of the first enactment of this act shall become\neffective on July 1, 2026.**\n\nCopyright (C) 2025 State Net  \n  \n---\n\n",
      "latest_version": false
    },
    {
      "date": "01/24/2025",
      "label": "Recommended as Substituted from Committee",
      "url": "https://custom.statenet.com/public/resources.cgi?mode=show_text&id=ID:bill:VA2024000S1214&verid=VA2024000S1214_20250124_0_RS&",
      "raw_html": "<html>\n<head>\n<title>Bill Resource</title>\n\n<!--   <link href=\"https://custom.statenet.com/network/Common/css/extregtext.css\" rel=\"stylesheet\" type=\"text/css\" />-->\n   <link href=\"https://custom.statenet.com/network/Common/css/xmltext-2.0.css\" rel=\"stylesheet\" type=\"text/css\" />\n   <link href=\"https://custom.statenet.com/network/Common/css/additional-text.css\" rel=\"stylesheet\" type=\"text/css\" />\n\n\t<style type=\"text/css\">\n<!--\n\ntd, body {\n     background-color: white;\n\tfont-family: Verdana, Arial, Helvetica, sans-serif;\n\tfont-size: 12px;\n}\n\n.resourceContainer {\n   border: 1px solid black;\n}\n-->\n</style>\n</head>\n<body>\n\n    <div style=\"width: 750px; margin: auto\">\n       <div style=\"font-size: .8em;margin-bottom: 10px\"><table width=\"100%\"><tr><td align=\"left\" style=\"font-size: .8em;\"><div>The following has special meaning:</div>\n<div><u class=\"amendmentInsertedText\">green underline denotes added text</u></div>\n<div><strike class=\"amendmentDeletedText\">red struck out text denotes deleted text</strike></div></td> <td align=\"right\"><a href=\"https://www.lexisnexis.com/statenet/\"><img alt=\"Powered by State Net\" src=\"https://custom.statenet.com/network/poweredby.gif\" /></a></td></tr></table></div><table id=\"text-identifier\"><tr><td class=\"key\">2024 VA S 1214</td> <td><table><tr><td class=\"label\">Author:</td> <td>Aird</td></tr> <tr><td class=\"label\">Version:</td> <td>Recommended as Substituted from Committee</td></tr> <tr><td class=\"label\">Version Date:</td> <td>01/24/2025</td></tr></table></td></tr></table><div class=\"documentBody\">\n  <a name=\"head_document_section\"></a><div class=\"head\">\n   <p class=\"center\">\n    <b>2025 SESSION</b>\n   </p>\n   <p class=\"left\">25106036D</p>\n   <p class=\"right\">\n    <b>SENATE SUBSTITUTE</b>\n   </p>\n   <p class=\"center\">\n    <b>SENATE BILL NO. 1214</b>\n   </p>\n   <p class=\"center\">AMENDMENT IN THE NATURE OF A SUBSTITUTE</p>\n   <p class=\"center\">(Proposed by the Senate Committee on General Laws and Technology</p>\n   <p class=\"center\">on January 24, 2025)</p>\n   <p class=\"center\">(Patron Prior to Substitute Senator Aird)</p>\n  </div>\n  <a name=\"code_document_section\"></a><div class=\"code\">\n   <p class=\"indent\">\n    <i>A BILL to amend and reenact &sect; 2.2-2007 of the Code of Virginia and to amend the Code of Virginia by adding in Title 2.2 a chapter numbered 55.6, consisting of sections numbered 2.2-5517 through 2.2-5522, relating to high-risk artificial intelligence; development, deployment, and use by public bodies; work group; report.</i>\n   </p>\n  </div>\n  <a name=\"text_document_section\"></a><div class=\"text\">\n   <span>\n    <p class=\"indent\">\n     <b>Be it enacted by the General Assembly of Virginia:</b>\n    </p>\n   </span>\n   <p class=\"indent\">\n    <b>1. That &sect; 2.2-2007 of the Code of Virginia is amended and reenacted and that the Code of Virginia is amended by adding in Title 2.2 a chapter numbered 55.6, consisting of sections numbered 2.2-5517 through 2.2-5522, as follows:</b>\n   </p>\n   <p class=\"indent\">\n    <b>&sect; 2.2-2007. Powers of the CIO.</b>\n   </p>\n   <p class=\"indent\">A. The CIO shall promulgate regulations necessary or incidental to the performance of duties or execution of powers conferred under this chapter. The CIO shall also develop policies, standards, and guidelines for the planning, budgeting, procurement, development, maintenance, security, and operations of information technology for executive branch agencies. Such policies, standards, and guidelines shall include those necessary to:</p>\n   <p class=\"indent\">1. Support state and local government exchange, acquisition, storage, use, sharing, and distribution of data and related technologies.</p>\n   <p class=\"indent\">2. Support the development of electronic transactions<u class=\"amendmentInsertedText\">,</u> including the use of electronic signatures as provided in &sect; 59.1-496.</p>\n   <p class=\"indent\">3. Support a unified approach to information technology across the totality of state government, thereby assuring that the citizens and businesses of the Commonwealth receive the greatest possible security, value, and convenience from investments made in technology.</p>\n   <p class=\"indent\">4. Ensure that the costs of information technology systems, products, data, and services are contained through the shared use of existing or planned equipment, data, or services.</p>\n   <p class=\"indent\">5. Provide for the effective management of information technology investments through their entire life cycles, including identification, business case development, selection, procurement, implementation, operation, performance evaluation, and enhancement or retirement. Such policies, standards, and guidelines shall include, at a minimum, the periodic review by the CIO of agency Commonwealth information technology projects.</p>\n   <p class=\"indent\">6. Establish an Information Technology Investment Management Standard based on acceptable technology investment methods to ensure that all executive branch agency technology expenditures are an integral part of the Commonwealth&#39;s performance management system, produce value for the agency and the Commonwealth, and are aligned with (i) agency strategic plans, (ii) the Governor&#39;s policy objectives, and (iii) the long-term objectives of the Council on Virginia&#39;s Future.</p>\n   <p class=\"indent\">B. In addition to other such duties as the Secretary may assign, the CIO shall:</p>\n   <p class=\"indent\">1. Oversee and administer the Virginia Technology Infrastructure Fund created pursuant to &sect; 2.2-2023.</p>\n   <p class=\"indent\">2. Report annually to the Governor, the Secretary, and the Joint Commission on Technology and Science created pursuant to &sect; 30-85 on the use and application of information technology by executive branch agencies to increase economic efficiency, citizen convenience, and public access to state government.</p>\n   <p class=\"indent\">3. Prepare annually a report for submission to the Secretary, the Information Technology Advisory Council, and the Joint Commission on Technology and Science on a prioritized list of Recommended Technology Investment Projects (RTIP Report) based upon major information technology projects submitted for business case approval pursuant to this chapter. As part of the RTIP Report, the CIO shall develop and regularly update a methodology for prioritizing projects based upon the allocation of points to defined criteria. The criteria and their definitions shall be presented in the RTIP Report. For each project recommended for funding in the RTIP Report, the CIO shall indicate the number of points and how they were awarded. For each listed project, the CIO shall also report (i) all projected costs of ongoing operations and maintenance activities of the project for the next three biennia following project implementation; (ii) a justification and description for each project baseline change; and (iii) whether the project fails to incorporate existing standards for the maintenance, exchange, and security of data. This report shall also include trends in current projected information technology spending by executive branch agencies and secretariats, including spending on projects, operations and maintenance, and payments to VITA. Agencies shall provide all project and cost information required to complete the RTIP Report to the CIO prior to May 31 immediately preceding any budget biennium in which the project appears in the Governor&#39;s budget bill.</p>\n   <p class=\"indent\">4. Provide oversight for executive branch agency efforts to modernize the planning, development, implementation, improvement, operations and maintenance, and retirement of Commonwealth information technology, including oversight for the selection, development and management of enterprise information technology.</p>\n   <p class=\"indent\">5. Develop statewide technical and data standards and specifications for information technology and related systems, including (i) the efficient exchange of electronic information and technology, including infrastructure, between the public and private sectors in the Commonwealth and (ii) the utilization of nationally recognized technical and data standards for health information technology systems or software purchased by an executive branch agency.</p>\n   <p class=\"indent\">6. Direct the compilation and maintenance of an inventory of information technology, including but not limited to personnel, facilities, equipment, goods, and contracts for services.</p>\n   <p class=\"indent\">7. Provide for the centralized marketing, provision, leasing, and executing of licensing agreements for electronic access to public information and government services through the Internet, wireless devices, personal digital assistants, kiosks, or other such related media on terms and conditions as may be determined to be in the best interest of the Commonwealth. VITA may fix and collect fees and charges for (i) public information, media, and other incidental services furnished by it to any private individual or entity, notwithstanding the charges set forth in &sect; 2.2-3704, and (ii) such use and services it provides to any executive branch agency or local government. Nothing in this subdivision authorizing VITA to fix and collect fees for providing information services shall be construed to prevent access to the public records of any public body pursuant to the provisions of the Virginia Freedom of Information Act (&sect; 2.2-3700 et seq.). VITA is authorized, subject to the approval by the Secretary of Administration and any other affected Secretariat, to delegate the powers and responsibilities granted in this subdivision to any agency within the executive branch.</p>\n   <p class=\"indent\">8. Periodically evaluate the feasibility of outsourcing information technology resources and services, and outsource those resources and services that are feasible and beneficial to the Commonwealth.</p>\n   <p class=\"indent\">9. Have the authority to enter into and amend contracts, including contracts with one or more other public bodies, or public agencies or institutions or localities of the several states, of the United States or its territories, or the District of Columbia, for the provision of information technology services.</p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">10. Develop, publish, and maintain policies and procedures concerning the development, procurement, implementation, utilization, and ongoing assessment of systems that employ high-risk artificial intelligence systems, as defined in &sect; 2.2-5517, and are in use by public bodies, consistent with the provisions of Chapter 55.6 (&sect; 2.2-5517 et seq.). Such policies and procedures shall, at a minimum, (i) govern the procurement, implementation, and ongoing assessment of any such system by a public body; (ii) address and provide resources regarding data security and privacy issues that may arise from the development and deployment of high-risk artificial intelligence systems by public bodies; (iii) be sufficient to ensure that no such system results in any algorithmic discrimination, as defined in &sect; 2.2-5517; (iv) create guidelines for acceptable use policies for public bodies integrating high-risk artificial intelligence systems pursuant to &sect; 2.2-5520; and (v) require a public body to assess the likely impact of any such system before implementing such system and perform ongoing assessments of such system to ensure that no such system results in any such algorithmic discrimination, as defined in &sect; 2.2-5517. Such policies and procedures shall include a requirement that a high-risk artificial intelligence system compliance clause be included in procurement contracts for systems that use a high-risk artificial intelligence system for which negotiation or renegotiation is begun on or after July 1, 2026, requiring compliance with the provisions of Chapter 55.6 (&sect; 2.2-5517 et seq.) and any other applicable state law governing the development or deployment of high-risk artificial intelligence systems, as applicable.</u>\n   </p>\n   <p class=\"indent\">C. Consistent with &sect; 2.2-2012, the CIO may enter into public-private partnership contracts to finance or implement information technology programs and projects. The CIO may issue a request for information to seek out potential private partners interested in providing programs or projects pursuant to an agreement under this subsection. The compensation for such services shall be computed with reference to and paid from the increased revenue or cost savings attributable to the successful implementation of the program or project for the period specified in the contract. The CIO shall be responsible for reviewing and approving the programs and projects and the terms of contracts for same under this subsection. The CIO shall determine annually the total amount of increased revenue or cost savings attributable to the successful implementation of a program or project under this subsection and such amount shall be deposited in the Virginia Technology Infrastructure Fund created in &sect; 2.2-2023. The CIO is authorized to use moneys deposited in the Fund to pay private partners pursuant to the terms of contracts under this subsection. All moneys in excess of that required to be paid to private partners, as determined by the CIO, shall be reported to the Comptroller and retained in the Fund. The CIO shall prepare an annual report to the Governor, the Secretary, and General Assembly on all contracts under this subsection, describing each information technology program or project, its progress, revenue impact, and such other information as may be relevant.</p>\n   <p class=\"indent\">D. Executive branch agencies shall cooperate with VITA in identifying the development and operational requirements of proposed information technology systems, products, data, and services, including the proposed use, functionality, and capacity, and the total cost of acquisition, operation, and maintenance.</p>\n   <p class=\"center\">\n    <u class=\"amendmentInsertedText\">CHAPTER 55.6.</u>\n   </p>\n   <p class=\"center\">\n    <u class=\"amendmentInsertedText\">USE OF HIGH-RISK ARTIFICIAL INTELLIGENCE SYSTEMS.</u>\n   </p>\n   <p class=\"indent\">\n    <b>\n     <u class=\"amendmentInsertedText\">&sect; 2.2-5517. Definitions.</u>\n    </b>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">As used in this chapter, unless the context requires a different meaning:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Algorithmic discrimination&quot; means any discrimination that results in an unlawful differential treatment or impact that disfavors an individual or group of individuals on the basis of their actual or perceived age, color, disability, ethnicity, genetic information, limited proficiency in the English language, national origin, race, religion, reproductive health, sex, sexual orientation, veteran status, or other classification protected under state or federal law. &quot;Algorithmic discrimination&quot; does not include (i) the offer, license, or use of a high-risk artificial intelligence system by a developer, integrator, or deployer for the sole purpose of the developer&#39;s, integrator&#39;s, or deployer&#39;s self-testing to identify, mitigate, or prevent discrimination or otherwise ensure compliance with state and federal law or (ii) the expansion of an applicant, customer, or participant pool to increase diversity or redress historical discrimination.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Artificial intelligence&quot; means a set of technologies that enables machines to perform tasks under varying and unpredictable circumstances that typically require human oversight or intelligence, or that can learn from experience and improve performance when exposed to data set</u>\n    <strike class=\"amendmentDeletedText\">s</strike>\n    <u class=\"amendmentInsertedText\">.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Artificial intelligence system&quot; means any machine-based system that, for any explicit or implicit objective, infers from the inputs such system receives how to generate outputs, including content, decisions, predictions, and recommendations, that can influence physical or virtual environments.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Consequential decision&quot; means any decision that has a material legal, or similarly significant, effect on the provision or denial to any consumer of, or the cost or terms of, (i) education enrollment or an education opportunity, (ii) employment or an employment opportunity, (iii) a financial or lending service, (iv) an essential government service, (v) health care services, (vi) housing, (vii) insurance, or (viii) a legal service.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Consumer&quot; means a natural person acting only in an individual or household context. &quot;Consumer&quot; does not include a natural person acting in a commercial or employment context.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Deployer&quot; means any public body that deploys or uses a high-risk artificial intelligence system to make a consequential decision.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Developer&quot; means any public body that develops or intentionally and substantially modifies a high-risk artificial intelligence system that is offered, sold, leased, given, or otherwise provided to consumers in the Commonwealth.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Facial recognition&quot; means the use of a computer system that, for the purpose of attempting to determine the identity of an unknown individual, uses an algorithm to compare the facial biometric data of an unknown individual derived from a photograph, video, or image to a database of photographs or images and associated facial biometric data in order to identify potential matches to an individual. &quot;Facial recognition&quot; does not include facial verification technology, which involves the process of comparing an image or facial biometric data of a known individual, where such information is provided by that individual, to an image database, or to government documentation containing an image of the known individual, to identify a potential match in pursuit of the individual&#39;s identity.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Foundation model&quot; means a machine learning model that (i) is trained on broad data at scale, (ii) is designed for generality of output, and (iii) can be adapted to a wide range of distinctive tasks.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;General-purpose artificial intelligence model&quot; means any form of artificial intelligence system that (i) displays significant generality, (ii) is capable of competently performing a wide range of distinct tasks, and (iii) can be integrated into a variety of downstream applications or systems. &quot;General-purpose artificial intelligence model&quot; does not include any artificial intelligence model that is used for development, prototyping, or research activities before such artificial intelligence model is released on the market.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Generative artificial intelligence&quot; means artificial intelligence based on a foundation model that is capable of and used to produce synthetic digital content, including audio, images, text, and videos.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Generative artificial intelligence system&quot; means any artificial intelligence system or service that incorporates generative artificial intelligence.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;High-risk artificial intelligence system&quot; means any artificial intelligence system that is specifically intended to autonomously make, or be a substantial factor in making, a consequential decision. A system or service is not a &quot;high-risk artificial intelligence system&quot; if it is intended to (i) perform a narrow procedural task, (ii) improve the result of a previously completed human activity, (iii) detect decision-making patterns or deviations from prior decision-making patterns and is not meant to replace or influence the previously completed human assessment without sufficient human review, or (iv) perform a preparatory task to an assessment relevant to a consequential decision. There is a rebuttable presumption that &quot;high-risk artificial intelligence system&quot; does not include any of the following technologies:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">1. Anti-fraud technology that does not use facial recognition technology;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">2. Anti-malware technology;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">3. Anti-virus technology;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">4. Artificial intelligence-enabled video games;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">5. Calculators;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">6. Cybersecurity technology;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">7. Databases;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">8. Data storage;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">9. Firewall technology;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">10. Internet domain registration;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">11. Internet website loading;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">12. Networking;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">13. Spam and robocall filtering;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">14. Spell-checking technology;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">15. Spreadsheets;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">16. Web caching;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">17. Web hosting or any similar technology; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">18. Technology that communicates with consumers in natural language for the purpose of providing users with information, making referrals or recommendations, and answering questions and is subject to an accepted use policy that prohibits generating content that is discriminatory or harmful.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Integrator&quot; means a public body that knowingly integrates an artificial intelligence system into a software application and places such software application on the market or makes such software application available for public use. An &quot;integrator&quot; does not include a public body offering information technology infrastructure.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Intentional and substantial modification&quot; means any deliberate change made to (i) an artificial intelligence system that results in any new reasonably foreseeable risk of algorithmic discrimination or (ii) a general-purpose artificial intelligence model that affects compliance of the general-purpose artificial intelligence model, materially changes the purpose of the general-purpose artificial intelligence model, or results in any new reasonably foreseeable risk of algorithmic discrimination. &quot;Intentional and substantial modification&quot; does not include any change made to a high-risk artificial intelligence system, or the performance of a high-risk artificial intelligence system, if (a) the high-risk artificial intelligence system continues to learn after such high-risk artificial intelligence system is offered, sold, leased, licensed, given, or otherwise made available to a deployer, or deployed, and (b) such change (1) is made to such high-risk artificial intelligence system as a result of any learning described in clause (a), and (2) was predetermined by the deployer or the third party contracted by the deployer when such deployer or third party completed the initial impact assessment of such high-risk artificial intelligence system as required in &sect; 2.2-5519.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Machine learning&quot; means the development of algorithms to build data-derived statistical models that are capable of drawing inferences from previously unseen data without explicit human instruction.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Public body&quot; means any authority, board, department, instrumentality, agency, or other unit of state government. &quot;Public body&quot; does not include any county, city, or town; or any local or regional governmental authority.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Significant update&quot; means any new version, new release, or other update to a high-risk artificial intelligence system that results in significant changes to such high-risk artificial intelligence system&#39;s use case or key functionality and that results in any new or reasonably foreseeable risk of algorithmic discrimination.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Substantial factor&quot; means a factor that (i) assists in making a consequential decision, (ii) is capable of altering the outcome of a consequential decision, and (iii) is generated by an artificial intelligence system. &quot;Substantial factor&quot; includes any use of an artificial intelligence system to generate any content, decision, prediction, or recommendation concerning a consumer that is used as a basis to make a consequential decision concerning the consumer.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Synthetic digital content&quot; means any digital content, including any audio, image, text, or video, that is produced or manipulated by a generative artificial intelligence system, including a general-purpose artificial intelligence model.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Trade secret&quot; means information, including a formula, pattern, compilation, program, device, method, technique, or process, that (i) derives independent economic value, actual or potential, from not being generally known to, and not being readily ascertainable by proper means by, other persons who can obtain economic value from its disclosure or use and (ii) is the subject of efforts that are reasonable under the circumstances to maintain its secrecy.</u>\n   </p>\n   <p class=\"indent\">\n    <b>\n     <u class=\"amendmentInsertedText\">&sect; 2.2-5518. Operating standards for public bodies developing high-risk artificial intelligence systems.</u>\n    </b>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">A. No developer of a high-risk artificial intelligence system shall offer, sell, lease, give, or otherwise provide to a deployer a high-risk artificial intelligence system unless the developer makes available to the deployer:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">1. A statement disclosing the intended uses of such high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">2. Documentation disclosing the following:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">a. The known or reasonably known limitations of such high-risk artificial intelligence system, including any and all known or reasonably foreseeable risks of algorithmic discrimination arising from the intended uses of such high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">b. The purpose of such high-risk artificial intelligence system and the intended benefits and uses of such high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">c. A summary describing how such high-risk artificial intelligence system was evaluated for performance and relevant information related to explainability before such high-risk artificial intelligence system was licensed, sold, given, or otherwise made available to a developer;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">d. The measures the developer has taken to mitigate reasonable foreseeable risks of algorithmic discrimination that the developer knows arises from deployment or use of such high-risk artificial intelligence system; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">e. How an individual can use such high-risk artificial intelligence system to make, or monitor such high-risk artificial intelligence system when such high-risk artificial intelligence system is deployed or used to make, a consequential decision;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">3. Documentation describing (i) how the high-risk artificial intelligence system was evaluated for performance and for mitigation of algorithmic discrimination before such system was made available to the deployer; (ii) the data governance measures used to cover the training data sets and the measures used to examine the suitability of data sources, possible biases of data sources, and appropriate mitigation; (iii) the intended outputs of the high-risk artificial intelligence system; (iv) the measures the developer has taken to mitigate known or reasonably foreseeable risks of algorithmic discrimination that may arise from the reasonably foreseeable deployment of the high-risk artificial intelligence system; and (v) how the high-risk artificial intelligence system should be used, not be used, and be monitored by an individual when such system is used to make, or is a substantial factor in making, a consequential decision; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">4. Any additional documentation that is reasonably necessary to assist the deployer in understanding the outputs and monitoring performance of the high-risk artificial intelligence system for risks of algorithmic discrimination.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">B. Each developer that offers, sells, leases, gives, or otherwise makes available to a deployer a high-risk artificial intelligence system shall make available to the deployer information and documentation in the developer&#39;s possession, custody, or control that is reasonably required to complete an impact assessment as required in &sect; 2.2-5519.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">C. A developer that also serves as a deployer for any high-risk artificial intelligence system shall not be required to generate the documentation required by this section unless such high-risk artificial intelligence system is provided to an unaffiliated entity acting as a deployer or as otherwise required by law.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">D. Nothing in this section shall be construed to require a developer to disclose any trade secret.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">E. High-risk artificial intelligence systems that are in conformity with the latest version of the Artificial Intelligence Risk Management Framework published by the National Institute of Standards and Technology, Standard ISO/IEC 42001 of the International Organization for Standardization, or another nationally or internationally recognized risk management framework for artificial intelligence systems, or parts thereof, shall be presumed to be in conformity with related requirements set out in this section and in associated regulations.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">F. For any disclosure required pursuant to this section, each developer shall, no later than 90 days after the developer performs an intentional and substantial modification to any high-risk artificial intelligence system, update such disclosure as necessary to ensure that such disclosure remains accurate.</u>\n   </p>\n   <p class=\"indent\">\n    <b>\n     <u class=\"amendmentInsertedText\">&sect; 2.2-5519. Operating standards for public bodies deploying high-risk artificial intelligence systems.</u>\n    </b>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">A. No deployer shall deploy or use a high-risk artificial intelligence system to make a consequential decision unless the deployer has designed and implemented a risk management policy and program for such high-risk artificial intelligence system. The risk management policy shall specify the principles, processes, and personnel that the deployer shall use in maintaining the risk management program to identify, mitigate, and document any risk of algorithmic discrimination that is a reasonably foreseeable consequence of deploying or using such high-risk artificial intelligence system to make a consequential decision. Each risk management policy and program designed, implemented, and maintained pursuant to this subsection shall be (i) at least as stringent as the latest version of the Artificial Intelligence Risk Management Framework published by the National Institute of Standards and Technology, Standard ISO/IEC 42001 of the International Organization for Standardization, or another nationally or internationally recognized risk management framework for artificial intelligence systems and (ii) reasonable considering (a) the size and complexity of the deployer; (b) the nature and scope of the high-risk artificial intelligence systems deployed and used by the deployer, including the intended uses of such high-risk artificial intelligence systems; (c) the sensitivity and volume of data processed in connection with the high-risk artificial intelligence systems deployed and used by the deployer; and (d) the cost to the deployer to implement and maintain such risk management program.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">B. Except as provided in this subsection, no deployer shall deploy or use a high-risk artificial intelligence system to make a consequential decision unless the deployer has completed an impact assessment for such high-risk artificial intelligence system. The deployer shall complete an impact assessment for a high-risk artificial intelligence system (i) before the deployer initially deploys such high-risk artificial intelligence system and (ii) not later than 90 days after each significant update to such high-risk artificial intelligence system is made available.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">Each impact assessment completed pursuant to this subsection shall include, at a minimum:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">1. A statement by the deployer disclosing (i) the purpose, intended use cases and deployment context of, and benefits afforded by the high-risk artificial intelligence system and (ii) whether the deployment or use of the high-risk artificial intelligence system poses a reasonably foreseeable risk of algorithmic discrimination and, if so, (a) the nature of such algorithmic discrimination and (b) the steps that have been taken, to the extent feasible, to mitigate such risk;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">2. For each post-deployment impact assessment completed pursuant to this subsection, whether the intended use cases of the high-risk artificial intelligence system as updated were consistent with, or varied from, the developer&#39;s intended uses of such high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">3. A description of (i) the categories of data the high-risk artificial intelligence system processes as inputs and (ii) the outputs such high-risk artificial intelligence system produces;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">4. If the deployer used data to customize the high-risk artificial intelligence system, an overview of the categories of data the deployer used to customize such high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">5. A list of any metrics used to evaluate the performance and known limitations of the high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">6. A description of any transparency measures taken concerning the high-risk artificial intelligence system, including any measures taken to disclose to a consumer that such high-risk artificial intelligence system is in use when such high-risk artificial intelligence system is in use; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">7. A description of any post-deployment monitoring performed and user safeguards provided concerning such high-risk artificial intelligence system, including any oversight process established by the deployer to address issues arising from deployment or use of such high-risk artificial intelligence system as such issues arise.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">A single impact assessment may address a comparable set of high-risk artificial intelligence systems deployed or used by a deployer. High-risk artificial intelligence systems that are in conformity with the latest version of the Artificial Intelligence Risk Management Framework published by the National Institute of Standards and Technology, Standard ISO/IEC 42001 of the International Organization for Standardization, or another nationally or internationally recognized risk management framework for artificial intelligence systems, or parts thereof, shall be presumed to be in conformity with related requirements set out in this section and in associated regulations. If a deployer completes an impact assessment for the purpose of complying with another applicable law or regulation, such impact assessment shall be deemed to satisfy the requirements established in this subsection if such impact assessment is reasonably similar in scope and effect to the impact assessment that would otherwise be completed pursuant to this subsection. A deployer that completes an impact assessment pursuant to this subsection shall maintain such impact assessment and all records concerning such impact assessment for five years.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">C. Not later than the time that a deployer uses a high-risk artificial intelligence system to make a consequential decision concerning a consumer, the deployer shall notify the consumer that the deployer is using a high-risk artificial intelligence system to make such consequential decision concerning such consumer and provide to the consumer a statement disclosing (i) the purpose of such high-risk artificial intelligence system, (ii) the nature of such system, (iii) the nature of the consequential decision, (iv) the contact information for the deployer, and (v) a description in plain language of such system.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">If such consequential decision is adverse to such consumer, the deployer shall provide to the consumer (a) a statement disclosing the principal reason or reasons for the consequential decision, including (1) the degree to which and manner in which the high-risk artificial intelligence system contributed to the consequential decision, (2) the type of data that was processed by such system in making the consequential decision, and (3) the sources of such data; (b) an opportunity to correct any incorrect personal data that the high-risk artificial intelligence system processed in making, or as a substantial factor in making, the consequential decision; and (c) an opportunity to appeal such adverse consequential decision concerning the consumer arising from the deployment of such system. Any such appeal shall allow for human review, if technically feasible, unless providing the opportunity for appeal is not in the best interest of the consumer, including instances in which any delay might pose a risk to the life or safety of such consumer.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">D. Each deployer shall make available, in a manner that is clear and readily available, a statement summarizing how such deployer manages any reasonably foreseeable risk of algorithmic discrimination that may arise from the use or deployment of the high-risk artificial intelligence system.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">E. For any disclosure required pursuant to this section, each deployer shall, no later than 90 days after the developer performs an intentional and substantial modification to any high-risk artificial intelligence system, update such disclosure as necessary to ensure that such disclosure remains accurate.</u>\n   </p>\n   <p class=\"indent\">\n    <b>\n     <u class=\"amendmentInsertedText\">&sect; 2.2-5520. Operating standards for public bodies integrating high-risk artificial intelligence systems.</u>\n    </b>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">Each integrator of a high-risk artificial intelligence system shall develop and adopt an acceptable use policy, which shall limit the use of the high-risk artificial intelligence system to mitigate known risks of algorithmic discrimination.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">Each integrator of a high-risk artificial intelligence system shall provide to the deployer clear, conspicuous notice of (i) the name or other identifier of the high-risk artificial intelligence system integrated into a software application provided to the deployer; (ii) the name and contact information of the developer of the high-risk artificial intelligence system integrated into a software application provided to the deployer; (iii) whether the integrator has adjusted the model weights of the high-risk artificial intelligence system integrated into the software application by exposing it to additional data, a summary of the adjustment process, and how such process and the resulting system were evaluated for risk of algorithmic discrimination; (iv) a summary of any other non-substantial modifications made by the integrator; and (v) the integrator&#39;s acceptable use policy.</u>\n   </p>\n   <p class=\"indent\">\n    <b>\n     <u class=\"amendmentInsertedText\">&sect; 2.2-5521. Exemptions.</u>\n    </b>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">A. Nothing in this chapter shall be construed to restrict a developer&#39;s, integrator&#39;s, or deployer&#39;s ability to (i) comply with federal, state, or municipal ordinances or regulations; (ii) comply with a civil, criminal, or regulatory inquiry, investigation, subpoena, or summons by federal, state, local, or other governmental authorities; (iii) cooperate with law-enforcement agencies concerning conduct or activity that the developer, integrator, or deployer reasonably and in good faith believes may violate federal, state, or local law, ordinances, or regulations; (iv) investigate, establish, exercise, prepare for, or defend legal claims; (v) provide a product or service specifically requested by a consumer; (vi) perform under a contract to which a consumer is a party, including fulfilling the terms of a written warranty; (vii) take steps at the request of a consumer prior to entering into a contract; (viii) take immediate steps to protect an interest that is essential for the life or physical safety of the consumer or another individual; (ix) prevent, detect, protect against, or respond to security incidents, identity theft, fraud, harassment, or malicious or deceptive activities; (x) take actions to prevent, detect, protect against, report, or respond to the production, generation, incorporation, or synthesization of child sex abuse material, or any illegal activity, preserve the integrity or security of systems, or investigate, report, or prosecute those responsible for any such action; (xi) engage in public or peer-reviewed scientific or statistical research in the public interest that adheres to all other applicable ethics and privacy laws and is approved, monitored, and governed by an institutional review board that determines, or similar independent oversight entities that determine, (a) that the expected benefits of the research outweigh the risks associated with such research and (b) whether the developer, integrator, or deployer has implemented reasonable safeguards to mitigate the risks associated with such research; (xii) assist another developer, integrator, or deployer with any of the obligations imposed by this chapter; or (xiii) take any action that is in the public interest in the areas of public health, community health, or population health, but solely to the extent that such action is subject to suitable and specific measures to safeguard the public.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">B. The obligations imposed on developers, integrators, or deployers by this chapter shall not restrict a developer&#39;s, integrator&#39;s, or deployer&#39;s ability to (i) conduct internal research to develop, improve, or repair products, services, or technologies; (ii) effectuate a product recall; (iii) identify and repair technical errors that impair existing or intended functionality; or (iv) perform internal operations that are reasonably aligned with the expectations of the consumer or reasonably anticipated based on the consumer&#39;s existing relationship with the developer, integrator, or deployer.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">C. Nothing in this chapter shall be construed to impose any obligation on a developer, integrator, or deployer to disclose trade secrets.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">D. The obligations imposed on developers, integrators, or deployers by this chapter shall not apply where compliance by the developer, integrator, or deployer with such obligations would violate an evidentiary privilege under the laws of the Commonwealth.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">E. Nothing in this chapter shall be construed to impose any obligation on a developer, integrator, or deployer that adversely affects the legally protected rights or freedoms of any person, including the rights of any person to freedom of speech or freedom of the press guaranteed in the First Amendment to the Constitution of the United States or under the Virginia Human Rights Act (&sect; 2.2-3900 et seq.).</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">F. If a developer, integrator, or deployer engages in any action authorized by an exemption set forth in this section, the developer, integrator, or deployer bears the burden of demonstrating that such action qualifies for such exemption.</u>\n   </p>\n   <p class=\"indent\">\n    <b>\n     <u class=\"amendmentInsertedText\">&sect; 2.2-5522. Additional requirements.</u>\n    </b>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">A. A public body shall not implement any system that employs high-risk artificial intelligence systems unless it has fulfilled the requirements of this section and complied with the provisions of this chapter and the high-risk artificial intelligence policies and procedures developed by the Chief Information Officer of the Commonwealth pursuant to subdivision B 10 of &sect; 2.2-2007.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">B. A public body procuring any system that employs high-risk artificial intelligence systems shall in all future contracts for the procurement of such systems for which negotiation or renegotiation is begun on or after July 1, 2026, include a high-risk artificial intelligence system compliance clause, as developed by the Chief Information Officer of the Commonwealth pursuant to &sect; 2.2-2007.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">C. Prior to implementing any system that employs high-risk artificial intelligence systems, the public body shall comply with the impact assessment requirements of &sect; 2.2-5519. A public body shall additionally perform ongoing assessments of such system after implementation. If the public body, or the head of the public body, determines, in its discretion, that such system does not comply with such requirements, the public body shall not implement such system or shall cease to use such system to the extent such system does not comply with such requirements.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">D. All public bodies that implement high-risk artificial intelligence systems shall annually report on initial and ongoing system assessments and provide an inventory of such systems used. Public bodies in the legislative branch shall submit such report and inventory to the General Assembly. Public bodies in the judicial branch shall submit such report and inventory to the Executive Secretary of the Supreme Court of Virginia. Public bodies in the executive branch and any other public bodies not specified in this subsection shall submit such report and inventory to the Chief Information Officer of the Commonwealth. Such report and inventory shall be transmitted to the appropriate entity annually.</u>\n   </p>\n   <p class=\"indent\">\n    <b>2. That the Chief Information Officer of the Commonwealth (CIO) shall convene a work group to examine the impact on and the ability of local governments to comply with the requirements of this act. The work group shall consist of a representative from the Virginia Association of Counties who is also a representative of a member county, a representative from the Virginia Municipal League who is also a representative of a member locality, a representative of the Virginia Association of Chiefs of Police, a representative from the Virginia Association of Commonwealth&#39;s Attorneys, the chief information officer of a school division, the chief information officer of a county, the chief information officer of a city, a representative from the Department of Human Resource Management, a representative of a regional technology council, a member of the Joint Commission on Technology and Science (JCOTS) who is a member of the House of Delegates, and a member of JCOTS who is a member of the Senate. The CIO shall submit a report of the work group&#39;s findings to JCOTS no later than December 1, 2025.</b>\n   </p>\n   <p class=\"indent\">\n    <b>3. That the provisions of the first enactment of this act shall become effective on July 1, 2026.</b>\n   </p>\n  </div>\n </div>\n    </div>\t\n<table cellpadding=0 cellspacing=0 width=\"100%\">\n   <tr>\n      <td>\n          Copyright &copy; 2025 State Net\n      </td>\n<BR>\n<!--???MOVED INTO resources.cgi      <td align=\"right\">\n          <img src=\"https://custom.statenet.com/network/poweredby.gif\" alt=\"Powered by State Net\">\n      </td>-->\n\n    </tr>\n</table>\n</body></html>\n",
      "markdown": "The following has special meaning: _green underline denotes added text_ ~~red struck out text denotes deleted text~~ | [![Powered by State Net](https://custom.statenet.com/network/poweredby.gif)](https://www.lexisnexis.com/statenet/)  \n---|---  \n  \n2024 VA S 1214 | | Author: | Aird  \n---|---  \nVersion: | Recommended as Substituted from Committee  \nVersion Date: | 01/24/2025  \n  \n**2025 SESSION**\n\n25106036D\n\n**SENATE SUBSTITUTE**\n\n**SENATE BILL NO. 1214**\n\nAMENDMENT IN THE NATURE OF A SUBSTITUTE\n\n(Proposed by the Senate Committee on General Laws and Technology\n\non January 24, 2025)\n\n(Patron Prior to Substitute Senator Aird)\n\n_A BILL to amend and reenact  2.2-2007 of the Code of Virginia and to amend\nthe Code of Virginia by adding in Title 2.2 a chapter numbered 55.6,\nconsisting of sections numbered 2.2-5517 through 2.2-5522, relating to high-\nrisk artificial intelligence; development, deployment, and use by public\nbodies; work group; report._\n\n**Be it enacted by the General Assembly of Virginia:**\n\n**1\\. That  2.2-2007 of the Code of Virginia is amended and reenacted and\nthat the Code of Virginia is amended by adding in Title 2.2 a chapter numbered\n55.6, consisting of sections numbered 2.2-5517 through 2.2-5522, as follows:**\n\n** 2.2-2007. Powers of the CIO.**\n\nA. The CIO shall promulgate regulations necessary or incidental to the\nperformance of duties or execution of powers conferred under this chapter. The\nCIO shall also develop policies, standards, and guidelines for the planning,\nbudgeting, procurement, development, maintenance, security, and operations of\ninformation technology for executive branch agencies. Such policies,\nstandards, and guidelines shall include those necessary to:\n\n1\\. Support state and local government exchange, acquisition, storage, use,\nsharing, and distribution of data and related technologies.\n\n2\\. Support the development of electronic transactions _,_ including the use\nof electronic signatures as provided in  59.1-496.\n\n3\\. Support a unified approach to information technology across the totality\nof state government, thereby assuring that the citizens and businesses of the\nCommonwealth receive the greatest possible security, value, and convenience\nfrom investments made in technology.\n\n4\\. Ensure that the costs of information technology systems, products, data,\nand services are contained through the shared use of existing or planned\nequipment, data, or services.\n\n5\\. Provide for the effective management of information technology investments\nthrough their entire life cycles, including identification, business case\ndevelopment, selection, procurement, implementation, operation, performance\nevaluation, and enhancement or retirement. Such policies, standards, and\nguidelines shall include, at a minimum, the periodic review by the CIO of\nagency Commonwealth information technology projects.\n\n6\\. Establish an Information Technology Investment Management Standard based\non acceptable technology investment methods to ensure that all executive\nbranch agency technology expenditures are an integral part of the\nCommonwealth's performance management system, produce value for the agency and\nthe Commonwealth, and are aligned with (i) agency strategic plans, (ii) the\nGovernor's policy objectives, and (iii) the long-term objectives of the\nCouncil on Virginia's Future.\n\nB. In addition to other such duties as the Secretary may assign, the CIO\nshall:\n\n1\\. Oversee and administer the Virginia Technology Infrastructure Fund created\npursuant to  2.2-2023.\n\n2\\. Report annually to the Governor, the Secretary, and the Joint Commission\non Technology and Science created pursuant to  30-85 on the use and\napplication of information technology by executive branch agencies to increase\neconomic efficiency, citizen convenience, and public access to state\ngovernment.\n\n3\\. Prepare annually a report for submission to the Secretary, the Information\nTechnology Advisory Council, and the Joint Commission on Technology and\nScience on a prioritized list of Recommended Technology Investment Projects\n(RTIP Report) based upon major information technology projects submitted for\nbusiness case approval pursuant to this chapter. As part of the RTIP Report,\nthe CIO shall develop and regularly update a methodology for prioritizing\nprojects based upon the allocation of points to defined criteria. The criteria\nand their definitions shall be presented in the RTIP Report. For each project\nrecommended for funding in the RTIP Report, the CIO shall indicate the number\nof points and how they were awarded. For each listed project, the CIO shall\nalso report (i) all projected costs of ongoing operations and maintenance\nactivities of the project for the next three biennia following project\nimplementation; (ii) a justification and description for each project baseline\nchange; and (iii) whether the project fails to incorporate existing standards\nfor the maintenance, exchange, and security of data. This report shall also\ninclude trends in current projected information technology spending by\nexecutive branch agencies and secretariats, including spending on projects,\noperations and maintenance, and payments to VITA. Agencies shall provide all\nproject and cost information required to complete the RTIP Report to the CIO\nprior to May 31 immediately preceding any budget biennium in which the project\nappears in the Governor's budget bill.\n\n4\\. Provide oversight for executive branch agency efforts to modernize the\nplanning, development, implementation, improvement, operations and\nmaintenance, and retirement of Commonwealth information technology, including\noversight for the selection, development and management of enterprise\ninformation technology.\n\n5\\. Develop statewide technical and data standards and specifications for\ninformation technology and related systems, including (i) the efficient\nexchange of electronic information and technology, including infrastructure,\nbetween the public and private sectors in the Commonwealth and (ii) the\nutilization of nationally recognized technical and data standards for health\ninformation technology systems or software purchased by an executive branch\nagency.\n\n6\\. Direct the compilation and maintenance of an inventory of information\ntechnology, including but not limited to personnel, facilities, equipment,\ngoods, and contracts for services.\n\n7\\. Provide for the centralized marketing, provision, leasing, and executing\nof licensing agreements for electronic access to public information and\ngovernment services through the Internet, wireless devices, personal digital\nassistants, kiosks, or other such related media on terms and conditions as may\nbe determined to be in the best interest of the Commonwealth. VITA may fix and\ncollect fees and charges for (i) public information, media, and other\nincidental services furnished by it to any private individual or entity,\nnotwithstanding the charges set forth in  2.2-3704, and (ii) such use and\nservices it provides to any executive branch agency or local government.\nNothing in this subdivision authorizing VITA to fix and collect fees for\nproviding information services shall be construed to prevent access to the\npublic records of any public body pursuant to the provisions of the Virginia\nFreedom of Information Act ( 2.2-3700 et seq.). VITA is authorized, subject\nto the approval by the Secretary of Administration and any other affected\nSecretariat, to delegate the powers and responsibilities granted in this\nsubdivision to any agency within the executive branch.\n\n8\\. Periodically evaluate the feasibility of outsourcing information\ntechnology resources and services, and outsource those resources and services\nthat are feasible and beneficial to the Commonwealth.\n\n9\\. Have the authority to enter into and amend contracts, including contracts\nwith one or more other public bodies, or public agencies or institutions or\nlocalities of the several states, of the United States or its territories, or\nthe District of Columbia, for the provision of information technology\nservices.\n\n_10\\. Develop, publish, and maintain policies and procedures concerning the\ndevelopment, procurement, implementation, utilization, and ongoing assessment\nof systems that employ high-risk artificial intelligence systems, as defined\nin  2.2-5517, and are in use by public bodies, consistent with the provisions\nof Chapter 55.6 ( 2.2-5517 et seq.). Such policies and procedures shall, at a\nminimum, (i) govern the procurement, implementation, and ongoing assessment of\nany such system by a public body; (ii) address and provide resources regarding\ndata security and privacy issues that may arise from the development and\ndeployment of high-risk artificial intelligence systems by public bodies;\n(iii) be sufficient to ensure that no such system results in any algorithmic\ndiscrimination, as defined in  2.2-5517; (iv) create guidelines for\nacceptable use policies for public bodies integrating high-risk artificial\nintelligence systems pursuant to  2.2-5520; and (v) require a public body to\nassess the likely impact of any such system before implementing such system\nand perform ongoing assessments of such system to ensure that no such system\nresults in any such algorithmic discrimination, as defined in  2.2-5517. Such\npolicies and procedures shall include a requirement that a high-risk\nartificial intelligence system compliance clause be included in procurement\ncontracts for systems that use a high-risk artificial intelligence system for\nwhich negotiation or renegotiation is begun on or after July 1, 2026,\nrequiring compliance with the provisions of Chapter 55.6 ( 2.2-5517 et seq.)\nand any other applicable state law governing the development or deployment of\nhigh-risk artificial intelligence systems, as applicable._\n\nC. Consistent with  2.2-2012, the CIO may enter into public-private\npartnership contracts to finance or implement information technology programs\nand projects. The CIO may issue a request for information to seek out\npotential private partners interested in providing programs or projects\npursuant to an agreement under this subsection. The compensation for such\nservices shall be computed with reference to and paid from the increased\nrevenue or cost savings attributable to the successful implementation of the\nprogram or project for the period specified in the contract. The CIO shall be\nresponsible for reviewing and approving the programs and projects and the\nterms of contracts for same under this subsection. The CIO shall determine\nannually the total amount of increased revenue or cost savings attributable to\nthe successful implementation of a program or project under this subsection\nand such amount shall be deposited in the Virginia Technology Infrastructure\nFund created in  2.2-2023. The CIO is authorized to use moneys deposited in\nthe Fund to pay private partners pursuant to the terms of contracts under this\nsubsection. All moneys in excess of that required to be paid to private\npartners, as determined by the CIO, shall be reported to the Comptroller and\nretained in the Fund. The CIO shall prepare an annual report to the Governor,\nthe Secretary, and General Assembly on all contracts under this subsection,\ndescribing each information technology program or project, its progress,\nrevenue impact, and such other information as may be relevant.\n\nD. Executive branch agencies shall cooperate with VITA in identifying the\ndevelopment and operational requirements of proposed information technology\nsystems, products, data, and services, including the proposed use,\nfunctionality, and capacity, and the total cost of acquisition, operation, and\nmaintenance.\n\n_CHAPTER 55.6._\n\n_USE OF HIGH-RISK ARTIFICIAL INTELLIGENCE SYSTEMS._\n\n**_ 2.2-5517. Definitions._ **\n\n_As used in this chapter, unless the context requires a different meaning:_\n\n_\" Algorithmic discrimination\" means any discrimination that results in an\nunlawful differential treatment or impact that disfavors an individual or\ngroup of individuals on the basis of their actual or perceived age, color,\ndisability, ethnicity, genetic information, limited proficiency in the English\nlanguage, national origin, race, religion, reproductive health, sex, sexual\norientation, veteran status, or other classification protected under state or\nfederal law. \"Algorithmic discrimination\" does not include (i) the offer,\nlicense, or use of a high-risk artificial intelligence system by a developer,\nintegrator, or deployer for the sole purpose of the developer's, integrator's,\nor deployer's self-testing to identify, mitigate, or prevent discrimination or\notherwise ensure compliance with state and federal law or (ii) the expansion\nof an applicant, customer, or participant pool to increase diversity or\nredress historical discrimination._\n\n_\" Artificial intelligence\" means a set of technologies that enables machines\nto perform tasks under varying and unpredictable circumstances that typically\nrequire human oversight or intelligence, or that can learn from experience and\nimprove performance when exposed to data set_ ~~s~~ _._\n\n_\" Artificial intelligence system\" means any machine-based system that, for\nany explicit or implicit objective, infers from the inputs such system\nreceives how to generate outputs, including content, decisions, predictions,\nand recommendations, that can influence physical or virtual environments._\n\n_\" Consequential decision\" means any decision that has a material legal, or\nsimilarly significant, effect on the provision or denial to any consumer of,\nor the cost or terms of, (i) education enrollment or an education opportunity,\n(ii) employment or an employment opportunity, (iii) a financial or lending\nservice, (iv) an essential government service, (v) health care services, (vi)\nhousing, (vii) insurance, or (viii) a legal service._\n\n_\" Consumer\" means a natural person acting only in an individual or household\ncontext. \"Consumer\" does not include a natural person acting in a commercial\nor employment context._\n\n_\" Deployer\" means any public body that deploys or uses a high-risk artificial\nintelligence system to make a consequential decision._\n\n_\" Developer\" means any public body that develops or intentionally and\nsubstantially modifies a high-risk artificial intelligence system that is\noffered, sold, leased, given, or otherwise provided to consumers in the\nCommonwealth._\n\n_\" Facial recognition\" means the use of a computer system that, for the\npurpose of attempting to determine the identity of an unknown individual, uses\nan algorithm to compare the facial biometric data of an unknown individual\nderived from a photograph, video, or image to a database of photographs or\nimages and associated facial biometric data in order to identify potential\nmatches to an individual. \"Facial recognition\" does not include facial\nverification technology, which involves the process of comparing an image or\nfacial biometric data of a known individual, where such information is\nprovided by that individual, to an image database, or to government\ndocumentation containing an image of the known individual, to identify a\npotential match in pursuit of the individual's identity._\n\n_\" Foundation model\" means a machine learning model that (i) is trained on\nbroad data at scale, (ii) is designed for generality of output, and (iii) can\nbe adapted to a wide range of distinctive tasks._\n\n_\" General-purpose artificial intelligence model\" means any form of artificial\nintelligence system that (i) displays significant generality, (ii) is capable\nof competently performing a wide range of distinct tasks, and (iii) can be\nintegrated into a variety of downstream applications or systems. \"General-\npurpose artificial intelligence model\" does not include any artificial\nintelligence model that is used for development, prototyping, or research\nactivities before such artificial intelligence model is released on the\nmarket._\n\n_\" Generative artificial intelligence\" means artificial intelligence based on\na foundation model that is capable of and used to produce synthetic digital\ncontent, including audio, images, text, and videos._\n\n_\" Generative artificial intelligence system\" means any artificial\nintelligence system or service that incorporates generative artificial\nintelligence._\n\n_\" High-risk artificial intelligence system\" means any artificial intelligence\nsystem that is specifically intended to autonomously make, or be a substantial\nfactor in making, a consequential decision. A system or service is not a\n\"high-risk artificial intelligence system\" if it is intended to (i) perform a\nnarrow procedural task, (ii) improve the result of a previously completed\nhuman activity, (iii) detect decision-making patterns or deviations from prior\ndecision-making patterns and is not meant to replace or influence the\npreviously completed human assessment without sufficient human review, or (iv)\nperform a preparatory task to an assessment relevant to a consequential\ndecision. There is a rebuttable presumption that \"high-risk artificial\nintelligence system\" does not include any of the following technologies:_\n\n_1\\. Anti-fraud technology that does not use facial recognition technology;_\n\n_2\\. Anti-malware technology;_\n\n_3\\. Anti-virus technology;_\n\n_4\\. Artificial intelligence-enabled video games;_\n\n_5\\. Calculators;_\n\n_6\\. Cybersecurity technology;_\n\n_7\\. Databases;_\n\n_8\\. Data storage;_\n\n_9\\. Firewall technology;_\n\n_10\\. Internet domain registration;_\n\n_11\\. Internet website loading;_\n\n_12\\. Networking;_\n\n_13\\. Spam and robocall filtering;_\n\n_14\\. Spell-checking technology;_\n\n_15\\. Spreadsheets;_\n\n_16\\. Web caching;_\n\n_17\\. Web hosting or any similar technology; or_\n\n_18\\. Technology that communicates with consumers in natural language for the\npurpose of providing users with information, making referrals or\nrecommendations, and answering questions and is subject to an accepted use\npolicy that prohibits generating content that is discriminatory or harmful._\n\n_\" Integrator\" means a public body that knowingly integrates an artificial\nintelligence system into a software application and places such software\napplication on the market or makes such software application available for\npublic use. An \"integrator\" does not include a public body offering\ninformation technology infrastructure._\n\n_\" Intentional and substantial modification\" means any deliberate change made\nto (i) an artificial intelligence system that results in any new reasonably\nforeseeable risk of algorithmic discrimination or (ii) a general-purpose\nartificial intelligence model that affects compliance of the general-purpose\nartificial intelligence model, materially changes the purpose of the general-\npurpose artificial intelligence model, or results in any new reasonably\nforeseeable risk of algorithmic discrimination. \"Intentional and substantial\nmodification\" does not include any change made to a high-risk artificial\nintelligence system, or the performance of a high-risk artificial intelligence\nsystem, if (a) the high-risk artificial intelligence system continues to learn\nafter such high-risk artificial intelligence system is offered, sold, leased,\nlicensed, given, or otherwise made available to a deployer, or deployed, and\n(b) such change (1) is made to such high-risk artificial intelligence system\nas a result of any learning described in clause (a), and (2) was predetermined\nby the deployer or the third party contracted by the deployer when such\ndeployer or third party completed the initial impact assessment of such high-\nrisk artificial intelligence system as required in  2.2-5519._\n\n_\" Machine learning\" means the development of algorithms to build data-derived\nstatistical models that are capable of drawing inferences from previously\nunseen data without explicit human instruction._\n\n_\" Public body\" means any authority, board, department, instrumentality,\nagency, or other unit of state government. \"Public body\" does not include any\ncounty, city, or town; or any local or regional governmental authority._\n\n_\" Significant update\" means any new version, new release, or other update to\na high-risk artificial intelligence system that results in significant changes\nto such high-risk artificial intelligence system's use case or key\nfunctionality and that results in any new or reasonably foreseeable risk of\nalgorithmic discrimination._\n\n_\" Substantial factor\" means a factor that (i) assists in making a\nconsequential decision, (ii) is capable of altering the outcome of a\nconsequential decision, and (iii) is generated by an artificial intelligence\nsystem. \"Substantial factor\" includes any use of an artificial intelligence\nsystem to generate any content, decision, prediction, or recommendation\nconcerning a consumer that is used as a basis to make a consequential decision\nconcerning the consumer._\n\n_\" Synthetic digital content\" means any digital content, including any audio,\nimage, text, or video, that is produced or manipulated by a generative\nartificial intelligence system, including a general-purpose artificial\nintelligence model._\n\n_\" Trade secret\" means information, including a formula, pattern, compilation,\nprogram, device, method, technique, or process, that (i) derives independent\neconomic value, actual or potential, from not being generally known to, and\nnot being readily ascertainable by proper means by, other persons who can\nobtain economic value from its disclosure or use and (ii) is the subject of\nefforts that are reasonable under the circumstances to maintain its secrecy._\n\n**_ 2.2-5518. Operating standards for public bodies developing high-risk\nartificial intelligence systems._ **\n\n_A. No developer of a high-risk artificial intelligence system shall offer,\nsell, lease, give, or otherwise provide to a deployer a high-risk artificial\nintelligence system unless the developer makes available to the deployer:_\n\n_1\\. A statement disclosing the intended uses of such high-risk artificial\nintelligence system;_\n\n_2\\. Documentation disclosing the following:_\n\n_a. The known or reasonably known limitations of such high-risk artificial\nintelligence system, including any and all known or reasonably foreseeable\nrisks of algorithmic discrimination arising from the intended uses of such\nhigh-risk artificial intelligence system;_\n\n_b. The purpose of such high-risk artificial intelligence system and the\nintended benefits and uses of such high-risk artificial intelligence system;_\n\n_c. A summary describing how such high-risk artificial intelligence system was\nevaluated for performance and relevant information related to explainability\nbefore such high-risk artificial intelligence system was licensed, sold,\ngiven, or otherwise made available to a developer;_\n\n_d. The measures the developer has taken to mitigate reasonable foreseeable\nrisks of algorithmic discrimination that the developer knows arises from\ndeployment or use of such high-risk artificial intelligence system; and_\n\n_e. How an individual can use such high-risk artificial intelligence system to\nmake, or monitor such high-risk artificial intelligence system when such high-\nrisk artificial intelligence system is deployed or used to make, a\nconsequential decision;_\n\n_3\\. Documentation describing (i) how the high-risk artificial intelligence\nsystem was evaluated for performance and for mitigation of algorithmic\ndiscrimination before such system was made available to the deployer; (ii) the\ndata governance measures used to cover the training data sets and the measures\nused to examine the suitability of data sources, possible biases of data\nsources, and appropriate mitigation; (iii) the intended outputs of the high-\nrisk artificial intelligence system; (iv) the measures the developer has taken\nto mitigate known or reasonably foreseeable risks of algorithmic\ndiscrimination that may arise from the reasonably foreseeable deployment of\nthe high-risk artificial intelligence system; and (v) how the high-risk\nartificial intelligence system should be used, not be used, and be monitored\nby an individual when such system is used to make, or is a substantial factor\nin making, a consequential decision; and_\n\n_4\\. Any additional documentation that is reasonably necessary to assist the\ndeployer in understanding the outputs and monitoring performance of the high-\nrisk artificial intelligence system for risks of algorithmic discrimination._\n\n_B. Each developer that offers, sells, leases, gives, or otherwise makes\navailable to a deployer a high-risk artificial intelligence system shall make\navailable to the deployer information and documentation in the developer 's\npossession, custody, or control that is reasonably required to complete an\nimpact assessment as required in  2.2-5519._\n\n_C. A developer that also serves as a deployer for any high-risk artificial\nintelligence system shall not be required to generate the documentation\nrequired by this section unless such high-risk artificial intelligence system\nis provided to an unaffiliated entity acting as a deployer or as otherwise\nrequired by law._\n\n_D. Nothing in this section shall be construed to require a developer to\ndisclose any trade secret._\n\n_E. High-risk artificial intelligence systems that are in conformity with the\nlatest version of the Artificial Intelligence Risk Management Framework\npublished by the National Institute of Standards and Technology, Standard\nISO/IEC 42001 of the International Organization for Standardization, or\nanother nationally or internationally recognized risk management framework for\nartificial intelligence systems, or parts thereof, shall be presumed to be in\nconformity with related requirements set out in this section and in associated\nregulations._\n\n_F. For any disclosure required pursuant to this section, each developer\nshall, no later than 90 days after the developer performs an intentional and\nsubstantial modification to any high-risk artificial intelligence system,\nupdate such disclosure as necessary to ensure that such disclosure remains\naccurate._\n\n**_ 2.2-5519. Operating standards for public bodies deploying high-risk\nartificial intelligence systems._ **\n\n_A. No deployer shall deploy or use a high-risk artificial intelligence system\nto make a consequential decision unless the deployer has designed and\nimplemented a risk management policy and program for such high-risk artificial\nintelligence system. The risk management policy shall specify the principles,\nprocesses, and personnel that the deployer shall use in maintaining the risk\nmanagement program to identify, mitigate, and document any risk of algorithmic\ndiscrimination that is a reasonably foreseeable consequence of deploying or\nusing such high-risk artificial intelligence system to make a consequential\ndecision. Each risk management policy and program designed, implemented, and\nmaintained pursuant to this subsection shall be (i) at least as stringent as\nthe latest version of the Artificial Intelligence Risk Management Framework\npublished by the National Institute of Standards and Technology, Standard\nISO/IEC 42001 of the International Organization for Standardization, or\nanother nationally or internationally recognized risk management framework for\nartificial intelligence systems and (ii) reasonable considering (a) the size\nand complexity of the deployer; (b) the nature and scope of the high-risk\nartificial intelligence systems deployed and used by the deployer, including\nthe intended uses of such high-risk artificial intelligence systems; (c) the\nsensitivity and volume of data processed in connection with the high-risk\nartificial intelligence systems deployed and used by the deployer; and (d) the\ncost to the deployer to implement and maintain such risk management program._\n\n_B. Except as provided in this subsection, no deployer shall deploy or use a\nhigh-risk artificial intelligence system to make a consequential decision\nunless the deployer has completed an impact assessment for such high-risk\nartificial intelligence system. The deployer shall complete an impact\nassessment for a high-risk artificial intelligence system (i) before the\ndeployer initially deploys such high-risk artificial intelligence system and\n(ii) not later than 90 days after each significant update to such high-risk\nartificial intelligence system is made available._\n\n_Each impact assessment completed pursuant to this subsection shall include,\nat a minimum:_\n\n_1\\. A statement by the deployer disclosing (i) the purpose, intended use\ncases and deployment context of, and benefits afforded by the high-risk\nartificial intelligence system and (ii) whether the deployment or use of the\nhigh-risk artificial intelligence system poses a reasonably foreseeable risk\nof algorithmic discrimination and, if so, (a) the nature of such algorithmic\ndiscrimination and (b) the steps that have been taken, to the extent feasible,\nto mitigate such risk;_\n\n_2\\. For each post-deployment impact assessment completed pursuant to this\nsubsection, whether the intended use cases of the high-risk artificial\nintelligence system as updated were consistent with, or varied from, the\ndeveloper 's intended uses of such high-risk artificial intelligence system;_\n\n_3\\. A description of (i) the categories of data the high-risk artificial\nintelligence system processes as inputs and (ii) the outputs such high-risk\nartificial intelligence system produces;_\n\n_4\\. If the deployer used data to customize the high-risk artificial\nintelligence system, an overview of the categories of data the deployer used\nto customize such high-risk artificial intelligence system;_\n\n_5\\. A list of any metrics used to evaluate the performance and known\nlimitations of the high-risk artificial intelligence system;_\n\n_6\\. A description of any transparency measures taken concerning the high-risk\nartificial intelligence system, including any measures taken to disclose to a\nconsumer that such high-risk artificial intelligence system is in use when\nsuch high-risk artificial intelligence system is in use; and_\n\n_7\\. A description of any post-deployment monitoring performed and user\nsafeguards provided concerning such high-risk artificial intelligence system,\nincluding any oversight process established by the deployer to address issues\narising from deployment or use of such high-risk artificial intelligence\nsystem as such issues arise._\n\n_A single impact assessment may address a comparable set of high-risk\nartificial intelligence systems deployed or used by a deployer. High-risk\nartificial intelligence systems that are in conformity with the latest version\nof the Artificial Intelligence Risk Management Framework published by the\nNational Institute of Standards and Technology, Standard ISO/IEC 42001 of the\nInternational Organization for Standardization, or another nationally or\ninternationally recognized risk management framework for artificial\nintelligence systems, or parts thereof, shall be presumed to be in conformity\nwith related requirements set out in this section and in associated\nregulations. If a deployer completes an impact assessment for the purpose of\ncomplying with another applicable law or regulation, such impact assessment\nshall be deemed to satisfy the requirements established in this subsection if\nsuch impact assessment is reasonably similar in scope and effect to the impact\nassessment that would otherwise be completed pursuant to this subsection. A\ndeployer that completes an impact assessment pursuant to this subsection shall\nmaintain such impact assessment and all records concerning such impact\nassessment for five years._\n\n_C. Not later than the time that a deployer uses a high-risk artificial\nintelligence system to make a consequential decision concerning a consumer,\nthe deployer shall notify the consumer that the deployer is using a high-risk\nartificial intelligence system to make such consequential decision concerning\nsuch consumer and provide to the consumer a statement disclosing (i) the\npurpose of such high-risk artificial intelligence system, (ii) the nature of\nsuch system, (iii) the nature of the consequential decision, (iv) the contact\ninformation for the deployer, and (v) a description in plain language of such\nsystem._\n\n_If such consequential decision is adverse to such consumer, the deployer\nshall provide to the consumer (a) a statement disclosing the principal reason\nor reasons for the consequential decision, including (1) the degree to which\nand manner in which the high-risk artificial intelligence system contributed\nto the consequential decision, (2) the type of data that was processed by such\nsystem in making the consequential decision, and (3) the sources of such data;\n(b) an opportunity to correct any incorrect personal data that the high-risk\nartificial intelligence system processed in making, or as a substantial factor\nin making, the consequential decision; and (c) an opportunity to appeal such\nadverse consequential decision concerning the consumer arising from the\ndeployment of such system. Any such appeal shall allow for human review, if\ntechnically feasible, unless providing the opportunity for appeal is not in\nthe best interest of the consumer, including instances in which any delay\nmight pose a risk to the life or safety of such consumer._\n\n_D. Each deployer shall make available, in a manner that is clear and readily\navailable, a statement summarizing how such deployer manages any reasonably\nforeseeable risk of algorithmic discrimination that may arise from the use or\ndeployment of the high-risk artificial intelligence system._\n\n_E. For any disclosure required pursuant to this section, each deployer shall,\nno later than 90 days after the developer performs an intentional and\nsubstantial modification to any high-risk artificial intelligence system,\nupdate such disclosure as necessary to ensure that such disclosure remains\naccurate._\n\n**_ 2.2-5520. Operating standards for public bodies integrating high-risk\nartificial intelligence systems._ **\n\n_Each integrator of a high-risk artificial intelligence system shall develop\nand adopt an acceptable use policy, which shall limit the use of the high-risk\nartificial intelligence system to mitigate known risks of algorithmic\ndiscrimination._\n\n_Each integrator of a high-risk artificial intelligence system shall provide\nto the deployer clear, conspicuous notice of (i) the name or other identifier\nof the high-risk artificial intelligence system integrated into a software\napplication provided to the deployer; (ii) the name and contact information of\nthe developer of the high-risk artificial intelligence system integrated into\na software application provided to the deployer; (iii) whether the integrator\nhas adjusted the model weights of the high-risk artificial intelligence system\nintegrated into the software application by exposing it to additional data, a\nsummary of the adjustment process, and how such process and the resulting\nsystem were evaluated for risk of algorithmic discrimination; (iv) a summary\nof any other non-substantial modifications made by the integrator; and (v) the\nintegrator 's acceptable use policy._\n\n**_ 2.2-5521. Exemptions._ **\n\n_A. Nothing in this chapter shall be construed to restrict a developer 's,\nintegrator's, or deployer's ability to (i) comply with federal, state, or\nmunicipal ordinances or regulations; (ii) comply with a civil, criminal, or\nregulatory inquiry, investigation, subpoena, or summons by federal, state,\nlocal, or other governmental authorities; (iii) cooperate with law-enforcement\nagencies concerning conduct or activity that the developer, integrator, or\ndeployer reasonably and in good faith believes may violate federal, state, or\nlocal law, ordinances, or regulations; (iv) investigate, establish, exercise,\nprepare for, or defend legal claims; (v) provide a product or service\nspecifically requested by a consumer; (vi) perform under a contract to which a\nconsumer is a party, including fulfilling the terms of a written warranty;\n(vii) take steps at the request of a consumer prior to entering into a\ncontract; (viii) take immediate steps to protect an interest that is essential\nfor the life or physical safety of the consumer or another individual; (ix)\nprevent, detect, protect against, or respond to security incidents, identity\ntheft, fraud, harassment, or malicious or deceptive activities; (x) take\nactions to prevent, detect, protect against, report, or respond to the\nproduction, generation, incorporation, or synthesization of child sex abuse\nmaterial, or any illegal activity, preserve the integrity or security of\nsystems, or investigate, report, or prosecute those responsible for any such\naction; (xi) engage in public or peer-reviewed scientific or statistical\nresearch in the public interest that adheres to all other applicable ethics\nand privacy laws and is approved, monitored, and governed by an institutional\nreview board that determines, or similar independent oversight entities that\ndetermine, (a) that the expected benefits of the research outweigh the risks\nassociated with such research and (b) whether the developer, integrator, or\ndeployer has implemented reasonable safeguards to mitigate the risks\nassociated with such research; (xii) assist another developer, integrator, or\ndeployer with any of the obligations imposed by this chapter; or (xiii) take\nany action that is in the public interest in the areas of public health,\ncommunity health, or population health, but solely to the extent that such\naction is subject to suitable and specific measures to safeguard the public._\n\n_B. The obligations imposed on developers, integrators, or deployers by this\nchapter shall not restrict a developer 's, integrator's, or deployer's ability\nto (i) conduct internal research to develop, improve, or repair products,\nservices, or technologies; (ii) effectuate a product recall; (iii) identify\nand repair technical errors that impair existing or intended functionality; or\n(iv) perform internal operations that are reasonably aligned with the\nexpectations of the consumer or reasonably anticipated based on the consumer's\nexisting relationship with the developer, integrator, or deployer._\n\n_C. Nothing in this chapter shall be construed to impose any obligation on a\ndeveloper, integrator, or deployer to disclose trade secrets._\n\n_D. The obligations imposed on developers, integrators, or deployers by this\nchapter shall not apply where compliance by the developer, integrator, or\ndeployer with such obligations would violate an evidentiary privilege under\nthe laws of the Commonwealth._\n\n_E. Nothing in this chapter shall be construed to impose any obligation on a\ndeveloper, integrator, or deployer that adversely affects the legally\nprotected rights or freedoms of any person, including the rights of any person\nto freedom of speech or freedom of the press guaranteed in the First Amendment\nto the Constitution of the United States or under the Virginia Human Rights\nAct (  2.2-3900 et seq.)._\n\n_F. If a developer, integrator, or deployer engages in any action authorized\nby an exemption set forth in this section, the developer, integrator, or\ndeployer bears the burden of demonstrating that such action qualifies for such\nexemption._\n\n**_ 2.2-5522. Additional requirements._ **\n\n_A. A public body shall not implement any system that employs high-risk\nartificial intelligence systems unless it has fulfilled the requirements of\nthis section and complied with the provisions of this chapter and the high-\nrisk artificial intelligence policies and procedures developed by the Chief\nInformation Officer of the Commonwealth pursuant to subdivision B 10 of \n2.2-2007._\n\n_B. A public body procuring any system that employs high-risk artificial\nintelligence systems shall in all future contracts for the procurement of such\nsystems for which negotiation or renegotiation is begun on or after July 1,\n2026, include a high-risk artificial intelligence system compliance clause, as\ndeveloped by the Chief Information Officer of the Commonwealth pursuant to \n2.2-2007._\n\n_C. Prior to implementing any system that employs high-risk artificial\nintelligence systems, the public body shall comply with the impact assessment\nrequirements of  2.2-5519. A public body shall additionally perform ongoing\nassessments of such system after implementation. If the public body, or the\nhead of the public body, determines, in its discretion, that such system does\nnot comply with such requirements, the public body shall not implement such\nsystem or shall cease to use such system to the extent such system does not\ncomply with such requirements._\n\n_D. All public bodies that implement high-risk artificial intelligence systems\nshall annually report on initial and ongoing system assessments and provide an\ninventory of such systems used. Public bodies in the legislative branch shall\nsubmit such report and inventory to the General Assembly. Public bodies in the\njudicial branch shall submit such report and inventory to the Executive\nSecretary of the Supreme Court of Virginia. Public bodies in the executive\nbranch and any other public bodies not specified in this subsection shall\nsubmit such report and inventory to the Chief Information Officer of the\nCommonwealth. Such report and inventory shall be transmitted to the\nappropriate entity annually._\n\n**2\\. That the Chief Information Officer of the Commonwealth (CIO) shall\nconvene a work group to examine the impact on and the ability of local\ngovernments to comply with the requirements of this act. The work group shall\nconsist of a representative from the Virginia Association of Counties who is\nalso a representative of a member county, a representative from the Virginia\nMunicipal League who is also a representative of a member locality, a\nrepresentative of the Virginia Association of Chiefs of Police, a\nrepresentative from the Virginia Association of Commonwealth 's Attorneys, the\nchief information officer of a school division, the chief information officer\nof a county, the chief information officer of a city, a representative from\nthe Department of Human Resource Management, a representative of a regional\ntechnology council, a member of the Joint Commission on Technology and Science\n(JCOTS) who is a member of the House of Delegates, and a member of JCOTS who\nis a member of the Senate. The CIO shall submit a report of the work group's\nfindings to JCOTS no later than December 1, 2025.**\n\n**3\\. That the provisions of the first enactment of this act shall become\neffective on July 1, 2026.**\n\nCopyright (C) 2025 State Net  \n  \n---\n\n",
      "latest_version": false
    },
    {
      "date": "01/30/2025",
      "label": "Recommended as Substituted from Committee",
      "url": "https://custom.statenet.com/public/resources.cgi?mode=show_text&id=ID:bill:VA2024000S1214&verid=VA2024000S1214_20250130_0_RS&",
      "raw_html": "<html>\n<head>\n<title>Bill Resource</title>\n\n<!--   <link href=\"https://custom.statenet.com/network/Common/css/extregtext.css\" rel=\"stylesheet\" type=\"text/css\" />-->\n   <link href=\"https://custom.statenet.com/network/Common/css/xmltext-2.0.css\" rel=\"stylesheet\" type=\"text/css\" />\n   <link href=\"https://custom.statenet.com/network/Common/css/additional-text.css\" rel=\"stylesheet\" type=\"text/css\" />\n\n\t<style type=\"text/css\">\n<!--\n\ntd, body {\n     background-color: white;\n\tfont-family: Verdana, Arial, Helvetica, sans-serif;\n\tfont-size: 12px;\n}\n\n.resourceContainer {\n   border: 1px solid black;\n}\n-->\n</style>\n</head>\n<body>\n\n    <div style=\"width: 750px; margin: auto\">\n       <div style=\"font-size: .8em;margin-bottom: 10px\"><table width=\"100%\"><tr><td align=\"left\" style=\"font-size: .8em;\"><div>The following has special meaning:</div>\n<div><u class=\"amendmentInsertedText\">green underline denotes added text</u></div>\n<div><strike class=\"amendmentDeletedText\">red struck out text denotes deleted text</strike></div></td> <td align=\"right\"><a href=\"https://www.lexisnexis.com/statenet/\"><img alt=\"Powered by State Net\" src=\"https://custom.statenet.com/network/poweredby.gif\" /></a></td></tr></table></div><table id=\"text-identifier\"><tr><td class=\"key\">2024 VA S 1214</td> <td><table><tr><td class=\"label\">Author:</td> <td>Aird</td></tr> <tr><td class=\"label\">Version:</td> <td>Recommended as Substituted from Committee</td></tr> <tr><td class=\"label\">Version Date:</td> <td>01/30/2025</td></tr></table></td></tr></table><div class=\"documentBody\">\n  <a name=\"head_document_section\"></a><div class=\"head\">\n   <p class=\"center\">SENATE BILL NO. 1214</p>\n   <p class=\"center\">AMENDMENT IN THE NATURE OF A SUBSTITUTE</p>\n   <p class=\"center\">(Proposed by the Senate Committee on Finance and Appropriations</p>\n   <p class=\"center\">on January 30, 2025)</p>\n   <p class=\"center\">(Patron Prior to Substitute--Senator Aird)</p>\n  </div>\n  <a name=\"code_document_section\"></a><div class=\"code\">\n   <p class=\"indent\">\n    <i>A BILL to amend and reenact &sect; 2.2-2007 of the Code of Virginia and to amend the Code of Virginia by adding in Title 2.2 a chapter numbered 55.6, consisting of sections numbered 2.2-5517 through 2.2-5522, relating to high-risk artificial intelligence; development, deployment, and use by public bodies; work group; report.</i>\n   </p>\n  </div>\n  <a name=\"text_document_section\"></a><div class=\"text\">\n   <span>\n    <p class=\"indent\">\n     <b>Be it enacted by the General Assembly of Virginia:</b>\n    </p>\n   </span>\n   <p class=\"indent\">\n    <b>1. That &sect; 2.2-2007 of the Code of Virginia is amended and reenacted and that the Code of Virginia is amended by adding in Title 2.2 a chapter numbered 55.6, consisting of sections numbered 2.2-5517 through 2.2-5522, as follows:</b>\n   </p>\n   <p class=\"indent\">\n    <b>&sect; 2.2-2007. Powers of the CIO.</b>\n   </p>\n   <p class=\"indent\">A. The CIO shall promulgate regulations necessary or incidental to the performance of duties or execution of powers conferred under this chapter. The CIO shall also develop policies, standards, and guidelines for the planning, budgeting, procurement, development, maintenance, security, and operations of information technology for executive branch agencies. Such policies, standards, and guidelines shall include those necessary to:</p>\n   <p class=\"indent\">1. Support state and local government exchange, acquisition, storage, use, sharing, and distribution of data and related technologies.</p>\n   <p class=\"indent\">2. Support the development of electronic transactions<u class=\"amendmentInsertedText\">,</u> including the use of electronic signatures as provided in &sect; 59.1-496.</p>\n   <p class=\"indent\">3. Support a unified approach to information technology across the totality of state government, thereby assuring that the citizens and businesses of the Commonwealth receive the greatest possible security, value, and convenience from investments made in technology.</p>\n   <p class=\"indent\">4. Ensure that the costs of information technology systems, products, data, and services are contained through the shared use of existing or planned equipment, data, or services.</p>\n   <p class=\"indent\">5. Provide for the effective management of information technology investments through their entire life cycles, including identification, business case development, selection, procurement, implementation, operation, performance evaluation, and enhancement or retirement. Such policies, standards, and guidelines shall include, at a minimum, the periodic review by the CIO of agency Commonwealth information technology projects.</p>\n   <p class=\"indent\">6. Establish an Information Technology Investment Management Standard based on acceptable technology investment methods to ensure that all executive branch agency technology expenditures are an integral part of the Commonwealth&#39;s performance management system, produce value for the agency and the Commonwealth, and are aligned with (i) agency strategic plans, (ii) the Governor&#39;s policy objectives, and (iii) the long-term objectives of the Council on Virginia&#39;s Future.</p>\n   <p class=\"indent\">B. In addition to other such duties as the Secretary may assign, the CIO shall:</p>\n   <p class=\"indent\">1. Oversee and administer the Virginia Technology Infrastructure Fund created pursuant to &sect; 2.2-2023.</p>\n   <p class=\"indent\">2. Report annually to the Governor, the Secretary, and the Joint Commission on Technology and Science created pursuant to &sect; 30-85 on the use and application of information technology by executive branch agencies to increase economic efficiency, citizen convenience, and public access to state government.</p>\n   <p class=\"indent\">3. Prepare annually a report for submission to the Secretary, the Information Technology Advisory Council, and the Joint Commission on Technology and Science on a prioritized list of Recommended Technology Investment Projects (RTIP Report) based upon major information technology projects submitted for business case approval pursuant to this chapter. As part of the RTIP Report, the CIO shall develop and regularly update a methodology for prioritizing projects based upon the allocation of points to defined criteria. The criteria and their definitions shall be presented in the RTIP Report. For each project recommended for funding in the RTIP Report, the CIO shall indicate the number of points and how they were awarded. For each listed project, the CIO shall also report (i) all projected costs of ongoing operations and maintenance activities of the project for the next three biennia following project implementation; (ii) a justification and description for each project baseline change; and (iii) whether the project fails to incorporate existing standards for the maintenance, exchange, and security of data. This report shall also include trends in current projected information technology spending by executive branch agencies and secretariats, including spending on projects, operations and maintenance, and payments to VITA. Agencies shall provide all project and cost information required to complete the RTIP Report to the CIO prior to May 31 immediately preceding any budget biennium in which the project appears in the Governor&#39;s budget bill.</p>\n   <p class=\"indent\">4. Provide oversight for executive branch agency efforts to modernize the planning, development, implementation, improvement, operations and maintenance, and retirement of Commonwealth information technology, including oversight for the selection, development and management of enterprise information technology.</p>\n   <p class=\"indent\">5. Develop statewide technical and data standards and specifications for information technology and related systems, including (i) the efficient exchange of electronic information and technology, including infrastructure, between the public and private sectors in the Commonwealth and (ii) the utilization of nationally recognized technical and data standards for health information technology systems or software purchased by an executive branch agency.</p>\n   <p class=\"indent\">6. Direct the compilation and maintenance of an inventory of information technology, including but not limited to personnel, facilities, equipment, goods, and contracts for services.</p>\n   <p class=\"indent\">7. Provide for the centralized marketing, provision, leasing, and executing of licensing agreements for electronic access to public information and government services through the Internet, wireless devices, personal digital assistants, kiosks, or other such related media on terms and conditions as may be determined to be in the best interest of the Commonwealth. VITA may fix and collect fees and charges for (i) public information, media, and other incidental services furnished by it to any private individual or entity, notwithstanding the charges set forth in &sect; 2.2-3704, and (ii) such use and services it provides to any executive branch agency or local government. Nothing in this subdivision authorizing VITA to fix and collect fees for providing information services shall be construed to prevent access to the public records of any public body pursuant to the provisions of the Virginia Freedom of Information Act (&sect; 2.2-3700 et seq.). VITA is authorized, subject to the approval by the Secretary of Administration and any other affected Secretariat, to delegate the powers and responsibilities granted in this subdivision to any agency within the executive branch.</p>\n   <p class=\"indent\">8. Periodically evaluate the feasibility of outsourcing information technology resources and services, and outsource those resources and services that are feasible and beneficial to the Commonwealth.</p>\n   <p class=\"indent\">9. Have the authority to enter into and amend contracts, including contracts with one or more other public bodies, or public agencies or institutions or localities of the several states, of the United States or its territories, or the District of Columbia, for the provision of information technology services.</p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">10. Develop, publish, and maintain policies and procedures concerning the development, procurement, implementation, utilization, and ongoing assessment of systems that employ high-risk artificial intelligence systems, as defined in &sect; 2.2-5517, and are in use by public bodies, consistent with the provisions of Chapter 55.6 (&sect; 2.2-5517 et seq.). Such policies and procedures shall, at a minimum, (i) govern the procurement, implementation, and ongoing assessment of any such system by a public body; (ii) address and provide resources regarding data security and privacy issues that may arise from the development and deployment of high-risk artificial intelligence systems by public bodies; (iii) be sufficient to ensure that no such system results in any algorithmic discrimination, as defined in &sect; 2.2-5517; (iv) create guidelines for acceptable use policies for public bodies integrating high-risk artificial intelligence systems pursuant to &sect; 2.2-5520; and (v) require a public body to assess the likely impact of any such system before implementing such system and perform ongoing assessments of such system to ensure that no such system results in any such algorithmic discrimination, as defined in &sect; 2.2-5517. Such policies and procedures shall include a requirement that a high-risk artificial intelligence system compliance clause be included in procurement contracts for systems that use a high-risk artificial intelligence system for which negotiation or renegotiation is begun on or after July 1, 2027, requiring compliance with the provisions of Chapter 55.6 (&sect; 2.2-5517 et seq.) and any other applicable state law governing the development or deployment of high-risk artificial intelligence systems, as applicable.</u>\n   </p>\n   <p class=\"indent\">C. Consistent with &sect; 2.2-2012, the CIO may enter into public-private partnership contracts to finance or implement information technology programs and projects. The CIO may issue a request for information to seek out potential private partners interested in providing programs or projects pursuant to an agreement under this subsection. The compensation for such services shall be computed with reference to and paid from the increased revenue or cost savings attributable to the successful implementation of the program or project for the period specified in the contract. The CIO shall be responsible for reviewing and approving the programs and projects and the terms of contracts for same under this subsection. The CIO shall determine annually the total amount of increased revenue or cost savings attributable to the successful implementation of a program or project under this subsection and such amount shall be deposited in the Virginia Technology Infrastructure Fund created in &sect; 2.2-2023. The CIO is authorized to use moneys deposited in the Fund to pay private partners pursuant to the terms of contracts under this subsection. All moneys in excess of that required to be paid to private partners, as determined by the CIO, shall be reported to the Comptroller and retained in the Fund. The CIO shall prepare an annual report to the Governor, the Secretary, and General Assembly on all contracts under this subsection, describing each information technology program or project, its progress, revenue impact, and such other information as may be relevant.</p>\n   <p class=\"indent\">D. Executive branch agencies shall cooperate with VITA in identifying the development and operational requirements of proposed information technology systems, products, data, and services, including the proposed use, functionality, and capacity, and the total cost of acquisition, operation, and maintenance.</p>\n   <p class=\"center\">\n    <u class=\"amendmentInsertedText\">CHAPTER 55.6.</u>\n   </p>\n   <p class=\"center\">\n    <u class=\"amendmentInsertedText\">USE OF HIGH-RISK ARTIFICIAL INTELLIGENCE SYSTEMS.</u>\n   </p>\n   <p class=\"indent\">\n    <b>\n     <u class=\"amendmentInsertedText\">&sect; 2.2-5517. Definitions.</u>\n    </b>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">As used in this chapter, unless the context requires a different meaning:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Algorithmic discrimination&quot; means any discrimination that results in an unlawful differential treatment or impact that disfavors an individual or group of individuals on the basis of their actual or perceived age, color, disability, ethnicity, genetic information, limited proficiency in the English language, national origin, race, religion, reproductive health, sex, sexual orientation, veteran status, or other classification protected under state or federal law. &quot;Algorithmic discrimination&quot; does not include (i) the offer, license, or use of a high-risk artificial intelligence system by a developer, integrator, or deployer for the sole purpose of the developer&#39;s, integrator&#39;s, or deployer&#39;s self-testing to identify, mitigate, or prevent discrimination or otherwise ensure compliance with state and federal law or (ii) the expansion of an applicant, customer, or participant pool to increase diversity or redress historical discrimination.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Artificial intelligence&quot; means a set of technologies that enables machines to perform tasks under varying and unpredictable circumstances that typically require human oversight or intelligence, or that can learn from experience and improve performance when exposed to data set</u>\n    <strike class=\"amendmentDeletedText\">s</strike>\n    <u class=\"amendmentInsertedText\">.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Artificial intelligence system&quot; means any machine-based system that, for any explicit or implicit objective, infers from the inputs such system receives how to generate outputs, including content, decisions, predictions, and recommendations, that can influence physical or virtual environments.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Consequential decision&quot; means any decision that has a material legal, or similarly significant, effect on the provision or denial to any consumer of, or the cost or terms of, (i) education enrollment or an education opportunity, (ii) employment or an employment opportunity, (iii) a financial or lending service, (iv) an essential government service, (v) health care services, (vi) housing, (vii) insurance, or (viii) a legal service.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Consumer&quot; means a natural person acting only in an individual or household context. &quot;Consumer&quot; does not include a natural person acting in a commercial or employment context.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Deployer&quot; means any public body that deploys or uses a high-risk artificial intelligence system to make a consequential decision.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Developer&quot; means any public body that develops or intentionally and substantially modifies a high-risk artificial intelligence system that is offered, sold, leased, given, or otherwise provided to consumers in the Commonwealth.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Facial recognition&quot; means the use of a computer system that, for the purpose of attempting to determine the identity of an unknown individual, uses an algorithm to compare the facial biometric data of an unknown individual derived from a photograph, video, or image to a database of photographs or images and associated facial biometric data in order to identify potential matches to an individual. &quot;Facial recognition&quot; does not include facial verification technology, which involves the process of comparing an image or facial biometric data of a known individual, where such information is provided by that individual, to an image database, or to government documentation containing an image of the known individual, to identify a potential match in pursuit of the individual&#39;s identity.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Foundation model&quot; means a machine learning model that (i) is trained on broad data at scale, (ii) is designed for generality of output, and (iii) can be adapted to a wide range of distinctive tasks.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;General-purpose artificial intelligence model&quot; means any form of artificial intelligence system that (i) displays significant generality, (ii) is capable of competently performing a wide range of distinct tasks, and (iii) can be integrated into a variety of downstream applications or systems. &quot;General-purpose artificial intelligence model&quot; does not include any artificial intelligence model that is used for development, prototyping, or research activities before such artificial intelligence model is released on the market.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Generative artificial intelligence&quot; means artificial intelligence based on a foundation model that is capable of and used to produce synthetic digital content, including audio, images, text, and videos.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Generative artificial intelligence system&quot; means any artificial intelligence system or service that incorporates generative artificial intelligence.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;High-risk artificial intelligence system&quot; means any artificial intelligence system that is specifically intended to autonomously make, or be a substantial factor in making, a consequential decision. A system or service is not a &quot;high-risk artificial intelligence system&quot; if it is intended to (i) perform a narrow procedural task, (ii) improve the result of a previously completed human activity, (iii) detect decision-making patterns or deviations from prior decision-making patterns and is not meant to replace or influence the previously completed human assessment without sufficient human review, or (iv) perform a preparatory task to an assessment relevant to a consequential decision. There is a rebuttable presumption that &quot;high-risk artificial intelligence system&quot; does not include any of the following technologies:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">1. Anti-fraud technology that does not use facial recognition technology;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">2. Anti-malware technology;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">3. Anti-virus technology;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">4. Artificial intelligence-enabled video games;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">5. Calculators;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">6. Cybersecurity technology;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">7. Databases;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">8. Data storage;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">9. Firewall technology;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">10. Internet domain registration;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">11. Internet website loading;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">12. Networking;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">13. Spam and robocall filtering;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">14. Spell-checking technology;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">15. Spreadsheets;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">16. Web caching;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">17. Web hosting or any similar technology; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">18. Technology that communicates with consumers in natural language for the purpose of providing users with information, making referrals or recommendations, and answering questions and is subject to an accepted use policy that prohibits generating content that is discriminatory or harmful.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Integrator&quot; means a public body that knowingly integrates an artificial intelligence system into a software application and places such software application on the market or makes such software application available for public use. An &quot;integrator&quot; does not include a public body offering information technology infrastructure.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Intentional and substantial modification&quot; means any deliberate change made to (i) an artificial intelligence system that results in any new reasonably foreseeable risk of algorithmic discrimination or (ii) a general-purpose artificial intelligence model that affects compliance of the general-purpose artificial intelligence model, materially changes the purpose of the general-purpose artificial intelligence model, or results in any new reasonably foreseeable risk of algorithmic discrimination. &quot;Intentional and substantial modification&quot; does not include any change made to a high-risk artificial intelligence system, or the performance of a high-risk artificial intelligence system, if (a) the high-risk artificial intelligence system continues to learn after such high-risk artificial intelligence system is offered, sold, leased, licensed, given, or otherwise made available to a deployer, or deployed, and (b) such change (1) is made to such high-risk artificial intelligence system as a result of any learning described in clause (a), and (2) was predetermined by the deployer or the third party contracted by the deployer when such deployer or third party completed the initial impact assessment of such high-risk artificial intelligence system as required in &sect; 2.2-5519.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Machine learning&quot; means the development of algorithms to build data-derived statistical models that are capable of drawing inferences from previously unseen data without explicit human instruction.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Public body&quot; means any authority, board, department, instrumentality, agency, or other unit of state government. &quot;Public body&quot; does not include any county, city, or town; or any local or regional governmental authority.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Significant update&quot; means any new version, new release, or other update to a high-risk artificial intelligence system that results in significant changes to such high-risk artificial intelligence system&#39;s use case or key functionality and that results in any new or reasonably foreseeable risk of algorithmic discrimination.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Substantial factor&quot; means a factor that (i) assists in making a consequential decision, (ii) is capable of altering the outcome of a consequential decision, and (iii) is generated by an artificial intelligence system. &quot;Substantial factor&quot; includes any use of an artificial intelligence system to generate any content, decision, prediction, or recommendation concerning a consumer that is used as a basis to make a consequential decision concerning the consumer.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Synthetic digital content&quot; means any digital content, including any audio, image, text, or video, that is produced or manipulated by a generative artificial intelligence system, including a general-purpose artificial intelligence model.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Trade secret&quot; means information, including a formula, pattern, compilation, program, device, method, technique, or process, that (i) derives independent economic value, actual or potential, from not being generally known to, and not being readily ascertainable by proper means by, other persons who can obtain economic value from its disclosure or use and (ii) is the subject of efforts that are reasonable under the circumstances to maintain its secrecy.</u>\n   </p>\n   <p class=\"indent\">\n    <b>\n     <u class=\"amendmentInsertedText\">&sect; 2.2-5518. Operating standards for public bodies developing high-risk artificial intelligence systems.</u>\n    </b>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">A. No developer of a high-risk artificial intelligence system shall offer, sell, lease, give, or otherwise provide to a deployer a high-risk artificial intelligence system unless the developer makes available to the deployer:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">1. A statement disclosing the intended uses of such high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">2. Documentation disclosing the following:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">a. The known or reasonably known limitations of such high-risk artificial intelligence system, including any and all known or reasonably foreseeable risks of algorithmic discrimination arising from the intended uses of such high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">b. The purpose of such high-risk artificial intelligence system and the intended benefits and uses of such high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">c. A summary describing how such high-risk artificial intelligence system was evaluated for performance and relevant information related to explainability before such high-risk artificial intelligence system was licensed, sold, given, or otherwise made available to a developer;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">d. The measures the developer has taken to mitigate reasonable foreseeable risks of algorithmic discrimination that the developer knows arises from deployment or use of such high-risk artificial intelligence system; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">e. How an individual can use such high-risk artificial intelligence system to make, or monitor such high-risk artificial intelligence system when such high-risk artificial intelligence system is deployed or used to make, a consequential decision;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">3. Documentation describing (i) how the high-risk artificial intelligence system was evaluated for performance and for mitigation of algorithmic discrimination before such system was made available to the deployer; (ii) the data governance measures used to cover the training data sets and the measures used to examine the suitability of data sources, possible biases of data sources, and appropriate mitigation; (iii) the intended outputs of the high-risk artificial intelligence system; (iv) the measures the developer has taken to mitigate known or reasonably foreseeable risks of algorithmic discrimination that may arise from the reasonably foreseeable deployment of the high-risk artificial intelligence system; and (v) how the high-risk artificial intelligence system should be used, not be used, and be monitored by an individual when such system is used to make, or is a substantial factor in making, a consequential decision; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">4. Any additional documentation that is reasonably necessary to assist the deployer in understanding the outputs and monitoring performance of the high-risk artificial intelligence system for risks of algorithmic discrimination.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">B. Each developer that offers, sells, leases, gives, or otherwise makes available to a deployer a high-risk artificial intelligence system shall make available to the deployer information and documentation in the developer&#39;s possession, custody, or control that is reasonably required to complete an impact assessment as required in &sect; 2.2-5519.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">C. A developer that also serves as a deployer for any high-risk artificial intelligence system shall not be required to generate the documentation required by this section unless such high-risk artificial intelligence system is provided to an unaffiliated entity acting as a deployer or as otherwise required by law.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">D. Nothing in this section shall be construed to require a developer to disclose any trade secret.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">E. High-risk artificial intelligence systems that are in conformity with the latest version of the Artificial Intelligence Risk Management Framework published by the National Institute of Standards and Technology, Standard ISO/IEC 42001 of the International Organization for Standardization, or another nationally or internationally recognized risk management framework for artificial intelligence systems, or parts thereof, shall be presumed to be in conformity with related requirements set out in this section and in associated regulations.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">F. For any disclosure required pursuant to this section, each developer shall, no later than 90 days after the developer performs an intentional and substantial modification to any high-risk artificial intelligence system, update such disclosure as necessary to ensure that such disclosure remains accurate.</u>\n   </p>\n   <p class=\"indent\">\n    <b>\n     <u class=\"amendmentInsertedText\">&sect; 2.2-5519. Operating standards for public bodies deploying high-risk artificial intelligence systems.</u>\n    </b>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">A. No deployer shall deploy or use a high-risk artificial intelligence system to make a consequential decision unless the deployer has designed and implemented a risk management policy and program for such high-risk artificial intelligence system. The risk management policy shall specify the principles, processes, and personnel that the deployer shall use in maintaining the risk management program to identify, mitigate, and document any risk of algorithmic discrimination that is a reasonably foreseeable consequence of deploying or using such high-risk artificial intelligence system to make a consequential decision. Each risk management policy and program designed, implemented, and maintained pursuant to this subsection shall be (i) at least as stringent as the latest version of the Artificial Intelligence Risk Management Framework published by the National Institute of Standards and Technology, Standard ISO/IEC 42001 of the International Organization for Standardization, or another nationally or internationally recognized risk management framework for artificial intelligence systems and (ii) reasonable considering (a) the size and complexity of the deployer; (b) the nature and scope of the high-risk artificial intelligence systems deployed and used by the deployer, including the intended uses of such high-risk artificial intelligence systems; (c) the sensitivity and volume of data processed in connection with the high-risk artificial intelligence systems deployed and used by the deployer; and (d) the cost to the deployer to implement and maintain such risk management program.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">B. Except as provided in this subsection, no deployer shall deploy or use a high-risk artificial intelligence system to make a consequential decision unless the deployer has completed an impact assessment for such high-risk artificial intelligence system. The deployer shall complete an impact assessment for a high-risk artificial intelligence system (i) before the deployer initially deploys such high-risk artificial intelligence system and (ii) not later than 90 days after each significant update to such high-risk artificial intelligence system is made available.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">Each impact assessment completed pursuant to this subsection shall include, at a minimum:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">1. A statement by the deployer disclosing (i) the purpose, intended use cases and deployment context of, and benefits afforded by the high-risk artificial intelligence system and (ii) whether the deployment or use of the high-risk artificial intelligence system poses a reasonably foreseeable risk of algorithmic discrimination and, if so, (a) the nature of such algorithmic discrimination and (b) the steps that have been taken, to the extent feasible, to mitigate such risk;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">2. For each post-deployment impact assessment completed pursuant to this subsection, whether the intended use cases of the high-risk artificial intelligence system as updated were consistent with, or varied from, the developer&#39;s intended uses of such high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">3. A description of (i) the categories of data the high-risk artificial intelligence system processes as inputs and (ii) the outputs such high-risk artificial intelligence system produces;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">4. If the deployer used data to customize the high-risk artificial intelligence system, an overview of the categories of data the deployer used to customize such high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">5. A list of any metrics used to evaluate the performance and known limitations of the high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">6. A description of any transparency measures taken concerning the high-risk artificial intelligence system, including any measures taken to disclose to a consumer that such high-risk artificial intelligence system is in use when such high-risk artificial intelligence system is in use; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">7. A description of any post-deployment monitoring performed and user safeguards provided concerning such high-risk artificial intelligence system, including any oversight process established by the deployer to address issues arising from deployment or use of such high-risk artificial intelligence system as such issues arise.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">A single impact assessment may address a comparable set of high-risk artificial intelligence systems deployed or used by a deployer. High-risk artificial intelligence systems that are in conformity with the latest version of the Artificial Intelligence Risk Management Framework published by the National Institute of Standards and Technology, Standard ISO/IEC 42001 of the International Organization for Standardization, or another nationally or internationally recognized risk management framework for artificial intelligence systems, or parts thereof, shall be presumed to be in conformity with related requirements set out in this section and in associated regulations. If a deployer completes an impact assessment for the purpose of complying with another applicable law or regulation, such impact assessment shall be deemed to satisfy the requirements established in this subsection if such impact assessment is reasonably similar in scope and effect to the impact assessment that would otherwise be completed pursuant to this subsection. A deployer that completes an impact assessment pursuant to this subsection shall maintain such impact assessment and all records concerning such impact assessment for five years.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">C. Not later than the time that a deployer uses a high-risk artificial intelligence system to make a consequential decision concerning a consumer, the deployer shall notify the consumer that the deployer is using a high-risk artificial intelligence system to make such consequential decision concerning such consumer and provide to the consumer a statement disclosing (i) the purpose of such high-risk artificial intelligence system, (ii) the nature of such system, (iii) the nature of the consequential decision, (iv) the contact information for the deployer, and (v) a description in plain language of such system.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">If such consequential decision is adverse to such consumer, the deployer shall provide to the consumer (a) a statement disclosing the principal reason or reasons for the consequential decision, including (1) the degree to which and manner in which the high-risk artificial intelligence system contributed to the consequential decision, (2) the type of data that was processed by such system in making the consequential decision, and (3) the sources of such data; (b) an opportunity to correct any incorrect personal data that the high-risk artificial intelligence system processed in making, or as a substantial factor in making, the consequential decision; and (c) an opportunity to appeal such adverse consequential decision concerning the consumer arising from the deployment of such system. Any such appeal shall allow for human review, if technically feasible, unless providing the opportunity for appeal is not in the best interest of the consumer, including instances in which any delay might pose a risk to the life or safety of such consumer.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">D. Each deployer shall make available, in a manner that is clear and readily available, a statement summarizing how such deployer manages any reasonably foreseeable risk of algorithmic discrimination that may arise from the use or deployment of the high-risk artificial intelligence system.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">E. For any disclosure required pursuant to this section, each deployer shall, no later than 90 days after the developer performs an intentional and substantial modification to any high-risk artificial intelligence system, update such disclosure as necessary to ensure that such disclosure remains accurate.</u>\n   </p>\n   <p class=\"indent\">\n    <b>\n     <u class=\"amendmentInsertedText\">&sect; 2.2-5520. Operating standards for public bodies integrating high-risk artificial intelligence systems.</u>\n    </b>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">Each integrator of a high-risk artificial intelligence system shall develop and adopt an acceptable use policy, which shall limit the use of the high-risk artificial intelligence system to mitigate known risks of algorithmic discrimination.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">Each integrator of a high-risk artificial intelligence system shall provide to the deployer clear, conspicuous notice of (i) the name or other identifier of the high-risk artificial intelligence system integrated into a software application provided to the deployer; (ii) the name and contact information of the developer of the high-risk artificial intelligence system integrated into a software application provided to the deployer; (iii) whether the integrator has adjusted the model weights of the high-risk artificial intelligence system integrated into the software application by exposing it to additional data, a summary of the adjustment process, and how such process and the resulting system were evaluated for risk of algorithmic discrimination; (iv) a summary of any other non-substantial modifications made by the integrator; and (v) the integrator&#39;s acceptable use policy.</u>\n   </p>\n   <p class=\"indent\">\n    <b>\n     <u class=\"amendmentInsertedText\">&sect; 2.2-5521. Exemptions.</u>\n    </b>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">A. Nothing in this chapter shall be construed to restrict a developer&#39;s, integrator&#39;s, or deployer&#39;s ability to (i) comply with federal, state, or municipal ordinances or regulations; (ii) comply with a civil, criminal, or regulatory inquiry, investigation, subpoena, or summons by federal, state, local, or other governmental authorities; (iii) cooperate with law-enforcement agencies concerning conduct or activity that the developer, integrator, or deployer reasonably and in good faith believes may violate federal, state, or local law, ordinances, or regulations; (iv) investigate, establish, exercise, prepare for, or defend legal claims; (v) provide a product or service specifically requested by a consumer; (vi) perform under a contract to which a consumer is a party, including fulfilling the terms of a written warranty; (vii) take steps at the request of a consumer prior to entering into a contract; (viii) take immediate steps to protect an interest that is essential for the life or physical safety of the consumer or another individual; (ix) prevent, detect, protect against, or respond to security incidents, identity theft, fraud, harassment, or malicious or deceptive activities; (x) take actions to prevent, detect, protect against, report, or respond to the production, generation, incorporation, or synthesization of child sex abuse material, or any illegal activity, preserve the integrity or security of systems, or investigate, report, or prosecute those responsible for any such action; (xi) engage in public or peer-reviewed scientific or statistical research in the public interest that adheres to all other applicable ethics and privacy laws and is approved, monitored, and governed by an institutional review board that determines, or similar independent oversight entities that determine, (a) that the expected benefits of the research outweigh the risks associated with such research and (b) whether the developer, integrator, or deployer has implemented reasonable safeguards to mitigate the risks associated with such research; (xii) assist another developer, integrator, or deployer with any of the obligations imposed by this chapter; or (xiii) take any action that is in the public interest in the areas of public health, community health, or population health, but solely to the extent that such action is subject to suitable and specific measures to safeguard the public.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">B. The obligations imposed on developers, integrators, or deployers by this chapter shall not restrict a developer&#39;s, integrator&#39;s, or deployer&#39;s ability to (i) conduct internal research to develop, improve, or repair products, services, or technologies; (ii) effectuate a product recall; (iii) identify and repair technical errors that impair existing or intended functionality; or (iv) perform internal operations that are reasonably aligned with the expectations of the consumer or reasonably anticipated based on the consumer&#39;s existing relationship with the developer, integrator, or deployer.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">C. Nothing in this chapter shall be construed to impose any obligation on a developer, integrator, or deployer to disclose trade secrets.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">D. The obligations imposed on developers, integrators, or deployers by this chapter shall not apply where compliance by the developer, integrator, or deployer with such obligations would violate an evidentiary privilege under the laws of the Commonwealth.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">E. Nothing in this chapter shall be construed to impose any obligation on a developer, integrator, or deployer that adversely affects the legally protected rights or freedoms of any person, including the rights of any person to freedom of speech or freedom of the press guaranteed in the First Amendment to the Constitution of the United States or under the Virginia Human Rights Act (&sect; 2.2-3900 et seq.).</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">F. If a developer, integrator, or deployer engages in any action authorized by an exemption set forth in this section, the developer, integrator, or deployer bears the burden of demonstrating that such action qualifies for such exemption.</u>\n   </p>\n   <p class=\"indent\">\n    <b>\n     <u class=\"amendmentInsertedText\">&sect; 2.2-5522. Additional requirements.</u>\n    </b>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">A. A public body shall not implement any system that employs high-risk artificial intelligence systems unless it has fulfilled the requirements of this section and complied with the provisions of this chapter and the high-risk artificial intelligence policies and procedures developed by the Chief Information Officer of the Commonwealth pursuant to subdivision B 10 of &sect; 2.2-2007.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">B. A public body procuring any system that employs high-risk artificial intelligence systems shall in all future contracts for the procurement of such systems for which negotiation or renegotiation is begun on or after July 1, 2027, include a high-risk artificial intelligence system compliance clause, as developed by the Chief Information Officer of the Commonwealth pursuant to &sect; 2.2-2007.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">C. Prior to implementing any system that employs high-risk artificial intelligence systems, the public body shall comply with the impact assessment requirements of &sect; 2.2-5519. A public body shall additionally perform ongoing assessments of such system after implementation. If the public body, or the head of the public body, determines, in its discretion, that such system does not comply with such requirements, the public body shall not implement such system or shall cease to use such system to the extent such system does not comply with such requirements.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">D. All public bodies that implement high-risk artificial intelligence systems shall annually report on initial and ongoing system assessments and provide an inventory of such systems used. Public bodies in the legislative branch shall submit such report and inventory to the General Assembly. Public bodies in the judicial branch shall submit such report and inventory to the Executive Secretary of the Supreme Court of Virginia. Public bodies in the executive branch and any other public bodies not specified in this subsection shall submit such report and inventory to the Chief Information Officer of the Commonwealth. Such report and inventory shall be transmitted to the appropriate entity annually.</u>\n   </p>\n   <p class=\"indent\">\n    <b>2. That the Chief Information Officer of the Commonwealth (CIO) shall convene a work group to examine the impact on and the ability of local governments to comply with the requirements of this act. The work group shall consist of a representative from the Virginia Association of Counties who is also a representative of a member county, a representative from the Virginia Municipal League who is also a representative of a member locality, a representative of the Virginia Association of Chiefs of Police, a representative from the Virginia Association of Commonwealth&#39;s Attorneys, the chief information officer of a school division, the chief information officer of a county, the chief information officer of a city, a representative from the Department of Human Resource Management, a representative of a regional technology council, a member of the Joint Commission on Technology and Science (JCOTS) who is a member of the House of Delegates, and a member of JCOTS who is a member of the Senate. The CIO shall submit a report of the work group&#39;s findings to JCOTS no later than December 1, 2025.</b>\n   </p>\n   <p class=\"indent\">\n    <b>3. That the provisions of the first enactment of this act shall become effective on July 1, 2027.</b>\n   </p>\n  </div>\n </div>\n    </div>\t\n<table cellpadding=0 cellspacing=0 width=\"100%\">\n   <tr>\n      <td>\n          Copyright &copy; 2025 State Net\n      </td>\n<BR>\n<!--???MOVED INTO resources.cgi      <td align=\"right\">\n          <img src=\"https://custom.statenet.com/network/poweredby.gif\" alt=\"Powered by State Net\">\n      </td>-->\n\n    </tr>\n</table>\n</body></html>\n",
      "markdown": "The following has special meaning: _green underline denotes added text_ ~~red struck out text denotes deleted text~~ | [![Powered by State Net](https://custom.statenet.com/network/poweredby.gif)](https://www.lexisnexis.com/statenet/)  \n---|---  \n  \n2024 VA S 1214 | | Author: | Aird  \n---|---  \nVersion: | Recommended as Substituted from Committee  \nVersion Date: | 01/30/2025  \n  \nSENATE BILL NO. 1214\n\nAMENDMENT IN THE NATURE OF A SUBSTITUTE\n\n(Proposed by the Senate Committee on Finance and Appropriations\n\non January 30, 2025)\n\n(Patron Prior to Substitute--Senator Aird)\n\n_A BILL to amend and reenact  2.2-2007 of the Code of Virginia and to amend\nthe Code of Virginia by adding in Title 2.2 a chapter numbered 55.6,\nconsisting of sections numbered 2.2-5517 through 2.2-5522, relating to high-\nrisk artificial intelligence; development, deployment, and use by public\nbodies; work group; report._\n\n**Be it enacted by the General Assembly of Virginia:**\n\n**1\\. That  2.2-2007 of the Code of Virginia is amended and reenacted and\nthat the Code of Virginia is amended by adding in Title 2.2 a chapter numbered\n55.6, consisting of sections numbered 2.2-5517 through 2.2-5522, as follows:**\n\n** 2.2-2007. Powers of the CIO.**\n\nA. The CIO shall promulgate regulations necessary or incidental to the\nperformance of duties or execution of powers conferred under this chapter. The\nCIO shall also develop policies, standards, and guidelines for the planning,\nbudgeting, procurement, development, maintenance, security, and operations of\ninformation technology for executive branch agencies. Such policies,\nstandards, and guidelines shall include those necessary to:\n\n1\\. Support state and local government exchange, acquisition, storage, use,\nsharing, and distribution of data and related technologies.\n\n2\\. Support the development of electronic transactions _,_ including the use\nof electronic signatures as provided in  59.1-496.\n\n3\\. Support a unified approach to information technology across the totality\nof state government, thereby assuring that the citizens and businesses of the\nCommonwealth receive the greatest possible security, value, and convenience\nfrom investments made in technology.\n\n4\\. Ensure that the costs of information technology systems, products, data,\nand services are contained through the shared use of existing or planned\nequipment, data, or services.\n\n5\\. Provide for the effective management of information technology investments\nthrough their entire life cycles, including identification, business case\ndevelopment, selection, procurement, implementation, operation, performance\nevaluation, and enhancement or retirement. Such policies, standards, and\nguidelines shall include, at a minimum, the periodic review by the CIO of\nagency Commonwealth information technology projects.\n\n6\\. Establish an Information Technology Investment Management Standard based\non acceptable technology investment methods to ensure that all executive\nbranch agency technology expenditures are an integral part of the\nCommonwealth's performance management system, produce value for the agency and\nthe Commonwealth, and are aligned with (i) agency strategic plans, (ii) the\nGovernor's policy objectives, and (iii) the long-term objectives of the\nCouncil on Virginia's Future.\n\nB. In addition to other such duties as the Secretary may assign, the CIO\nshall:\n\n1\\. Oversee and administer the Virginia Technology Infrastructure Fund created\npursuant to  2.2-2023.\n\n2\\. Report annually to the Governor, the Secretary, and the Joint Commission\non Technology and Science created pursuant to  30-85 on the use and\napplication of information technology by executive branch agencies to increase\neconomic efficiency, citizen convenience, and public access to state\ngovernment.\n\n3\\. Prepare annually a report for submission to the Secretary, the Information\nTechnology Advisory Council, and the Joint Commission on Technology and\nScience on a prioritized list of Recommended Technology Investment Projects\n(RTIP Report) based upon major information technology projects submitted for\nbusiness case approval pursuant to this chapter. As part of the RTIP Report,\nthe CIO shall develop and regularly update a methodology for prioritizing\nprojects based upon the allocation of points to defined criteria. The criteria\nand their definitions shall be presented in the RTIP Report. For each project\nrecommended for funding in the RTIP Report, the CIO shall indicate the number\nof points and how they were awarded. For each listed project, the CIO shall\nalso report (i) all projected costs of ongoing operations and maintenance\nactivities of the project for the next three biennia following project\nimplementation; (ii) a justification and description for each project baseline\nchange; and (iii) whether the project fails to incorporate existing standards\nfor the maintenance, exchange, and security of data. This report shall also\ninclude trends in current projected information technology spending by\nexecutive branch agencies and secretariats, including spending on projects,\noperations and maintenance, and payments to VITA. Agencies shall provide all\nproject and cost information required to complete the RTIP Report to the CIO\nprior to May 31 immediately preceding any budget biennium in which the project\nappears in the Governor's budget bill.\n\n4\\. Provide oversight for executive branch agency efforts to modernize the\nplanning, development, implementation, improvement, operations and\nmaintenance, and retirement of Commonwealth information technology, including\noversight for the selection, development and management of enterprise\ninformation technology.\n\n5\\. Develop statewide technical and data standards and specifications for\ninformation technology and related systems, including (i) the efficient\nexchange of electronic information and technology, including infrastructure,\nbetween the public and private sectors in the Commonwealth and (ii) the\nutilization of nationally recognized technical and data standards for health\ninformation technology systems or software purchased by an executive branch\nagency.\n\n6\\. Direct the compilation and maintenance of an inventory of information\ntechnology, including but not limited to personnel, facilities, equipment,\ngoods, and contracts for services.\n\n7\\. Provide for the centralized marketing, provision, leasing, and executing\nof licensing agreements for electronic access to public information and\ngovernment services through the Internet, wireless devices, personal digital\nassistants, kiosks, or other such related media on terms and conditions as may\nbe determined to be in the best interest of the Commonwealth. VITA may fix and\ncollect fees and charges for (i) public information, media, and other\nincidental services furnished by it to any private individual or entity,\nnotwithstanding the charges set forth in  2.2-3704, and (ii) such use and\nservices it provides to any executive branch agency or local government.\nNothing in this subdivision authorizing VITA to fix and collect fees for\nproviding information services shall be construed to prevent access to the\npublic records of any public body pursuant to the provisions of the Virginia\nFreedom of Information Act ( 2.2-3700 et seq.). VITA is authorized, subject\nto the approval by the Secretary of Administration and any other affected\nSecretariat, to delegate the powers and responsibilities granted in this\nsubdivision to any agency within the executive branch.\n\n8\\. Periodically evaluate the feasibility of outsourcing information\ntechnology resources and services, and outsource those resources and services\nthat are feasible and beneficial to the Commonwealth.\n\n9\\. Have the authority to enter into and amend contracts, including contracts\nwith one or more other public bodies, or public agencies or institutions or\nlocalities of the several states, of the United States or its territories, or\nthe District of Columbia, for the provision of information technology\nservices.\n\n_10\\. Develop, publish, and maintain policies and procedures concerning the\ndevelopment, procurement, implementation, utilization, and ongoing assessment\nof systems that employ high-risk artificial intelligence systems, as defined\nin  2.2-5517, and are in use by public bodies, consistent with the provisions\nof Chapter 55.6 ( 2.2-5517 et seq.). Such policies and procedures shall, at a\nminimum, (i) govern the procurement, implementation, and ongoing assessment of\nany such system by a public body; (ii) address and provide resources regarding\ndata security and privacy issues that may arise from the development and\ndeployment of high-risk artificial intelligence systems by public bodies;\n(iii) be sufficient to ensure that no such system results in any algorithmic\ndiscrimination, as defined in  2.2-5517; (iv) create guidelines for\nacceptable use policies for public bodies integrating high-risk artificial\nintelligence systems pursuant to  2.2-5520; and (v) require a public body to\nassess the likely impact of any such system before implementing such system\nand perform ongoing assessments of such system to ensure that no such system\nresults in any such algorithmic discrimination, as defined in  2.2-5517. Such\npolicies and procedures shall include a requirement that a high-risk\nartificial intelligence system compliance clause be included in procurement\ncontracts for systems that use a high-risk artificial intelligence system for\nwhich negotiation or renegotiation is begun on or after July 1, 2027,\nrequiring compliance with the provisions of Chapter 55.6 ( 2.2-5517 et seq.)\nand any other applicable state law governing the development or deployment of\nhigh-risk artificial intelligence systems, as applicable._\n\nC. Consistent with  2.2-2012, the CIO may enter into public-private\npartnership contracts to finance or implement information technology programs\nand projects. The CIO may issue a request for information to seek out\npotential private partners interested in providing programs or projects\npursuant to an agreement under this subsection. The compensation for such\nservices shall be computed with reference to and paid from the increased\nrevenue or cost savings attributable to the successful implementation of the\nprogram or project for the period specified in the contract. The CIO shall be\nresponsible for reviewing and approving the programs and projects and the\nterms of contracts for same under this subsection. The CIO shall determine\nannually the total amount of increased revenue or cost savings attributable to\nthe successful implementation of a program or project under this subsection\nand such amount shall be deposited in the Virginia Technology Infrastructure\nFund created in  2.2-2023. The CIO is authorized to use moneys deposited in\nthe Fund to pay private partners pursuant to the terms of contracts under this\nsubsection. All moneys in excess of that required to be paid to private\npartners, as determined by the CIO, shall be reported to the Comptroller and\nretained in the Fund. The CIO shall prepare an annual report to the Governor,\nthe Secretary, and General Assembly on all contracts under this subsection,\ndescribing each information technology program or project, its progress,\nrevenue impact, and such other information as may be relevant.\n\nD. Executive branch agencies shall cooperate with VITA in identifying the\ndevelopment and operational requirements of proposed information technology\nsystems, products, data, and services, including the proposed use,\nfunctionality, and capacity, and the total cost of acquisition, operation, and\nmaintenance.\n\n_CHAPTER 55.6._\n\n_USE OF HIGH-RISK ARTIFICIAL INTELLIGENCE SYSTEMS._\n\n**_ 2.2-5517. Definitions._ **\n\n_As used in this chapter, unless the context requires a different meaning:_\n\n_\" Algorithmic discrimination\" means any discrimination that results in an\nunlawful differential treatment or impact that disfavors an individual or\ngroup of individuals on the basis of their actual or perceived age, color,\ndisability, ethnicity, genetic information, limited proficiency in the English\nlanguage, national origin, race, religion, reproductive health, sex, sexual\norientation, veteran status, or other classification protected under state or\nfederal law. \"Algorithmic discrimination\" does not include (i) the offer,\nlicense, or use of a high-risk artificial intelligence system by a developer,\nintegrator, or deployer for the sole purpose of the developer's, integrator's,\nor deployer's self-testing to identify, mitigate, or prevent discrimination or\notherwise ensure compliance with state and federal law or (ii) the expansion\nof an applicant, customer, or participant pool to increase diversity or\nredress historical discrimination._\n\n_\" Artificial intelligence\" means a set of technologies that enables machines\nto perform tasks under varying and unpredictable circumstances that typically\nrequire human oversight or intelligence, or that can learn from experience and\nimprove performance when exposed to data set_ ~~s~~ _._\n\n_\" Artificial intelligence system\" means any machine-based system that, for\nany explicit or implicit objective, infers from the inputs such system\nreceives how to generate outputs, including content, decisions, predictions,\nand recommendations, that can influence physical or virtual environments._\n\n_\" Consequential decision\" means any decision that has a material legal, or\nsimilarly significant, effect on the provision or denial to any consumer of,\nor the cost or terms of, (i) education enrollment or an education opportunity,\n(ii) employment or an employment opportunity, (iii) a financial or lending\nservice, (iv) an essential government service, (v) health care services, (vi)\nhousing, (vii) insurance, or (viii) a legal service._\n\n_\" Consumer\" means a natural person acting only in an individual or household\ncontext. \"Consumer\" does not include a natural person acting in a commercial\nor employment context._\n\n_\" Deployer\" means any public body that deploys or uses a high-risk artificial\nintelligence system to make a consequential decision._\n\n_\" Developer\" means any public body that develops or intentionally and\nsubstantially modifies a high-risk artificial intelligence system that is\noffered, sold, leased, given, or otherwise provided to consumers in the\nCommonwealth._\n\n_\" Facial recognition\" means the use of a computer system that, for the\npurpose of attempting to determine the identity of an unknown individual, uses\nan algorithm to compare the facial biometric data of an unknown individual\nderived from a photograph, video, or image to a database of photographs or\nimages and associated facial biometric data in order to identify potential\nmatches to an individual. \"Facial recognition\" does not include facial\nverification technology, which involves the process of comparing an image or\nfacial biometric data of a known individual, where such information is\nprovided by that individual, to an image database, or to government\ndocumentation containing an image of the known individual, to identify a\npotential match in pursuit of the individual's identity._\n\n_\" Foundation model\" means a machine learning model that (i) is trained on\nbroad data at scale, (ii) is designed for generality of output, and (iii) can\nbe adapted to a wide range of distinctive tasks._\n\n_\" General-purpose artificial intelligence model\" means any form of artificial\nintelligence system that (i) displays significant generality, (ii) is capable\nof competently performing a wide range of distinct tasks, and (iii) can be\nintegrated into a variety of downstream applications or systems. \"General-\npurpose artificial intelligence model\" does not include any artificial\nintelligence model that is used for development, prototyping, or research\nactivities before such artificial intelligence model is released on the\nmarket._\n\n_\" Generative artificial intelligence\" means artificial intelligence based on\na foundation model that is capable of and used to produce synthetic digital\ncontent, including audio, images, text, and videos._\n\n_\" Generative artificial intelligence system\" means any artificial\nintelligence system or service that incorporates generative artificial\nintelligence._\n\n_\" High-risk artificial intelligence system\" means any artificial intelligence\nsystem that is specifically intended to autonomously make, or be a substantial\nfactor in making, a consequential decision. A system or service is not a\n\"high-risk artificial intelligence system\" if it is intended to (i) perform a\nnarrow procedural task, (ii) improve the result of a previously completed\nhuman activity, (iii) detect decision-making patterns or deviations from prior\ndecision-making patterns and is not meant to replace or influence the\npreviously completed human assessment without sufficient human review, or (iv)\nperform a preparatory task to an assessment relevant to a consequential\ndecision. There is a rebuttable presumption that \"high-risk artificial\nintelligence system\" does not include any of the following technologies:_\n\n_1\\. Anti-fraud technology that does not use facial recognition technology;_\n\n_2\\. Anti-malware technology;_\n\n_3\\. Anti-virus technology;_\n\n_4\\. Artificial intelligence-enabled video games;_\n\n_5\\. Calculators;_\n\n_6\\. Cybersecurity technology;_\n\n_7\\. Databases;_\n\n_8\\. Data storage;_\n\n_9\\. Firewall technology;_\n\n_10\\. Internet domain registration;_\n\n_11\\. Internet website loading;_\n\n_12\\. Networking;_\n\n_13\\. Spam and robocall filtering;_\n\n_14\\. Spell-checking technology;_\n\n_15\\. Spreadsheets;_\n\n_16\\. Web caching;_\n\n_17\\. Web hosting or any similar technology; or_\n\n_18\\. Technology that communicates with consumers in natural language for the\npurpose of providing users with information, making referrals or\nrecommendations, and answering questions and is subject to an accepted use\npolicy that prohibits generating content that is discriminatory or harmful._\n\n_\" Integrator\" means a public body that knowingly integrates an artificial\nintelligence system into a software application and places such software\napplication on the market or makes such software application available for\npublic use. An \"integrator\" does not include a public body offering\ninformation technology infrastructure._\n\n_\" Intentional and substantial modification\" means any deliberate change made\nto (i) an artificial intelligence system that results in any new reasonably\nforeseeable risk of algorithmic discrimination or (ii) a general-purpose\nartificial intelligence model that affects compliance of the general-purpose\nartificial intelligence model, materially changes the purpose of the general-\npurpose artificial intelligence model, or results in any new reasonably\nforeseeable risk of algorithmic discrimination. \"Intentional and substantial\nmodification\" does not include any change made to a high-risk artificial\nintelligence system, or the performance of a high-risk artificial intelligence\nsystem, if (a) the high-risk artificial intelligence system continues to learn\nafter such high-risk artificial intelligence system is offered, sold, leased,\nlicensed, given, or otherwise made available to a deployer, or deployed, and\n(b) such change (1) is made to such high-risk artificial intelligence system\nas a result of any learning described in clause (a), and (2) was predetermined\nby the deployer or the third party contracted by the deployer when such\ndeployer or third party completed the initial impact assessment of such high-\nrisk artificial intelligence system as required in  2.2-5519._\n\n_\" Machine learning\" means the development of algorithms to build data-derived\nstatistical models that are capable of drawing inferences from previously\nunseen data without explicit human instruction._\n\n_\" Public body\" means any authority, board, department, instrumentality,\nagency, or other unit of state government. \"Public body\" does not include any\ncounty, city, or town; or any local or regional governmental authority._\n\n_\" Significant update\" means any new version, new release, or other update to\na high-risk artificial intelligence system that results in significant changes\nto such high-risk artificial intelligence system's use case or key\nfunctionality and that results in any new or reasonably foreseeable risk of\nalgorithmic discrimination._\n\n_\" Substantial factor\" means a factor that (i) assists in making a\nconsequential decision, (ii) is capable of altering the outcome of a\nconsequential decision, and (iii) is generated by an artificial intelligence\nsystem. \"Substantial factor\" includes any use of an artificial intelligence\nsystem to generate any content, decision, prediction, or recommendation\nconcerning a consumer that is used as a basis to make a consequential decision\nconcerning the consumer._\n\n_\" Synthetic digital content\" means any digital content, including any audio,\nimage, text, or video, that is produced or manipulated by a generative\nartificial intelligence system, including a general-purpose artificial\nintelligence model._\n\n_\" Trade secret\" means information, including a formula, pattern, compilation,\nprogram, device, method, technique, or process, that (i) derives independent\neconomic value, actual or potential, from not being generally known to, and\nnot being readily ascertainable by proper means by, other persons who can\nobtain economic value from its disclosure or use and (ii) is the subject of\nefforts that are reasonable under the circumstances to maintain its secrecy._\n\n**_ 2.2-5518. Operating standards for public bodies developing high-risk\nartificial intelligence systems._ **\n\n_A. No developer of a high-risk artificial intelligence system shall offer,\nsell, lease, give, or otherwise provide to a deployer a high-risk artificial\nintelligence system unless the developer makes available to the deployer:_\n\n_1\\. A statement disclosing the intended uses of such high-risk artificial\nintelligence system;_\n\n_2\\. Documentation disclosing the following:_\n\n_a. The known or reasonably known limitations of such high-risk artificial\nintelligence system, including any and all known or reasonably foreseeable\nrisks of algorithmic discrimination arising from the intended uses of such\nhigh-risk artificial intelligence system;_\n\n_b. The purpose of such high-risk artificial intelligence system and the\nintended benefits and uses of such high-risk artificial intelligence system;_\n\n_c. A summary describing how such high-risk artificial intelligence system was\nevaluated for performance and relevant information related to explainability\nbefore such high-risk artificial intelligence system was licensed, sold,\ngiven, or otherwise made available to a developer;_\n\n_d. The measures the developer has taken to mitigate reasonable foreseeable\nrisks of algorithmic discrimination that the developer knows arises from\ndeployment or use of such high-risk artificial intelligence system; and_\n\n_e. How an individual can use such high-risk artificial intelligence system to\nmake, or monitor such high-risk artificial intelligence system when such high-\nrisk artificial intelligence system is deployed or used to make, a\nconsequential decision;_\n\n_3\\. Documentation describing (i) how the high-risk artificial intelligence\nsystem was evaluated for performance and for mitigation of algorithmic\ndiscrimination before such system was made available to the deployer; (ii) the\ndata governance measures used to cover the training data sets and the measures\nused to examine the suitability of data sources, possible biases of data\nsources, and appropriate mitigation; (iii) the intended outputs of the high-\nrisk artificial intelligence system; (iv) the measures the developer has taken\nto mitigate known or reasonably foreseeable risks of algorithmic\ndiscrimination that may arise from the reasonably foreseeable deployment of\nthe high-risk artificial intelligence system; and (v) how the high-risk\nartificial intelligence system should be used, not be used, and be monitored\nby an individual when such system is used to make, or is a substantial factor\nin making, a consequential decision; and_\n\n_4\\. Any additional documentation that is reasonably necessary to assist the\ndeployer in understanding the outputs and monitoring performance of the high-\nrisk artificial intelligence system for risks of algorithmic discrimination._\n\n_B. Each developer that offers, sells, leases, gives, or otherwise makes\navailable to a deployer a high-risk artificial intelligence system shall make\navailable to the deployer information and documentation in the developer 's\npossession, custody, or control that is reasonably required to complete an\nimpact assessment as required in  2.2-5519._\n\n_C. A developer that also serves as a deployer for any high-risk artificial\nintelligence system shall not be required to generate the documentation\nrequired by this section unless such high-risk artificial intelligence system\nis provided to an unaffiliated entity acting as a deployer or as otherwise\nrequired by law._\n\n_D. Nothing in this section shall be construed to require a developer to\ndisclose any trade secret._\n\n_E. High-risk artificial intelligence systems that are in conformity with the\nlatest version of the Artificial Intelligence Risk Management Framework\npublished by the National Institute of Standards and Technology, Standard\nISO/IEC 42001 of the International Organization for Standardization, or\nanother nationally or internationally recognized risk management framework for\nartificial intelligence systems, or parts thereof, shall be presumed to be in\nconformity with related requirements set out in this section and in associated\nregulations._\n\n_F. For any disclosure required pursuant to this section, each developer\nshall, no later than 90 days after the developer performs an intentional and\nsubstantial modification to any high-risk artificial intelligence system,\nupdate such disclosure as necessary to ensure that such disclosure remains\naccurate._\n\n**_ 2.2-5519. Operating standards for public bodies deploying high-risk\nartificial intelligence systems._ **\n\n_A. No deployer shall deploy or use a high-risk artificial intelligence system\nto make a consequential decision unless the deployer has designed and\nimplemented a risk management policy and program for such high-risk artificial\nintelligence system. The risk management policy shall specify the principles,\nprocesses, and personnel that the deployer shall use in maintaining the risk\nmanagement program to identify, mitigate, and document any risk of algorithmic\ndiscrimination that is a reasonably foreseeable consequence of deploying or\nusing such high-risk artificial intelligence system to make a consequential\ndecision. Each risk management policy and program designed, implemented, and\nmaintained pursuant to this subsection shall be (i) at least as stringent as\nthe latest version of the Artificial Intelligence Risk Management Framework\npublished by the National Institute of Standards and Technology, Standard\nISO/IEC 42001 of the International Organization for Standardization, or\nanother nationally or internationally recognized risk management framework for\nartificial intelligence systems and (ii) reasonable considering (a) the size\nand complexity of the deployer; (b) the nature and scope of the high-risk\nartificial intelligence systems deployed and used by the deployer, including\nthe intended uses of such high-risk artificial intelligence systems; (c) the\nsensitivity and volume of data processed in connection with the high-risk\nartificial intelligence systems deployed and used by the deployer; and (d) the\ncost to the deployer to implement and maintain such risk management program._\n\n_B. Except as provided in this subsection, no deployer shall deploy or use a\nhigh-risk artificial intelligence system to make a consequential decision\nunless the deployer has completed an impact assessment for such high-risk\nartificial intelligence system. The deployer shall complete an impact\nassessment for a high-risk artificial intelligence system (i) before the\ndeployer initially deploys such high-risk artificial intelligence system and\n(ii) not later than 90 days after each significant update to such high-risk\nartificial intelligence system is made available._\n\n_Each impact assessment completed pursuant to this subsection shall include,\nat a minimum:_\n\n_1\\. A statement by the deployer disclosing (i) the purpose, intended use\ncases and deployment context of, and benefits afforded by the high-risk\nartificial intelligence system and (ii) whether the deployment or use of the\nhigh-risk artificial intelligence system poses a reasonably foreseeable risk\nof algorithmic discrimination and, if so, (a) the nature of such algorithmic\ndiscrimination and (b) the steps that have been taken, to the extent feasible,\nto mitigate such risk;_\n\n_2\\. For each post-deployment impact assessment completed pursuant to this\nsubsection, whether the intended use cases of the high-risk artificial\nintelligence system as updated were consistent with, or varied from, the\ndeveloper 's intended uses of such high-risk artificial intelligence system;_\n\n_3\\. A description of (i) the categories of data the high-risk artificial\nintelligence system processes as inputs and (ii) the outputs such high-risk\nartificial intelligence system produces;_\n\n_4\\. If the deployer used data to customize the high-risk artificial\nintelligence system, an overview of the categories of data the deployer used\nto customize such high-risk artificial intelligence system;_\n\n_5\\. A list of any metrics used to evaluate the performance and known\nlimitations of the high-risk artificial intelligence system;_\n\n_6\\. A description of any transparency measures taken concerning the high-risk\nartificial intelligence system, including any measures taken to disclose to a\nconsumer that such high-risk artificial intelligence system is in use when\nsuch high-risk artificial intelligence system is in use; and_\n\n_7\\. A description of any post-deployment monitoring performed and user\nsafeguards provided concerning such high-risk artificial intelligence system,\nincluding any oversight process established by the deployer to address issues\narising from deployment or use of such high-risk artificial intelligence\nsystem as such issues arise._\n\n_A single impact assessment may address a comparable set of high-risk\nartificial intelligence systems deployed or used by a deployer. High-risk\nartificial intelligence systems that are in conformity with the latest version\nof the Artificial Intelligence Risk Management Framework published by the\nNational Institute of Standards and Technology, Standard ISO/IEC 42001 of the\nInternational Organization for Standardization, or another nationally or\ninternationally recognized risk management framework for artificial\nintelligence systems, or parts thereof, shall be presumed to be in conformity\nwith related requirements set out in this section and in associated\nregulations. If a deployer completes an impact assessment for the purpose of\ncomplying with another applicable law or regulation, such impact assessment\nshall be deemed to satisfy the requirements established in this subsection if\nsuch impact assessment is reasonably similar in scope and effect to the impact\nassessment that would otherwise be completed pursuant to this subsection. A\ndeployer that completes an impact assessment pursuant to this subsection shall\nmaintain such impact assessment and all records concerning such impact\nassessment for five years._\n\n_C. Not later than the time that a deployer uses a high-risk artificial\nintelligence system to make a consequential decision concerning a consumer,\nthe deployer shall notify the consumer that the deployer is using a high-risk\nartificial intelligence system to make such consequential decision concerning\nsuch consumer and provide to the consumer a statement disclosing (i) the\npurpose of such high-risk artificial intelligence system, (ii) the nature of\nsuch system, (iii) the nature of the consequential decision, (iv) the contact\ninformation for the deployer, and (v) a description in plain language of such\nsystem._\n\n_If such consequential decision is adverse to such consumer, the deployer\nshall provide to the consumer (a) a statement disclosing the principal reason\nor reasons for the consequential decision, including (1) the degree to which\nand manner in which the high-risk artificial intelligence system contributed\nto the consequential decision, (2) the type of data that was processed by such\nsystem in making the consequential decision, and (3) the sources of such data;\n(b) an opportunity to correct any incorrect personal data that the high-risk\nartificial intelligence system processed in making, or as a substantial factor\nin making, the consequential decision; and (c) an opportunity to appeal such\nadverse consequential decision concerning the consumer arising from the\ndeployment of such system. Any such appeal shall allow for human review, if\ntechnically feasible, unless providing the opportunity for appeal is not in\nthe best interest of the consumer, including instances in which any delay\nmight pose a risk to the life or safety of such consumer._\n\n_D. Each deployer shall make available, in a manner that is clear and readily\navailable, a statement summarizing how such deployer manages any reasonably\nforeseeable risk of algorithmic discrimination that may arise from the use or\ndeployment of the high-risk artificial intelligence system._\n\n_E. For any disclosure required pursuant to this section, each deployer shall,\nno later than 90 days after the developer performs an intentional and\nsubstantial modification to any high-risk artificial intelligence system,\nupdate such disclosure as necessary to ensure that such disclosure remains\naccurate._\n\n**_ 2.2-5520. Operating standards for public bodies integrating high-risk\nartificial intelligence systems._ **\n\n_Each integrator of a high-risk artificial intelligence system shall develop\nand adopt an acceptable use policy, which shall limit the use of the high-risk\nartificial intelligence system to mitigate known risks of algorithmic\ndiscrimination._\n\n_Each integrator of a high-risk artificial intelligence system shall provide\nto the deployer clear, conspicuous notice of (i) the name or other identifier\nof the high-risk artificial intelligence system integrated into a software\napplication provided to the deployer; (ii) the name and contact information of\nthe developer of the high-risk artificial intelligence system integrated into\na software application provided to the deployer; (iii) whether the integrator\nhas adjusted the model weights of the high-risk artificial intelligence system\nintegrated into the software application by exposing it to additional data, a\nsummary of the adjustment process, and how such process and the resulting\nsystem were evaluated for risk of algorithmic discrimination; (iv) a summary\nof any other non-substantial modifications made by the integrator; and (v) the\nintegrator 's acceptable use policy._\n\n**_ 2.2-5521. Exemptions._ **\n\n_A. Nothing in this chapter shall be construed to restrict a developer 's,\nintegrator's, or deployer's ability to (i) comply with federal, state, or\nmunicipal ordinances or regulations; (ii) comply with a civil, criminal, or\nregulatory inquiry, investigation, subpoena, or summons by federal, state,\nlocal, or other governmental authorities; (iii) cooperate with law-enforcement\nagencies concerning conduct or activity that the developer, integrator, or\ndeployer reasonably and in good faith believes may violate federal, state, or\nlocal law, ordinances, or regulations; (iv) investigate, establish, exercise,\nprepare for, or defend legal claims; (v) provide a product or service\nspecifically requested by a consumer; (vi) perform under a contract to which a\nconsumer is a party, including fulfilling the terms of a written warranty;\n(vii) take steps at the request of a consumer prior to entering into a\ncontract; (viii) take immediate steps to protect an interest that is essential\nfor the life or physical safety of the consumer or another individual; (ix)\nprevent, detect, protect against, or respond to security incidents, identity\ntheft, fraud, harassment, or malicious or deceptive activities; (x) take\nactions to prevent, detect, protect against, report, or respond to the\nproduction, generation, incorporation, or synthesization of child sex abuse\nmaterial, or any illegal activity, preserve the integrity or security of\nsystems, or investigate, report, or prosecute those responsible for any such\naction; (xi) engage in public or peer-reviewed scientific or statistical\nresearch in the public interest that adheres to all other applicable ethics\nand privacy laws and is approved, monitored, and governed by an institutional\nreview board that determines, or similar independent oversight entities that\ndetermine, (a) that the expected benefits of the research outweigh the risks\nassociated with such research and (b) whether the developer, integrator, or\ndeployer has implemented reasonable safeguards to mitigate the risks\nassociated with such research; (xii) assist another developer, integrator, or\ndeployer with any of the obligations imposed by this chapter; or (xiii) take\nany action that is in the public interest in the areas of public health,\ncommunity health, or population health, but solely to the extent that such\naction is subject to suitable and specific measures to safeguard the public._\n\n_B. The obligations imposed on developers, integrators, or deployers by this\nchapter shall not restrict a developer 's, integrator's, or deployer's ability\nto (i) conduct internal research to develop, improve, or repair products,\nservices, or technologies; (ii) effectuate a product recall; (iii) identify\nand repair technical errors that impair existing or intended functionality; or\n(iv) perform internal operations that are reasonably aligned with the\nexpectations of the consumer or reasonably anticipated based on the consumer's\nexisting relationship with the developer, integrator, or deployer._\n\n_C. Nothing in this chapter shall be construed to impose any obligation on a\ndeveloper, integrator, or deployer to disclose trade secrets._\n\n_D. The obligations imposed on developers, integrators, or deployers by this\nchapter shall not apply where compliance by the developer, integrator, or\ndeployer with such obligations would violate an evidentiary privilege under\nthe laws of the Commonwealth._\n\n_E. Nothing in this chapter shall be construed to impose any obligation on a\ndeveloper, integrator, or deployer that adversely affects the legally\nprotected rights or freedoms of any person, including the rights of any person\nto freedom of speech or freedom of the press guaranteed in the First Amendment\nto the Constitution of the United States or under the Virginia Human Rights\nAct (  2.2-3900 et seq.)._\n\n_F. If a developer, integrator, or deployer engages in any action authorized\nby an exemption set forth in this section, the developer, integrator, or\ndeployer bears the burden of demonstrating that such action qualifies for such\nexemption._\n\n**_ 2.2-5522. Additional requirements._ **\n\n_A. A public body shall not implement any system that employs high-risk\nartificial intelligence systems unless it has fulfilled the requirements of\nthis section and complied with the provisions of this chapter and the high-\nrisk artificial intelligence policies and procedures developed by the Chief\nInformation Officer of the Commonwealth pursuant to subdivision B 10 of \n2.2-2007._\n\n_B. A public body procuring any system that employs high-risk artificial\nintelligence systems shall in all future contracts for the procurement of such\nsystems for which negotiation or renegotiation is begun on or after July 1,\n2027, include a high-risk artificial intelligence system compliance clause, as\ndeveloped by the Chief Information Officer of the Commonwealth pursuant to \n2.2-2007._\n\n_C. Prior to implementing any system that employs high-risk artificial\nintelligence systems, the public body shall comply with the impact assessment\nrequirements of  2.2-5519. A public body shall additionally perform ongoing\nassessments of such system after implementation. If the public body, or the\nhead of the public body, determines, in its discretion, that such system does\nnot comply with such requirements, the public body shall not implement such\nsystem or shall cease to use such system to the extent such system does not\ncomply with such requirements._\n\n_D. All public bodies that implement high-risk artificial intelligence systems\nshall annually report on initial and ongoing system assessments and provide an\ninventory of such systems used. Public bodies in the legislative branch shall\nsubmit such report and inventory to the General Assembly. Public bodies in the\njudicial branch shall submit such report and inventory to the Executive\nSecretary of the Supreme Court of Virginia. Public bodies in the executive\nbranch and any other public bodies not specified in this subsection shall\nsubmit such report and inventory to the Chief Information Officer of the\nCommonwealth. Such report and inventory shall be transmitted to the\nappropriate entity annually._\n\n**2\\. That the Chief Information Officer of the Commonwealth (CIO) shall\nconvene a work group to examine the impact on and the ability of local\ngovernments to comply with the requirements of this act. The work group shall\nconsist of a representative from the Virginia Association of Counties who is\nalso a representative of a member county, a representative from the Virginia\nMunicipal League who is also a representative of a member locality, a\nrepresentative of the Virginia Association of Chiefs of Police, a\nrepresentative from the Virginia Association of Commonwealth 's Attorneys, the\nchief information officer of a school division, the chief information officer\nof a county, the chief information officer of a city, a representative from\nthe Department of Human Resource Management, a representative of a regional\ntechnology council, a member of the Joint Commission on Technology and Science\n(JCOTS) who is a member of the House of Delegates, and a member of JCOTS who\nis a member of the Senate. The CIO shall submit a report of the work group's\nfindings to JCOTS no later than December 1, 2025.**\n\n**3\\. That the provisions of the first enactment of this act shall become\neffective on July 1, 2027.**\n\nCopyright (C) 2025 State Net  \n  \n---\n\n",
      "latest_version": true
    }
  ]
}