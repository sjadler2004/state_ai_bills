{
  "bill_id": "NE2025000L642",
  "source_url": "http://custom.statenet.com/public/resources.cgi?id=ID:bill:NE2025000L642&cuiq=93d84396-c63b-526a-b152-38b7f79b4cfd&client_md=e4f6fea4-27b4-5d41-b7d3-766fe52569f0",
  "versions": [
    {
      "date": "01/22/2025",
      "label": "Introduced",
      "url": "https://custom.statenet.com/public/resources.cgi?mode=show_text&id=ID:bill:NE2025000L642&verid=NE2025000L642_20250122_0_I&",
      "raw_html": "<html>\n<head>\n<title>Bill Resource</title>\n\n<!--   <link href=\"https://custom.statenet.com/network/Common/css/extregtext.css\" rel=\"stylesheet\" type=\"text/css\" />-->\n   <link href=\"https://custom.statenet.com/network/Common/css/xmltext-2.0.css\" rel=\"stylesheet\" type=\"text/css\" />\n   <link href=\"https://custom.statenet.com/network/Common/css/additional-text.css\" rel=\"stylesheet\" type=\"text/css\" />\n\n\t<style type=\"text/css\">\n<!--\n\ntd, body {\n     background-color: white;\n\tfont-family: Verdana, Arial, Helvetica, sans-serif;\n\tfont-size: 12px;\n}\n\n.resourceContainer {\n   border: 1px solid black;\n}\n-->\n</style>\n</head>\n<body>\n\n    <div style=\"width: 750px; margin: auto\">\n       <div style=\"font-size: .8em;margin-bottom: 10px\"><table width=\"100%\"><tr><td align=\"left\" style=\"font-size: .8em;\"><div>The following has special meaning:</div>\n<div><u class=\"amendmentInsertedText\">green underline denotes added text</u></div>\n<div><strike class=\"amendmentDeletedText\">red struck out text denotes deleted text</strike></div></td> <td align=\"right\"><a href=\"https://www.lexisnexis.com/statenet/\"><img alt=\"Powered by State Net\" src=\"https://custom.statenet.com/network/poweredby.gif\" /></a></td></tr></table></div><table id=\"text-identifier\"><tr><td class=\"key\">2025 NE L 642</td> <td><table><tr><td class=\"label\">Author:</td> <td>Bostar</td></tr> <tr><td class=\"label\">Version:</td> <td>Introduced</td></tr> <tr><td class=\"label\">Version Date:</td> <td>01/22/2025</td></tr></table></td></tr></table><div class=\"documentBody\">\n  <a name=\"head_document_section\"></a><div class=\"head\">\n   <p class=\"center\">LEGISLATURE OF NEBRASKA</p>\n   <p class=\"center\">ONE HUNDRED NINTH LEGISLATURE</p>\n   <p class=\"center\">FIRST SESSION</p>\n   <p class=\"center\">\n    <b>LEGISLATIVE BILL 642</b>\n   </p>\n   <p class=\"left\">Introduced by Bostar, 29.</p>\n   <p class=\"left\">Read first time January 22, 2025</p>\n   <p class=\"left\">Committee:</p>\n  </div>\n  <a name=\"code_document_section\"></a><div class=\"code\">\n   <p class=\"left\">A BILL FOR AN ACT relating to discrimination; to adopt the Artificial Intelligence Consumer Protection Act; and to provide severability.</p>\n  </div>\n  <a name=\"text_document_section\"></a><div class=\"text\">\n   <span>\n    <p class=\"left\">Be it enacted by the people of the State of Nebraska,</p>\n   </span>\n   <p class=\"indent\">\n    <b>Section 1. </b>\n    <u class=\"amendmentInsertedText\">Sections 1 to 7 of this act shall be known and may be cited as the Artificial Intelligence Consumer Protection Act.</u>\n   </p>\n   <p class=\"indent\">\n    <b>Sec. 2. </b>\n    <u class=\"amendmentInsertedText\">For purposes of the Artificial Intelligence Consumer Protection Act:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(1)(a) Algorithmic discrimination means any use of an artificial intelligence system that violates state or federal anti-discrimination laws, including federal statutes prohibiting discrimination on the basis of citizenship status, color, disability, national origin, race, or sex, or any other classification protected under the laws of this state or federal law; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) Algorithmic discrimination does not include:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) The offer, license, or use of a high-risk artificial intelligence system by a developer or deployer for the sole purpose of:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) The developer&#39;s or deployer&#39;s self-testing to identify, mitigate, or prevent discrimination or otherwise ensure compliance with state and federal law; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) Expanding an applicant, customer, or participant pool to increase diversity or redress historical discrimination; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) An act or omission by or on behalf of a private club or other establishment that is not in fact open to the public, pursuant to the federal Civil Rights Act of 1964, 42 U.S.C. 2000a(e), as such section existed on January 1, 2025;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(2) Artificial intelligence system means any machine-based system that, for any explicit or implicit objective, infers from the inputs the system receives how to generate outputs, including content, decisions, predictions, or recommendations, that can influence physical or virtual environments;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(3) Consequential decision means a decision that has a material legal or similarly significant effect on the provision or denial to any consumer of any, or the cost or terms of any:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(a) Education enrollment or an education opportunity;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) Employment;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(c) Lending decision;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(d) Essential government service;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(e) Health care services;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(f) Housing;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(g) Insurance;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(h) Legal service; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) Pardon, parole, probation, or release decision;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(4) Consumer means any individual who is a resident of this state;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(5) Deploy means to use a high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(6) Deployer means a person doing business in this state that deploys a high-risk artificial intelligence system in this state;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(7) Developer means a person doing business in this state that develops or intentionally and substantially modifies a high-risk artificial intelligence system in this state;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(8) Health care services has the same meaning as in 42 U.S.C. 234(d) (2), as such section existed on January 1, 2025;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(9)(a) High-risk artificial intelligence system means any artificial intelligence system that, when deployed, makes a consequential decision without human review or intervention; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) High-risk artificial intelligence system does not include:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) Any artificial intelligence system if the artificial intelligence system is intended to:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) Perform a narrow procedural task;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) Improve the result of a previously completed human activity;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(C) Perform a preparatory task to an assessment that is relevant to a consequential decision; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(D) Detect decisionmaking patterns or deviations from preexisting decisionmaking patterns and is not intended to replace or influence </u>a <u class=\"amendmentInsertedText\">previously completed human assessment without sufficient human review; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Any of the following technology:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) Antifraud technology;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) Antimalware;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(C) Antivirus;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(D) Artificial intelligence-enabled video game;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(E) Calculator;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(F) Cybersecurity;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(G) Database;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(H) Data storage;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(I) Firewall;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(J) Internet domain registration;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(K) Internet website loading;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(L) Networking;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(M) Spam-filtering;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(N) Robocall-filtering;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(O) Spell-checking;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(P) Spreadsheet;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(Q) Web caching;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(R) Web hosting or any similar technology; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(S) Technology that:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(I) Communicates with any consumer in natural language for the purpose of providing such consumer with information, making any referral or recommendation, or answering any question; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(II) Is subject to an acceptable use policy that prohibits generating content that is unlawful or harmful;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(10) Insurer means any person engaged as principal, indemnitor, surety, or contractor in the business of making contracts of insurance;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(11)(a) Intentional and substantial modification means a deliberate and material change made to an artificial intelligence system that materially increases the known risk of algorithmic discrimination; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) Intentional and substantial modification does not include any change made to any high-risk artificial intelligence system, or the performance of any high-risk artificial intelligence system, if:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) The high-risk artificial intelligence system continues to learn after the high-risk artificial intelligence system is:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) Offered, sold, leased, licensed, given, or otherwise made available to a deployer; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) Deployed;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) The change is made to the high-risk artificial intelligence system as a result of any learning described in subdivision (10)(b)(i) of this section;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) The change was predetermined by the deployer, or a third party contracted by the deployer, when the deployer or third party completed an initial impact assessment of such high-risk artificial intelligence system pursuant to subsection (3) of section 4 of this act; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iv) The change is included in technical documentation for the high- risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(12) Intentionally and substantially modifies means intentional and substantial modification as defined in this section;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(13) Principal basis means the use of an output of a high-risk artificial intelligence system to make a decision without:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(a) Human review, oversight, involvement, or intervention; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) Meaningful consideration by a human;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(14) Red teaming means an exercise that is conducted to identify the potential adverse behaviors or outcomes of an artificial intelligence system, identify how such behaviors or outcomes occur, and stress test the safeguards against such behaviors or outcomes;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(15)(a) Substantial factor means any factor that:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) Is the principal basis for making a consequential decision;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Is capable of altering the outcome of a consequential decision; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) Is generated by an artificial intelligence system; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) Substantial factor includes any use of any artificial intelligence system to generate any content, decision, prediction, or recommendation concerning any consumer that is used as a basis to make </u>a <u class=\"amendmentInsertedText\">consequential decision concerning the consumer; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(16) Trade secret has the same meaning as in section 87-502.</u>\n   </p>\n   <p class=\"indent\">\n    <b>Sec. 3. </b>\n    <u class=\"amendmentInsertedText\">(1)(a) On and after February 1, 2026, a developer of </u>a <u class=\"amendmentInsertedText\">high-risk artificial intelligence system shall use reasonable care to protect consumers from any known risks of algorithmic discrimination arising from the intended and contracted uses of the high-risk artificial intelligence system.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) In any enforcement action brought on or after February 1, 2026, by the Attorney General pursuant to section 7 of this act, there is </u>a <u class=\"amendmentInsertedText\">rebuttable presumption that a developer used reasonable care as required under this section if the developer complied with this section.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(2) Except as otherwise provided in subsection (6) of this section, on and after February 1, 2026, each developer of a high-risk artificial intelligence system shall make available to the deployer or other developer of the high-risk artificial intelligence system:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(a) A general statement describing the uses and known harmful or inappropriate uses of the high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) Documentation disclosing:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) A high-level summary of the types of data used to train the high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Each known limitation of the high-risk artificial intelligence system, including each known or reasonably foreseeable risk of algorithmic discrimination arising from the intended use of the high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) The purpose of the high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iv) Any intended benefit and use of the high-risk artificial intelligence system; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(v) Information necessary to allow the deployer to comply with the requirements of section 4 of this act;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(c) Documentation describing:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) How the high-risk artificial intelligence system was evaluated for performance and mitigation of algorithmic discrimination before the high-risk artificial intelligence system was offered, sold, leased, licensed, given, or otherwise made available to the deployer;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) The data governance measures used to cover the training datasets and the measures used to examine the suitability of data sources, possible biases, and appropriate mitigation;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) Intended outputs of the high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iv) The measures the developer has taken to mitigate known risks of algorithmic discrimination that could arise from the deployment of the high-risk artificial intelligence system; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(v) How the high-risk artificial intelligence system should be used, not be used, and be monitored by an individual when the high-risk artificial intelligence system is used to make, or is a substantial factor in making, a consequential decision; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(d) Documentation that is reasonably necessary to assist the deployer in understanding each output and monitor the performance of the high-risk artificial intelligence system for each risk of algorithmic discrimination.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(3)(a) Except as otherwise provided in subsection (6) of this section, on or after February 1, 2026, a developer that offers, sells, leases, licenses, gives, or otherwise makes any high-risk artificial intelligence system available to a deployer or other developer shall to the extent feasible make available to the deployer or other developer the documentation and information necessary for the deployer or a third party contracted by the deployer to complete an impact assessment pursuant to subsection (3) of section 4 of this act. Such documentation and information includes any model card or other impact assessment.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) A developer that also serves as a deployer for a high-risk artificial intelligence system is not required to generate the documentation required by this section unless the high-risk artificial intelligence system is provided to an unaffiliated entity acting as a deployer.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(4)(a) On and after February 1, 2026, a developer shall make a statement summarizing the following available in a manner that is clear and readily available in a public use case inventory:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) The types of high-risk artificial intelligence systems that the developer has developed and currently makes available to a deployer or other developer;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) The types of high-risk artificial intelligence system that the developer has intentionally and substantially modified and currently makes available to a deployer or other developer; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) How the developer manages known risks of algorithmic discrimination that could arise from the development or intentional and substantial modification of the types of high-risk artificial intelligence systems described in subdivisions (4)(a)(i) and (ii) of this section.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) A developer shall update the statement described in subdivision (4)(a) of this section:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) As necessary to ensure that the statement remains accurate; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) No later than ninety days after the developer intentionally and substantially modifies any high-risk artificial intelligence system described in subdivision (4)(a)(ii) of this section.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(5)(a) On and after February 1, 2026, a developer of a high-risk artificial intelligence system shall disclose to all known deployers or other developers of the high-risk artificial intelligence system, each known risk of algorithmic discrimination arising from any intended use of the high-risk artificial intelligence system without unreasonable delay after the date on which:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) The developer discovers through the developer&#39;s ongoing testing and analysis that the developer&#39;s high-risk artificial intelligence system has been deployed and has caused or is reasonably likely to have caused algorithmic discrimination; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) The developer receives from a deployer a credible report that the high-risk artificial intelligence system has been deployed and has caused algorithmic discrimination.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) The Attorney General shall prescribe the form and manner of the disclosure described in subdivision (a) of this subsection.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(6) Nothing in subsections (2) through (5) of this section requires a developer to disclose any:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(a) Trade secret;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) Information protected from disclosure by state or federal law; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(c) Information that would create a security risk to the developer.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(7)(a) On and after February 1, 2026, the Attorney General may provide a written demand to any developer to disclose to the Attorney General the statement or documentation described in subsection (2) of this section if such a statement or documentation is relevant to an investigation related to the developer conducted by the Attorney General. Such statement or documentation shall be provided to the Attorney General in a form and manner prescribed by the Attorney General.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) The Attorney General may evaluate such statement or documentation, if it is relevant to an investigation conducted by the Attorney General regarding a violation of the Artificial Intelligence Consumer Protection Act, to ensure compliance with the Artificial Intelligence Consumer Protection Act.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(c) In any disclosure pursuant to this subsection, any developer may designate the statement or documentation as including proprietary information or a trade secret.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(d) To the extent any such statement or documentation includes any proprietary information or any trade secret, such statement or documentation shall be exempt from disclosure.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(8) If a developer completes documentation for the purpose of complying with another applicable law or regulation, such documentation shall be deemed to satisfy this section if such documentation is reasonably similar in scope and effect to the documentation that would otherwise be completed pursuant to this section.</u>\n   </p>\n   <p class=\"indent\">\n    <b>Sec. 4. </b>\n    <u class=\"amendmentInsertedText\">(1)(a) On and after February 1, 2026, a deployer of any high-risk artificial intelligence system shall use reasonable care to protect consumers from each known risk of algorithmic discrimination.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) In any enforcement action brought on or after February 1, 2026, by the Attorney General pursuant to section 7 of this act, there is </u>a <u class=\"amendmentInsertedText\">rebuttable presumption that a deployer of a high-risk artificial intelligence system used reasonable care as required under this section if the deployer complied with this section.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(2)(a) Except as otherwise provided in subsection (6) of this section, on and after February 1, 2026, a deployer of a high-risk artificial intelligence system shall implement a risk management policy and program to govern the deployer&#39;s deployment of the high-risk artificial intelligence system. High-risk artificial intelligence systems that are in conformity with the guidance and standards set forth in the following as of January 1, 2025, shall be presumed to be in conformity with this section:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) The Artificial Intelligence Risk Management Framework published by the National Institute of Standards and Technology; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) The standard ISO/IEC 42001 of the International Organization for Standardization.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) Any risk management policy and program implemented pursuant to subdivision (a) of this subsection may cover multiple high-risk artificial intelligence systems deployed by the deployer.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(3)(a) Except as otherwise provided in this subsection or subsection (6) of this section:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) An impact assessment shall be completed for each high-risk artificial intelligence system deployed on or after February 1, 2026. Such impact assessment shall be completed by the deployer or by a third party contracted by the deployer; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) On and after February 1, 2026, for each deployed high-risk artificial intelligence system, a deployer or a third party contracted by the deployer shall complete an impact assessment within ninety days after any intentional and substantial modification to such high-risk artificial intelligence system is made available.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) An impact assessment completed pursuant to this subsection shall include to the extent reasonably known by or available to the deployer:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) A statement by the deployer disclosing:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) The purpose of the high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) Any intended-use case for the high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(C) The deployment context of the high-risk artificial intelligence system; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(D) Any benefit afforded by the high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) An analysis of whether the deployment of the high-risk artificial intelligence system poses any known risk of algorithmic discrimination and, if so, the nature of the algorithmic discrimination and the steps that have been taken to mitigate any such risk;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) A high-level summary of the categories of data the high-risk artificial intelligence system processes as inputs and the outputs the high-risk artificial intelligence system produces;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iv) If the deployer used data to customize the high-risk artificial intelligence system, an overview of the categories of data the deployer used to customize the high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(v) Any metric used to evaluate the performance and any known limitation of the high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(vi) A description of any transparency measure taken concerning the high-risk artificial intelligence system, including any measure taken to disclose to a consumer when the high-risk artificial intelligence system is in use; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(vii) A description of each postdeployment monitoring and user safeguard provided concerning the high-risk artificial intelligence system, including the oversight, use, and learning process established by the deployer to address any issue that arises from the deployment of the high-risk artificial intelligence system.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(c) Any impact assessment completed pursuant to this subsection following an intentional and substantial modification to a high-risk artificial intelligence system on or after February 1, 2026, shall include a statement that discloses the extent to which the high-risk artificial intelligence system was used in a manner that was consistent with or varied from any use of the high-risk artificial intelligence system intended by the developer.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(d) A single impact assessment may address a comparable set of high- risk artificial intelligence systems deployed by a deployer.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(e) Any impact assessment completed to comply with another applicable law or regulation by a deployer or by a third party contracted by the deployer shall satisfy this subsection if such impact assessment is reasonably similar in scope and effect to the impact assessment that would otherwise be completed pursuant to this subsection.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(f) A deployer shall maintain:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) The most recently completed impact assessment required under this subsection for each high-risk artificial intelligence system of the deployer;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Each record concerning each such impact assessment; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) For at least three years following the final deployment of each high-risk artificial intelligence system, each prior impact assessment, if any, and each record concerning such impact assessment.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(4)(a) On and after February 1, 2026, prior to deploying any high- risk artificial intelligence system to make or be a substantial factor in making any consequential decision concerning any consumer, the deployer shall:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) Notify the consumer that the deployer has deployed a high-risk artificial intelligence system to make or be a substantial factor in making a consequential decision;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Provide to the consumer:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) A statement that discloses the purpose of the high-risk artificial intelligence system and the nature of the consequential decision;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) The contact information for the deployer;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(C) A description written in plain language that describes the high- risk artificial intelligence system; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(D) Instructions on how to access the statement described in subdivision (5)(a) of this section; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) If applicable, provide information to the consumer regarding the consumer&#39;s right to opt out of the processing of personal data concerning the consumer for any purpose of profiling in furtherance of decisions that produce legal or similarly significant effects concerning the consumer under subdivision (2)(e)(iii) of section 87-1107.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) On and after February 1, 2026, for each high-risk artificial intelligence system that makes or is a substantial factor in making any consequential decision that is adverse to any consumer, the deployer of such high-risk artificial intelligence system shall provide to such consumer:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) A statement that discloses each principal reason for the consequential decision, including:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) The degree to and manner in which the high-risk artificial intelligence system contributed to the consequential decision;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) The type of data that was processed by the high-risk artificial intelligence system in making the consequential decision; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(C) Each source of the data described in subdivision (b)(i)(B) of this subsection;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) An opportunity to correct any incorrect personal data that the high-risk artificial intelligence system processed in making or processed as a substantial factor in making the consequential decision; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) An opportunity to appeal any adverse consequential decision concerning the consumer arising from the deployment of the high-risk artificial intelligence system unless providing the opportunity for appeal is not in the best interest of the consumer, including instances when any delay might pose a risk to the life or safety of such consumer. Any such appeal shall allow for human review if technically feasible.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(c)(i) Except as provided in subdivision (c)(ii) of this subsection, a deployer shall provide the notice, statement, contact information, and description required under subdivisions (4)(a) and (b) of this section:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) Directly to the consumer;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) In plain language;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(C) In each language in which the deployer in the ordinary course of business provides any contract, disclaimer, sale announcement, or other information to any consumer; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(D) In a format that is accessible to any consumer with any disability.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) If the deployer is unable to provide the notice, statement, contact information, and description required under subdivisions (a) and (b) of this subsection directly to the consumer, the deployer shall make the notice, statement, contact information, and description available in a manner that is reasonably calculated to ensure that the consumer receives the notice, statement, contact information, and description.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(5)(a) Except as provided in subsection (6) of this section, on and after February 1, 2026, a deployer shall make a statement with the following information available in a manner that is clear and readily available:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) The types of high-risk artificial intelligence systems that are currently deployed by the deployer;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) How the deployer manages known risks of algorithmic discrimination that may arise from the deployment of the types of high- risk artificial intelligence systems described in subdivision (a)(ii) of this subsection; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) A description of the nature, source, and extent of the information collected and used by the deployer.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) A deployer shall update the statement described in subdivision (a) of this subsection at least once each year.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(6) Subsections (2), (3), and (5) of this section do not apply to </u>a <u class=\"amendmentInsertedText\">deployer if when deploying a high-risk artificial intelligence system and at all times while the high-risk artificial intelligence system is deployed:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(a) The deployer:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) Employs fewer than fifty full-time equivalent employees; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Does not use the deployer&#39;s own data to train the high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) The high-risk artificial intelligence system:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) Is used for any intended use that is disclosed to the deployer as required under subdivision (2)(a) of section 3 of this act; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Continues learning based on data derived from sources other than the deployer&#39;s own data; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(c) The deployer makes available to consumers any impact assessment that:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) The developer of the high-risk artificial intelligence system has completed and provided to the deployer; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Includes information that is substantially similar to the information in the impact assessment required under subdivision (3)(b) of this section.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(7) Nothing in this section requires a deployer to disclose a trade secret or information protected from disclosure by state or federal law. To the extent that a deployer withholds information pursuant to this subsection or subsection (5) of section 6 of this act, the deployer shall notify the consumer and provide a basis for such withholding.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(8)(a) On and after February 1, 2026, in connection with an ongoing investigation related to the deployer, the Attorney General may require any deployer or third party contracted by a deployer to disclose any of the following to the Attorney General no later than ninety days after such request in a form and manner prescribed by the Attorney General:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) The risk management policy implemented pursuant to subsection (2) of this section;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) The impact assessment completed pursuant to subsection (3) of this section; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) The records maintained pursuant to subdivision (3)(f) of this section.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) If such risk management policy, impact assessment, or record is relevant to an investigation conducted by the Attorney General regarding a violation of the Artificial Intelligence Consumer Protection Act, the Attorney General may evaluate the risk management policy, impact assessment, or records disclosed pursuant to subdivision (a) of this subsection to ensure compliance with the Artificial Intelligence Consumer Protection Act.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(c) Any disclosure under this subsection shall not be a public record subject to disclosure pursuant to sections 84-712 to 84-712.09.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(d) A deployer may designate any statement or documentation disclosed under this subsection as including proprietary information or </u>a <u class=\"amendmentInsertedText\">trade secret.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(9) If a deployer completes documentation for the purpose of complying with another applicable law or regulation, such documentation shall be deemed to satisfy this section if such documentation is reasonably similar in scope and effect to the documentation that would otherwise be completed pursuant to this section.</u>\n   </p>\n   <p class=\"indent\">\n    <b>Sec. 5. </b>\n    <u class=\"amendmentInsertedText\">(1) On and after February 1, 2026, and except as otherwise provided in subsection (2) of this section, a deployer or other developer that deploys, offers, sells, leases, licenses, gives, or otherwise makes available any artificial intelligence system that is intended to interact with any consumer shall include in the disclosure to each consumer who interacts with such artificial intelligence system that the consumer is interacting with an artificial intelligence system.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(2) Disclosure is not required under subsection (1) of this section under any circumstance when it would be obvious to a reasonable person that the person is interacting with an artificial intelligence system.</u>\n   </p>\n   <p class=\"indent\">\n    <b>Sec. 6. </b>\n    <u class=\"amendmentInsertedText\">(1) The Artificial Intelligence Consumer Protection Act does not restrict the ability of any developer, deployer, or other person to:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(a) Comply with federal, state, or municipal laws, ordinances, or regulations;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) Comply with any civil, criminal, or regulatory inquiry, investigation, subpoena, or summons by any federal, state, municipal, or other governmental authority;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(c) Cooperate with any law enforcement agency concerning conduct or activity that the developer, deployer, or other person reasonably and in good faith believes may violate any federal, state, or municipal law, ordinance, or regulation;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(d) Investigate, establish, exercise, prepare for, or defend any legal claim;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(e) Take immediate action to protect any interest that is essential for the life or physical safety of any consumer or another individual;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(f) By any means:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) Prevent, detect, protect against, or respond to any security incident, identity theft, fraud, harassment, malicious or deceptive activity, or illegal activity;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Investigate, report, or prosecute any person responsible for any action described in subdivision (f)(i) of this subsection; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) Preserve the integrity or security of any system of the developer, deployer, or other person;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(g) Engage in public or peer-reviewed scientific or statistical research in the public interest that:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) Adheres to each applicable ethics or privacy law; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Is conducted in accordance with 45 C.F.R. part 46, as such section existed on January 1, 2025, or any relevant requirement established by the federal Food and Drug Administration;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(h) Conduct any research, testing, or development activity regarding any artificial intelligence system or model, other than testing conducted under real-world conditions, before the artificial intelligence system or model is placed on the market, deployed, or put into service; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) Provide assistance complying with the Artificial Intelligence Consumer Protection Act to any other developer, deployer, or person.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(2) The Artificial Intelligence Consumer Protection Act does not restrict the ability of any developer, deployer, or other person to:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(a) Effectuate a product recall; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) Identify and repair any technical error that impairs existing or intended functionality of any artificial intelligence system.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(3) The Artificial Intelligence Consumer Protection Act does not apply to any instance in which compliance with such act would violate any evidentiary privilege under the laws of this state.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(4) The Artificial Intelligence Consumer Protection Act does not and shall not be construed to impose any obligation on any developer, deployer, or other person that adversely affects any right or freedom of any person, including the rights of a person to freedom of speech or freedom of the press.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(5) The Artificial Intelligence Consumer Protection Act does not apply to any developer, deployer, or other person:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(a) If the developer, deployer, or other person develops, deploys, puts into service, or intentionally and substantially modifies any high- risk artificial intelligence system:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) That has been approved, authorized, certified, cleared, developed, deployed, or granted by any federal agency acting within the scope of authority of such federal agency; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) In compliance with standards established by any federal agency, if the standards are substantially equivalent or more stringent than the requirements of the Artificial Intelligence Consumer Protection Act;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) Conducting research to support an application:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) For approval or certification from any federal agency, federal administration, or federal commission; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) That is subject to review by any federal agency, federal administration, or federal commission;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(c) Performing work under or in connection with any contract with the United States Department of Commerce, the United States Department of Defense, or the National Aeronautics and Space Administration, unless such work relates to any high-risk artificial intelligence system that is used to make or is a substantial factor in making a decision concerning employment or housing; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(d) That is providing or facilitating any health care recommendation that:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) Is generated by any artificial intelligence system; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Includes a health care provider in the process to implement the recommendation.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(6) The Artificial Intelligence Consumer Protection Act does not apply to any artificial intelligence system that is acquired by or for the federal government or any federal agency or department, unless the artificial intelligence system is a high-risk artificial intelligence system that is used to make or is a substantial factor in making a decision concerning employment or housing.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(7) The Artificial Intelligence Consumer Protection Act does not apply to any of the following that are subject to the Unfair Insurance Trade Practices Act:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(a) Any insurer;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) Any fraternal benefit society as described in section 44-1072; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(c) Any developer of an artificial intelligence system used by an insurer.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(8)(a) For purposes of this subsection:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) Affiliate has the same meaning as in section 8-916;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Bank has the same meaning as in section 8-909; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) Credit union has the same meaning as in section 21-1705.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) The Artificial Intelligence Consumer Protection Act does not apply to any bank, credit union, affiliate or subsidiary of any bank or credit union, or service provider that is subject to examination by any state or federal prudential regulator under any published guidance or regulations that apply to the use of high-risk artificial intelligence systems and the guidance or regulations:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) Impose requirements that are substantially equivalent to or more stringent than the requirements imposed in the Artificial Intelligence Consumer Protection Act as determined by the Attorney General; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) At a minimum, require the bank, credit union, affiliate or subsidiary of the bank or credit union, or service provider to:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) Regularly audit the use of any high-risk artificial intelligence system by the bank, credit union, or affiliate or subsidiary of the bank or credit union for compliance with state and federal antidiscrimination laws and regulations applicable to the bank, credit union, affiliate or subsidiary of the bank or credit union, or service provider; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) Mitigate any algorithmic discrimination caused by the use of any high-risk artificial intelligence system or any risk of algorithmic discrimination that is a result of the use of any high-risk artificial intelligence system.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(9) If any developer, deployer, or other person engages in any action pursuant to an exemption set forth in this section, the developer, deployer, or other person bears the burden of demonstrating that the action qualifies for the exemption.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(10) This section does not apply to:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(a) Artificial intelligence systems, including their output, specifically developed and put into service for the sole purpose of scientific research and development;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) A regulated entity subject to the supervision and regulation of the Federal Housing Finance Agency; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(c) A creditor as defined by and subject to the federal Equal Credit Opportunity Act, 15 U.S.C. 1691 et seq., or the regulations adopted pursuant to such act.</u>\n   </p>\n   <p class=\"indent\">\n    <b>Sec. 7. </b>\n    <u class=\"amendmentInsertedText\">(1) The Attorney General has exclusive authority to enforce the Artificial Intelligence Consumer Protection Act.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(2) Except as provided in subsection (5) of this section, the Attorney General shall, prior to initiating any action for a violation of the Artificial Intelligence Consumer Protection Act, issue a notice of violation to the developer, deployer, or other person describing with specificity the alleged violation and the actions that shall be taken by the recipient of the notice to cure the violation. If the developer, deployer, or other person fails to cure such violation not later than ninety days after receipt of the notice of violation, the Attorney General may bring an action under the Artificial Intelligence Consumer Protection Act.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(3) In any action commenced by the Attorney General to enforce the Artificial Intelligence Consumer Protection Act, it is an affirmative defense that the developer, deployer, or other person:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(a) Discovers and cures a violation of the Artificial Intelligence Consumer Protection Act as a result of:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) Feedback that the developer, deployer, or other person encourages deployers or users to provide to the developer, deployer, or other person;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Adversarial testing or red teaming; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) An internal review process; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) Is otherwise in compliance with:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) The Artificial Intelligence Risk Management Framework published by the National Institute of Standards and Technology and standard ISO/IEC 42001 of the International Organization for Standardization, as such framework and standard existed on January 1, 2025;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Another nationally or internationally recognized risk management framework for artificial intelligence systems, if the standards are substantially equivalent to or more stringent than the requirements of the Artificial Intelligence Consumer Protection Act as determined by the Attorney General; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) Any risk management framework for artificial intelligence systems designated and publicly disseminated by the Attorney General.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(4) Any developer, deployer, or other person bears the burden of demonstrating to the Attorney General that the requirements of subsection (3) of this section have been satisfied.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(5)(a) The Artificial Intelligence Consumer Protection Act shall not be construed to preempt or otherwise affect any right, claim, remedy, presumption, or defense available at law or in equity.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) Any rebuttable presumption or affirmative defense under the Artificial Intelligence Consumer Protection Act applies only to an enforcement action brought by the Attorney General pursuant to this section and shall not apply to any right, claim, remedy, presumption, or defense available at law or in equity.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(6) The Artificial Intelligence Consumer Protection Act does not provide the basis for and is not subject to any private right of action for any violation of the Artificial Intelligence Consumer Protection Act or any other law.</u>\n   </p>\n   <p class=\"indent\">\n    <b>Sec. 8. </b> If any section in this act or any part of any section is declared invalid or unconstitutional, the declaration shall not affect the validity or constitutionality of the remaining portions.</p>\n  </div>\n </div>\n    </div>\t\n<table cellpadding=0 cellspacing=0 width=\"100%\">\n   <tr>\n      <td>\n          Copyright &copy; 2025 State Net\n      </td>\n<BR>\n<!--???MOVED INTO resources.cgi      <td align=\"right\">\n          <img src=\"https://custom.statenet.com/network/poweredby.gif\" alt=\"Powered by State Net\">\n      </td>-->\n\n    </tr>\n</table>\n</body></html>\n",
      "markdown": "The following has special meaning: _green underline denotes added text_ ~~red struck out text denotes deleted text~~ | [![Powered by State Net](https://custom.statenet.com/network/poweredby.gif)](https://www.lexisnexis.com/statenet/)  \n---|---  \n  \n2025 NE L 642 | | Author: | Bostar  \n---|---  \nVersion: | Introduced  \nVersion Date: | 01/22/2025  \n  \nLEGISLATURE OF NEBRASKA\n\nONE HUNDRED NINTH LEGISLATURE\n\nFIRST SESSION\n\n**LEGISLATIVE BILL 642**\n\nIntroduced by Bostar, 29.\n\nRead first time January 22, 2025\n\nCommittee:\n\nA BILL FOR AN ACT relating to discrimination; to adopt the Artificial\nIntelligence Consumer Protection Act; and to provide severability.\n\nBe it enacted by the people of the State of Nebraska,\n\n**Section 1.** _Sections 1 to 7 of this act shall be known and may be cited as\nthe Artificial Intelligence Consumer Protection Act._\n\n**Sec. 2.** _For purposes of the Artificial Intelligence Consumer Protection\nAct:_\n\n_(1)(a) Algorithmic discrimination means any use of an artificial intelligence\nsystem that violates state or federal anti-discrimination laws, including\nfederal statutes prohibiting discrimination on the basis of citizenship\nstatus, color, disability, national origin, race, or sex, or any other\nclassification protected under the laws of this state or federal law; and_\n\n_(b) Algorithmic discrimination does not include:_\n\n_(i) The offer, license, or use of a high-risk artificial intelligence system\nby a developer or deployer for the sole purpose of:_\n\n_(A) The developer 's or deployer's self-testing to identify, mitigate, or\nprevent discrimination or otherwise ensure compliance with state and federal\nlaw; or_\n\n_(B) Expanding an applicant, customer, or participant pool to increase\ndiversity or redress historical discrimination; or_\n\n_(ii) An act or omission by or on behalf of a private club or other\nestablishment that is not in fact open to the public, pursuant to the federal\nCivil Rights Act of 1964, 42 U.S.C. 2000a(e), as such section existed on\nJanuary 1, 2025;_\n\n_(2) Artificial intelligence system means any machine-based system that, for\nany explicit or implicit objective, infers from the inputs the system receives\nhow to generate outputs, including content, decisions, predictions, or\nrecommendations, that can influence physical or virtual environments;_\n\n_(3) Consequential decision means a decision that has a material legal or\nsimilarly significant effect on the provision or denial to any consumer of\nany, or the cost or terms of any:_\n\n_(a) Education enrollment or an education opportunity;_\n\n_(b) Employment;_\n\n_(c) Lending decision;_\n\n_(d) Essential government service;_\n\n_(e) Health care services;_\n\n_(f) Housing;_\n\n_(g) Insurance;_\n\n_(h) Legal service; or_\n\n_(i) Pardon, parole, probation, or release decision;_\n\n_(4) Consumer means any individual who is a resident of this state;_\n\n_(5) Deploy means to use a high-risk artificial intelligence system;_\n\n_(6) Deployer means a person doing business in this state that deploys a high-\nrisk artificial intelligence system in this state;_\n\n_(7) Developer means a person doing business in this state that develops or\nintentionally and substantially modifies a high-risk artificial intelligence\nsystem in this state;_\n\n_(8) Health care services has the same meaning as in 42 U.S.C. 234(d) (2), as\nsuch section existed on January 1, 2025;_\n\n_(9)(a) High-risk artificial intelligence system means any artificial\nintelligence system that, when deployed, makes a consequential decision\nwithout human review or intervention; and_\n\n_(b) High-risk artificial intelligence system does not include:_\n\n_(i) Any artificial intelligence system if the artificial intelligence system\nis intended to:_\n\n_(A) Perform a narrow procedural task;_\n\n_(B) Improve the result of a previously completed human activity;_\n\n_(C) Perform a preparatory task to an assessment that is relevant to a\nconsequential decision; or_\n\n_(D) Detect decisionmaking patterns or deviations from preexisting\ndecisionmaking patterns and is not intended to replace or influence_ a\n_previously completed human assessment without sufficient human review; and_\n\n_(ii) Any of the following technology:_\n\n_(A) Antifraud technology;_\n\n_(B) Antimalware;_\n\n_(C) Antivirus;_\n\n_(D) Artificial intelligence-enabled video game;_\n\n_(E) Calculator;_\n\n_(F) Cybersecurity;_\n\n_(G) Database;_\n\n_(H) Data storage;_\n\n_(I) Firewall;_\n\n_(J) Internet domain registration;_\n\n_(K) Internet website loading;_\n\n_(L) Networking;_\n\n_(M) Spam-filtering;_\n\n_(N) Robocall-filtering;_\n\n_(O) Spell-checking;_\n\n_(P) Spreadsheet;_\n\n_(Q) Web caching;_\n\n_(R) Web hosting or any similar technology; or_\n\n_(S) Technology that:_\n\n_(I) Communicates with any consumer in natural language for the purpose of\nproviding such consumer with information, making any referral or\nrecommendation, or answering any question; and_\n\n_(II) Is subject to an acceptable use policy that prohibits generating content\nthat is unlawful or harmful;_\n\n_(10) Insurer means any person engaged as principal, indemnitor, surety, or\ncontractor in the business of making contracts of insurance;_\n\n_(11)(a) Intentional and substantial modification means a deliberate and\nmaterial change made to an artificial intelligence system that materially\nincreases the known risk of algorithmic discrimination; and_\n\n_(b) Intentional and substantial modification does not include any change made\nto any high-risk artificial intelligence system, or the performance of any\nhigh-risk artificial intelligence system, if:_\n\n_(i) The high-risk artificial intelligence system continues to learn after the\nhigh-risk artificial intelligence system is:_\n\n_(A) Offered, sold, leased, licensed, given, or otherwise made available to a\ndeployer; or_\n\n_(B) Deployed;_\n\n_(ii) The change is made to the high-risk artificial intelligence system as a\nresult of any learning described in subdivision (10)(b)(i) of this section;_\n\n_(iii) The change was predetermined by the deployer, or a third party\ncontracted by the deployer, when the deployer or third party completed an\ninitial impact assessment of such high-risk artificial intelligence system\npursuant to subsection (3) of section 4 of this act; and_\n\n_(iv) The change is included in technical documentation for the high- risk\nartificial intelligence system;_\n\n_(12) Intentionally and substantially modifies means intentional and\nsubstantial modification as defined in this section;_\n\n_(13) Principal basis means the use of an output of a high-risk artificial\nintelligence system to make a decision without:_\n\n_(a) Human review, oversight, involvement, or intervention; or_\n\n_(b) Meaningful consideration by a human;_\n\n_(14) Red teaming means an exercise that is conducted to identify the\npotential adverse behaviors or outcomes of an artificial intelligence system,\nidentify how such behaviors or outcomes occur, and stress test the safeguards\nagainst such behaviors or outcomes;_\n\n_(15)(a) Substantial factor means any factor that:_\n\n_(i) Is the principal basis for making a consequential decision;_\n\n_(ii) Is capable of altering the outcome of a consequential decision; and_\n\n_(iii) Is generated by an artificial intelligence system; and_\n\n_(b) Substantial factor includes any use of any artificial intelligence system\nto generate any content, decision, prediction, or recommendation concerning\nany consumer that is used as a basis to make_ a _consequential decision\nconcerning the consumer; and_\n\n_(16) Trade secret has the same meaning as in section 87-502._\n\n**Sec. 3.** _(1)(a) On and after February 1, 2026, a developer of_ a _high-\nrisk artificial intelligence system shall use reasonable care to protect\nconsumers from any known risks of algorithmic discrimination arising from the\nintended and contracted uses of the high-risk artificial intelligence system._\n\n_(b) In any enforcement action brought on or after February 1, 2026, by the\nAttorney General pursuant to section 7 of this act, there is_ a _rebuttable\npresumption that a developer used reasonable care as required under this\nsection if the developer complied with this section._\n\n_(2) Except as otherwise provided in subsection (6) of this section, on and\nafter February 1, 2026, each developer of a high-risk artificial intelligence\nsystem shall make available to the deployer or other developer of the high-\nrisk artificial intelligence system:_\n\n_(a) A general statement describing the uses and known harmful or\ninappropriate uses of the high-risk artificial intelligence system;_\n\n_(b) Documentation disclosing:_\n\n_(i) A high-level summary of the types of data used to train the high-risk\nartificial intelligence system;_\n\n_(ii) Each known limitation of the high-risk artificial intelligence system,\nincluding each known or reasonably foreseeable risk of algorithmic\ndiscrimination arising from the intended use of the high-risk artificial\nintelligence system;_\n\n_(iii) The purpose of the high-risk artificial intelligence system;_\n\n_(iv) Any intended benefit and use of the high-risk artificial intelligence\nsystem; and_\n\n_(v) Information necessary to allow the deployer to comply with the\nrequirements of section 4 of this act;_\n\n_(c) Documentation describing:_\n\n_(i) How the high-risk artificial intelligence system was evaluated for\nperformance and mitigation of algorithmic discrimination before the high-risk\nartificial intelligence system was offered, sold, leased, licensed, given, or\notherwise made available to the deployer;_\n\n_(ii) The data governance measures used to cover the training datasets and the\nmeasures used to examine the suitability of data sources, possible biases, and\nappropriate mitigation;_\n\n_(iii) Intended outputs of the high-risk artificial intelligence system;_\n\n_(iv) The measures the developer has taken to mitigate known risks of\nalgorithmic discrimination that could arise from the deployment of the high-\nrisk artificial intelligence system; and_\n\n_(v) How the high-risk artificial intelligence system should be used, not be\nused, and be monitored by an individual when the high-risk artificial\nintelligence system is used to make, or is a substantial factor in making, a\nconsequential decision; and_\n\n_(d) Documentation that is reasonably necessary to assist the deployer in\nunderstanding each output and monitor the performance of the high-risk\nartificial intelligence system for each risk of algorithmic discrimination._\n\n_(3)(a) Except as otherwise provided in subsection (6) of this section, on or\nafter February 1, 2026, a developer that offers, sells, leases, licenses,\ngives, or otherwise makes any high-risk artificial intelligence system\navailable to a deployer or other developer shall to the extent feasible make\navailable to the deployer or other developer the documentation and information\nnecessary for the deployer or a third party contracted by the deployer to\ncomplete an impact assessment pursuant to subsection (3) of section 4 of this\nact. Such documentation and information includes any model card or other\nimpact assessment._\n\n_(b) A developer that also serves as a deployer for a high-risk artificial\nintelligence system is not required to generate the documentation required by\nthis section unless the high-risk artificial intelligence system is provided\nto an unaffiliated entity acting as a deployer._\n\n_(4)(a) On and after February 1, 2026, a developer shall make a statement\nsummarizing the following available in a manner that is clear and readily\navailable in a public use case inventory:_\n\n_(i) The types of high-risk artificial intelligence systems that the developer\nhas developed and currently makes available to a deployer or other developer;_\n\n_(ii) The types of high-risk artificial intelligence system that the developer\nhas intentionally and substantially modified and currently makes available to\na deployer or other developer; and_\n\n_(iii) How the developer manages known risks of algorithmic discrimination\nthat could arise from the development or intentional and substantial\nmodification of the types of high-risk artificial intelligence systems\ndescribed in subdivisions (4)(a)(i) and (ii) of this section._\n\n_(b) A developer shall update the statement described in subdivision (4)(a) of\nthis section:_\n\n_(i) As necessary to ensure that the statement remains accurate; and_\n\n_(ii) No later than ninety days after the developer intentionally and\nsubstantially modifies any high-risk artificial intelligence system described\nin subdivision (4)(a)(ii) of this section._\n\n_(5)(a) On and after February 1, 2026, a developer of a high-risk artificial\nintelligence system shall disclose to all known deployers or other developers\nof the high-risk artificial intelligence system, each known risk of\nalgorithmic discrimination arising from any intended use of the high-risk\nartificial intelligence system without unreasonable delay after the date on\nwhich:_\n\n_(i) The developer discovers through the developer 's ongoing testing and\nanalysis that the developer's high-risk artificial intelligence system has\nbeen deployed and has caused or is reasonably likely to have caused\nalgorithmic discrimination; or_\n\n_(ii) The developer receives from a deployer a credible report that the high-\nrisk artificial intelligence system has been deployed and has caused\nalgorithmic discrimination._\n\n_(b) The Attorney General shall prescribe the form and manner of the\ndisclosure described in subdivision (a) of this subsection._\n\n_(6) Nothing in subsections (2) through (5) of this section requires a\ndeveloper to disclose any:_\n\n_(a) Trade secret;_\n\n_(b) Information protected from disclosure by state or federal law; or_\n\n_(c) Information that would create a security risk to the developer._\n\n_(7)(a) On and after February 1, 2026, the Attorney General may provide a\nwritten demand to any developer to disclose to the Attorney General the\nstatement or documentation described in subsection (2) of this section if such\na statement or documentation is relevant to an investigation related to the\ndeveloper conducted by the Attorney General. Such statement or documentation\nshall be provided to the Attorney General in a form and manner prescribed by\nthe Attorney General._\n\n_(b) The Attorney General may evaluate such statement or documentation, if it\nis relevant to an investigation conducted by the Attorney General regarding a\nviolation of the Artificial Intelligence Consumer Protection Act, to ensure\ncompliance with the Artificial Intelligence Consumer Protection Act._\n\n_(c) In any disclosure pursuant to this subsection, any developer may\ndesignate the statement or documentation as including proprietary information\nor a trade secret._\n\n_(d) To the extent any such statement or documentation includes any\nproprietary information or any trade secret, such statement or documentation\nshall be exempt from disclosure._\n\n_(8) If a developer completes documentation for the purpose of complying with\nanother applicable law or regulation, such documentation shall be deemed to\nsatisfy this section if such documentation is reasonably similar in scope and\neffect to the documentation that would otherwise be completed pursuant to this\nsection._\n\n**Sec. 4.** _(1)(a) On and after February 1, 2026, a deployer of any high-risk\nartificial intelligence system shall use reasonable care to protect consumers\nfrom each known risk of algorithmic discrimination._\n\n_(b) In any enforcement action brought on or after February 1, 2026, by the\nAttorney General pursuant to section 7 of this act, there is_ a _rebuttable\npresumption that a deployer of a high-risk artificial intelligence system used\nreasonable care as required under this section if the deployer complied with\nthis section._\n\n_(2)(a) Except as otherwise provided in subsection (6) of this section, on and\nafter February 1, 2026, a deployer of a high-risk artificial intelligence\nsystem shall implement a risk management policy and program to govern the\ndeployer 's deployment of the high-risk artificial intelligence system. High-\nrisk artificial intelligence systems that are in conformity with the guidance\nand standards set forth in the following as of January 1, 2025, shall be\npresumed to be in conformity with this section:_\n\n_(i) The Artificial Intelligence Risk Management Framework published by the\nNational Institute of Standards and Technology; or_\n\n_(ii) The standard ISO/IEC 42001 of the International Organization for\nStandardization._\n\n_(b) Any risk management policy and program implemented pursuant to\nsubdivision (a) of this subsection may cover multiple high-risk artificial\nintelligence systems deployed by the deployer._\n\n_(3)(a) Except as otherwise provided in this subsection or subsection (6) of\nthis section:_\n\n_(i) An impact assessment shall be completed for each high-risk artificial\nintelligence system deployed on or after February 1, 2026. Such impact\nassessment shall be completed by the deployer or by a third party contracted\nby the deployer; and_\n\n_(ii) On and after February 1, 2026, for each deployed high-risk artificial\nintelligence system, a deployer or a third party contracted by the deployer\nshall complete an impact assessment within ninety days after any intentional\nand substantial modification to such high-risk artificial intelligence system\nis made available._\n\n_(b) An impact assessment completed pursuant to this subsection shall include\nto the extent reasonably known by or available to the deployer:_\n\n_(i) A statement by the deployer disclosing:_\n\n_(A) The purpose of the high-risk artificial intelligence system;_\n\n_(B) Any intended-use case for the high-risk artificial intelligence system;_\n\n_(C) The deployment context of the high-risk artificial intelligence system;\nand_\n\n_(D) Any benefit afforded by the high-risk artificial intelligence system;_\n\n_(ii) An analysis of whether the deployment of the high-risk artificial\nintelligence system poses any known risk of algorithmic discrimination and, if\nso, the nature of the algorithmic discrimination and the steps that have been\ntaken to mitigate any such risk;_\n\n_(iii) A high-level summary of the categories of data the high-risk artificial\nintelligence system processes as inputs and the outputs the high-risk\nartificial intelligence system produces;_\n\n_(iv) If the deployer used data to customize the high-risk artificial\nintelligence system, an overview of the categories of data the deployer used\nto customize the high-risk artificial intelligence system;_\n\n_(v) Any metric used to evaluate the performance and any known limitation of\nthe high-risk artificial intelligence system;_\n\n_(vi) A description of any transparency measure taken concerning the high-risk\nartificial intelligence system, including any measure taken to disclose to a\nconsumer when the high-risk artificial intelligence system is in use; and_\n\n_(vii) A description of each postdeployment monitoring and user safeguard\nprovided concerning the high-risk artificial intelligence system, including\nthe oversight, use, and learning process established by the deployer to\naddress any issue that arises from the deployment of the high-risk artificial\nintelligence system._\n\n_(c) Any impact assessment completed pursuant to this subsection following an\nintentional and substantial modification to a high-risk artificial\nintelligence system on or after February 1, 2026, shall include a statement\nthat discloses the extent to which the high-risk artificial intelligence\nsystem was used in a manner that was consistent with or varied from any use of\nthe high-risk artificial intelligence system intended by the developer._\n\n_(d) A single impact assessment may address a comparable set of high- risk\nartificial intelligence systems deployed by a deployer._\n\n_(e) Any impact assessment completed to comply with another applicable law or\nregulation by a deployer or by a third party contracted by the deployer shall\nsatisfy this subsection if such impact assessment is reasonably similar in\nscope and effect to the impact assessment that would otherwise be completed\npursuant to this subsection._\n\n_(f) A deployer shall maintain:_\n\n_(i) The most recently completed impact assessment required under this\nsubsection for each high-risk artificial intelligence system of the deployer;_\n\n_(ii) Each record concerning each such impact assessment; and_\n\n_(iii) For at least three years following the final deployment of each high-\nrisk artificial intelligence system, each prior impact assessment, if any, and\neach record concerning such impact assessment._\n\n_(4)(a) On and after February 1, 2026, prior to deploying any high- risk\nartificial intelligence system to make or be a substantial factor in making\nany consequential decision concerning any consumer, the deployer shall:_\n\n_(i) Notify the consumer that the deployer has deployed a high-risk artificial\nintelligence system to make or be a substantial factor in making a\nconsequential decision;_\n\n_(ii) Provide to the consumer:_\n\n_(A) A statement that discloses the purpose of the high-risk artificial\nintelligence system and the nature of the consequential decision;_\n\n_(B) The contact information for the deployer;_\n\n_(C) A description written in plain language that describes the high- risk\nartificial intelligence system; and_\n\n_(D) Instructions on how to access the statement described in subdivision\n(5)(a) of this section; and_\n\n_(iii) If applicable, provide information to the consumer regarding the\nconsumer 's right to opt out of the processing of personal data concerning the\nconsumer for any purpose of profiling in furtherance of decisions that produce\nlegal or similarly significant effects concerning the consumer under\nsubdivision (2)(e)(iii) of section 87-1107._\n\n_(b) On and after February 1, 2026, for each high-risk artificial intelligence\nsystem that makes or is a substantial factor in making any consequential\ndecision that is adverse to any consumer, the deployer of such high-risk\nartificial intelligence system shall provide to such consumer:_\n\n_(i) A statement that discloses each principal reason for the consequential\ndecision, including:_\n\n_(A) The degree to and manner in which the high-risk artificial intelligence\nsystem contributed to the consequential decision;_\n\n_(B) The type of data that was processed by the high-risk artificial\nintelligence system in making the consequential decision; and_\n\n_(C) Each source of the data described in subdivision (b)(i)(B) of this\nsubsection;_\n\n_(ii) An opportunity to correct any incorrect personal data that the high-risk\nartificial intelligence system processed in making or processed as a\nsubstantial factor in making the consequential decision; and_\n\n_(iii) An opportunity to appeal any adverse consequential decision concerning\nthe consumer arising from the deployment of the high-risk artificial\nintelligence system unless providing the opportunity for appeal is not in the\nbest interest of the consumer, including instances when any delay might pose a\nrisk to the life or safety of such consumer. Any such appeal shall allow for\nhuman review if technically feasible._\n\n_(c)(i) Except as provided in subdivision (c)(ii) of this subsection, a\ndeployer shall provide the notice, statement, contact information, and\ndescription required under subdivisions (4)(a) and (b) of this section:_\n\n_(A) Directly to the consumer;_\n\n_(B) In plain language;_\n\n_(C) In each language in which the deployer in the ordinary course of business\nprovides any contract, disclaimer, sale announcement, or other information to\nany consumer; and_\n\n_(D) In a format that is accessible to any consumer with any disability._\n\n_(ii) If the deployer is unable to provide the notice, statement, contact\ninformation, and description required under subdivisions (a) and (b) of this\nsubsection directly to the consumer, the deployer shall make the notice,\nstatement, contact information, and description available in a manner that is\nreasonably calculated to ensure that the consumer receives the notice,\nstatement, contact information, and description._\n\n_(5)(a) Except as provided in subsection (6) of this section, on and after\nFebruary 1, 2026, a deployer shall make a statement with the following\ninformation available in a manner that is clear and readily available:_\n\n_(i) The types of high-risk artificial intelligence systems that are currently\ndeployed by the deployer;_\n\n_(ii) How the deployer manages known risks of algorithmic discrimination that\nmay arise from the deployment of the types of high- risk artificial\nintelligence systems described in subdivision (a)(ii) of this subsection; and_\n\n_(iii) A description of the nature, source, and extent of the information\ncollected and used by the deployer._\n\n_(b) A deployer shall update the statement described in subdivision (a) of\nthis subsection at least once each year._\n\n_(6) Subsections (2), (3), and (5) of this section do not apply to_ a\n_deployer if when deploying a high-risk artificial intelligence system and at\nall times while the high-risk artificial intelligence system is deployed:_\n\n_(a) The deployer:_\n\n_(i) Employs fewer than fifty full-time equivalent employees; and_\n\n_(ii) Does not use the deployer 's own data to train the high-risk artificial\nintelligence system;_\n\n_(b) The high-risk artificial intelligence system:_\n\n_(i) Is used for any intended use that is disclosed to the deployer as\nrequired under subdivision (2)(a) of section 3 of this act; and_\n\n_(ii) Continues learning based on data derived from sources other than the\ndeployer 's own data; and_\n\n_(c) The deployer makes available to consumers any impact assessment that:_\n\n_(i) The developer of the high-risk artificial intelligence system has\ncompleted and provided to the deployer; and_\n\n_(ii) Includes information that is substantially similar to the information in\nthe impact assessment required under subdivision (3)(b) of this section._\n\n_(7) Nothing in this section requires a deployer to disclose a trade secret or\ninformation protected from disclosure by state or federal law. To the extent\nthat a deployer withholds information pursuant to this subsection or\nsubsection (5) of section 6 of this act, the deployer shall notify the\nconsumer and provide a basis for such withholding._\n\n_(8)(a) On and after February 1, 2026, in connection with an ongoing\ninvestigation related to the deployer, the Attorney General may require any\ndeployer or third party contracted by a deployer to disclose any of the\nfollowing to the Attorney General no later than ninety days after such request\nin a form and manner prescribed by the Attorney General:_\n\n_(i) The risk management policy implemented pursuant to subsection (2) of this\nsection;_\n\n_(ii) The impact assessment completed pursuant to subsection (3) of this\nsection; or_\n\n_(iii) The records maintained pursuant to subdivision (3)(f) of this section._\n\n_(b) If such risk management policy, impact assessment, or record is relevant\nto an investigation conducted by the Attorney General regarding a violation of\nthe Artificial Intelligence Consumer Protection Act, the Attorney General may\nevaluate the risk management policy, impact assessment, or records disclosed\npursuant to subdivision (a) of this subsection to ensure compliance with the\nArtificial Intelligence Consumer Protection Act._\n\n_(c) Any disclosure under this subsection shall not be a public record subject\nto disclosure pursuant to sections 84-712 to 84-712.09._\n\n_(d) A deployer may designate any statement or documentation disclosed under\nthis subsection as including proprietary information or_ a _trade secret._\n\n_(9) If a deployer completes documentation for the purpose of complying with\nanother applicable law or regulation, such documentation shall be deemed to\nsatisfy this section if such documentation is reasonably similar in scope and\neffect to the documentation that would otherwise be completed pursuant to this\nsection._\n\n**Sec. 5.** _(1) On and after February 1, 2026, and except as otherwise\nprovided in subsection (2) of this section, a deployer or other developer that\ndeploys, offers, sells, leases, licenses, gives, or otherwise makes available\nany artificial intelligence system that is intended to interact with any\nconsumer shall include in the disclosure to each consumer who interacts with\nsuch artificial intelligence system that the consumer is interacting with an\nartificial intelligence system._\n\n_(2) Disclosure is not required under subsection (1) of this section under any\ncircumstance when it would be obvious to a reasonable person that the person\nis interacting with an artificial intelligence system._\n\n**Sec. 6.** _(1) The Artificial Intelligence Consumer Protection Act does not\nrestrict the ability of any developer, deployer, or other person to:_\n\n_(a) Comply with federal, state, or municipal laws, ordinances, or\nregulations;_\n\n_(b) Comply with any civil, criminal, or regulatory inquiry, investigation,\nsubpoena, or summons by any federal, state, municipal, or other governmental\nauthority;_\n\n_(c) Cooperate with any law enforcement agency concerning conduct or activity\nthat the developer, deployer, or other person reasonably and in good faith\nbelieves may violate any federal, state, or municipal law, ordinance, or\nregulation;_\n\n_(d) Investigate, establish, exercise, prepare for, or defend any legal\nclaim;_\n\n_(e) Take immediate action to protect any interest that is essential for the\nlife or physical safety of any consumer or another individual;_\n\n_(f) By any means:_\n\n_(i) Prevent, detect, protect against, or respond to any security incident,\nidentity theft, fraud, harassment, malicious or deceptive activity, or illegal\nactivity;_\n\n_(ii) Investigate, report, or prosecute any person responsible for any action\ndescribed in subdivision (f)(i) of this subsection; or_\n\n_(iii) Preserve the integrity or security of any system of the developer,\ndeployer, or other person;_\n\n_(g) Engage in public or peer-reviewed scientific or statistical research in\nthe public interest that:_\n\n_(i) Adheres to each applicable ethics or privacy law; and_\n\n_(ii) Is conducted in accordance with 45 C.F.R. part 46, as such section\nexisted on January 1, 2025, or any relevant requirement established by the\nfederal Food and Drug Administration;_\n\n_(h) Conduct any research, testing, or development activity regarding any\nartificial intelligence system or model, other than testing conducted under\nreal-world conditions, before the artificial intelligence system or model is\nplaced on the market, deployed, or put into service; or_\n\n_(i) Provide assistance complying with the Artificial Intelligence Consumer\nProtection Act to any other developer, deployer, or person._\n\n_(2) The Artificial Intelligence Consumer Protection Act does not restrict the\nability of any developer, deployer, or other person to:_\n\n_(a) Effectuate a product recall; or_\n\n_(b) Identify and repair any technical error that impairs existing or intended\nfunctionality of any artificial intelligence system._\n\n_(3) The Artificial Intelligence Consumer Protection Act does not apply to any\ninstance in which compliance with such act would violate any evidentiary\nprivilege under the laws of this state._\n\n_(4) The Artificial Intelligence Consumer Protection Act does not and shall\nnot be construed to impose any obligation on any developer, deployer, or other\nperson that adversely affects any right or freedom of any person, including\nthe rights of a person to freedom of speech or freedom of the press._\n\n_(5) The Artificial Intelligence Consumer Protection Act does not apply to any\ndeveloper, deployer, or other person:_\n\n_(a) If the developer, deployer, or other person develops, deploys, puts into\nservice, or intentionally and substantially modifies any high- risk artificial\nintelligence system:_\n\n_(i) That has been approved, authorized, certified, cleared, developed,\ndeployed, or granted by any federal agency acting within the scope of\nauthority of such federal agency; or_\n\n_(ii) In compliance with standards established by any federal agency, if the\nstandards are substantially equivalent or more stringent than the requirements\nof the Artificial Intelligence Consumer Protection Act;_\n\n_(b) Conducting research to support an application:_\n\n_(i) For approval or certification from any federal agency, federal\nadministration, or federal commission; or_\n\n_(ii) That is subject to review by any federal agency, federal administration,\nor federal commission;_\n\n_(c) Performing work under or in connection with any contract with the United\nStates Department of Commerce, the United States Department of Defense, or the\nNational Aeronautics and Space Administration, unless such work relates to any\nhigh-risk artificial intelligence system that is used to make or is a\nsubstantial factor in making a decision concerning employment or housing; or_\n\n_(d) That is providing or facilitating any health care recommendation that:_\n\n_(i) Is generated by any artificial intelligence system; and_\n\n_(ii) Includes a health care provider in the process to implement the\nrecommendation._\n\n_(6) The Artificial Intelligence Consumer Protection Act does not apply to any\nartificial intelligence system that is acquired by or for the federal\ngovernment or any federal agency or department, unless the artificial\nintelligence system is a high-risk artificial intelligence system that is used\nto make or is a substantial factor in making a decision concerning employment\nor housing._\n\n_(7) The Artificial Intelligence Consumer Protection Act does not apply to any\nof the following that are subject to the Unfair Insurance Trade Practices\nAct:_\n\n_(a) Any insurer;_\n\n_(b) Any fraternal benefit society as described in section 44-1072; and_\n\n_(c) Any developer of an artificial intelligence system used by an insurer._\n\n_(8)(a) For purposes of this subsection:_\n\n_(i) Affiliate has the same meaning as in section 8-916;_\n\n_(ii) Bank has the same meaning as in section 8-909; and_\n\n_(iii) Credit union has the same meaning as in section 21-1705._\n\n_(b) The Artificial Intelligence Consumer Protection Act does not apply to any\nbank, credit union, affiliate or subsidiary of any bank or credit union, or\nservice provider that is subject to examination by any state or federal\nprudential regulator under any published guidance or regulations that apply to\nthe use of high-risk artificial intelligence systems and the guidance or\nregulations:_\n\n_(i) Impose requirements that are substantially equivalent to or more\nstringent than the requirements imposed in the Artificial Intelligence\nConsumer Protection Act as determined by the Attorney General; and_\n\n_(ii) At a minimum, require the bank, credit union, affiliate or subsidiary of\nthe bank or credit union, or service provider to:_\n\n_(A) Regularly audit the use of any high-risk artificial intelligence system\nby the bank, credit union, or affiliate or subsidiary of the bank or credit\nunion for compliance with state and federal antidiscrimination laws and\nregulations applicable to the bank, credit union, affiliate or subsidiary of\nthe bank or credit union, or service provider; and_\n\n_(B) Mitigate any algorithmic discrimination caused by the use of any high-\nrisk artificial intelligence system or any risk of algorithmic discrimination\nthat is a result of the use of any high-risk artificial intelligence system._\n\n_(9) If any developer, deployer, or other person engages in any action\npursuant to an exemption set forth in this section, the developer, deployer,\nor other person bears the burden of demonstrating that the action qualifies\nfor the exemption._\n\n_(10) This section does not apply to:_\n\n_(a) Artificial intelligence systems, including their output, specifically\ndeveloped and put into service for the sole purpose of scientific research and\ndevelopment;_\n\n_(b) A regulated entity subject to the supervision and regulation of the\nFederal Housing Finance Agency; or_\n\n_(c) A creditor as defined by and subject to the federal Equal Credit\nOpportunity Act, 15 U.S.C. 1691 et seq., or the regulations adopted pursuant\nto such act._\n\n**Sec. 7.** _(1) The Attorney General has exclusive authority to enforce the\nArtificial Intelligence Consumer Protection Act._\n\n_(2) Except as provided in subsection (5) of this section, the Attorney\nGeneral shall, prior to initiating any action for a violation of the\nArtificial Intelligence Consumer Protection Act, issue a notice of violation\nto the developer, deployer, or other person describing with specificity the\nalleged violation and the actions that shall be taken by the recipient of the\nnotice to cure the violation. If the developer, deployer, or other person\nfails to cure such violation not later than ninety days after receipt of the\nnotice of violation, the Attorney General may bring an action under the\nArtificial Intelligence Consumer Protection Act._\n\n_(3) In any action commenced by the Attorney General to enforce the Artificial\nIntelligence Consumer Protection Act, it is an affirmative defense that the\ndeveloper, deployer, or other person:_\n\n_(a) Discovers and cures a violation of the Artificial Intelligence Consumer\nProtection Act as a result of:_\n\n_(i) Feedback that the developer, deployer, or other person encourages\ndeployers or users to provide to the developer, deployer, or other person;_\n\n_(ii) Adversarial testing or red teaming; or_\n\n_(iii) An internal review process; and_\n\n_(b) Is otherwise in compliance with:_\n\n_(i) The Artificial Intelligence Risk Management Framework published by the\nNational Institute of Standards and Technology and standard ISO/IEC 42001 of\nthe International Organization for Standardization, as such framework and\nstandard existed on January 1, 2025;_\n\n_(ii) Another nationally or internationally recognized risk management\nframework for artificial intelligence systems, if the standards are\nsubstantially equivalent to or more stringent than the requirements of the\nArtificial Intelligence Consumer Protection Act as determined by the Attorney\nGeneral; or_\n\n_(iii) Any risk management framework for artificial intelligence systems\ndesignated and publicly disseminated by the Attorney General._\n\n_(4) Any developer, deployer, or other person bears the burden of\ndemonstrating to the Attorney General that the requirements of subsection (3)\nof this section have been satisfied._\n\n_(5)(a) The Artificial Intelligence Consumer Protection Act shall not be\nconstrued to preempt or otherwise affect any right, claim, remedy,\npresumption, or defense available at law or in equity._\n\n_(b) Any rebuttable presumption or affirmative defense under the Artificial\nIntelligence Consumer Protection Act applies only to an enforcement action\nbrought by the Attorney General pursuant to this section and shall not apply\nto any right, claim, remedy, presumption, or defense available at law or in\nequity._\n\n_(6) The Artificial Intelligence Consumer Protection Act does not provide the\nbasis for and is not subject to any private right of action for any violation\nof the Artificial Intelligence Consumer Protection Act or any other law._\n\n**Sec. 8.** If any section in this act or any part of any section is declared\ninvalid or unconstitutional, the declaration shall not affect the validity or\nconstitutionality of the remaining portions.\n\nCopyright (C) 2025 State Net  \n  \n---\n\n",
      "latest_version": true
    }
  ]
}