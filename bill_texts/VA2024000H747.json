{
  "bill_id": "VA2024000H747",
  "source_url": "http://custom.statenet.com/public/resources.cgi?id=ID:bill:VA2024000H747&cuiq=93d84396-c63b-526a-b152-38b7f79b4cfd&client_md=e4f6fea4-27b4-5d41-b7d3-766fe52569f0",
  "versions": [
    {
      "date": "01/09/2024",
      "label": "Introduced",
      "url": "https://custom.statenet.com/public/resources.cgi?mode=show_text&id=ID:bill:VA2024000H747&verid=VA2024000H747_20240109_0_I&",
      "raw_html": "<html>\n<head>\n<title>Bill Resource</title>\n\n<!--   <link href=\"https://custom.statenet.com/network/Common/css/extregtext.css\" rel=\"stylesheet\" type=\"text/css\" />-->\n   <link href=\"https://custom.statenet.com/network/Common/css/xmltext-2.0.css\" rel=\"stylesheet\" type=\"text/css\" />\n   <link href=\"https://custom.statenet.com/network/Common/css/additional-text.css\" rel=\"stylesheet\" type=\"text/css\" />\n\n\t<style type=\"text/css\">\n<!--\n\ntd, body {\n     background-color: white;\n\tfont-family: Verdana, Arial, Helvetica, sans-serif;\n\tfont-size: 12px;\n}\n\n.resourceContainer {\n   border: 1px solid black;\n}\n-->\n</style>\n</head>\n<body>\n\n    <div style=\"width: 750px; margin: auto\">\n       <div style=\"font-size: .8em;margin-bottom: 10px\"><table width=\"100%\"><tr><td align=\"left\" style=\"font-size: .8em;\"><div>The following has special meaning:</div>\n<div><u class=\"amendmentInsertedText\">green underline denotes added text</u></div>\n<div><strike class=\"amendmentDeletedText\">red struck out text denotes deleted text</strike></div></td> <td align=\"right\"><a href=\"https://www.lexisnexis.com/statenet/\"><img alt=\"Powered by State Net\" src=\"https://custom.statenet.com/network/poweredby.gif\" /></a></td></tr></table></div><table id=\"text-identifier\"><tr><td class=\"key\">2024 VA H 747</td> <td><table><tr><td class=\"label\">Author:</td> <td>Maldonado</td></tr> <tr><td class=\"label\">Version:</td> <td>Introduced</td></tr> <tr><td class=\"label\">Version Date:</td> <td>01/09/2024</td></tr></table></td></tr></table><div class=\"documentBody\">\n  <a name=\"head_document_section\"></a><div class=\"head\">\n   <p class=\"center\"> HOUSE BILL NO. 747 </p>\n   <p class=\"center\"> Offered January 10, 2024 </p>\n   <p class=\"center\"> Prefiled January 9, 2024 </p>\n  </div>\n  <a name=\"code_document_section\"></a><div class=\"code\">\n   <p class=\"indent\">\n    <i>A BILL to amend the Code of Virginia by adding in Title 59.1 a chapter numbered 57, consisting of sections numbered 59.1-603 through 59.1-608, relating to Artificial Intelligence Developer Act established; civil penalty.</i>\n   </p>\n   <p class=\"center\"> Patron-- Maldonado </p>\n   <p class=\"center\"> Committee Referral Pending </p>\n  </div>\n  <a name=\"text_document_section\"></a><div class=\"text\">\n   <span>\n    <p class=\"indent\">Be it enacted by the General Assembly of Virginia:</p>\n   </span>\n   <p class=\"indent\">1. That the Code of Virginia is amended by adding in Title 59.1 a chapter numbered 57, consisting of sections numbered 59.1-603 through 59.1-608, as follows:</p>\n   <p class=\"center\">\n    <u class=\"amendmentInsertedText\">CHAPTER 57.</u>\n   </p>\n   <p class=\"center\">\n    <u class=\"amendmentInsertedText\">ARTIFICIAL INTELLIGENCE DEVELOPER ACT.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">Section 59.1-603. Definitions.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">As used in this chapter, unless the context requires a different meaning:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Algorithmic discrimination&quot; means any discrimination that is (i) prohibited under state or federal law and (ii) a reasonably foreseeable consequence of deploying or using a high-risk artificial intelligence system to make a consequential decision.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Artificial intelligence&quot; means technology that uses data to train statistical models for the purpose of enabling a computer system or service to autonomously perform any task, including visual perception, language processing, and speech recognition, that is normally associated with human intelligence or perception.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Artificial intelligence system&quot; means any computer system or service that incorporates artificial intelligence.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Consequential decision&quot; means any decision that has a material legal, or similarly significant, effect on a consumer&#39;s access to credit, criminal justice, education, employment, health care, housing, or insurance.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Deployer&quot; means any person doing business in the Commonwealth that deploys or uses a high-risk artificial intelligence system to make a consequential decision.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Developer&quot; means any person doing business in the Commonwealth that develops or intentionally and substantially modifies (i) a high-risk artificial intelligence system or (ii) a generative artificial intelligence system that is offered, sold, leased, given, or otherwise provided to consumers in the Commonwealth.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Foundation model&quot; means a machine learning model that (i) is trained on broad data at scale, (ii) is designed for generality of output, and (iii) can be adapted to a wide range of distinctive tasks.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Generative artificial intelligence&quot; means any form of artificial intelligence, including a foundation model, that is able to produce synthetic digital content including audio, images, text, and videos.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Generative artificial intelligence system&quot; means any computer system or service that incorporates generative artificial intelligence.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;High-risk artificial intelligence system&quot; means any artificial intelligence system that is specifically intended to autonomously make, or be a controlling factor in making, a consequential decision. A system or service is not a &quot;high-risk artificial intelligence system&quot; if it is intended to (i) perform a narrow procedural task, (ii) improve the result of a previously completed human activity, (iii) detect decision-making patterns or deviations from prior decision-making patterns and is not meant to replace or influence the previously completed human assessment without proper human review, or (iv) perform a preparatory task to an assessment relevant to a consequential decision.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Machine learning&quot; means the process by which artificial intelligence is developed using data and algorithms to draw inferences therefrom to automatically adapt or improve its accuracy without explicit programming from a developer.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Search engine&quot; means any computer system or service that (i) searches for and identifies items in a database that correspond to keywords or characters specified by a user and (ii) is offered to or used by any consumer in the Commonwealth.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Search engine operator&quot; means any person that owns or controls a search engine.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Significant update&quot; means any new version, new release, or other update to a high-risk artificial intelligence system that results in significant changes to such high-risk artificial intelligence system&#39;s use case, key functionality, or expected outcomes.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Social media platform&quot; means an electronic medium or service where users may create, share, or view user-generated content, including videos, photographs, blogs, podcasts, messages, emails, or website profiles or locations, and create a personal account.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Social media platform operator&quot; means any person that owns or controls a social media platform.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">&quot;Synthetic digital content&quot; means any digital content, including any audio, image, text, or video, that is produced by a generative artificial intelligence system.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">Section 59.1-604. Operating standards for developers.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">A. No developer of a high-risk artificial intelligence system shall offer, sell, lease, give, or otherwise provide to a deployer a high-risk artificial intelligence system unless the developer provides to the deployer (i) a statement disclosing the intended uses of such high-risk artificial intelligence system and (ii) documentation disclosing (a) the known limitations of such high-risk artificial intelligence system, including any and all reasonably foreseeable risks of algorithmic discrimination arising from the intended uses of such high-risk artificial intelligence system; (b) the purpose of such high-risk artificial intelligence system and the intended benefits and uses of such high-risk artificial intelligence system; (c) a summary describing how such high-risk artificial intelligence system was evaluated for validity and explainability before such high-risk artificial intelligence system was licensed or sold; (d) the measures the developer has taken to mitigate any risk of algorithmic discrimination that the developer knows arises from deployment or use of such high-risk artificial intelligence system; and (e) how an individual can use such high-risk artificial intelligence system to make, or monitor such high-risk artificial intelligence system when such high-risk artificial intelligence system is deployed or used to make, a consequential decision.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">B. Each developer that offers, sells, leases, gives, or otherwise provides to a deployer a high-risk artificial intelligence system shall provide to the deployer the technical capability to access, or otherwise make available to the deployer, all information and documentation in the developer&#39;s possession, custody, or control that the deployer reasonably requires to complete an impact assessment.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">C. Nothing in this section shall be construed to require a developer to disclose any trade secret.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">Section 59.1-605. Operating standards for developers relating to generative artificial intelligence.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">A. No developer that develops or intentionally and substantially modifies a generative artificial intelligence system on or after October 1, 2024, shall offer, sell, lease, give, or otherwise provide such generative artificial intelligence system to any consumer in the Commonwealth or any person doing business in the Commonwealth unless such generative artificial intelligence system satisfies the requirements established in this subsection.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">Each generative artificial intelligence system described in this section shall (i) reduce and mitigate the reasonably foreseeable risks described in this section through, for example, the involvement of independent experts and documentation of any reasonably foreseeable, but non-mitigable, risks; (ii) exclusively incorporate and process datasets that are subject to data governance measures that are appropriate for generative artificial intelligence systems, including data governance measures to examine the suitability of data sources for possible biases and appropriate mitigation; and (iii) achieve, throughout the life cycle of such generative artificial intelligence system, appropriate levels of performance, predictability, interpretability, corrigibility, safety, and cybersecurity, as assessed through appropriate methods, including model evaluation involving independent experts, documented analysis, and extensive testing, during conceptualization, design, and development of such generative artificial intelligence system.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">B. Except as otherwise provided in this subsection, no developer that develops or intentionally and substantially modifies a generative artificial intelligence system on or after October 1, 2024, shall offer, sell, lease, give, or otherwise provide such generative artificial intelligence system to any consumer in the Commonwealth or any person doing business in the Commonwealth unless such developer has completed an impact assessment for such generative artificial intelligence system pursuant to this subsection.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">Each impact assessment completed pursuant to this subsection shall include, at a minimum, an evaluation of (i) the intended purpose of such generative artificial intelligence system; (ii) the extent to which such generative artificial intelligence system has been or is likely to be used; (iii) the extent to which any prior use of such generative artificial intelligence system has harmed the health or safety of individuals, adversely impacted the fundamental rights of individuals, or given rise to significant concerns relating to the materialization of such harm or adverse impact, as demonstrated by reports or documented allegations submitted to authorities of competent jurisdiction; (iv) the potential extent to which use of such generative artificial intelligence system will harm the health and safety of individuals or adversely impact the fundamental rights of individuals, including the intensity of such harm or adverse impact and the number of individuals likely to suffer such harm or adverse impact; (v) the extent to which individuals who may be harmed or adversely impacted by such generative artificial intelligence system are dependent on the outcomes produced by such generative artificial intelligence system because, among other reasons, it is reasonably impossible, for legal or practical reasons, for such individuals to opt out of such outcomes; (vi) the extent to which individuals who may be harmed or adversely impacted by users of such generative artificial intelligence system are comparatively more vulnerable to such users due, among other factors, to an imbalance of age, economic or social circumstances, knowledge, or power; and (vii) the extent to which the outcomes produced by such generative artificial intelligence system, other than outcomes affecting health and safety, are easily reversible.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">A single impact assessment may address a comparable set of generative artificial intelligence systems developed or intentionally and substantially modified by a developer. If a developer completes an impact assessment for the purpose of complying with another applicable law or regulation, such impact assessment shall be deemed to satisfy the requirements established in this subsection if such impact assessment is reasonably similar in scope and effect to the impact assessment that would otherwise be completed pursuant to this subsection. A developer that completes an impact assessment pursuant to this subsection shall maintain such impact assessment and all records concerning such impact assessment for a reasonable period of time.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">C. Each developer that offers, sells, leases, gives, or otherwise provides any generative artificial intelligence system described in this section to any search engine operator or social media platform operator shall provide to such search engine operator or social media platform operator the technical capability such search engine operator or social media platform operator reasonably requires to perform such search engine operator&#39;s or social media platform operator&#39;s duties as described in this chapter.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">D. Nothing in this section shall be construed to require a developer to disclose any trade secret.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">Section 59.1-606. Operating standards for deployers.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">A. Each deployer shall use reasonable care to avoid any risk of algorithmic discrimination that is a reasonably foreseeable consequence of deploying or using a high-risk artificial intelligence system to make a consequential decision.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">B. No deployer shall deploy or use a high-risk artificial intelligence system to make a consequential decision unless the deployer has designed and implemented a risk management policy and program for such high-risk artificial intelligence system. The risk management policy shall specify the principles, processes, and personnel that the deployer shall use in maintaining the risk management program to identify, mitigate, and document any risk of algorithmic discrimination that is a reasonably foreseeable consequence of deploying or using such high-risk artificial intelligence system to make a consequential decision. Each risk management policy and program designed, implemented, and maintained pursuant to this subsection shall be (i) at least as stringent as the latest version of the Artificial Intelligence Risk Management Framework published by the National Institute of Standards and Technology or another nationally or internationally recognized risk management framework for artificial intelligence systems and (ii) reasonable considering (a) the size and complexity of the deployer; (b) the nature and scope of the high-risk artificial intelligence systems deployed and used by the deployer, including the intended uses of such high-risk artificial intelligence systems; (c) the sensitivity and volume of data processed in connection with the high-risk artificial intelligence systems deployed and used by the deployer; and (d) the cost to the deployer to implement and maintain such risk management program.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">C. Except as provided in this subsection, no deployer shall deploy or use a high-risk artificial intelligence system to make a consequential decision unless the deployer has completed an impact assessment for such high-risk artificial intelligence system. The deployer shall complete an impact assessment for a high-risk artificial intelligence system (i) before the deployer initially deploys such high-risk artificial intelligence system and (ii) not later than 90 days after each significant update to such high-risk artificial intelligence system.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">Each impact assessment completed pursuant to this subsection shall include, at a minimum:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">1. A statement by the deployer disclosing (i) the purpose, intended use cases and deployment context of, and benefits afforded by the high-risk artificial intelligence system and (ii) whether the deployment or use of the high-risk artificial intelligence system poses a reasonably foreseeable risk of algorithmic discrimination and, if so, (a) the nature of such algorithmic discrimination and (b) the steps that have been taken, to the extent feasible, to mitigate such risk;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">2. For each post-deployment impact assessment completed pursuant to this section, the extent to which the high-risk artificial intelligence system was used in a manner that was consistent with, or varied from, the developer&#39;s intended uses of such high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">3. A description of (i) the data the high-risk artificial intelligence system processes as inputs and (ii) the outputs such high-risk artificial intelligence system produces;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">4. If the deployer used data to retrain the high-risk artificial intelligence system, an overview of the type of data the deployer used to retrain such high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">5. A description of any transparency measures taken concerning the high-risk artificial intelligence system, including any measures taken to disclose to a consumer in the Commonwealth that such high-risk artificial intelligence system is in use when such high-risk artificial intelligence system is in use; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">6. A description of any post-deployment monitoring performed and user safeguards provided concerning such high-risk artificial intelligence system, including any oversight process established by the deployer to address issues arising from deployment or use of such high-risk artificial intelligence system as such issues arise.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">A single impact assessment may address a comparable set of high-risk artificial intelligence systems deployed or used by a deployer. If a deployer completes an impact assessment for the purpose of complying with another applicable law or regulation, such impact assessment shall be deemed to satisfy the requirements established in this subsection if such impact assessment is reasonably similar in scope and effect to the impact assessment that would otherwise be completed pursuant to this subsection. A deployer that completes an impact assessment pursuant to this subsection shall maintain such impact assessment and all records concerning such impact assessment for a reasonable period of time.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">D. Not later than the time that a deployer uses a high-risk artificial intelligence system to make a consequential decision concerning an individual, the deployer shall notify the individual that the deployer is using a high-risk artificial intelligence system to make such consequential decision concerning such individual and provide to the individual a statement disclosing the purpose of such high-risk artificial intelligence system.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">E. Each deployer shall make available, in a manner that is clear and readily available, a statement summarizing the types of high-risk artificial intelligence systems that are currently deployed or used by a deployer and how such deployer manages any reasonably foreseeable risk of algorithmic discrimination that may arise from use or deployment of each high-risk artificial intelligence system described in this section.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">Section 59.1-607. Exemptions.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">A. Nothing in this chapter shall be construed to restrict a developer&#39;s, deployer&#39;s, search engine operator&#39;s, or social media platform operator&#39;s ability to (i) comply with federal, state, or municipal ordinances or regulations; (ii) comply with a civil, criminal, or regulatory inquiry, investigation, subpoena, or summons by federal, state, municipal, or other governmental authorities; (iii) cooperate with law-enforcement agencies concerning conduct or activity that the developer, deployer, search engine operator, or social media platform operator reasonably and in good faith believes may violate federal, state, or municipal ordinances or regulations; (iv) investigate, establish, exercise, prepare for, or defend legal claims; (v) provide a product or service specifically requested by a consumer; (vi) perform under a contract to which a consumer is a party, including fulfilling the terms of a written warranty; (vii) take steps at the request of a consumer prior to entering into a contract; (viii) take immediate steps to protect an interest that is essential for the life or physical safety of the consumer or another individual; (ix) prevent, detect, protect against, or respond to security incidents, identity theft, fraud, harassment, malicious or deceptive activities, or any illegal activity, preserve the integrity or security of systems, or investigate, report, or prosecute those responsible for any such action; (x) engage in public or peer-reviewed scientific or statistical research in the public interest that adheres to all other applicable ethics and privacy laws and is approved, monitored, and governed by an institutional review board that determines, or similar independent oversight entities that determine, (a) that the expected benefits of the research outweigh the risks associated with such research and (b) whether the developer, deployer, search engine operator, or social media platform operator has implemented reasonable safeguards to mitigate the risks associated with such research; (xi) assist another developer, deployer, search engine operator, or social media platform operator with any of the obligations imposed by this chapter; or (xii) take any action that is in the public interest in the areas of public health, community health, or population health, but solely to the extent that such action is subject to suitable and specific measures to safeguard the public.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">B. The obligations imposed on developers, deployers, search engine operators, or social media platform operators by this chapter shall not restrict a developer&#39;s, deployer&#39;s, search engine operator&#39;s, or social media platform operator&#39;s ability to (i) conduct internal research to develop, improve, or repair products, services, or technologies; (ii) effectuate a product recall; (iii) identify and repair technical errors that impair existing or intended functionality; or (iv) perform internal operations that are reasonably aligned with the expectations of the consumer or reasonably anticipated based on the consumer&#39;s existing relationship with the developer, deployer, search engine operator, or social media platform operator.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">C. The obligations imposed on developers, deployers, search engine operators, or social media platform operators by this chapter shall not apply where compliance by the developer, deployer, search engine operator, or social media platform operator with such obligations would violate an evidentiary privilege under the laws of the Commonwealth.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">D. Nothing this chapter shall be construed to impose any obligation on a developer, deployer, search engine operator, or social media platform operator that adversely affects the rights or freedoms of any person, including the rights of any person to freedom of speech or freedom of the press guaranteed in the First Amendment to the United States Constitution or under the Virginia Human Rights Act (Section 2.2-3900 et seq.).</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">E. If a developer, deployer, search engine operator, or social media platform operator engages in any action pursuant to an exemption set forth in this section, the developer, deployer, search engine operator, or social media platform operator bears the burden of demonstrating that such action qualifies for such exemption.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">Section 59.1-608. Enforcement; civil penalty.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">A. The Attorney General shall have exclusive authority to enforce the provisions of this chapter.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">B. Whenever the Attorney General has reasonable cause to believe that any person has engaged in, is engaging in, or is about to engage in any violation of this chapter, the Attorney General is empowered to issue a civil investigative demand. The provisions of Section 59.1-9.10 shall apply mutatis mutandis to civil investigative demands issued pursuant to this section.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">C. Notwithstanding any contrary provision of law, the Attorney General may cause an action to be brought in the appropriate circuit court in the name of the Commonwealth to enjoin any violation of this chapter. The circuit court having jurisdiction may enjoin such violation notwithstanding the existence of an adequate remedy at law. In any action brought pursuant to this section, it shall not be necessary that damages be proved.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">D. Any person who violates the provisions of this chapter shall be subject to a civil penalty in an amount not to exceed $1,000 plus reasonable attorney fees, expenses, and court costs, as determined by the court. Any person who willfully violates the provisions of this chapter shall be subject to a civil penalty in amount not less than $1,000 and not more than $10,000 plus reasonable attorney fees, expenses, and court costs, as determined by the court. Such civil penalties shall be paid into the Literary Fund.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">E. Each violation of this chapter shall constitute a separate violation and shall be subject to any civil penalties imposed under this section.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">F. The Attorney General may require that a developer disclose to the Attorney General any statement or documentation described in this chapter if such statement or documentation is relevant to an investigation conducted by the Attorney General. The Attorney General may also require that a deployer disclose to the Attorney General any risk management policy designed and implemented, impact assessment completed, or record maintained pursuant to this chapter if such risk management policy, impact assessment, or record is relevant to an investigation conducted by the Attorney General.</u>\n   </p>\n   <p class=\"indent\">2. That the provisions of Section 59.1-606 of the Code of Virginia, as created by this act, shall become effective on July 1, 2026.</p>\n  </div>\n </div>\n    </div>\t\n<table cellpadding=0 cellspacing=0 width=\"100%\">\n   <tr>\n      <td>\n          Copyright &copy; 2025 State Net\n      </td>\n<BR>\n<!--???MOVED INTO resources.cgi      <td align=\"right\">\n          <img src=\"https://custom.statenet.com/network/poweredby.gif\" alt=\"Powered by State Net\">\n      </td>-->\n\n    </tr>\n</table>\n</body></html>\n",
      "markdown": "The following has special meaning: _green underline denotes added text_ ~~red struck out text denotes deleted text~~ | [![Powered by State Net](https://custom.statenet.com/network/poweredby.gif)](https://www.lexisnexis.com/statenet/)  \n---|---  \n  \n2024 VA H 747 | | Author: | Maldonado  \n---|---  \nVersion: | Introduced  \nVersion Date: | 01/09/2024  \n  \nHOUSE BILL NO. 747\n\nOffered January 10, 2024\n\nPrefiled January 9, 2024\n\n_A BILL to amend the Code of Virginia by adding in Title 59.1 a chapter\nnumbered 57, consisting of sections numbered 59.1-603 through 59.1-608,\nrelating to Artificial Intelligence Developer Act established; civil penalty._\n\nPatron-- Maldonado\n\nCommittee Referral Pending\n\nBe it enacted by the General Assembly of Virginia:\n\n1\\. That the Code of Virginia is amended by adding in Title 59.1 a chapter\nnumbered 57, consisting of sections numbered 59.1-603 through 59.1-608, as\nfollows:\n\n_CHAPTER 57._\n\n_ARTIFICIAL INTELLIGENCE DEVELOPER ACT._\n\n_Section 59.1-603. Definitions._\n\n_As used in this chapter, unless the context requires a different meaning:_\n\n_\" Algorithmic discrimination\" means any discrimination that is (i) prohibited\nunder state or federal law and (ii) a reasonably foreseeable consequence of\ndeploying or using a high-risk artificial intelligence system to make a\nconsequential decision._\n\n_\" Artificial intelligence\" means technology that uses data to train\nstatistical models for the purpose of enabling a computer system or service to\nautonomously perform any task, including visual perception, language\nprocessing, and speech recognition, that is normally associated with human\nintelligence or perception._\n\n_\" Artificial intelligence system\" means any computer system or service that\nincorporates artificial intelligence._\n\n_\" Consequential decision\" means any decision that has a material legal, or\nsimilarly significant, effect on a consumer's access to credit, criminal\njustice, education, employment, health care, housing, or insurance._\n\n_\" Deployer\" means any person doing business in the Commonwealth that deploys\nor uses a high-risk artificial intelligence system to make a consequential\ndecision._\n\n_\" Developer\" means any person doing business in the Commonwealth that\ndevelops or intentionally and substantially modifies (i) a high-risk\nartificial intelligence system or (ii) a generative artificial intelligence\nsystem that is offered, sold, leased, given, or otherwise provided to\nconsumers in the Commonwealth._\n\n_\" Foundation model\" means a machine learning model that (i) is trained on\nbroad data at scale, (ii) is designed for generality of output, and (iii) can\nbe adapted to a wide range of distinctive tasks._\n\n_\" Generative artificial intelligence\" means any form of artificial\nintelligence, including a foundation model, that is able to produce synthetic\ndigital content including audio, images, text, and videos._\n\n_\" Generative artificial intelligence system\" means any computer system or\nservice that incorporates generative artificial intelligence._\n\n_\" High-risk artificial intelligence system\" means any artificial intelligence\nsystem that is specifically intended to autonomously make, or be a controlling\nfactor in making, a consequential decision. A system or service is not a\n\"high-risk artificial intelligence system\" if it is intended to (i) perform a\nnarrow procedural task, (ii) improve the result of a previously completed\nhuman activity, (iii) detect decision-making patterns or deviations from prior\ndecision-making patterns and is not meant to replace or influence the\npreviously completed human assessment without proper human review, or (iv)\nperform a preparatory task to an assessment relevant to a consequential\ndecision._\n\n_\" Machine learning\" means the process by which artificial intelligence is\ndeveloped using data and algorithms to draw inferences therefrom to\nautomatically adapt or improve its accuracy without explicit programming from\na developer._\n\n_\" Search engine\" means any computer system or service that (i) searches for\nand identifies items in a database that correspond to keywords or characters\nspecified by a user and (ii) is offered to or used by any consumer in the\nCommonwealth._\n\n_\" Search engine operator\" means any person that owns or controls a search\nengine._\n\n_\" Significant update\" means any new version, new release, or other update to\na high-risk artificial intelligence system that results in significant changes\nto such high-risk artificial intelligence system's use case, key\nfunctionality, or expected outcomes._\n\n_\" Social media platform\" means an electronic medium or service where users\nmay create, share, or view user-generated content, including videos,\nphotographs, blogs, podcasts, messages, emails, or website profiles or\nlocations, and create a personal account._\n\n_\" Social media platform operator\" means any person that owns or controls a\nsocial media platform._\n\n_\" Synthetic digital content\" means any digital content, including any audio,\nimage, text, or video, that is produced by a generative artificial\nintelligence system._\n\n_Section 59.1-604. Operating standards for developers._\n\n_A. No developer of a high-risk artificial intelligence system shall offer,\nsell, lease, give, or otherwise provide to a deployer a high-risk artificial\nintelligence system unless the developer provides to the deployer (i) a\nstatement disclosing the intended uses of such high-risk artificial\nintelligence system and (ii) documentation disclosing (a) the known\nlimitations of such high-risk artificial intelligence system, including any\nand all reasonably foreseeable risks of algorithmic discrimination arising\nfrom the intended uses of such high-risk artificial intelligence system; (b)\nthe purpose of such high-risk artificial intelligence system and the intended\nbenefits and uses of such high-risk artificial intelligence system; (c) a\nsummary describing how such high-risk artificial intelligence system was\nevaluated for validity and explainability before such high-risk artificial\nintelligence system was licensed or sold; (d) the measures the developer has\ntaken to mitigate any risk of algorithmic discrimination that the developer\nknows arises from deployment or use of such high-risk artificial intelligence\nsystem; and (e) how an individual can use such high-risk artificial\nintelligence system to make, or monitor such high-risk artificial intelligence\nsystem when such high-risk artificial intelligence system is deployed or used\nto make, a consequential decision._\n\n_B. Each developer that offers, sells, leases, gives, or otherwise provides to\na deployer a high-risk artificial intelligence system shall provide to the\ndeployer the technical capability to access, or otherwise make available to\nthe deployer, all information and documentation in the developer 's\npossession, custody, or control that the deployer reasonably requires to\ncomplete an impact assessment._\n\n_C. Nothing in this section shall be construed to require a developer to\ndisclose any trade secret._\n\n_Section 59.1-605. Operating standards for developers relating to generative\nartificial intelligence._\n\n_A. No developer that develops or intentionally and substantially modifies a\ngenerative artificial intelligence system on or after October 1, 2024, shall\noffer, sell, lease, give, or otherwise provide such generative artificial\nintelligence system to any consumer in the Commonwealth or any person doing\nbusiness in the Commonwealth unless such generative artificial intelligence\nsystem satisfies the requirements established in this subsection._\n\n_Each generative artificial intelligence system described in this section\nshall (i) reduce and mitigate the reasonably foreseeable risks described in\nthis section through, for example, the involvement of independent experts and\ndocumentation of any reasonably foreseeable, but non-mitigable, risks; (ii)\nexclusively incorporate and process datasets that are subject to data\ngovernance measures that are appropriate for generative artificial\nintelligence systems, including data governance measures to examine the\nsuitability of data sources for possible biases and appropriate mitigation;\nand (iii) achieve, throughout the life cycle of such generative artificial\nintelligence system, appropriate levels of performance, predictability,\ninterpretability, corrigibility, safety, and cybersecurity, as assessed\nthrough appropriate methods, including model evaluation involving independent\nexperts, documented analysis, and extensive testing, during conceptualization,\ndesign, and development of such generative artificial intelligence system._\n\n_B. Except as otherwise provided in this subsection, no developer that\ndevelops or intentionally and substantially modifies a generative artificial\nintelligence system on or after October 1, 2024, shall offer, sell, lease,\ngive, or otherwise provide such generative artificial intelligence system to\nany consumer in the Commonwealth or any person doing business in the\nCommonwealth unless such developer has completed an impact assessment for such\ngenerative artificial intelligence system pursuant to this subsection._\n\n_Each impact assessment completed pursuant to this subsection shall include,\nat a minimum, an evaluation of (i) the intended purpose of such generative\nartificial intelligence system; (ii) the extent to which such generative\nartificial intelligence system has been or is likely to be used; (iii) the\nextent to which any prior use of such generative artificial intelligence\nsystem has harmed the health or safety of individuals, adversely impacted the\nfundamental rights of individuals, or given rise to significant concerns\nrelating to the materialization of such harm or adverse impact, as\ndemonstrated by reports or documented allegations submitted to authorities of\ncompetent jurisdiction; (iv) the potential extent to which use of such\ngenerative artificial intelligence system will harm the health and safety of\nindividuals or adversely impact the fundamental rights of individuals,\nincluding the intensity of such harm or adverse impact and the number of\nindividuals likely to suffer such harm or adverse impact; (v) the extent to\nwhich individuals who may be harmed or adversely impacted by such generative\nartificial intelligence system are dependent on the outcomes produced by such\ngenerative artificial intelligence system because, among other reasons, it is\nreasonably impossible, for legal or practical reasons, for such individuals to\nopt out of such outcomes; (vi) the extent to which individuals who may be\nharmed or adversely impacted by users of such generative artificial\nintelligence system are comparatively more vulnerable to such users due, among\nother factors, to an imbalance of age, economic or social circumstances,\nknowledge, or power; and (vii) the extent to which the outcomes produced by\nsuch generative artificial intelligence system, other than outcomes affecting\nhealth and safety, are easily reversible._\n\n_A single impact assessment may address a comparable set of generative\nartificial intelligence systems developed or intentionally and substantially\nmodified by a developer. If a developer completes an impact assessment for the\npurpose of complying with another applicable law or regulation, such impact\nassessment shall be deemed to satisfy the requirements established in this\nsubsection if such impact assessment is reasonably similar in scope and effect\nto the impact assessment that would otherwise be completed pursuant to this\nsubsection. A developer that completes an impact assessment pursuant to this\nsubsection shall maintain such impact assessment and all records concerning\nsuch impact assessment for a reasonable period of time._\n\n_C. Each developer that offers, sells, leases, gives, or otherwise provides\nany generative artificial intelligence system described in this section to any\nsearch engine operator or social media platform operator shall provide to such\nsearch engine operator or social media platform operator the technical\ncapability such search engine operator or social media platform operator\nreasonably requires to perform such search engine operator 's or social media\nplatform operator's duties as described in this chapter._\n\n_D. Nothing in this section shall be construed to require a developer to\ndisclose any trade secret._\n\n_Section 59.1-606. Operating standards for deployers._\n\n_A. Each deployer shall use reasonable care to avoid any risk of algorithmic\ndiscrimination that is a reasonably foreseeable consequence of deploying or\nusing a high-risk artificial intelligence system to make a consequential\ndecision._\n\n_B. No deployer shall deploy or use a high-risk artificial intelligence system\nto make a consequential decision unless the deployer has designed and\nimplemented a risk management policy and program for such high-risk artificial\nintelligence system. The risk management policy shall specify the principles,\nprocesses, and personnel that the deployer shall use in maintaining the risk\nmanagement program to identify, mitigate, and document any risk of algorithmic\ndiscrimination that is a reasonably foreseeable consequence of deploying or\nusing such high-risk artificial intelligence system to make a consequential\ndecision. Each risk management policy and program designed, implemented, and\nmaintained pursuant to this subsection shall be (i) at least as stringent as\nthe latest version of the Artificial Intelligence Risk Management Framework\npublished by the National Institute of Standards and Technology or another\nnationally or internationally recognized risk management framework for\nartificial intelligence systems and (ii) reasonable considering (a) the size\nand complexity of the deployer; (b) the nature and scope of the high-risk\nartificial intelligence systems deployed and used by the deployer, including\nthe intended uses of such high-risk artificial intelligence systems; (c) the\nsensitivity and volume of data processed in connection with the high-risk\nartificial intelligence systems deployed and used by the deployer; and (d) the\ncost to the deployer to implement and maintain such risk management program._\n\n_C. Except as provided in this subsection, no deployer shall deploy or use a\nhigh-risk artificial intelligence system to make a consequential decision\nunless the deployer has completed an impact assessment for such high-risk\nartificial intelligence system. The deployer shall complete an impact\nassessment for a high-risk artificial intelligence system (i) before the\ndeployer initially deploys such high-risk artificial intelligence system and\n(ii) not later than 90 days after each significant update to such high-risk\nartificial intelligence system._\n\n_Each impact assessment completed pursuant to this subsection shall include,\nat a minimum:_\n\n_1\\. A statement by the deployer disclosing (i) the purpose, intended use\ncases and deployment context of, and benefits afforded by the high-risk\nartificial intelligence system and (ii) whether the deployment or use of the\nhigh-risk artificial intelligence system poses a reasonably foreseeable risk\nof algorithmic discrimination and, if so, (a) the nature of such algorithmic\ndiscrimination and (b) the steps that have been taken, to the extent feasible,\nto mitigate such risk;_\n\n_2\\. For each post-deployment impact assessment completed pursuant to this\nsection, the extent to which the high-risk artificial intelligence system was\nused in a manner that was consistent with, or varied from, the developer 's\nintended uses of such high-risk artificial intelligence system;_\n\n_3\\. A description of (i) the data the high-risk artificial intelligence\nsystem processes as inputs and (ii) the outputs such high-risk artificial\nintelligence system produces;_\n\n_4\\. If the deployer used data to retrain the high-risk artificial\nintelligence system, an overview of the type of data the deployer used to\nretrain such high-risk artificial intelligence system;_\n\n_5\\. A description of any transparency measures taken concerning the high-risk\nartificial intelligence system, including any measures taken to disclose to a\nconsumer in the Commonwealth that such high-risk artificial intelligence\nsystem is in use when such high-risk artificial intelligence system is in use;\nand_\n\n_6\\. A description of any post-deployment monitoring performed and user\nsafeguards provided concerning such high-risk artificial intelligence system,\nincluding any oversight process established by the deployer to address issues\narising from deployment or use of such high-risk artificial intelligence\nsystem as such issues arise._\n\n_A single impact assessment may address a comparable set of high-risk\nartificial intelligence systems deployed or used by a deployer. If a deployer\ncompletes an impact assessment for the purpose of complying with another\napplicable law or regulation, such impact assessment shall be deemed to\nsatisfy the requirements established in this subsection if such impact\nassessment is reasonably similar in scope and effect to the impact assessment\nthat would otherwise be completed pursuant to this subsection. A deployer that\ncompletes an impact assessment pursuant to this subsection shall maintain such\nimpact assessment and all records concerning such impact assessment for a\nreasonable period of time._\n\n_D. Not later than the time that a deployer uses a high-risk artificial\nintelligence system to make a consequential decision concerning an individual,\nthe deployer shall notify the individual that the deployer is using a high-\nrisk artificial intelligence system to make such consequential decision\nconcerning such individual and provide to the individual a statement\ndisclosing the purpose of such high-risk artificial intelligence system._\n\n_E. Each deployer shall make available, in a manner that is clear and readily\navailable, a statement summarizing the types of high-risk artificial\nintelligence systems that are currently deployed or used by a deployer and how\nsuch deployer manages any reasonably foreseeable risk of algorithmic\ndiscrimination that may arise from use or deployment of each high-risk\nartificial intelligence system described in this section._\n\n_Section 59.1-607. Exemptions._\n\n_A. Nothing in this chapter shall be construed to restrict a developer 's,\ndeployer's, search engine operator's, or social media platform operator's\nability to (i) comply with federal, state, or municipal ordinances or\nregulations; (ii) comply with a civil, criminal, or regulatory inquiry,\ninvestigation, subpoena, or summons by federal, state, municipal, or other\ngovernmental authorities; (iii) cooperate with law-enforcement agencies\nconcerning conduct or activity that the developer, deployer, search engine\noperator, or social media platform operator reasonably and in good faith\nbelieves may violate federal, state, or municipal ordinances or regulations;\n(iv) investigate, establish, exercise, prepare for, or defend legal claims;\n(v) provide a product or service specifically requested by a consumer; (vi)\nperform under a contract to which a consumer is a party, including fulfilling\nthe terms of a written warranty; (vii) take steps at the request of a consumer\nprior to entering into a contract; (viii) take immediate steps to protect an\ninterest that is essential for the life or physical safety of the consumer or\nanother individual; (ix) prevent, detect, protect against, or respond to\nsecurity incidents, identity theft, fraud, harassment, malicious or deceptive\nactivities, or any illegal activity, preserve the integrity or security of\nsystems, or investigate, report, or prosecute those responsible for any such\naction; (x) engage in public or peer-reviewed scientific or statistical\nresearch in the public interest that adheres to all other applicable ethics\nand privacy laws and is approved, monitored, and governed by an institutional\nreview board that determines, or similar independent oversight entities that\ndetermine, (a) that the expected benefits of the research outweigh the risks\nassociated with such research and (b) whether the developer, deployer, search\nengine operator, or social media platform operator has implemented reasonable\nsafeguards to mitigate the risks associated with such research; (xi) assist\nanother developer, deployer, search engine operator, or social media platform\noperator with any of the obligations imposed by this chapter; or (xii) take\nany action that is in the public interest in the areas of public health,\ncommunity health, or population health, but solely to the extent that such\naction is subject to suitable and specific measures to safeguard the public._\n\n_B. The obligations imposed on developers, deployers, search engine operators,\nor social media platform operators by this chapter shall not restrict a\ndeveloper 's, deployer's, search engine operator's, or social media platform\noperator's ability to (i) conduct internal research to develop, improve, or\nrepair products, services, or technologies; (ii) effectuate a product recall;\n(iii) identify and repair technical errors that impair existing or intended\nfunctionality; or (iv) perform internal operations that are reasonably aligned\nwith the expectations of the consumer or reasonably anticipated based on the\nconsumer's existing relationship with the developer, deployer, search engine\noperator, or social media platform operator._\n\n_C. The obligations imposed on developers, deployers, search engine operators,\nor social media platform operators by this chapter shall not apply where\ncompliance by the developer, deployer, search engine operator, or social media\nplatform operator with such obligations would violate an evidentiary privilege\nunder the laws of the Commonwealth._\n\n_D. Nothing this chapter shall be construed to impose any obligation on a\ndeveloper, deployer, search engine operator, or social media platform operator\nthat adversely affects the rights or freedoms of any person, including the\nrights of any person to freedom of speech or freedom of the press guaranteed\nin the First Amendment to the United States Constitution or under the Virginia\nHuman Rights Act (Section 2.2-3900 et seq.)._\n\n_E. If a developer, deployer, search engine operator, or social media platform\noperator engages in any action pursuant to an exemption set forth in this\nsection, the developer, deployer, search engine operator, or social media\nplatform operator bears the burden of demonstrating that such action qualifies\nfor such exemption._\n\n_Section 59.1-608. Enforcement; civil penalty._\n\n_A. The Attorney General shall have exclusive authority to enforce the\nprovisions of this chapter._\n\n_B. Whenever the Attorney General has reasonable cause to believe that any\nperson has engaged in, is engaging in, or is about to engage in any violation\nof this chapter, the Attorney General is empowered to issue a civil\ninvestigative demand. The provisions of Section 59.1-9.10 shall apply mutatis\nmutandis to civil investigative demands issued pursuant to this section._\n\n_C. Notwithstanding any contrary provision of law, the Attorney General may\ncause an action to be brought in the appropriate circuit court in the name of\nthe Commonwealth to enjoin any violation of this chapter. The circuit court\nhaving jurisdiction may enjoin such violation notwithstanding the existence of\nan adequate remedy at law. In any action brought pursuant to this section, it\nshall not be necessary that damages be proved._\n\n_D. Any person who violates the provisions of this chapter shall be subject to\na civil penalty in an amount not to exceed $1,000 plus reasonable attorney\nfees, expenses, and court costs, as determined by the court. Any person who\nwillfully violates the provisions of this chapter shall be subject to a civil\npenalty in amount not less than $1,000 and not more than $10,000 plus\nreasonable attorney fees, expenses, and court costs, as determined by the\ncourt. Such civil penalties shall be paid into the Literary Fund._\n\n_E. Each violation of this chapter shall constitute a separate violation and\nshall be subject to any civil penalties imposed under this section._\n\n_F. The Attorney General may require that a developer disclose to the Attorney\nGeneral any statement or documentation described in this chapter if such\nstatement or documentation is relevant to an investigation conducted by the\nAttorney General. The Attorney General may also require that a deployer\ndisclose to the Attorney General any risk management policy designed and\nimplemented, impact assessment completed, or record maintained pursuant to\nthis chapter if such risk management policy, impact assessment, or record is\nrelevant to an investigation conducted by the Attorney General._\n\n2\\. That the provisions of Section 59.1-606 of the Code of Virginia, as\ncreated by this act, shall become effective on July 1, 2026.\n\nCopyright (C) 2025 State Net  \n  \n---\n\n",
      "latest_version": true
    }
  ]
}