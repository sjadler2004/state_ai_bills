{
  "bill_id": "NY2025000A768",
  "source_url": "http://custom.statenet.com/public/resources.cgi?id=ID:bill:NY2025000A768&cuiq=93d84396-c63b-526a-b152-38b7f79b4cfd&client_md=e4f6fea4-27b4-5d41-b7d3-766fe52569f0",
  "versions": [
    {
      "date": "01/08/2025",
      "label": "Introduced",
      "url": "https://custom.statenet.com/public/resources.cgi?mode=show_text&id=ID:bill:NY2025000A768&verid=NY2025000A768_20250108_0_I&",
      "raw_html": "<html>\n<head>\n<title>Bill Resource</title>\n\n<!--   <link href=\"https://custom.statenet.com/network/Common/css/extregtext.css\" rel=\"stylesheet\" type=\"text/css\" />-->\n   <link href=\"https://custom.statenet.com/network/Common/css/xmltext-2.0.css\" rel=\"stylesheet\" type=\"text/css\" />\n   <link href=\"https://custom.statenet.com/network/Common/css/additional-text.css\" rel=\"stylesheet\" type=\"text/css\" />\n\n\t<style type=\"text/css\">\n<!--\n\ntd, body {\n     background-color: white;\n\tfont-family: Verdana, Arial, Helvetica, sans-serif;\n\tfont-size: 12px;\n}\n\n.resourceContainer {\n   border: 1px solid black;\n}\n-->\n</style>\n</head>\n<body>\n\n    <div style=\"width: 750px; margin: auto\">\n       <div style=\"font-size: .8em;margin-bottom: 10px\"><table width=\"100%\"><tr><td align=\"left\" style=\"font-size: .8em;\"><div>The following has special meaning:</div>\n<div><u class=\"amendmentInsertedText\">green underline denotes added text</u></div>\n<div><strike class=\"amendmentDeletedText\">red struck out text denotes deleted text</strike></div></td> <td align=\"right\"><a href=\"https://www.lexisnexis.com/statenet/\"><img alt=\"Powered by State Net\" src=\"https://custom.statenet.com/network/poweredby.gif\" /></a></td></tr></table></div><table id=\"text-identifier\"><tr><td class=\"key\">2025 NY A 768</td> <td><table><tr><td class=\"label\">Author:</td> <td>Bores</td></tr> <tr><td class=\"label\">Version:</td> <td>Introduced</td></tr> <tr><td class=\"label\">Version Date:</td> <td>01/08/2025</td></tr></table></td></tr></table><div class=\"documentBody\">\n  <a name=\"head_document_section\"></a><div class=\"head\">\n   <p class=\"center\">\n    <b>STATE OF NEW YORK</b>\n   </p>\n   <p class=\"center\">768 </p>\n   <p class=\"center\">2025-2026 Regular Sessions </p>\n   <p class=\"center\">\n    <b>IN ASSEMBLY</b>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(Prefiled)</u>\n   </p>\n   <p class=\"center\">January 8, 2025 </p>\n   <p class=\"indent\">Introduced by M. of A. BORES -- read once and referred to the Committee on Consumer Affairs and Protection </p>\n  </div>\n  <a name=\"title_document_section\"></a><div class=\"title\">\n   <p class=\"indent\">AN ACT to amend the general business law, in relation to preventing the use of artificial intelligence algorithms to discriminate against protected classes </p>\n  </div>\n  <a name=\"text_document_section\"></a><div class=\"text\">\n   <span>\n    <p class=\"indent\">\n     <b>The People of the State of New York, represented in Senate and Assembly, do enact as follows:</b>\n    </p>\n   </span>\n   <p class=\"indent\">Section 1. Short title. This act shall be known and may be cited as the &quot;New York artificial intelligence consumer protection act&quot;. </p>\n   <p class=\"indent\">Section 2. The general business law is amended by adding a new article 45-A to read as follows: </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">ARTICLE 45-A</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">NEW YORK ARTIFICIAL INTELLIGENCE CONSUMER PROTECTION ACT</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">Section 1550. Definitions.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">1551. Required documentation.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">1552. Risk management.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">1553. Technical documentation.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">1554. Required disclosure.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">1555. Preemption.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">1556. Enforcement.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">Section 1550. Definitions. For the purposes of this article, the following terms shall have the following meanings:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">1. &quot;Algorithmic discrimination&quot;:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(a) shall mean any condition in which the use of an artificial intelligence decision system results in any unlawful differential treatment or impact that disfavors any individual or group of individuals on the basis of their actual or perceived age, color, disability, ethnicity, genetic information, English language proficiency, national origin, race, religion, reproductive health, sex, veteran status, or other classification protected pursuant to state or federal law; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) shall not include:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) the offer, license, or use of a high-risk artificial intelligence decision system by a developer or deployer for the sole purpose of:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) such developer&#39;s or deployer&#39;s self-testing to identify, mitigate, or prevent discrimination or otherwise ensure compliance with state and federal law; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) expanding an applicant, customer, or participant pool to increase diversity or redress historic discrimination; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) an act or omission by or on behalf of a private club or other establishment not open to the general public, as set forth in title II of the Civil Rights Act of 1964, 42 U.S.C. Section 2000a(e), as amended.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">2. &quot;Artificial intelligence decision system&quot; shall mean any computational process, derived from machine learning, statistical modeling, data analytics, or artificial intelligence, that issues simplified output, including any content, decision, prediction, or recommendation, that is used to substantially assist or replace discretionary decision making for making consequential decisions that impact consumers.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">3. &quot;Bias and governance audit&quot; means an impartial evaluation by an independent auditor, which shall include, at a minimum, the testing of an artificial intelligence decision system to assess such system&#39;s disparate impact on employees because of such employee&#39;s age, race, creed, color, ethnicity, national origin, disability, citizenship or immigration status, marital or familial status, military status, religion, or sex, including sexual orientation, gender identity, gender expression, pregnancy, pregnancy outcomes, and reproductive healthcare choices.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">4. &quot;Consequential decision&quot; shall mean any decision that has a material legal or similarly significant effect on the provision or denial to any consumer of, or the cost or terms of, any:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(a) education enrollment or education opportunity;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) employment or employment opportunity;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(c) financial or lending service;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(d) essential government service;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(e) health care service, as defined in section 42 U.S.C. Section 324(d)(2), as amended;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(f) housing or housing opportunity;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(g) insurance; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(h) legal service.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">5. &quot;Consumer&quot; shall mean any New York state resident.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">6. &quot;Deploy&quot; shall mean to use a high-risk artificial intelligence decision system.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">7. &quot;Deployer&quot; shall mean any person doing business in this state that deploys a high-risk artificial intelligence decision system.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">8. &quot;Developer&quot; shall mean any person doing business in this state that develops, or intentionally and substantially modifies, an artificial intelligence decision system.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">9. &quot;General-purpose artificial intelligence model&quot;:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(a) shall mean any form of artificial intelligence decision system that:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) displays significant generality;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) is capable of competently performing a wide range of distinct tasks; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) can be integrated into a variety of downstream applications or systems; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) shall not include any artificial intelligence model that is used for development, prototyping, and research activities before such artificial intelligence model is released on the market.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">10. &quot;High-risk artificial intelligence decision system&quot;:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(a) shall mean any artificial intelligence decision system that, when deployed, makes, or is a substantial factor in making, a consequential decision; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) shall not include:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) any artificial intelligence decision system that is intended to:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) perform any narrow procedural task; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) detect decision-making patterns, or deviations from decision-making patterns, unless such artificial intelligence decision system is intended to replace or influence any assessment previously completed by an individual without sufficient human review; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) unless the technology, when deployed, makes, or is a substantial factor in making, a consequential decision:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) any anti-fraud technology that does not make use of facial recognition technology;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) any artificial intelligence-enabled video game technology;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(C) any anti-malware, anti-virus, calculator, cybersecurity, database, data storage, firewall, Internet domain registration, Internet-web-site loading, networking, robocall-filtering, spam-filtering, spellchecking, spreadsheet, web-caching, web-hosting, or similar technology;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(D) any technology that performs tasks exclusively related to an entity&#39;s internal management affairs, including, but not limited to, ordering office supplies or processing payments; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(E) any technology that communicates with consumers in natural language for the purpose of providing consumers with information, making referrals or recommendations, and answering questions, and is subject to an accepted use policy that prohibits generating content that is discriminatory or harmful.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">11. &quot;Intentional and substantial modification&quot;:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(a) shall mean any deliberate change made to:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) an artificial intelligence decision system that results in any new reasonably foreseeable risk of algorithmic discrimination; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) a general-purpose artificial intelligence model that:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) affects compliance of the general-purpose artificial intelligence model;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) materially changes the purpose of the general-purpose artificial intelligence model; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(C) results in any new reasonably foreseeable risk of algorithmic discrimination; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) shall not include any change made to a high-risk artificial intelligence decision system, or the performance of a high-risk artificial intelligence decision system, if:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) the high-risk artificial intelligence decision system continues to learn after such high-risk artificial intelligence decision system is:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) offered, sold, leased, licensed, given or otherwise made available to a deployer; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) deployed; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) such change:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) is made to such high-risk artificial intelligence decision system as a result of any learning described in subparagraph (i) of this paragraph;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) was predetermined by the deployer, or the third party contracted by the deployer, when such deployer or third party completed the initial impact assessment of such high-risk artificial intelligence decision system pursuant to subdivision three of section one thousand five hundred fifty-two of this article; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(C) is included in the technical documentation for such high-risk artificial intelligence decision system.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">12. &quot;Person&quot; shall mean any individual, association, corporation, limited liability company, partnership, trust or other legal entity authorized to do business in this state.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">13. &quot;Red-teaming&quot; shall mean an exercise that is conducted to identify the potential adverse behaviors or outcomes of an artificial intelligence decision system and how such behaviors or outcomes occur, and stress test the safeguards against such adverse behaviors or outcomes.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">14. &quot;Substantial factor&quot;:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(a) shall mean a factor that:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) assists in making a consequential decision;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) is capable of altering the outcome of a consequential decision; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) is generated by an artificial intelligence decision system; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) includes, but is not limited to, any use of an artificial intelligence decision system to generate any content, decision, prediction, or recommendation concerning a consumer that is used as a basis to make a consequential decision concerning such consumer.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">15. &quot;Synthetic digital content&quot; shall mean any digital content, including, but not limited to, any audio, image, text, or video, that is produced or manipulated by an artificial intelligence decision system, including, but not limited to, a general-purpose artificial intelligence model.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">16. &quot;Trade secret&quot; shall mean any form and type of financial, business, scientific, technical, economic, or engineering information, including, but not limited to, a pattern, plan, compilation, program device, formula, design, prototype, method, technique, process, procedure, program, or code, whether tangible or intangible, and whether stored, compiled, or memorialized physically, electronically, graphically, photographically, or in writing, that:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(a) derives independent economic value, whether actual or potential, from not being generally known to, or readily ascertainable by proper means by, other persons who can obtain economic value from its disclosure or use; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) is the subject of efforts that are reasonable under the circumstances to maintain its secrecy.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">Section 1551. Required documentation. 1. (a) Beginning on January first, two thousand twenty-seven, each developer of a high-risk artificial intelligence decision system shall use reasonable care to protect consumers from any known or reasonably foreseeable risks of algorithmic discrimination arising from the intended and contracted uses of a high-risk artificial intelligence decision system. In any enforcement action brought on or after such date by the attorney general pursuant to this article, there shall be a rebuttable presumption that a developer used reasonable care as required pursuant to this subdivision if:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) the developer complied with the provisions of this section; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) an independent third party identified by the attorney general pursuant to paragraph (b) of this subdivision and retained by the developer completed bias and governance audits for the high-risk artificial intelligence decision system.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) No later than January first, two thousand twenty-six, and at least annually thereafter, the attorney general shall:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) identify independent third parties who, in the attorney general&#39;s opinion, are qualified to complete bias and governance audits for the purposes of subparagraph (ii) of paragraph (a) of this subdivision; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) publish a list of such independent third parties available on the attorney general&#39;s website.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">2. Beginning on January first, two thousand twenty-seven, and except as provided in subdivision five of this section, a developer of a highrisk artificial intelligence decision system shall make available to each deployer or other developer the following information:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(a) A general statement describing the reasonably foreseeable uses, and the known harmful or inappropriate uses, of such high-risk artificial intelligence decision system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) Documentation disclosing:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) high-level summaries of the type of data used to train such highrisk artificial intelligence decision system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) the known or reasonably foreseeable limitations of such high-risk artificial intelligence decision system, including, but not limited to, the known or reasonably foreseeable risks of algorithmic discrimination arising from the intended uses of such high-risk artificial intelligence decision system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) the purpose of such high-risk artificial intelligence decision system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iv) the intended benefits and uses of such high-risk artificial intelligence decision system; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(v) any other information necessary to enable such deployer or other developer to comply with the provisions of this article;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(c) Documentation describing:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) how such high-risk artificial intelligence decision system was evaluated for performance, and mitigation of algorithmic discrimination, before such high-risk artificial intelligence decision system was offered, sold, leased, licensed, given, or otherwise made available to such deployer or other developer;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) the data governance measures used to cover the training datasets and examine the suitability of data sources, possible biases, and appropriate mitigation;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) the intended outputs of such high-risk artificial intelligence decision system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iv) the measures such deployer or other developer has taken to mitigate any known or reasonably foreseeable risks of algorithmic discrimination that may arise from deployment of such high-risk artificial intelligence decision system; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(v) how such high-risk artificial intelligence decision system should be used, not be used, and be monitored by an individual when such highrisk artificial intelligence decision system is used to make, or as a substantial factor in making, a consequential decision; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(d) Any additional documentation that is reasonably necessary to assist a deployer or other developer to:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) understand the outputs of such high-risk artificial intelligence decision system; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) monitor the performance of such high-risk artificial intelligence decision system for risks of algorithmic discrimination.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">3. (a) Except as provided in subdivision five of this section, any developer that, on or after January first, two thousand twenty-seven, offers, sells, leases, licenses, gives, or otherwise makes available to a deployer or other developer a high-risk artificial intelligence decision system shall, to the extent feasible, make available to such deployers and other developers the documentation and information relating to such high-risk artificial intelligence decision system necessary for a deployer, or the third party contracted by a deployer, to complete an impact assessment pursuant to this article. The developer shall make such documentation and information available through artifacts such as model cards, dataset cards, or other impact assessments.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) A developer that also serves as a deployer for any high-risk artificial intelligence decision system shall not be required to generate the documentation and information required pursuant to this section unless such high-risk artificial intelligence decision system is provided to an unaffiliated entity acting as a deployer.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">4. (a) Beginning on January first, two thousand twenty-seven, each developer shall publish, in a manner that is clear and readily available, on such developer&#39;s website, or a public use case inventory, a statement summarizing:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) the types of high-risk artificial intelligence decision systems that such developer:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) has developed or intentionally and substantially modified; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) currently makes available to a deployer or other developer; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) how such developer manages any known or reasonably foreseeable risks of algorithmic discrimination that may arise from the development or intentional and substantial modification of the types of high-risk artificial intelligence decision systems described in subparagraph (i) of this subdivision.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) Each developer shall update the statement described in paragraph (a) of this subdivision:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) as necessary to ensure that such statement remains accurate; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) no later than ninety days after the developer intentionally and substantially modifies any high-risk artificial intelligence decision system described in subparagraph (i) of paragraph (a) of this subdivision.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">5. Nothing in subdivisions two or four of this section shall be construed to require a developer to disclose any information:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(a) that is a trade secret or otherwise protected from disclosure pursuant to state or federal law; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) the disclosure of which would present a security risk to such developer.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">6. Beginning on January first, two thousand twenty-seven, the attorney general may require that a developer disclose to the attorney general, as part of an investigation conducted by the attorney general and in a form and manner prescribed by the attorney general, the general statement or documentation described in subdivision two of this section. The attorney general may evaluate such general statement or documentation to ensure compliance with the provisions of this section. In disclosing such general statement or documentation to the attorney general pursuant to this subdivision, the developer may designate such general statement or documentation as including any information that is exempt from disclosure pursuant to subdivision five of this section or article six of the public officers law. To the extent such general statement or documentation includes such information, such general statement or documentation shall be exempt from disclosure. To the extent any information contained in such general statement or documentation is subject to the attorney-client privilege or work product protection, such disclosure shall not constitute a waiver of such privilege or protection.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">Section 1552. Risk management. 1. (a) Beginning on January first, two thousand twenty-seven, each deployer of a high-risk artificial intelligence decision system shall use reasonable care to protect consumers from any known or reasonably foreseeable risks of algorithmic discrimination. In any enforcement action brought on or after said date by the attorney general pursuant to this article, there shall be a rebuttable presumption that a deployer of a high-risk artificial intelligence decision system used reasonable care as required pursuant to this subdivision if:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) the deployer complied with the provisions of this section; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) an independent third party identified by the attorney general pursuant to paragraph (b) of this subdivision and retained by the deployer completed bias and governance audits for the high-risk artificial intelligence decision system.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) No later than January first, two thousand twenty-seven, and at least annually thereafter, the attorney general shall:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) identify the independent third parties who, in the attorney general&#39;s opinion, are qualified to complete bias and governance audits for the purposes of subparagraph (ii) of paragraph (a) of this subdivision; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) make a list of such independent third parties available on the attorney general&#39;s web site.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">2. (a) Beginning on January first, two thousand twenty-seven, and except as provided in subdivision seven of this section, each deployer of a high-risk artificial intelligence decision system shall implement and maintain a risk management policy and program to govern such deployer&#39;s deployment of the high-risk artificial intelligence decision system. The risk management policy and program shall specify and incorporate the principles, processes, and personnel that the deployer shall use to identify, document, and mitigate any known or reasonably foreseeable risks of algorithmic discrimination. The risk management policy shall be the product of an iterative process, the risk management program shall be an iterative process and both the risk management policy and program shall be planned, implemented, and regularly and systematically reviewed and updated over the lifecycle of the high-risk artificial intelligence decision system. Each risk management policy and program implemented and maintained pursuant to this subdivision shall be reasonable, considering:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) the guidance and standards set forth in the latest version of:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) the &quot;Artificial Intelligence Risk Management Framework&quot; published by the national institute of standards and technology;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) ISO or IEC 42001 of the international organization for standardization; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(C) a nationally or internationally recognized risk management framework for artificial intelligence decision systems, other than the guidance and standards specified in clauses (A) and (B) of this subparagraph, that imposes requirements that are substantially equivalent to, and at least as stringent as, the requirements established pursuant to this section for risk management policies and programs;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) the size and complexity of the deployer;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) the nature and scope of the high-risk artificial intelligence decision systems deployed by the deployer, including, but not limited to, the intended uses of such high-risk artificial intelligence decision systems; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iv) the sensitivity and volume of data processed in connection with the high-risk artificial intelligence decision systems deployed by the deployer.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) A risk management policy and program implemented and maintained pursuant to paragraph (a) of this subdivision may cover multiple highrisk artificial intelligence decision systems deployed by the deployer.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">3. (a) Except as provided in paragraphs (c) and (d) of this subdivision and subdivision seven of this section:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) a deployer that deploys a high-risk artificial intelligence decision system on or after January first, two thousand twenty-seven, or a third party contracted by the deployer, shall complete an impact assessment of the high-risk artificial intelligence decision system; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) beginning on January first, two thousand twenty-seven, a deployer, or a third party contracted by the deployer, shall complete an impact assessment of a deployed high-risk artificial intelligence decision system:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) at least annually; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) no later than ninety days after an intentional and substantial modification to such high-risk artificial intelligence decision system is made available.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) (i) Each impact assessment completed pursuant to this subdivision shall include, at a minimum and to the extent reasonably known by, or available to, the deployer:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) a statement by the deployer disclosing the purpose, intended use cases and deployment context of, and benefits afforded by, the high-risk artificial intelligence decision system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) an analysis of whether the deployment of the high-risk artificial intelligence decision system poses any known or reasonably foreseeable risks of algorithmic discrimination and, if so, the nature of such algorithmic discrimination and the steps that have been taken to mitigate such risks;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(C) A description of:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(I) the categories of data the high-risk artificial intelligence decision system processes as inputs; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(II) the outputs such high-risk artificial intelligence decision system produces;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(D) if the deployer used data to customize the high-risk artificial intelligence decision system, an overview of the categories of data the deployer used to customize such high-risk artificial intelligence decision system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(E) any metrics used to evaluate the performance and known limitations of the high-risk artificial intelligence decision system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(F) a description of any transparency measures taken concerning the high-risk artificial intelligence decision system, including, but not limited to, any measures taken to disclose to a consumer that such highrisk artificial intelligence decision system is in use when such highrisk artificial intelligence decision system is in use; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(G) a description of the post-deployment monitoring and user safeguards provided concerning such high-risk artificial intelligence decision system, including, but not limited to, the oversight, use, and learning process established by the deployer to address issues arising from deployment of such high-risk artificial intelligence decision system.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) In addition to the statement, analysis, descriptions, overview, and metrics required pursuant to subparagraph (i) of this paragraph, an impact assessment completed pursuant to this subdivision following an intentional and substantial modification made to a high-risk artificial intelligence decision system on or after January first, two thousand twenty-seven, shall include a statement disclosing the extent to which the high-risk artificial intelligence decision system was used in a manner that was consistent with, or varied from, the developer&#39;s intended uses of such high-risk artificial intelligence decision system.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(c) A single impact assessment may address a comparable set of highrisk artificial intelligence decision systems deployed by a deployer.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(d) If a deployer, or a third party contracted by the deployer, completes an impact assessment for the purpose of complying with another applicable law or regulation, such impact assessment shall be deemed to satisfy the requirements established in this subdivision if such impact assessment is reasonably similar in scope and effect to the impact assessment that would otherwise be completed pursuant to this subdivision.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(e) A deployer shall maintain the most recently completed impact assessment of a high-risk artificial intelligence decision system as required pursuant to this subdivision, all records concerning each such impact assessment and all prior impact assessments, if any, for a period of at least three years following the final deployment of the high-risk artificial intelligence decision system.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">4. Except as provided in subdivision seven of this section, a deployer, or a third party contracted by the deployer, shall review, no later than January first, two thousand twenty-seven, and at least annually thereafter, the deployment of each high-risk artificial intelligence decision system deployed by the deployer to ensure that such high-risk artificial intelligence decision system is not causing algorithmic discrimination.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">5. (a) Beginning on January first, two thousand twenty-seven, and before a deployer deploys a high-risk artificial intelligence decision system to make, or be a substantial factor in making, a consequential decision concerning a consumer, the deployer shall:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) notify the consumer that the deployer has deployed a high-risk artificial intelligence decision system to make, or be a substantial factor in making, such consequential decision; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) provide to the consumer:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) a statement disclosing:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(I) the purpose of such high-risk artificial intelligence decision system; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(II) the nature of such consequential decision;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) contact information for such deployer;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(C) a description, in plain language, of such high-risk artificial intelligence decision system; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(D) instructions on how to access the statement made available pursuant to paragraph (a) of subdivision six of this section.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) Beginning on January first, two thousand twenty-seven, a deployer that has deployed a high-risk artificial intelligence decision system to make, or as a substantial factor in making, a consequential decision concerning a consumer shall, if such consequential decision is adverse to the consumer, provide to such consumer:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) a statement disclosing the principal reason or reasons for such adverse consequential decision, including, but not limited to:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) the degree to which, and manner in which, the high-risk artificial intelligence decision system contributed to such adverse consequential decision;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) the type of data that was processed by such high-risk artificial intelligence decision system in making such adverse consequential decision; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(C) the source of such data; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) an opportunity to:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) correct any incorrect personal data that the high-risk artificial intelligence decision system processed in making, or as a substantial factor in making, such adverse consequential decision; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) appeal such adverse consequential decision, which shall, if technically feasible, allow for human review unless providing such opportunity is not in the best interest of such consumer, including, but not limited to, in instances in which any delay might pose a risk to the life or safety of such consumer.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(c) The deployer shall provide the notice, statements, information, description, and instructions required pursuant to paragraphs (a) and (b) of this subdivision:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) directly to the consumer;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) in plain language;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) in all languages in which such deployer, in the ordinary course of such deployer&#39;s business, provides contracts, disclaimers, sale announcements, and other information to consumers; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iv) in a format that is accessible to consumers with disabilities.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">6. (a) Beginning on January first, two thousand twenty-seven, and except as provided in subdivision seven of this section, each deployer shall make available, in a manner that is clear and readily available on such deployer&#39;s website, a statement summarizing:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) the types of high-risk artificial intelligence decision systems that are currently deployed by such deployer;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) how such deployer manages any known or reasonably foreseeable risks of algorithmic discrimination that may arise from deployment of each high-risk artificial intelligence decision system described in subparagraph (i) of this paragraph; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) in detail, the nature, source and extent of the information collected and used by such deployer.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) Each deployer shall periodically update the statement required pursuant to paragraph (a) of this subdivision.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">7. The provisions of subdivisions two, three, four, and six of this section shall not apply to a deployer if, at the time the deployer deploys a high-risk artificial intelligence decision system, and at all times while the high-risk artificial intelligence decision system is deployed:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(a) the deployer:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) has entered into a contract with the developer in which the developer has agreed to assume the deployer&#39;s duties pursuant to subdivisions two, three, four, or six of this section; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) does not exclusively use such deployer&#39;s own data to train such high-risk artificial intelligence decision system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) such high-risk artificial intelligence decision system:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) is used for the intended uses that are disclosed to such deployer pursuant to subparagraph (iv) of paragraph (b) of subdivision two of section one thousand five hundred fifty-one of this article; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) continues learning based on a broad range of data sources and not solely based on the deployer&#39;s own data; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(c) such deployer makes available to consumers any impact assessment that:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) the developer of such high-risk artificial intelligence decision system has completed and provided to such deployer; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) includes information that is substantially similar to the information included in the statement, analysis, descriptions, overview, and metrics required pursuant to subparagraph (i) of paragraph (b) of subdivision three of this section.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">8. Nothing in this subdivision or subdivisions two, three, four, five, or six of this section shall be construed to require a deployer to disclose any information that is a trade secret or otherwise protected from disclosure pursuant to state or federal law. If a deployer withholds any information from a consumer pursuant this subdivision, the deployer shall send notice to such consumer disclosing:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(a) that the deployer is withholding such information from such consumer; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) the basis for the deployer&#39;s decision to withhold such information from such consumer.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">9. Beginning on January first, two thousand twenty-seven, the attorney general may require that a deployer, or a third party contracted by the deployer pursuant to subdivision three of this section, as applicable, disclose to the attorney general, as part of an investigation conducted by the attorney general, no later than ninety days after a request by the attorney general, and in a form and manner prescribed by the attorney general, the risk management policy implemented pursuant to subdivision two of this section, the impact assessment completed pursuant to subdivision three of this section; or records maintained pursuant to paragraph (e) of subdivision three of this section. The attorney general may evaluate such risk management policy, impact assessment or records to ensure compliance with the provisions of this section. In disclosing such risk management policy, impact assessment or records to the attorney general pursuant to this subdivision, the deployer or third-party contractor, as applicable, may designate such risk management policy, impact assessment or records as including any information that is exempt from disclosure pursuant to subdivision eight of this section or article six of the public officers law. To the extent such risk management policy, impact assessment, or records include such information, such risk management policy, impact assessment, or records shall be exempt from disclosure. To the extent any information contained in such risk management policy, impact assessment, or record is subject to the attorneyclient privilege or work product protection, such disclosure shall not constitute a waiver of such privilege or protection.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">Section 1553. Technical documentation. 1. Beginning on January first, two thousand twenty-seven, each developer of a general-purpose artificial intelligence model shall, except as provided in subdivision two of this section:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(a) create and maintain technical documentation for the general-purpose artificial intelligence model, which shall:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) include:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) the training and testing processes for such general-purpose artificial intelligence model; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) the results of an evaluation of such general-purpose artificial intelligence model performed to determine whether such general-purpose artificial intelligence model is in compliance with the provisions of this article;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) include, as appropriate, considering the size and risk profile of such general-purpose artificial intelligence model, at least:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) the tasks such general-purpose artificial intelligence model is intended to perform;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) the type and nature of artificial intelligence decision systems in which such general-purpose artificial intelligence model is intended to be integrated;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(C) acceptable use policies for such general-purpose artificial intelligence model;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(D) the date such general-purpose artificial intelligence model is released;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(E) the methods by which such general-purpose artificial intelligence model is distributed; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(F) the modality and format of inputs and outputs for such generalpurpose artificial intelligence model; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) be reviewed and revised at least annually, or more frequently, as necessary to maintain the accuracy of such technical documentation; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) create, implement, maintain and make available to persons that intend to integrate such general-purpose artificial intelligence model into such persons&#39; artificial intelligence decision systems documentation and information that:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) enables such persons to:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) understand the capabilities and limitations of such general-purpose artificial intelligence model; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) comply with such persons&#39; obligations pursuant to this article;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) discloses, at a minimum:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) the technical means required for such general-purpose artificial intelligence model to be integrated into such persons&#39; artificial intelligence decision systems;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) the information listed in subparagraph (ii) of paragraph (a) of this subdivision; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) except as provided in subdivision two of this section, is reviewed and revised at least annually, or more frequently, as necessary to maintain the accuracy of such documentation and information.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">2. (a) The provisions of paragraph (a) and subparagraph (iii) of paragraph (b) of subdivision one of this section shall not apply to a developer that develops, or intentionally and substantially modifies, a general-purpose artificial intelligence model on or after January first, two thousand twenty-seven, if:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) (A) the developer releases such general-purpose artificial intelligence model under a free and open-source license that allows for:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(I) access to, and modification, distribution, and usage of, such general-purpose artificial intelligence model; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(II) the parameters of such general-purpose artificial intelligence model to be made publicly available pursuant to clause (B) of this subparagraph; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) unless such general-purpose artificial intelligence model is deployed as a high-risk artificial intelligence decision system, the parameters of such general-purpose artificial intelligence model, including, but not limited to, the weights and information concerning the model architecture and model usage for such general-purpose artificial intelligence model, are made publicly available; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) the general-purpose artificial intelligence model is:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) not offered for sale in the market;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) not intended to interact with consumers; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(C) solely utilized:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(I) for an entity&#39;s internal purposes; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(II) pursuant to an agreement between multiple entities for such entities&#39; internal purposes.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) The provisions of this section shall not apply to a developer that develops, or intentionally and substantially modifies, a general-purpose artificial intelligence model on or after January first, two thousand twenty-seven, if such general purpose artificial intelligence model performs tasks exclusively related to an entity&#39;s internal management affairs, including, but not limited to, ordering office supplies or processing payments.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(c) A developer that takes any action under an exemption pursuant to paragraph (a) or (b) of this subdivision shall bear the burden of demonstrating that such action qualifies for such exemption.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(d) A developer that is exempt pursuant to subparagraph (ii) of paragraph (a) of this subdivision shall establish and maintain an artificial intelligence risk management framework, which shall:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) be the product of an iterative process and ongoing efforts; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) include, at a minimum:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) an internal governance function;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) a map function that shall establish the context to frame risks;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(C) a risk management function; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(D) a function to measure identified risks by assessing, analyzing and tracking such risks.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">3. Nothing in subdivision one of this section shall be construed to require a developer to disclose any information that is a trade secret or otherwise protected from disclosure pursuant to state or federal law.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">4. Beginning on January first, two thousand twenty-seven, the attorney general may require that a developer disclose to the attorney general, as part of an investigation conducted by the attorney general, no later than ninety days after a request by the attorney general and in a form and manner prescribed by the attorney general, any documentation maintained pursuant to this section. The attorney general may evaluate such documentation to ensure compliance with the provisions of this section. In disclosing any documentation to the attorney general pursuant to this subdivision, the developer may designate such documentation as including any information that is exempt from disclosure pursuant to subdivision three of this section or article six of the public officers law. To the extent such documentation includes such information, such documentation shall be exempt from disclosure. To the extent any information contained in such documentation is subject to the attorney-client privilege or work product protection, such disclosure shall not constitute a waiver of such privilege or protection.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">Section 1554. Required disclosure. 1. Beginning on January first, two thousand twenty-seven, and except as provided in subdivision two of this section, each person doing business in this state, including, but not limited to, each deployer that deploys, offers, sells, leases, licenses, gives, or otherwise makes available, as applicable, any artificial intelligence decision system that is intended to interact with consumers shall ensure that it is disclosed to each consumer who interacts with such artificial intelligence decision system that such consumer is interacting with an artificial intelligence decision system.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">2. No disclosure shall be required pursuant to subdivision one of this section under circumstances in which a reasonable person would deem it obvious that such person is interacting with an artificial intelligence decision system.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">Section 1555. Preemption. 1. Nothing in this article shall be construed to restrict a developer&#39;s, deployer&#39;s, or other person&#39;s ability to:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(a) comply with federal, state or municipal law;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) comply with a civil, criminal or regulatory inquiry, investigation, subpoena, or summons by a federal, state, municipal, or other governmental authority;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(c) cooperate with a law enforcement agency concerning conduct or activity that the developer, deployer, or other person reasonably and in good faith believes may violate federal, state, or municipal law;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(d) investigate, establish, exercise, prepare for, or defend a legal claim;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(e) take immediate steps to protect an interest that is essential for the life or physical safety of a consumer or another individual;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(f) (i) by any means other than facial recognition technology, prevent, detect, protect against, or respond to:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) a security incident;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) a malicious or deceptive activity; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(C) identity theft, fraud, harassment or any other illegal activity;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) investigate, report, or prosecute the persons responsible for any action described in subparagraph (i) of this paragraph; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) preserve the integrity or security of systems;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(g) engage in public or peer-reviewed scientific or statistical research in the public interest that:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) adheres to all other applicable ethics and privacy laws; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) is conducted in accordance with:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) part forty-six of title forty-five of the code of federal regulations, as amended; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) relevant requirements established by the federal food and drug administration;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(h) conduct research, testing, and development activities regarding an artificial intelligence decision system or model, other than testing conducted pursuant to real world conditions, before such artificial intelligence decision system or model is placed on the market, deployed, or put into service, as applicable;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) effectuate a product recall;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(j) identify and repair technical errors that impair existing or intended functionality; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(k) assist another developer, deployer, or person with any of the obligations imposed pursuant to this article.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">2. The obligations imposed on developers, deployers, or other persons pursuant to this article shall not apply where compliance by the developer, deployer, or other person with the provisions of this article would violate an evidentiary privilege pursuant to state law.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">3. Nothing in this article shall be construed to impose any obligation on a developer, deployer, or other person that adversely affects the rights or freedoms of any person, including, but not limited to, the rights of any person:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(a) to freedom of speech or freedom of the press guaranteed in:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) the first amendment to the United States constitution; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) section eight of the New York state constitution; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) pursuant to section seventy-nine-h of the civil rights law.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">4. Nothing in this article shall be construed to apply to any developer, deployer, or other person:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(a) insofar as such developer, deployer or other person develops, deploys, puts into service, or intentionally and substantially modifies, as applicable, a high-risk artificial intelligence decision system:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) that has been approved, authorized, certified, cleared, developed, or granted by:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) a federal agency, including, but not limited to, the federal food and drug administration or the federal aviation administration, acting within the scope of such federal agency&#39;s authority; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) a regulated entity subject to supervision and regulation by the federal housing finance agency; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) in compliance with standards that are:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) established by:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(I) any federal agency, including, but not limited to, the federal office of the national coordinator for health information technology; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(II) a regulated entity subject to supervision and regulation by the federal housing finance agency; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) substantially equivalent to, and at least as stringent as, the standards established pursuant to this article;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) conducting research to support an application:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) for approval or certification from any federal agency, including, but not limited to, the federal food and drug administration, the federal aviation administration, or the federal communications commission; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) that is otherwise subject to review by any federal agency;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(c) performing work pursuant to, or in connection with, a contract with the federal department of commerce, the federal department of defense, or the national aeronautics and space administration, unless such developer, deployer, or other person is performing such work on a high-risk artificial intelligence decision system that is used to make, or as a substantial factor in making, a decision concerning employment or housing; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(d) that is a covered entity, as defined by the health insurance portability and accountability act of 1996 and the regulations promulgated thereunder, as amended, and providing health care recommendations that:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) are generated by an artificial intelligence decision system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) require a health care provider to take action to implement such recommendations; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) are not considered to be high risk.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">5. Nothing in this article shall be construed to apply to any artificial intelligence decision system that is acquired by or for the federal government or any federal agency or department, including, but not limited to, the federal department of commerce, the federal department of defense, or the national aeronautics and space administration, unless such artificial intelligence decision system is a high-risk artificial intelligence decision system that is used to make, or as a substantial factor in making, a decision concerning employment or housing.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">6. Any insurer, as defined by section five hundred one of the insurance law, or fraternal benefit society, as defined by section four thousand five hundred one of the insurance law, shall be deemed to be in full compliance with the provisions of this article if such insurer or fraternal benefit society has implemented and maintains a written artificial intelligence decision systems program in accordance with all requirements established by the superintendent of financial services.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">7. (a) Any bank, out-of-state bank, New York credit union, federal credit union, or out-of-state credit union, or any affiliate or subsidiary thereof, shall be deemed to be in full compliance with the provisions of this article if such bank, out-of-state bank, New York credit union, federal credit union, out-of-state credit union, affiliate, or subsidiary is subject to examination by any state or federal prudential regulator pursuant to any published guidance or regulations that apply to the use of high-risk artificial intelligence decision systems, and such guidance or regulations:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) impose requirements that are substantially equivalent to, and at least as stringent as, the requirements of this article; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) at a minimum, require such bank, out-of-state bank, New York credit union, federal credit union, out-of-state credit union, affiliate, or subsidiary to:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) regularly audit such bank&#39;s, out-of-state bank&#39;s, New York credit union&#39;s, federal credit union&#39;s, out-of-state credit union&#39;s, affiliate&#39;s, or subsidiary&#39;s use of high-risk artificial intelligence decision systems for compliance with state and federal anti-discrimination laws and regulations applicable to such bank, out-of-state bank, New York credit union, federal credit union, out-of-state credit union, affiliate, or subsidiary; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) mitigate any algorithmic discrimination caused by the use of a high-risk artificial intelligence decision system, or any risk of algorithmic discrimination that is reasonably foreseeable as a result of the use of a high-risk artificial intelligence decision system.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) For the purposes of this subdivision, the following terms shall have the following meanings:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) &quot;Affiliate&quot; shall have the same meaning as set forth in section nine hundred twelve of the business corporation law.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) &quot;Bank&quot; shall have the same meaning as set forth in section two of the banking law.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) &quot;Credit union&quot; shall have the same meaning as set forth in section two of the banking law.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iv) &quot;Out-of-state bank&quot; shall have the same meaning as set forth in section two hundred twenty-two of the banking law.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(v) &quot;Subsidiary&quot; shall have the same meaning as set forth in section one hundred forty-one of the banking law.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">8. If a developer, deployer, or other person engages in any action under an exemption pursuant to subdivisions one, two, three, four, five, six, or seven of this section, the developer, deployer, or other person bears the burden of demonstrating that such action qualifies for such exemption.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">Section 1556. Enforcement. 1. The attorney general shall have exclusive authority to enforce the provisions of this article.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">2. Except as provided in subdivision six of this section, during the period beginning on January first, two thousand twenty-seven, and ending on January first, two thousand twenty-eight, the attorney general shall, prior to initiating any action for a violation of this section, issue a notice of violation to the developer, deployer, or other person if the attorney general determines that it is possible to cure such violation. If the developer, deployer, or other person fails to cure such violation within sixty days after receipt of such notice of violation, the attorney general may bring an action pursuant to this section.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">3. Except as provided in subdivision six of this section, beginning on January first, two thousand twenty-eight, the attorney general may, in determining whether to grant a developer, deployer, or other person the opportunity to cure a violation described in subdivision two of this section, consider:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(a) the number of violations;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) the size and complexity of the developer, deployer, or other person;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(c) the nature and extent of the developer&#39;s, deployer&#39;s, or other person&#39;s business;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(d) the substantial likelihood of injury to the public;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(e) the safety of persons or property; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(f) whether such violation was likely caused by human or technical error.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">4. Nothing in this article shall be construed as providing the basis for a private right of action for violations of the provisions of this article.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">5. Except as provided in subdivisions one, two, three, four, and six of this section, a violation of the requirements established in this article shall constitute an unfair trade practice for purposes of section three hundred forty-nine of this chapter and shall be enforced solely by the attorney general; provided, however, that subdivision (h) of section three hundred forty-nine of this chapter shall not apply to any such violation.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">6. (a) In any action commenced by the attorney general for any violation of this article, it shall be an affirmative defense that the developer, deployer, or other person:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) discovers a violation of any provision of this article through red-teaming;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) no later than sixty days after discovering such violation through red-teaming:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) cures such violation; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) provides to the attorney general, in a form and manner prescribed by the attorney general, notice that such violation has been cured and evidence that any harm caused by such violation has been mitigated; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) is otherwise in compliance with the latest version of:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) the Artificial Intelligence Risk Management Framework published by the national institute of standards and technology;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) ISO/IEC 42001 of the international organization for standardization and the international electrotechnical commission;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(C) a nationally or internationally recognized risk management framework for artificial intelligence decision systems, other than the risk management frameworks described in clauses (A) and (B) of this subparagraph, that imposes requirements that are substantially equivalent to, and at least as stringent as, the requirements established pursuant to this article; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(D) any risk management framework for artificial intelligence decision systems that is substantially equivalent to, and at least as stringent as, the risk management frameworks described in clauses (A), (B), and (C) of this subparagraph.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) The developer, deployer, or other person bears the burden of demonstrating to the attorney general that the requirements established pursuant to paragraph (a) of this subdivision have been satisfied.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(c) Nothing in this article, including, but not limited to, the enforcement authority granted to the attorney general pursuant to this section, shall be construed to preempt or otherwise affect any right, claim, remedy, presumption, or defense available at law or in equity. Any rebuttable presumption or affirmative defense established pursuant to this article shall apply only to an enforcement action brought by the attorney general pursuant to this section and shall not apply to any right, claim, remedy, presumption, or defense available at law or in equity.</u>\n   </p>\n   <p class=\"indent\">Section 3. This act shall take effect on the two hundred seventieth day after it shall have become a law.</p>\n  </div>\n </div>\n    </div>\t\n<table cellpadding=0 cellspacing=0 width=\"100%\">\n   <tr>\n      <td>\n          Copyright &copy; 2025 State Net\n      </td>\n<BR>\n<!--???MOVED INTO resources.cgi      <td align=\"right\">\n          <img src=\"https://custom.statenet.com/network/poweredby.gif\" alt=\"Powered by State Net\">\n      </td>-->\n\n    </tr>\n</table>\n</body></html>\n",
      "markdown": "The following has special meaning: _green underline denotes added text_ ~~red struck out text denotes deleted text~~ | [![Powered by State Net](https://custom.statenet.com/network/poweredby.gif)](https://www.lexisnexis.com/statenet/)  \n---|---  \n  \n2025 NY A 768 | | Author: | Bores  \n---|---  \nVersion: | Introduced  \nVersion Date: | 01/08/2025  \n  \n**STATE OF NEW YORK**\n\n768\n\n2025-2026 Regular Sessions\n\n**IN ASSEMBLY**\n\n_(Prefiled)_\n\nJanuary 8, 2025\n\nIntroduced by M. of A. BORES -- read once and referred to the Committee on\nConsumer Affairs and Protection\n\nAN ACT to amend the general business law, in relation to preventing the use of\nartificial intelligence algorithms to discriminate against protected classes\n\n**The People of the State of New York, represented in Senate and Assembly, do\nenact as follows:**\n\nSection 1. Short title. This act shall be known and may be cited as the \"New\nYork artificial intelligence consumer protection act\".\n\nSection 2. The general business law is amended by adding a new article 45-A to\nread as follows:\n\n_ARTICLE 45-A_\n\n_NEW YORK ARTIFICIAL INTELLIGENCE CONSUMER PROTECTION ACT_\n\n_Section 1550. Definitions._\n\n_1551\\. Required documentation._\n\n_1552\\. Risk management._\n\n_1553\\. Technical documentation._\n\n_1554\\. Required disclosure._\n\n_1555\\. Preemption._\n\n_1556\\. Enforcement._\n\n_Section 1550. Definitions. For the purposes of this article, the following\nterms shall have the following meanings:_\n\n_1. \"Algorithmic discrimination\":_\n\n_(a) shall mean any condition in which the use of an artificial intelligence\ndecision system results in any unlawful differential treatment or impact that\ndisfavors any individual or group of individuals on the basis of their actual\nor perceived age, color, disability, ethnicity, genetic information, English\nlanguage proficiency, national origin, race, religion, reproductive health,\nsex, veteran status, or other classification protected pursuant to state or\nfederal law; and_\n\n_(b) shall not include:_\n\n_(i) the offer, license, or use of a high-risk artificial intelligence\ndecision system by a developer or deployer for the sole purpose of:_\n\n_(A) such developer 's or deployer's self-testing to identify, mitigate, or\nprevent discrimination or otherwise ensure compliance with state and federal\nlaw; or_\n\n_(B) expanding an applicant, customer, or participant pool to increase\ndiversity or redress historic discrimination; or_\n\n_(ii) an act or omission by or on behalf of a private club or other\nestablishment not open to the general public, as set forth in title II of the\nCivil Rights Act of 1964, 42 U.S.C. Section 2000a(e), as amended._\n\n_2. \"Artificial intelligence decision system\" shall mean any computational\nprocess, derived from machine learning, statistical modeling, data analytics,\nor artificial intelligence, that issues simplified output, including any\ncontent, decision, prediction, or recommendation, that is used to\nsubstantially assist or replace discretionary decision making for making\nconsequential decisions that impact consumers._\n\n_3. \"Bias and governance audit\" means an impartial evaluation by an\nindependent auditor, which shall include, at a minimum, the testing of an\nartificial intelligence decision system to assess such system's disparate\nimpact on employees because of such employee's age, race, creed, color,\nethnicity, national origin, disability, citizenship or immigration status,\nmarital or familial status, military status, religion, or sex, including\nsexual orientation, gender identity, gender expression, pregnancy, pregnancy\noutcomes, and reproductive healthcare choices._\n\n_4. \"Consequential decision\" shall mean any decision that has a material legal\nor similarly significant effect on the provision or denial to any consumer of,\nor the cost or terms of, any:_\n\n_(a) education enrollment or education opportunity;_\n\n_(b) employment or employment opportunity;_\n\n_(c) financial or lending service;_\n\n_(d) essential government service;_\n\n_(e) health care service, as defined in section 42 U.S.C. Section 324(d)(2),\nas amended;_\n\n_(f) housing or housing opportunity;_\n\n_(g) insurance; or_\n\n_(h) legal service._\n\n_5. \"Consumer\" shall mean any New York state resident._\n\n_6. \"Deploy\" shall mean to use a high-risk artificial intelligence decision\nsystem._\n\n_7. \"Deployer\" shall mean any person doing business in this state that deploys\na high-risk artificial intelligence decision system._\n\n_8. \"Developer\" shall mean any person doing business in this state that\ndevelops, or intentionally and substantially modifies, an artificial\nintelligence decision system._\n\n_9. \"General-purpose artificial intelligence model\":_\n\n_(a) shall mean any form of artificial intelligence decision system that:_\n\n_(i) displays significant generality;_\n\n_(ii) is capable of competently performing a wide range of distinct tasks;\nand_\n\n_(iii) can be integrated into a variety of downstream applications or systems;\nand_\n\n_(b) shall not include any artificial intelligence model that is used for\ndevelopment, prototyping, and research activities before such artificial\nintelligence model is released on the market._\n\n_10. \"High-risk artificial intelligence decision system\":_\n\n_(a) shall mean any artificial intelligence decision system that, when\ndeployed, makes, or is a substantial factor in making, a consequential\ndecision; and_\n\n_(b) shall not include:_\n\n_(i) any artificial intelligence decision system that is intended to:_\n\n_(A) perform any narrow procedural task; or_\n\n_(B) detect decision-making patterns, or deviations from decision-making\npatterns, unless such artificial intelligence decision system is intended to\nreplace or influence any assessment previously completed by an individual\nwithout sufficient human review; or_\n\n_(ii) unless the technology, when deployed, makes, or is a substantial factor\nin making, a consequential decision:_\n\n_(A) any anti-fraud technology that does not make use of facial recognition\ntechnology;_\n\n_(B) any artificial intelligence-enabled video game technology;_\n\n_(C) any anti-malware, anti-virus, calculator, cybersecurity, database, data\nstorage, firewall, Internet domain registration, Internet-web-site loading,\nnetworking, robocall-filtering, spam-filtering, spellchecking, spreadsheet,\nweb-caching, web-hosting, or similar technology;_\n\n_(D) any technology that performs tasks exclusively related to an entity 's\ninternal management affairs, including, but not limited to, ordering office\nsupplies or processing payments; or_\n\n_(E) any technology that communicates with consumers in natural language for\nthe purpose of providing consumers with information, making referrals or\nrecommendations, and answering questions, and is subject to an accepted use\npolicy that prohibits generating content that is discriminatory or harmful._\n\n_11. \"Intentional and substantial modification\":_\n\n_(a) shall mean any deliberate change made to:_\n\n_(i) an artificial intelligence decision system that results in any new\nreasonably foreseeable risk of algorithmic discrimination; or_\n\n_(ii) a general-purpose artificial intelligence model that:_\n\n_(A) affects compliance of the general-purpose artificial intelligence model;_\n\n_(B) materially changes the purpose of the general-purpose artificial\nintelligence model; or_\n\n_(C) results in any new reasonably foreseeable risk of algorithmic\ndiscrimination; and_\n\n_(b) shall not include any change made to a high-risk artificial intelligence\ndecision system, or the performance of a high-risk artificial intelligence\ndecision system, if:_\n\n_(i) the high-risk artificial intelligence decision system continues to learn\nafter such high-risk artificial intelligence decision system is:_\n\n_(A) offered, sold, leased, licensed, given or otherwise made available to a\ndeployer; or_\n\n_(B) deployed; and_\n\n_(ii) such change:_\n\n_(A) is made to such high-risk artificial intelligence decision system as a\nresult of any learning described in subparagraph (i) of this paragraph;_\n\n_(B) was predetermined by the deployer, or the third party contracted by the\ndeployer, when such deployer or third party completed the initial impact\nassessment of such high-risk artificial intelligence decision system pursuant\nto subdivision three of section one thousand five hundred fifty-two of this\narticle; and_\n\n_(C) is included in the technical documentation for such high-risk artificial\nintelligence decision system._\n\n_12. \"Person\" shall mean any individual, association, corporation, limited\nliability company, partnership, trust or other legal entity authorized to do\nbusiness in this state._\n\n_13. \"Red-teaming\" shall mean an exercise that is conducted to identify the\npotential adverse behaviors or outcomes of an artificial intelligence decision\nsystem and how such behaviors or outcomes occur, and stress test the\nsafeguards against such adverse behaviors or outcomes._\n\n_14. \"Substantial factor\":_\n\n_(a) shall mean a factor that:_\n\n_(i) assists in making a consequential decision;_\n\n_(ii) is capable of altering the outcome of a consequential decision; and_\n\n_(iii) is generated by an artificial intelligence decision system; and_\n\n_(b) includes, but is not limited to, any use of an artificial intelligence\ndecision system to generate any content, decision, prediction, or\nrecommendation concerning a consumer that is used as a basis to make a\nconsequential decision concerning such consumer._\n\n_15. \"Synthetic digital content\" shall mean any digital content, including,\nbut not limited to, any audio, image, text, or video, that is produced or\nmanipulated by an artificial intelligence decision system, including, but not\nlimited to, a general-purpose artificial intelligence model._\n\n_16. \"Trade secret\" shall mean any form and type of financial, business,\nscientific, technical, economic, or engineering information, including, but\nnot limited to, a pattern, plan, compilation, program device, formula, design,\nprototype, method, technique, process, procedure, program, or code, whether\ntangible or intangible, and whether stored, compiled, or memorialized\nphysically, electronically, graphically, photographically, or in writing,\nthat:_\n\n_(a) derives independent economic value, whether actual or potential, from not\nbeing generally known to, or readily ascertainable by proper means by, other\npersons who can obtain economic value from its disclosure or use; and_\n\n_(b) is the subject of efforts that are reasonable under the circumstances to\nmaintain its secrecy._\n\n_Section 1551. Required documentation. 1. (a) Beginning on January first, two\nthousand twenty-seven, each developer of a high-risk artificial intelligence\ndecision system shall use reasonable care to protect consumers from any known\nor reasonably foreseeable risks of algorithmic discrimination arising from the\nintended and contracted uses of a high-risk artificial intelligence decision\nsystem. In any enforcement action brought on or after such date by the\nattorney general pursuant to this article, there shall be a rebuttable\npresumption that a developer used reasonable care as required pursuant to this\nsubdivision if:_\n\n_(i) the developer complied with the provisions of this section; and_\n\n_(ii) an independent third party identified by the attorney general pursuant\nto paragraph (b) of this subdivision and retained by the developer completed\nbias and governance audits for the high-risk artificial intelligence decision\nsystem._\n\n_(b) No later than January first, two thousand twenty-six, and at least\nannually thereafter, the attorney general shall:_\n\n_(i) identify independent third parties who, in the attorney general 's\nopinion, are qualified to complete bias and governance audits for the purposes\nof subparagraph (ii) of paragraph (a) of this subdivision; and_\n\n_(ii) publish a list of such independent third parties available on the\nattorney general 's website._\n\n_2\\. Beginning on January first, two thousand twenty-seven, and except as\nprovided in subdivision five of this section, a developer of a highrisk\nartificial intelligence decision system shall make available to each deployer\nor other developer the following information:_\n\n_(a) A general statement describing the reasonably foreseeable uses, and the\nknown harmful or inappropriate uses, of such high-risk artificial intelligence\ndecision system;_\n\n_(b) Documentation disclosing:_\n\n_(i) high-level summaries of the type of data used to train such highrisk\nartificial intelligence decision system;_\n\n_(ii) the known or reasonably foreseeable limitations of such high-risk\nartificial intelligence decision system, including, but not limited to, the\nknown or reasonably foreseeable risks of algorithmic discrimination arising\nfrom the intended uses of such high-risk artificial intelligence decision\nsystem;_\n\n_(iii) the purpose of such high-risk artificial intelligence decision system;_\n\n_(iv) the intended benefits and uses of such high-risk artificial intelligence\ndecision system; and_\n\n_(v) any other information necessary to enable such deployer or other\ndeveloper to comply with the provisions of this article;_\n\n_(c) Documentation describing:_\n\n_(i) how such high-risk artificial intelligence decision system was evaluated\nfor performance, and mitigation of algorithmic discrimination, before such\nhigh-risk artificial intelligence decision system was offered, sold, leased,\nlicensed, given, or otherwise made available to such deployer or other\ndeveloper;_\n\n_(ii) the data governance measures used to cover the training datasets and\nexamine the suitability of data sources, possible biases, and appropriate\nmitigation;_\n\n_(iii) the intended outputs of such high-risk artificial intelligence decision\nsystem;_\n\n_(iv) the measures such deployer or other developer has taken to mitigate any\nknown or reasonably foreseeable risks of algorithmic discrimination that may\narise from deployment of such high-risk artificial intelligence decision\nsystem; and_\n\n_(v) how such high-risk artificial intelligence decision system should be\nused, not be used, and be monitored by an individual when such highrisk\nartificial intelligence decision system is used to make, or as a substantial\nfactor in making, a consequential decision; and_\n\n_(d) Any additional documentation that is reasonably necessary to assist a\ndeployer or other developer to:_\n\n_(i) understand the outputs of such high-risk artificial intelligence decision\nsystem; and_\n\n_(ii) monitor the performance of such high-risk artificial intelligence\ndecision system for risks of algorithmic discrimination._\n\n_3\\. (a) Except as provided in subdivision five of this section, any developer\nthat, on or after January first, two thousand twenty-seven, offers, sells,\nleases, licenses, gives, or otherwise makes available to a deployer or other\ndeveloper a high-risk artificial intelligence decision system shall, to the\nextent feasible, make available to such deployers and other developers the\ndocumentation and information relating to such high-risk artificial\nintelligence decision system necessary for a deployer, or the third party\ncontracted by a deployer, to complete an impact assessment pursuant to this\narticle. The developer shall make such documentation and information available\nthrough artifacts such as model cards, dataset cards, or other impact\nassessments._\n\n_(b) A developer that also serves as a deployer for any high-risk artificial\nintelligence decision system shall not be required to generate the\ndocumentation and information required pursuant to this section unless such\nhigh-risk artificial intelligence decision system is provided to an\nunaffiliated entity acting as a deployer._\n\n_4\\. (a) Beginning on January first, two thousand twenty-seven, each developer\nshall publish, in a manner that is clear and readily available, on such\ndeveloper 's website, or a public use case inventory, a statement\nsummarizing:_\n\n_(i) the types of high-risk artificial intelligence decision systems that such\ndeveloper:_\n\n_(A) has developed or intentionally and substantially modified; and_\n\n_(B) currently makes available to a deployer or other developer; and_\n\n_(ii) how such developer manages any known or reasonably foreseeable risks of\nalgorithmic discrimination that may arise from the development or intentional\nand substantial modification of the types of high-risk artificial intelligence\ndecision systems described in subparagraph (i) of this subdivision._\n\n_(b) Each developer shall update the statement described in paragraph (a) of\nthis subdivision:_\n\n_(i) as necessary to ensure that such statement remains accurate; and_\n\n_(ii) no later than ninety days after the developer intentionally and\nsubstantially modifies any high-risk artificial intelligence decision system\ndescribed in subparagraph (i) of paragraph (a) of this subdivision._\n\n_5\\. Nothing in subdivisions two or four of this section shall be construed to\nrequire a developer to disclose any information:_\n\n_(a) that is a trade secret or otherwise protected from disclosure pursuant to\nstate or federal law; or_\n\n_(b) the disclosure of which would present a security risk to such developer._\n\n_6\\. Beginning on January first, two thousand twenty-seven, the attorney\ngeneral may require that a developer disclose to the attorney general, as part\nof an investigation conducted by the attorney general and in a form and manner\nprescribed by the attorney general, the general statement or documentation\ndescribed in subdivision two of this section. The attorney general may\nevaluate such general statement or documentation to ensure compliance with the\nprovisions of this section. In disclosing such general statement or\ndocumentation to the attorney general pursuant to this subdivision, the\ndeveloper may designate such general statement or documentation as including\nany information that is exempt from disclosure pursuant to subdivision five of\nthis section or article six of the public officers law. To the extent such\ngeneral statement or documentation includes such information, such general\nstatement or documentation shall be exempt from disclosure. To the extent any\ninformation contained in such general statement or documentation is subject to\nthe attorney-client privilege or work product protection, such disclosure\nshall not constitute a waiver of such privilege or protection._\n\n_Section 1552. Risk management. 1. (a) Beginning on January first, two\nthousand twenty-seven, each deployer of a high-risk artificial intelligence\ndecision system shall use reasonable care to protect consumers from any known\nor reasonably foreseeable risks of algorithmic discrimination. In any\nenforcement action brought on or after said date by the attorney general\npursuant to this article, there shall be a rebuttable presumption that a\ndeployer of a high-risk artificial intelligence decision system used\nreasonable care as required pursuant to this subdivision if:_\n\n_(i) the deployer complied with the provisions of this section; and_\n\n_(ii) an independent third party identified by the attorney general pursuant\nto paragraph (b) of this subdivision and retained by the deployer completed\nbias and governance audits for the high-risk artificial intelligence decision\nsystem._\n\n_(b) No later than January first, two thousand twenty-seven, and at least\nannually thereafter, the attorney general shall:_\n\n_(i) identify the independent third parties who, in the attorney general 's\nopinion, are qualified to complete bias and governance audits for the purposes\nof subparagraph (ii) of paragraph (a) of this subdivision; and_\n\n_(ii) make a list of such independent third parties available on the attorney\ngeneral 's web site._\n\n_2\\. (a) Beginning on January first, two thousand twenty-seven, and except as\nprovided in subdivision seven of this section, each deployer of a high-risk\nartificial intelligence decision system shall implement and maintain a risk\nmanagement policy and program to govern such deployer 's deployment of the\nhigh-risk artificial intelligence decision system. The risk management policy\nand program shall specify and incorporate the principles, processes, and\npersonnel that the deployer shall use to identify, document, and mitigate any\nknown or reasonably foreseeable risks of algorithmic discrimination. The risk\nmanagement policy shall be the product of an iterative process, the risk\nmanagement program shall be an iterative process and both the risk management\npolicy and program shall be planned, implemented, and regularly and\nsystematically reviewed and updated over the lifecycle of the high-risk\nartificial intelligence decision system. Each risk management policy and\nprogram implemented and maintained pursuant to this subdivision shall be\nreasonable, considering:_\n\n_(i) the guidance and standards set forth in the latest version of:_\n\n_(A) the \"Artificial Intelligence Risk Management Framework\" published by the\nnational institute of standards and technology;_\n\n_(B) ISO or IEC 42001 of the international organization for standardization;\nor_\n\n_(C) a nationally or internationally recognized risk management framework for\nartificial intelligence decision systems, other than the guidance and\nstandards specified in clauses (A) and (B) of this subparagraph, that imposes\nrequirements that are substantially equivalent to, and at least as stringent\nas, the requirements established pursuant to this section for risk management\npolicies and programs;_\n\n_(ii) the size and complexity of the deployer;_\n\n_(iii) the nature and scope of the high-risk artificial intelligence decision\nsystems deployed by the deployer, including, but not limited to, the intended\nuses of such high-risk artificial intelligence decision systems; and_\n\n_(iv) the sensitivity and volume of data processed in connection with the\nhigh-risk artificial intelligence decision systems deployed by the deployer._\n\n_(b) A risk management policy and program implemented and maintained pursuant\nto paragraph (a) of this subdivision may cover multiple highrisk artificial\nintelligence decision systems deployed by the deployer._\n\n_3\\. (a) Except as provided in paragraphs (c) and (d) of this subdivision and\nsubdivision seven of this section:_\n\n_(i) a deployer that deploys a high-risk artificial intelligence decision\nsystem on or after January first, two thousand twenty-seven, or a third party\ncontracted by the deployer, shall complete an impact assessment of the high-\nrisk artificial intelligence decision system; and_\n\n_(ii) beginning on January first, two thousand twenty-seven, a deployer, or a\nthird party contracted by the deployer, shall complete an impact assessment of\na deployed high-risk artificial intelligence decision system:_\n\n_(A) at least annually; and_\n\n_(B) no later than ninety days after an intentional and substantial\nmodification to such high-risk artificial intelligence decision system is made\navailable._\n\n_(b) (i) Each impact assessment completed pursuant to this subdivision shall\ninclude, at a minimum and to the extent reasonably known by, or available to,\nthe deployer:_\n\n_(A) a statement by the deployer disclosing the purpose, intended use cases\nand deployment context of, and benefits afforded by, the high-risk artificial\nintelligence decision system;_\n\n_(B) an analysis of whether the deployment of the high-risk artificial\nintelligence decision system poses any known or reasonably foreseeable risks\nof algorithmic discrimination and, if so, the nature of such algorithmic\ndiscrimination and the steps that have been taken to mitigate such risks;_\n\n_(C) A description of:_\n\n_(I) the categories of data the high-risk artificial intelligence decision\nsystem processes as inputs; and_\n\n_(II) the outputs such high-risk artificial intelligence decision system\nproduces;_\n\n_(D) if the deployer used data to customize the high-risk artificial\nintelligence decision system, an overview of the categories of data the\ndeployer used to customize such high-risk artificial intelligence decision\nsystem;_\n\n_(E) any metrics used to evaluate the performance and known limitations of the\nhigh-risk artificial intelligence decision system;_\n\n_(F) a description of any transparency measures taken concerning the high-risk\nartificial intelligence decision system, including, but not limited to, any\nmeasures taken to disclose to a consumer that such highrisk artificial\nintelligence decision system is in use when such highrisk artificial\nintelligence decision system is in use; and_\n\n_(G) a description of the post-deployment monitoring and user safeguards\nprovided concerning such high-risk artificial intelligence decision system,\nincluding, but not limited to, the oversight, use, and learning process\nestablished by the deployer to address issues arising from deployment of such\nhigh-risk artificial intelligence decision system._\n\n_(ii) In addition to the statement, analysis, descriptions, overview, and\nmetrics required pursuant to subparagraph (i) of this paragraph, an impact\nassessment completed pursuant to this subdivision following an intentional and\nsubstantial modification made to a high-risk artificial intelligence decision\nsystem on or after January first, two thousand twenty-seven, shall include a\nstatement disclosing the extent to which the high-risk artificial intelligence\ndecision system was used in a manner that was consistent with, or varied from,\nthe developer 's intended uses of such high-risk artificial intelligence\ndecision system._\n\n_(c) A single impact assessment may address a comparable set of highrisk\nartificial intelligence decision systems deployed by a deployer._\n\n_(d) If a deployer, or a third party contracted by the deployer, completes an\nimpact assessment for the purpose of complying with another applicable law or\nregulation, such impact assessment shall be deemed to satisfy the requirements\nestablished in this subdivision if such impact assessment is reasonably\nsimilar in scope and effect to the impact assessment that would otherwise be\ncompleted pursuant to this subdivision._\n\n_(e) A deployer shall maintain the most recently completed impact assessment\nof a high-risk artificial intelligence decision system as required pursuant to\nthis subdivision, all records concerning each such impact assessment and all\nprior impact assessments, if any, for a period of at least three years\nfollowing the final deployment of the high-risk artificial intelligence\ndecision system._\n\n_4\\. Except as provided in subdivision seven of this section, a deployer, or a\nthird party contracted by the deployer, shall review, no later than January\nfirst, two thousand twenty-seven, and at least annually thereafter, the\ndeployment of each high-risk artificial intelligence decision system deployed\nby the deployer to ensure that such high-risk artificial intelligence decision\nsystem is not causing algorithmic discrimination._\n\n_5\\. (a) Beginning on January first, two thousand twenty-seven, and before a\ndeployer deploys a high-risk artificial intelligence decision system to make,\nor be a substantial factor in making, a consequential decision concerning a\nconsumer, the deployer shall:_\n\n_(i) notify the consumer that the deployer has deployed a high-risk artificial\nintelligence decision system to make, or be a substantial factor in making,\nsuch consequential decision; and_\n\n_(ii) provide to the consumer:_\n\n_(A) a statement disclosing:_\n\n_(I) the purpose of such high-risk artificial intelligence decision system;\nand_\n\n_(II) the nature of such consequential decision;_\n\n_(B) contact information for such deployer;_\n\n_(C) a description, in plain language, of such high-risk artificial\nintelligence decision system; and_\n\n_(D) instructions on how to access the statement made available pursuant to\nparagraph (a) of subdivision six of this section._\n\n_(b) Beginning on January first, two thousand twenty-seven, a deployer that\nhas deployed a high-risk artificial intelligence decision system to make, or\nas a substantial factor in making, a consequential decision concerning a\nconsumer shall, if such consequential decision is adverse to the consumer,\nprovide to such consumer:_\n\n_(i) a statement disclosing the principal reason or reasons for such adverse\nconsequential decision, including, but not limited to:_\n\n_(A) the degree to which, and manner in which, the high-risk artificial\nintelligence decision system contributed to such adverse consequential\ndecision;_\n\n_(B) the type of data that was processed by such high-risk artificial\nintelligence decision system in making such adverse consequential decision;\nand_\n\n_(C) the source of such data; and_\n\n_(ii) an opportunity to:_\n\n_(A) correct any incorrect personal data that the high-risk artificial\nintelligence decision system processed in making, or as a substantial factor\nin making, such adverse consequential decision; and_\n\n_(B) appeal such adverse consequential decision, which shall, if technically\nfeasible, allow for human review unless providing such opportunity is not in\nthe best interest of such consumer, including, but not limited to, in\ninstances in which any delay might pose a risk to the life or safety of such\nconsumer._\n\n_(c) The deployer shall provide the notice, statements, information,\ndescription, and instructions required pursuant to paragraphs (a) and (b) of\nthis subdivision:_\n\n_(i) directly to the consumer;_\n\n_(ii) in plain language;_\n\n_(iii) in all languages in which such deployer, in the ordinary course of such\ndeployer 's business, provides contracts, disclaimers, sale announcements, and\nother information to consumers; and_\n\n_(iv) in a format that is accessible to consumers with disabilities._\n\n_6\\. (a) Beginning on January first, two thousand twenty-seven, and except as\nprovided in subdivision seven of this section, each deployer shall make\navailable, in a manner that is clear and readily available on such deployer 's\nwebsite, a statement summarizing:_\n\n_(i) the types of high-risk artificial intelligence decision systems that are\ncurrently deployed by such deployer;_\n\n_(ii) how such deployer manages any known or reasonably foreseeable risks of\nalgorithmic discrimination that may arise from deployment of each high-risk\nartificial intelligence decision system described in subparagraph (i) of this\nparagraph; and_\n\n_(iii) in detail, the nature, source and extent of the information collected\nand used by such deployer._\n\n_(b) Each deployer shall periodically update the statement required pursuant\nto paragraph (a) of this subdivision._\n\n_7\\. The provisions of subdivisions two, three, four, and six of this section\nshall not apply to a deployer if, at the time the deployer deploys a high-risk\nartificial intelligence decision system, and at all times while the high-risk\nartificial intelligence decision system is deployed:_\n\n_(a) the deployer:_\n\n_(i) has entered into a contract with the developer in which the developer has\nagreed to assume the deployer 's duties pursuant to subdivisions two, three,\nfour, or six of this section; and_\n\n_(ii) does not exclusively use such deployer 's own data to train such high-\nrisk artificial intelligence decision system;_\n\n_(b) such high-risk artificial intelligence decision system:_\n\n_(i) is used for the intended uses that are disclosed to such deployer\npursuant to subparagraph (iv) of paragraph (b) of subdivision two of section\none thousand five hundred fifty-one of this article; and_\n\n_(ii) continues learning based on a broad range of data sources and not solely\nbased on the deployer 's own data; and_\n\n_(c) such deployer makes available to consumers any impact assessment that:_\n\n_(i) the developer of such high-risk artificial intelligence decision system\nhas completed and provided to such deployer; and_\n\n_(ii) includes information that is substantially similar to the information\nincluded in the statement, analysis, descriptions, overview, and metrics\nrequired pursuant to subparagraph (i) of paragraph (b) of subdivision three of\nthis section._\n\n_8\\. Nothing in this subdivision or subdivisions two, three, four, five, or\nsix of this section shall be construed to require a deployer to disclose any\ninformation that is a trade secret or otherwise protected from disclosure\npursuant to state or federal law. If a deployer withholds any information from\na consumer pursuant this subdivision, the deployer shall send notice to such\nconsumer disclosing:_\n\n_(a) that the deployer is withholding such information from such consumer;\nand_\n\n_(b) the basis for the deployer 's decision to withhold such information from\nsuch consumer._\n\n_9\\. Beginning on January first, two thousand twenty-seven, the attorney\ngeneral may require that a deployer, or a third party contracted by the\ndeployer pursuant to subdivision three of this section, as applicable,\ndisclose to the attorney general, as part of an investigation conducted by the\nattorney general, no later than ninety days after a request by the attorney\ngeneral, and in a form and manner prescribed by the attorney general, the risk\nmanagement policy implemented pursuant to subdivision two of this section, the\nimpact assessment completed pursuant to subdivision three of this section; or\nrecords maintained pursuant to paragraph (e) of subdivision three of this\nsection. The attorney general may evaluate such risk management policy, impact\nassessment or records to ensure compliance with the provisions of this\nsection. In disclosing such risk management policy, impact assessment or\nrecords to the attorney general pursuant to this subdivision, the deployer or\nthird-party contractor, as applicable, may designate such risk management\npolicy, impact assessment or records as including any information that is\nexempt from disclosure pursuant to subdivision eight of this section or\narticle six of the public officers law. To the extent such risk management\npolicy, impact assessment, or records include such information, such risk\nmanagement policy, impact assessment, or records shall be exempt from\ndisclosure. To the extent any information contained in such risk management\npolicy, impact assessment, or record is subject to the attorneyclient\nprivilege or work product protection, such disclosure shall not constitute a\nwaiver of such privilege or protection._\n\n_Section 1553. Technical documentation. 1. Beginning on January first, two\nthousand twenty-seven, each developer of a general-purpose artificial\nintelligence model shall, except as provided in subdivision two of this\nsection:_\n\n_(a) create and maintain technical documentation for the general-purpose\nartificial intelligence model, which shall:_\n\n_(i) include:_\n\n_(A) the training and testing processes for such general-purpose artificial\nintelligence model; and_\n\n_(B) the results of an evaluation of such general-purpose artificial\nintelligence model performed to determine whether such general-purpose\nartificial intelligence model is in compliance with the provisions of this\narticle;_\n\n_(ii) include, as appropriate, considering the size and risk profile of such\ngeneral-purpose artificial intelligence model, at least:_\n\n_(A) the tasks such general-purpose artificial intelligence model is intended\nto perform;_\n\n_(B) the type and nature of artificial intelligence decision systems in which\nsuch general-purpose artificial intelligence model is intended to be\nintegrated;_\n\n_(C) acceptable use policies for such general-purpose artificial intelligence\nmodel;_\n\n_(D) the date such general-purpose artificial intelligence model is released;_\n\n_(E) the methods by which such general-purpose artificial intelligence model\nis distributed; and_\n\n_(F) the modality and format of inputs and outputs for such generalpurpose\nartificial intelligence model; and_\n\n_(iii) be reviewed and revised at least annually, or more frequently, as\nnecessary to maintain the accuracy of such technical documentation; and_\n\n_(b) create, implement, maintain and make available to persons that intend to\nintegrate such general-purpose artificial intelligence model into such persons\n' artificial intelligence decision systems documentation and information\nthat:_\n\n_(i) enables such persons to:_\n\n_(A) understand the capabilities and limitations of such general-purpose\nartificial intelligence model; and_\n\n_(B) comply with such persons ' obligations pursuant to this article;_\n\n_(ii) discloses, at a minimum:_\n\n_(A) the technical means required for such general-purpose artificial\nintelligence model to be integrated into such persons ' artificial\nintelligence decision systems;_\n\n_(B) the information listed in subparagraph (ii) of paragraph (a) of this\nsubdivision; and_\n\n_(iii) except as provided in subdivision two of this section, is reviewed and\nrevised at least annually, or more frequently, as necessary to maintain the\naccuracy of such documentation and information._\n\n_2\\. (a) The provisions of paragraph (a) and subparagraph (iii) of paragraph\n(b) of subdivision one of this section shall not apply to a developer that\ndevelops, or intentionally and substantially modifies, a general-purpose\nartificial intelligence model on or after January first, two thousand twenty-\nseven, if:_\n\n_(i) (A) the developer releases such general-purpose artificial intelligence\nmodel under a free and open-source license that allows for:_\n\n_(I) access to, and modification, distribution, and usage of, such general-\npurpose artificial intelligence model; and_\n\n_(II) the parameters of such general-purpose artificial intelligence model to\nbe made publicly available pursuant to clause (B) of this subparagraph; and_\n\n_(B) unless such general-purpose artificial intelligence model is deployed as\na high-risk artificial intelligence decision system, the parameters of such\ngeneral-purpose artificial intelligence model, including, but not limited to,\nthe weights and information concerning the model architecture and model usage\nfor such general-purpose artificial intelligence model, are made publicly\navailable; or_\n\n_(ii) the general-purpose artificial intelligence model is:_\n\n_(A) not offered for sale in the market;_\n\n_(B) not intended to interact with consumers; and_\n\n_(C) solely utilized:_\n\n_(I) for an entity 's internal purposes; or_\n\n_(II) pursuant to an agreement between multiple entities for such entities '\ninternal purposes._\n\n_(b) The provisions of this section shall not apply to a developer that\ndevelops, or intentionally and substantially modifies, a general-purpose\nartificial intelligence model on or after January first, two thousand twenty-\nseven, if such general purpose artificial intelligence model performs tasks\nexclusively related to an entity 's internal management affairs, including,\nbut not limited to, ordering office supplies or processing payments._\n\n_(c) A developer that takes any action under an exemption pursuant to\nparagraph (a) or (b) of this subdivision shall bear the burden of\ndemonstrating that such action qualifies for such exemption._\n\n_(d) A developer that is exempt pursuant to subparagraph (ii) of paragraph (a)\nof this subdivision shall establish and maintain an artificial intelligence\nrisk management framework, which shall:_\n\n_(i) be the product of an iterative process and ongoing efforts; and_\n\n_(ii) include, at a minimum:_\n\n_(A) an internal governance function;_\n\n_(B) a map function that shall establish the context to frame risks;_\n\n_(C) a risk management function; and_\n\n_(D) a function to measure identified risks by assessing, analyzing and\ntracking such risks._\n\n_3\\. Nothing in subdivision one of this section shall be construed to require\na developer to disclose any information that is a trade secret or otherwise\nprotected from disclosure pursuant to state or federal law._\n\n_4\\. Beginning on January first, two thousand twenty-seven, the attorney\ngeneral may require that a developer disclose to the attorney general, as part\nof an investigation conducted by the attorney general, no later than ninety\ndays after a request by the attorney general and in a form and manner\nprescribed by the attorney general, any documentation maintained pursuant to\nthis section. The attorney general may evaluate such documentation to ensure\ncompliance with the provisions of this section. In disclosing any\ndocumentation to the attorney general pursuant to this subdivision, the\ndeveloper may designate such documentation as including any information that\nis exempt from disclosure pursuant to subdivision three of this section or\narticle six of the public officers law. To the extent such documentation\nincludes such information, such documentation shall be exempt from disclosure.\nTo the extent any information contained in such documentation is subject to\nthe attorney-client privilege or work product protection, such disclosure\nshall not constitute a waiver of such privilege or protection._\n\n_Section 1554. Required disclosure. 1. Beginning on January first, two\nthousand twenty-seven, and except as provided in subdivision two of this\nsection, each person doing business in this state, including, but not limited\nto, each deployer that deploys, offers, sells, leases, licenses, gives, or\notherwise makes available, as applicable, any artificial intelligence decision\nsystem that is intended to interact with consumers shall ensure that it is\ndisclosed to each consumer who interacts with such artificial intelligence\ndecision system that such consumer is interacting with an artificial\nintelligence decision system._\n\n_2\\. No disclosure shall be required pursuant to subdivision one of this\nsection under circumstances in which a reasonable person would deem it obvious\nthat such person is interacting with an artificial intelligence decision\nsystem._\n\n_Section 1555. Preemption. 1. Nothing in this article shall be construed to\nrestrict a developer 's, deployer's, or other person's ability to:_\n\n_(a) comply with federal, state or municipal law;_\n\n_(b) comply with a civil, criminal or regulatory inquiry, investigation,\nsubpoena, or summons by a federal, state, municipal, or other governmental\nauthority;_\n\n_(c) cooperate with a law enforcement agency concerning conduct or activity\nthat the developer, deployer, or other person reasonably and in good faith\nbelieves may violate federal, state, or municipal law;_\n\n_(d) investigate, establish, exercise, prepare for, or defend a legal claim;_\n\n_(e) take immediate steps to protect an interest that is essential for the\nlife or physical safety of a consumer or another individual;_\n\n_(f) (i) by any means other than facial recognition technology, prevent,\ndetect, protect against, or respond to:_\n\n_(A) a security incident;_\n\n_(B) a malicious or deceptive activity; or_\n\n_(C) identity theft, fraud, harassment or any other illegal activity;_\n\n_(ii) investigate, report, or prosecute the persons responsible for any action\ndescribed in subparagraph (i) of this paragraph; or_\n\n_(iii) preserve the integrity or security of systems;_\n\n_(g) engage in public or peer-reviewed scientific or statistical research in\nthe public interest that:_\n\n_(i) adheres to all other applicable ethics and privacy laws; and_\n\n_(ii) is conducted in accordance with:_\n\n_(A) part forty-six of title forty-five of the code of federal regulations, as\namended; or_\n\n_(B) relevant requirements established by the federal food and drug\nadministration;_\n\n_(h) conduct research, testing, and development activities regarding an\nartificial intelligence decision system or model, other than testing conducted\npursuant to real world conditions, before such artificial intelligence\ndecision system or model is placed on the market, deployed, or put into\nservice, as applicable;_\n\n_(i) effectuate a product recall;_\n\n_(j) identify and repair technical errors that impair existing or intended\nfunctionality; or_\n\n_(k) assist another developer, deployer, or person with any of the obligations\nimposed pursuant to this article._\n\n_2\\. The obligations imposed on developers, deployers, or other persons\npursuant to this article shall not apply where compliance by the developer,\ndeployer, or other person with the provisions of this article would violate an\nevidentiary privilege pursuant to state law._\n\n_3\\. Nothing in this article shall be construed to impose any obligation on a\ndeveloper, deployer, or other person that adversely affects the rights or\nfreedoms of any person, including, but not limited to, the rights of any\nperson:_\n\n_(a) to freedom of speech or freedom of the press guaranteed in:_\n\n_(i) the first amendment to the United States constitution; and_\n\n_(ii) section eight of the New York state constitution; or_\n\n_(b) pursuant to section seventy-nine-h of the civil rights law._\n\n_4\\. Nothing in this article shall be construed to apply to any developer,\ndeployer, or other person:_\n\n_(a) insofar as such developer, deployer or other person develops, deploys,\nputs into service, or intentionally and substantially modifies, as applicable,\na high-risk artificial intelligence decision system:_\n\n_(i) that has been approved, authorized, certified, cleared, developed, or\ngranted by:_\n\n_(A) a federal agency, including, but not limited to, the federal food and\ndrug administration or the federal aviation administration, acting within the\nscope of such federal agency 's authority; or_\n\n_(B) a regulated entity subject to supervision and regulation by the federal\nhousing finance agency; or_\n\n_(ii) in compliance with standards that are:_\n\n_(A) established by:_\n\n_(I) any federal agency, including, but not limited to, the federal office of\nthe national coordinator for health information technology; or_\n\n_(II) a regulated entity subject to supervision and regulation by the federal\nhousing finance agency; and_\n\n_(B) substantially equivalent to, and at least as stringent as, the standards\nestablished pursuant to this article;_\n\n_(b) conducting research to support an application:_\n\n_(i) for approval or certification from any federal agency, including, but not\nlimited to, the federal food and drug administration, the federal aviation\nadministration, or the federal communications commission; or_\n\n_(ii) that is otherwise subject to review by any federal agency;_\n\n_(c) performing work pursuant to, or in connection with, a contract with the\nfederal department of commerce, the federal department of defense, or the\nnational aeronautics and space administration, unless such developer,\ndeployer, or other person is performing such work on a high-risk artificial\nintelligence decision system that is used to make, or as a substantial factor\nin making, a decision concerning employment or housing; or_\n\n_(d) that is a covered entity, as defined by the health insurance portability\nand accountability act of 1996 and the regulations promulgated thereunder, as\namended, and providing health care recommendations that:_\n\n_(i) are generated by an artificial intelligence decision system;_\n\n_(ii) require a health care provider to take action to implement such\nrecommendations; and_\n\n_(iii) are not considered to be high risk._\n\n_5\\. Nothing in this article shall be construed to apply to any artificial\nintelligence decision system that is acquired by or for the federal government\nor any federal agency or department, including, but not limited to, the\nfederal department of commerce, the federal department of defense, or the\nnational aeronautics and space administration, unless such artificial\nintelligence decision system is a high-risk artificial intelligence decision\nsystem that is used to make, or as a substantial factor in making, a decision\nconcerning employment or housing._\n\n_6\\. Any insurer, as defined by section five hundred one of the insurance law,\nor fraternal benefit society, as defined by section four thousand five hundred\none of the insurance law, shall be deemed to be in full compliance with the\nprovisions of this article if such insurer or fraternal benefit society has\nimplemented and maintains a written artificial intelligence decision systems\nprogram in accordance with all requirements established by the superintendent\nof financial services._\n\n_7\\. (a) Any bank, out-of-state bank, New York credit union, federal credit\nunion, or out-of-state credit union, or any affiliate or subsidiary thereof,\nshall be deemed to be in full compliance with the provisions of this article\nif such bank, out-of-state bank, New York credit union, federal credit union,\nout-of-state credit union, affiliate, or subsidiary is subject to examination\nby any state or federal prudential regulator pursuant to any published\nguidance or regulations that apply to the use of high-risk artificial\nintelligence decision systems, and such guidance or regulations:_\n\n_(i) impose requirements that are substantially equivalent to, and at least as\nstringent as, the requirements of this article; and_\n\n_(ii) at a minimum, require such bank, out-of-state bank, New York credit\nunion, federal credit union, out-of-state credit union, affiliate, or\nsubsidiary to:_\n\n_(A) regularly audit such bank 's, out-of-state bank's, New York credit\nunion's, federal credit union's, out-of-state credit union's, affiliate's, or\nsubsidiary's use of high-risk artificial intelligence decision systems for\ncompliance with state and federal anti-discrimination laws and regulations\napplicable to such bank, out-of-state bank, New York credit union, federal\ncredit union, out-of-state credit union, affiliate, or subsidiary; and_\n\n_(B) mitigate any algorithmic discrimination caused by the use of a high-risk\nartificial intelligence decision system, or any risk of algorithmic\ndiscrimination that is reasonably foreseeable as a result of the use of a\nhigh-risk artificial intelligence decision system._\n\n_(b) For the purposes of this subdivision, the following terms shall have the\nfollowing meanings:_\n\n_(i) \"Affiliate\" shall have the same meaning as set forth in section nine\nhundred twelve of the business corporation law._\n\n_(ii) \"Bank\" shall have the same meaning as set forth in section two of the\nbanking law._\n\n_(iii) \"Credit union\" shall have the same meaning as set forth in section two\nof the banking law._\n\n_(iv) \"Out-of-state bank\" shall have the same meaning as set forth in section\ntwo hundred twenty-two of the banking law._\n\n_(v) \"Subsidiary\" shall have the same meaning as set forth in section one\nhundred forty-one of the banking law._\n\n_8\\. If a developer, deployer, or other person engages in any action under an\nexemption pursuant to subdivisions one, two, three, four, five, six, or seven\nof this section, the developer, deployer, or other person bears the burden of\ndemonstrating that such action qualifies for such exemption._\n\n_Section 1556. Enforcement. 1. The attorney general shall have exclusive\nauthority to enforce the provisions of this article._\n\n_2\\. Except as provided in subdivision six of this section, during the period\nbeginning on January first, two thousand twenty-seven, and ending on January\nfirst, two thousand twenty-eight, the attorney general shall, prior to\ninitiating any action for a violation of this section, issue a notice of\nviolation to the developer, deployer, or other person if the attorney general\ndetermines that it is possible to cure such violation. If the developer,\ndeployer, or other person fails to cure such violation within sixty days after\nreceipt of such notice of violation, the attorney general may bring an action\npursuant to this section._\n\n_3\\. Except as provided in subdivision six of this section, beginning on\nJanuary first, two thousand twenty-eight, the attorney general may, in\ndetermining whether to grant a developer, deployer, or other person the\nopportunity to cure a violation described in subdivision two of this section,\nconsider:_\n\n_(a) the number of violations;_\n\n_(b) the size and complexity of the developer, deployer, or other person;_\n\n_(c) the nature and extent of the developer 's, deployer's, or other person's\nbusiness;_\n\n_(d) the substantial likelihood of injury to the public;_\n\n_(e) the safety of persons or property; and_\n\n_(f) whether such violation was likely caused by human or technical error._\n\n_4\\. Nothing in this article shall be construed as providing the basis for a\nprivate right of action for violations of the provisions of this article._\n\n_5\\. Except as provided in subdivisions one, two, three, four, and six of this\nsection, a violation of the requirements established in this article shall\nconstitute an unfair trade practice for purposes of section three hundred\nforty-nine of this chapter and shall be enforced solely by the attorney\ngeneral; provided, however, that subdivision (h) of section three hundred\nforty-nine of this chapter shall not apply to any such violation._\n\n_6\\. (a) In any action commenced by the attorney general for any violation of\nthis article, it shall be an affirmative defense that the developer, deployer,\nor other person:_\n\n_(i) discovers a violation of any provision of this article through red-\nteaming;_\n\n_(ii) no later than sixty days after discovering such violation through red-\nteaming:_\n\n_(A) cures such violation; and_\n\n_(B) provides to the attorney general, in a form and manner prescribed by the\nattorney general, notice that such violation has been cured and evidence that\nany harm caused by such violation has been mitigated; and_\n\n_(iii) is otherwise in compliance with the latest version of:_\n\n_(A) the Artificial Intelligence Risk Management Framework published by the\nnational institute of standards and technology;_\n\n_(B) ISO/IEC 42001 of the international organization for standardization and\nthe international electrotechnical commission;_\n\n_(C) a nationally or internationally recognized risk management framework for\nartificial intelligence decision systems, other than the risk management\nframeworks described in clauses (A) and (B) of this subparagraph, that imposes\nrequirements that are substantially equivalent to, and at least as stringent\nas, the requirements established pursuant to this article; or_\n\n_(D) any risk management framework for artificial intelligence decision\nsystems that is substantially equivalent to, and at least as stringent as, the\nrisk management frameworks described in clauses (A), (B), and (C) of this\nsubparagraph._\n\n_(b) The developer, deployer, or other person bears the burden of\ndemonstrating to the attorney general that the requirements established\npursuant to paragraph (a) of this subdivision have been satisfied._\n\n_(c) Nothing in this article, including, but not limited to, the enforcement\nauthority granted to the attorney general pursuant to this section, shall be\nconstrued to preempt or otherwise affect any right, claim, remedy,\npresumption, or defense available at law or in equity. Any rebuttable\npresumption or affirmative defense established pursuant to this article shall\napply only to an enforcement action brought by the attorney general pursuant\nto this section and shall not apply to any right, claim, remedy, presumption,\nor defense available at law or in equity._\n\nSection 3. This act shall take effect on the two hundred seventieth day after\nit shall have become a law.\n\nCopyright (C) 2025 State Net  \n  \n---\n\n",
      "latest_version": true
    }
  ]
}