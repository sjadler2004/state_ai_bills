{
  "bill_id": "RI2025000S627",
  "source_url": "http://custom.statenet.com/public/resources.cgi?id=ID:bill:RI2025000S627&cuiq=93d84396-c63b-526a-b152-38b7f79b4cfd&client_md=e4f6fea4-27b4-5d41-b7d3-766fe52569f0",
  "versions": [
    {
      "date": "03/07/2025",
      "label": "Introduced",
      "url": "https://custom.statenet.com/public/resources.cgi?mode=show_text&id=ID:bill:RI2025000S627&verid=RI2025000S627_20250307_0_I&",
      "raw_html": "<html>\n<head>\n<title>Bill Resource</title>\n\n<!--   <link href=\"https://custom.statenet.com/network/Common/css/extregtext.css\" rel=\"stylesheet\" type=\"text/css\" />-->\n   <link href=\"https://custom.statenet.com/network/Common/css/xmltext-2.0.css\" rel=\"stylesheet\" type=\"text/css\" />\n   <link href=\"https://custom.statenet.com/network/Common/css/additional-text.css\" rel=\"stylesheet\" type=\"text/css\" />\n\n\t<style type=\"text/css\">\n<!--\n\ntd, body {\n     background-color: white;\n\tfont-family: Verdana, Arial, Helvetica, sans-serif;\n\tfont-size: 12px;\n}\n\n.resourceContainer {\n   border: 1px solid black;\n}\n-->\n</style>\n</head>\n<body>\n\n    <div style=\"width: 750px; margin: auto\">\n       <div style=\"font-size: .8em;margin-bottom: 10px\"><table width=\"100%\"><tr><td align=\"left\" style=\"font-size: .8em;\"><div>The following has special meaning:</div>\n<div><u class=\"amendmentInsertedText\">green underline denotes added text</u></div>\n<div><strike class=\"amendmentDeletedText\">red struck out text denotes deleted text</strike></div></td> <td align=\"right\"><a href=\"https://www.lexisnexis.com/statenet/\"><img alt=\"Powered by State Net\" src=\"https://custom.statenet.com/network/poweredby.gif\" /></a></td></tr></table></div><table id=\"text-identifier\"><tr><td class=\"key\">2025 RI S 627</td> <td><table><tr><td class=\"label\">Author:</td> <td>DiPalma</td></tr> <tr><td class=\"label\">Version:</td> <td>Introduced</td></tr> <tr><td class=\"label\">Version Date:</td> <td>03/07/2025</td></tr></table></td></tr></table><div class=\"documentBody\">\n  <a name=\"head_document_section\"></a><div class=\"head\">\n   <p class=\"center\">\n    <b>2025 - - S 0627</b>\n   </p>\n   <p class=\"center\">\n    <b>STATE OF RHODE ISLAND</b>\n   </p>\n   <p class=\"center\">\n    <b>IN GENERAL ASSEMBLY</b>\n   </p>\n   <p class=\"center\">\n    <b>JANUARY SESSION, A.D. 2025</b>\n   </p>\n   <p class=\"center\">\n    <b>____________</b>\n   </p>\n  </div>\n  <a name=\"title_document_section\"></a><div class=\"title\">\n   <p class=\"center\">\n    <b>AN ACT</b>\n   </p>\n   <p class=\"center\">\n    <b>RELATING TO COMMERCIAL LAW - - GENERAL REGULATORY PROVISIONS - - ARTIFICIAL INTELLIGENCE ACT</b>\n   </p>\n  </div>\n  <a name=\"history_document_section\"></a><div class=\"history\">\n   <p class=\"indent\">\n    <b>\n     <u>Introduced By:</u>\n    </b> Senators DiPalma, Gu, Burke, Paolino, Urso, Zurier, and Pearson</p>\n   <p class=\"indent\">\n    <b>\n     <u>Date Introduced:</u>\n    </b> March 07, 2025</p>\n   <p class=\"indent\">\n    <b>\n     <u>Referred To:</u>\n    </b> Senate Artificial Intelligence &amp; Emerging Tech</p>\n  </div>\n  <a name=\"text_document_section\"></a><div class=\"text\">\n   <span>\n    <p class=\"indent\">It is enacted by the General Assembly as follows:</p>\n   </span>\n   <p class=\"indent\">SECTION 1. Title 6 of the General Laws entitled &quot;COMMERCIAL LAW -- GENERAL REGULATORY PROVISIONS&quot; is hereby amended by adding thereto the following chapter:</p>\n   <p class=\"center\">\n    <u class=\"amendmentInsertedText\">\n     <b>CHAPTER 61</b>\n    </u>\n   </p>\n   <p class=\"center\">\n    <u class=\"amendmentInsertedText\">\n     <b>ARTIFICIAL INTELLIGENCE ACT</b>\n    </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">\n     <b>\n      <u>6-61-1. Short title. </u>\n     </b>\n    </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">This act shall be known and may be cited as the &quot;Artificial Intelligence Act&quot;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">\n     <b>\n      <u>6-61-2. Definitions. </u>\n     </b>\n    </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">As used in this chapter:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(1) &quot;Algorithmic discrimination&quot; means: </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) Any use of an artificial intelligence system that results in any unlawful differential treatment or impact that disfavors any individual or group of individuals on the basis of one or more classifications protected under the laws of this state or federal law; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Does not include:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) The offer, license or use of a high-risk artificial intelligence system by a developer, integrator or deployer for the sole purpose of:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(I) The developer&#39;s, integrator&#39;s or deployer&#39;s self-testing to identify, mitigate or prevent discrimination or otherwise ensure compliance with state and federal law; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(II) Expanding an applicant, customer or participant pool to increase diversity or redress historic discrimination; or </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) An act or omission by or on behalf of a private club or other establishment not in fact open to the public, as set forth in Title II of the Civil Rights Act of 1964, 42 USC &sect; 2000a(e), as amended from time to time.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(2) &quot;Artificial intelligence system&quot; means any machine-based system that, for any explicit or implicit objective, infers from the inputs such system receives how to generate outputs including, but not limited to, content, decisions, predictions or recommendations, that can influence physical or virtual environments.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(3) &quot;Consequential decision&quot; means any decision or judgment that has a legal, material or similarly significant effect on a consumer with respect to: </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) Employment, including any such decision or judgment made:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) Concerning hiring, termination, compensation or promotion; or </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) By way of any automated task allocation that limits, segregates or classifies employees for the purpose of assigning or determining material terms or conditions of employment; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Education or vocational training, including any such decision or judgment made concerning: </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) Assessments; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) Student cheating or plagiarism detection; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(C) Accreditation; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(D) Certification; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(E) Admissions; or </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(F) Financial aid or scholarships; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) The provision or denial, or terms and conditions, of: </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) Financial lending or credit services; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) Housing or lodging including, but not limited to, rentals or short-term housing or lodging; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(C) Insurance; or </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(D) Legal services; or </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iv) The provision or denial of: </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) Essential government services; or </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) Healthcare services.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(4) &quot;Consumer&quot; means any individual who is a resident of this state.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(5) &quot;Deploy&quot; means to use a high-risk artificial intelligence system to make, or as a substantial factor in making, a consequential decision.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(6) &quot;Deployer&quot; means any person doing business in this state that deploys a high-risk artificial intelligence system in this state.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(7) &quot;Developer&quot; means any person doing business in this state that develops, or intentionally and substantially modifies, an artificial intelligence system.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(8) &quot;General-purpose artificial intelligence model&quot; means:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) Any form of artificial intelligence system that: </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) Displays significant generality; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) Is capable of competently performing a wide range of distinct tasks; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(C) Can be integrated into a variety of downstream applications or systems; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Does not include any artificial intelligence model that is used for development, prototyping and research activities before such artificial intelligence model is released on the market.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(9) &quot;High-risk artificial intelligence system&quot; means: </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) Any artificial intelligence system that, when deployed, makes, or is a substantial factor in making, a consequential decision; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Does not include: </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) Any artificial intelligence system that is intended to: </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(I) Perform any narrow procedural task; or </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(II) Detect decision-making patterns, or deviations from decision-making patterns, unless such artificial intelligence system is intended to replace or influence any assessment previously completed by an individual without sufficient human review; or </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) Unless the technology, when deployed, makes, or is a substantial factor in making, a consequential decision: </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(I) Any anti-fraud technology that does not make use of facial recognition technology; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(II) Any artificial intelligence-enabled video game technology; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(III) Any anti-malware, anti-virus, calculator, cybersecurity, database, data storage, firewall, Internet domain registration, Internet-website loading, networking, robocall-filtering, spam-filtering, spellchecking, spreadsheet, web-caching, web-hosting or similar technology; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(IV) Any technology that performs tasks exclusively related to an entity&#39;s internal management affairs including, but not limited to, ordering office supplies or processing payments; or </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(V) Any technology that communicates with consumers in natural language for the purpose of providing users with information, making referrals or recommendations and answering questions, and is subject to an accepted use policy that prohibits generating content that is discriminatory or harmful;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(10) &quot;Integrator&quot; means any person doing business in this state that, with respect to a given high-risk artificial intelligence system: </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) Neither develops nor intentionally and substantially modifies the high-risk artificial intelligence system; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Integrates the high-risk artificial intelligence system into a product or service such person offers to any other person.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(11) &quot;Intentional and substantial modification&quot; means: </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) Any deliberate change made to: </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) An artificial intelligence system that materially increases the risk of algorithmic discrimination; or </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) A general-purpose artificial intelligence model that: </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(I) Affects compliance of the general-purpose artificial intelligence model; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(II) Materially changes the purpose of the general-purpose artificial intelligence model; or </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(III) Materially increases the risk of algorithmic discrimination; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Does not include any change made to a high-risk artificial intelligence system, or the performance of a high-risk artificial intelligence system, if: </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) The high-risk artificial intelligence system continues to learn after such high-risk artificial intelligence system is: </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(I) Offered, sold, leased, licensed, given or otherwise made available to a deployer; or </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(II) Is deployed; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) Such change: </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(I) Is made to such high-risk artificial intelligence system as a result of any learning described in subsection (11)(ii)(A) of this section; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(II) Was predetermined by the deployer, or the third party contracted by the deployer, when such deployer or third party completed the initial impact assessment of such high-risk artificial intelligence system pursuant to &sect; 6-61-4(c); and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(III) Is included in the technical documentation for such high-risk artificial intelligence system.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(12) &quot;Person&quot; means any individual, association, corporation, limited liability company, partnership, trust or other legal entity.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(13) &quot;Red-teaming&quot; means an exercise that is conducted to identify the potential adverse behaviors or outcomes of an artificial intelligence system, how such behaviors or outcomes occur and stress test the safeguards against such behaviors or outcomes.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(14) &quot;Substantial factor&quot; means: </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) A factor that alters the outcome of a consequential decision and is generated by an artificial intelligence system; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Includes, but is not limited to, any use of an artificial intelligence system to generate any content, decision, prediction or recommendation concerning a consumer that is used as a basis to make a consequential decision concerning the consumer. Substantial factor does not include any output produced by an artificial intelligence system where an individual was involved in the data processing that produced such output and such individual meaningfully considered such data as part of such data processing and had the authority to change or influence the output produced by such data processing.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(15) &quot;Synthetic digital content&quot; means any digital content including, but not limited to, any audio, image, text or video, that is produced or manipulated by an artificial intelligence system including, but not limited to, a general-purpose artificial intelligence model.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(16) &quot;Trade secret&quot; means information, including a formula, pattern, compilation, program, device, method, technique, or process, that:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) Derives independent economic value, actual or potential, from not being generally known to, and not being readily ascertainable by proper means by, other persons who can obtain economic value from its disclosure or use; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Is the subject of efforts that are reasonable under the circumstances to maintain its secrecy.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">\n     <b>\n      <u>6-61-3. Artificial intelligence developers. </u>\n     </b>\n    </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(a) Beginning on October 1, 2026, a developer of a high-risk artificial intelligence system shall use reasonable care to protect consumers from any known or reasonably foreseeable risks of algorithmic discrimination arising from the intended and contracted uses of the high-risk artificial intelligence system. In any enforcement action brought on or after said date by the attorney general pursuant to the provisions of this chapter, there shall be a rebuttable presumption that a developer used reasonable care as required under this section if the developer complied with the provisions of this section or, if the developer enters into a contract with an integrator as set forth in &sect; 6-61-4(b), the developer and integrator complied with the provisions of this section and &sect; 6-61-4.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) Except as provided in &sect; 6-61-4(c), a developer of a high-risk artificial intelligence system shall, beginning on October 1, 2026, make available to each deployer, or other developer, of the high-risk artificial intelligence system:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(1) A general statement describing the reasonably foreseeable uses, and the known harmful or inappropriate uses, of such high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(2) Documentation disclosing:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) High-level summaries of the type of data used to train such high-risk artificial intelligence system; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) The known or reasonably foreseeable limitations of such high-risk artificial intelligence system including, but not limited to, the known or reasonably foreseeable risks of algorithmic discrimination arising from the intended uses of such high-risk artificial intelligence system; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) The purpose of such high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iv) The intended benefits and uses of such high-risk artificial intelligence system; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(v) All other information necessary to enable such deployer to comply with the provisions of this chapter;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(3) Documentation describing: </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) How such high-risk artificial intelligence system was evaluated for performance, and mitigation of algorithmic discrimination, before such high-risk artificial intelligence system was offered, sold, leased, licensed, given or otherwise made available to such deployer; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) The data governance measures used to cover the training datasets and the measures used to examine the suitability of data sources, possible biases and appropriate mitigation; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) The intended outputs of such high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iv) The measures the developer has taken to mitigate any known or reasonably foreseeable risks of algorithmic discrimination that may arise from deployment of such high-risk artificial intelligence system; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(v) How such high-risk artificial intelligence system should be used, not be used and be monitored by an individual when such high-risk artificial intelligence system is used to make, or as a substantial factor in making, a consequential decision.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(4) Any additional documentation that is reasonably necessary to assist a deployer to:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) Understand the outputs of such high-risk artificial intelligence system; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Monitor the performance of such high-risk artificial intelligence system for risks of algorithmic discrimination.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(c)(1) Except as provided in &sect; 6-61-4(c), any developer that, on or after October 1, 2026, offers, sells, leases, licenses, gives or otherwise makes available to a deployer or another developer a high-risk artificial intelligence system shall, to the extent feasible, make available to the deployers and other developers of such high-risk artificial intelligence system the documentation and information necessary for a deployer, or the third party contracted by a deployer, to complete an impact assessment pursuant to &sect; 6-61-5(c). The developer shall make such documentation and information available through artifacts such as model cards, dataset cards or other impact assessments.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(2) A developer that also serves as a deployer for any high-risk artificial intelligence system shall not be required to generate the documentation required by this section unless such high-risk artificial intelligence system is provided to an unaffiliated entity acting as a deployer.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(d)(1) Beginning on October 1, 2026, each developer shall make available, in a manner that is clear and readily available on such developer&#39;s Internet website or in a public use case inventory, a statement summarizing:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) The types of high-risk artificial intelligence systems that such developer:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) Has developed or intentionally and substantially modified; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) Currently makes available to a deployer or another developer; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) How such developer manages any known or reasonably foreseeable risks of algorithmic discrimination that may arise from development or intentional and substantial modification of the types of high-risk artificial intelligence systems described in subsection (d)(1)(i)(A) of this section.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(2) Each developer shall update the statement described in subsection (b)(1) of this section as necessary to ensure that such statement remains accurate, and not later than ninety (90) days after the developer intentionally and substantially modifies any high-risk artificial intelligence system described in subsection (d)(1)(i) of this section.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(e) Beginning on October 1, 2026, a developer of a high-risk artificial intelligence system shall disclose to the attorney general, in a form and manner prescribed by the attorney general, and to all known deployers or other developers of the high-risk artificial intelligence system, any known or reasonably foreseeable risks of algorithmic discrimination arising from the intended uses of such high-risk artificial intelligence system. The developer shall make such disclosures without unreasonable delay but in no event later than ninety (90) days after the date on which:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(1) The developer discovers, through the developer&#39;s ongoing testing and analysis, that the high-risk artificial intelligence system has:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) Been deployed; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Caused, or is reasonably likely to have caused, algorithmic discrimination to at least one thousand (1,000) consumers; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(2) The developer receives, from a deployer of the high-risk artificial intelligence system, a credible report disclosing that such high-risk artificial intelligence system has:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) Been deployed; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Caused algorithmic discrimination to at least one thousand (1,000) consumers.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(f) The provisions of subsections (b) through (e), inclusive, of this section shall not be construed to require a developer to disclose any information: </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(1) That is a trade secret or otherwise protected from disclosure under state or federal law; or </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(2) The disclosure of which would present a security risk to the developer.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(g) Beginning on October 1, 2026, the attorney general may require that a developer disclose to the attorney general, as part of an investigation conducted by the attorney general and in a form and manner prescribed by the attorney general, the general statement or documentation described in subsection (b) of this section. The attorney general may evaluate such general statement or documentation to ensure compliance with the provisions of this section. In disclosing such general statement or documentation to the attorney general pursuant to this subsection, the developer may designate such general statement or documentation as including any information that is exempt from disclosure under subsection (f) of this section or the provisions of title 38 (&quot;access to public records&quot;). To the extent such general statement or documentation includes such information, such general statement or documentation shall be exempt from disclosure pursuant to the provisions of this chapter or title 38. To the extent any information contained in such general statement or documentation is subject to the attorney-client privilege or work product protection, such disclosure shall not constitute a waiver of such privilege or protection.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">\n     <b>\n      <u>6-61-4. High-risk artificial intelligence system. </u>\n     </b>\n    </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(a) Beginning on October 1, 2026, if an integrator integrates a high-risk artificial intelligence system into a product or service the integrator offers to any other person, such integrator shall use reasonable care to protect consumers from any known or reasonably foreseeable risks of algorithmic discrimination arising from the intended and contracted uses of such integrated high-risk artificial intelligence system. In any enforcement action brought on or after said date by the attorney general pursuant to the provisions of this chapter, there shall be a rebuttable presumption that the integrator used reasonable care as required under this section if the integrator complied with the provisions of this chapter.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) Beginning on October 1, 2026, no integrator shall integrate a high-risk artificial intelligence system into a product or service the integrator offers to any other person unless the integrator has entered into a contract with the developer of the high-risk artificial intelligence system. The contract shall be binding and clearly set forth the duties of the developer and integrator with respect to the integrated high-risk artificial intelligence system including, but not limited to, whether the developer or integrator shall be responsible for performing the developer&#39;s duties of &sect; 6-61-3(b) and (c).</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(c) The provisions of &sect; 6-61-3(b) and (c) shall not apply to a developer of an integrated high-risk artificial intelligence system if, at all times while the integrated high-risk artificial intelligence system is integrated into a product or service an integrator offers to any other person, the developer has entered into a contract with the integrator in which such integrator has agreed to assume the developer&#39;s duties under &sect; 6-61-3(b) and (c).</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(d)(1) Beginning on October 1, 2026, each integrator shall make available, in a manner that is clear and readily available on such integrator&#39;s Internet website or in a public use case inventory, a statement summarizing:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) The types of high-risk artificial intelligence systems that such integrator has integrated into products or services such integrator currently offers to any other person; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) How such integrator manages any known or reasonably foreseeable risks of algorithmic discrimination that may arise from the types of high-risk artificial intelligence systems described in this chapter.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(2) Each integrator shall update the statement described in subsection (d)(1) of this section:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) As necessary to ensure that such statement remains accurate; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Not later than ninety (90) days after any intentional and substantial modification is made to any high-risk artificial intelligence system described in subsection (d)(1) of this section.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(e) The provisions of subsections (b) through (d), inclusive, of this section shall not be construed to require a developer or integrator to disclose any information: </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(1) That is a trade secret or otherwise protected from disclosure under state or federal law; or </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(2) The disclosure of which would present a security risk to the developer or integrator.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(f) Beginning on October 1, 2026, the attorney general may require that a developer disclose to the attorney general, as part of an investigation conducted by the attorney general and in a form and manner prescribed by the attorney general, the general statement or documentation described in subsection (b) of this section. The attorney general may evaluate such general statement or documentation to ensure compliance with the provisions of this section. In disclosing such general statement or documentation to the attorney general pursuant to this subsection, the developer may designate such general statement or documentation as including any information that is exempt from disclosure under subsection (e) of this section or the provisions of title 38 (&quot;access to public records&quot;). To the extent such general statement or documentation includes such information, such general statement or documentation shall be exempt from disclosure pursuant to the provisions of this chapter or title 38. To the extent any information contained in such general statement or documentation is subject to the attorney-client privilege or work product protection, such disclosure shall not constitute a waiver of such privilege or protection.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">\n     <b>\n      <u>6-61-5. Reasonable care to protect from foreseeable risks. </u>\n     </b>\n    </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(a) Beginning on October 1, 2026, each deployer of a high-risk artificial intelligence system shall use reasonable care to protect consumers from any known or reasonably foreseeable risks of algorithmic discrimination. In any enforcement action brought on or after said date by the attorney general pursuant to the provisions of this chapter, there shall be a rebuttable presumption that a section of a high-risk artificial intelligence system used reasonable care as required under this subsection if the deployer complied with the provisions of this chapter.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b)(1) Beginning on October 1, 2026, and except as provided in subsection (g) of this section, each deployer of a high-risk artificial intelligence system shall implement and maintain a risk management policy and program to govern such deployer&#39;s deployment of the high-risk artificial intelligence system. The risk management policy and program shall specify and incorporate the principles, processes and personnel that the deployer shall use to identify, document and mitigate any known or reasonably foreseeable risks of algorithmic discrimination. The risk management policy shall be the product of an iterative process, the risk management program shall be an iterative process and both the risk management policy and program shall be planned, implemented and regularly and systematically reviewed and updated over the lifecycle of the high-risk artificial intelligence system. Each risk management policy and program implemented and maintained pursuant to this subsection shall be reasonable, considering:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) The guidance and standards set forth in the latest version of:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) The &quot;Artificial Intelligence Risk Management Framework&quot; published by the National Institute of Standards and Technology; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) ISO or IEC 42001 of the International Organization for Standardization; or </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(C) A nationally or internationally recognized risk management framework for artificial intelligence systems, other than the guidance and standards specified in this subsection, that imposes requirements that are substantially equivalent to, and at least as stringent as, the requirements set forth in this section for risk management policies and programs;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) The size and complexity of the deployer;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) The nature and scope of the high-risk artificial intelligence systems deployed by the deployer including, but not limited to, the intended uses of such high-risk artificial intelligence systems; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iv) The sensitivity and volume of data processed in connection with the high-risk artificial intelligence systems deployed by the deployer.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(2) A risk management policy and program implemented and maintained pursuant to subsection (b)(1) of this section may cover multiple high-risk artificial intelligence systems deployed by the deployer.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(c)(1) Except as provided in subsections (c)(3), (c)(4) and (g) of this section:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) A deployer that deploys a high-risk artificial intelligence system on or after October 1, 2026, or a third party contracted by the deployer, shall complete an impact assessment of the high-risk artificial intelligence system; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Beginning on October 1, 2026, a deployer, or a third party contracted by the deployer, shall complete an impact assessment of a deployed high-risk artificial intelligence system:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) At least annually; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) Not later than ninety (90) days after an intentional and substantial modification to such high-risk artificial intelligence system is made available.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(2)(i) Each impact assessment completed pursuant to this subsection shall include, at a minimum and to the extent reasonably known by, or available to, the deployer:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) A statement by the deployer disclosing the purpose, intended use cases and deployment context of, and benefits afforded by, the high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) An analysis of whether the deployment of the high-risk artificial intelligence system poses any known or reasonably foreseeable risks of algorithmic discrimination and, if so, the nature of such algorithmic discrimination and the steps that have been taken to mitigate such risks;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(C) A description of:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(I) The categories of data the high-risk artificial intelligence system processes as inputs; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(II) The outputs such high-risk artificial intelligence system produces;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(D) If the deployer used data to customize the high-risk artificial intelligence system, an overview of the categories of data the deployer used to customize such high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(E) Any metrics used to evaluate the performance and known limitations of the high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(F) A description of any transparency measures taken concerning the high-risk artificial intelligence system including, but not limited to, any measures taken to disclose to a consumer that such high-risk artificial intelligence system is in use when such high-risk artificial intelligence system is in use; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(G) A description of the post-deployment monitoring and user safeguards provided concerning such high-risk artificial intelligence system including, but not limited to, the oversight, use and learning process established by the deployer to address issues arising from deployment of such high-risk artificial intelligence system.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) In addition to the statement, analysis, descriptions, overview and metrics required under subsection (c)(2) of this section, an impact assessment completed pursuant to this subsection following an intentional and substantial modification made to a high-risk artificial intelligence system on or after October 1, 2026, shall include a statement disclosing the extent to which the high-risk artificial intelligence system was used in a manner that was consistent with, or varied from, the developer&#39;s intended uses of such high-risk artificial intelligence system.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) A single impact assessment may address a comparable set of high-risk artificial intelligence systems deployed by a deployer.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iv) If a deployer, or a third party contracted by the deployer, completes an impact assessment for the purpose of complying with another applicable law or regulation, such impact assessment shall be deemed to satisfy the requirements established in this subsection if such impact assessment is reasonably similar in scope and effect to the impact assessment that would otherwise be completed pursuant to this subsection.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(v) A deployer shall maintain the most recently completed impact assessment of a high-risk artificial intelligence system as required under this subsection, all records concerning each such impact assessment and all prior impact assessments, if any, for a period of at least three (3) years following the final deployment of the high-risk artificial intelligence system.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(d) Except as provided in subsection (g) of this section, a deployer, or a third party contracted by the deployer, shall review, not later than October 1, 2026, and at least annually thereafter, the deployment of each high-risk artificial intelligence system deployed by the deployer to ensure that such high-risk artificial intelligence system is not causing algorithmic discrimination.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(e)(1) Beginning on October 1, 2026, and before a deployer deploys a high-risk artificial intelligence system to make, or be a substantial factor in making, a consequential decision concerning a consumer, the deployer shall:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) Notify the consumer that the deployer has deployed a high-risk artificial intelligence system to make, or be a substantial factor in making, such consequential decision; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Provide to the consumer:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) A statement disclosing:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(I) The purpose of such high-risk artificial intelligence system; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(II) The nature of such consequential decision; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) The right to opt-out of any automated decision-making based on the consumer&#39;s personal data; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(C) Contact information for such deployer; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(D) A description, in plain language, of such high-risk artificial intelligence system; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(E) Instructions on how to access the statement made available pursuant to subsection (f) of this section.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(2) Beginning on October 1, 2026, a deployer that has deployed a high-risk artificial intelligence system to make, or as a substantial factor in making, a consequential decision concerning a consumer shall, if such consequential decision is adverse to the consumer, provide to such consumer:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) A statement disclosing the principal reason or reasons for such adverse consequential decision including, but not limited to: </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) The degree to which, and manner in which, the high-risk artificial intelligence system contributed to such adverse consequential decision; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) The type of data that were processed by such high-risk artificial intelligence system in making such adverse consequential decision; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(C) The source of the data described in this subsection;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) An opportunity to:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) Examine the personal data that the high-risk artificial intelligence system processed in making, or as a substantial factor in making, such adverse consequential decision; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) Correct any incorrect personal data described in this subsection; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(3)(i) Except as provided in this subsection, an opportunity to appeal such adverse consequential decision if such adverse consequential decision is based upon inaccurate personal data, taking into account both the nature of such personal data and the purpose for which such personal data was processed. Such appeal shall, if technically feasible, allow for human review.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) No deployer shall be required to provide an opportunity to appeal pursuant to subsection (e)(3)(i) of this section in any instance in which providing such opportunity to appeal is not in the best interest of the consumer including, but not limited to, in any instance in which any delay might pose a risk to the life or safety of the consumer.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) The deployer shall provide the notice, statements, information, description and instructions required under the provisions of this subsection:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) Directly to the consumer;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) In plain language;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(C) In all languages in which such deployer, in the ordinary course of such deployer&#39;s business, provides contracts, disclaimers, sale announcements and other information to consumers; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(D) In a format that is accessible to consumers with disabilities.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(f)(1) Beginning on October 1, 2026, and except as provided in subsection (g) of this section, each deployer shall make available, in a manner that is clear and readily available on such deployer&#39;s Internet website, a statement summarizing:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) The types of high-risk artificial intelligence systems that are currently deployed by such deployer;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) How such deployer manages any known or reasonably foreseeable risks of algorithmic discrimination that may arise from deployment of each high-risk artificial intelligence system described in this subsection; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) In detail, the nature, source and extent of the information collected and used by such deployer.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(2) Each deployer shall periodically update the statement described in subsection(f)(1) of this section.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(g) The provisions of subsections (b) through (d), inclusive, of this section and subsection (f) of this section shall not apply to a deployer if, at the time the deployer deploys a high-risk artificial intelligence system and at all times while the high-risk artificial intelligence system is deployed:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(1) The deployer:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) Has entered into a contract with the developer in which the developer has agreed to assume the deployer&#39;s duties under subsections (b) through (d), inclusive, of this section and subsection (f) of this section and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Does not exclusively use such deployer&#39;s own data to train such high-risk artificial intelligence system;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(2) Such high-risk artificial intelligence system:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) Is used for the intended uses that are disclosed to such deployer; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Continues learning based on a broad range of data sources and not solely based on the deployer&#39;s own data; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(3) Such deployer makes available to consumers any impact assessment that:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) The developer of such high-risk artificial intelligence system has completed and provided to such deployer; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Includes information that is substantially similar to the information included in the statement, analysis, descriptions, overview and metrics required pursuant to the provisions of this section.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(h) If a deployer deploys a high-risk artificial intelligence system on or after October 1, 2026, and subsequently discovers that the high-risk artificial intelligence system has caused algorithmic discrimination to at least one thousand (1,000) consumers, the deployer shall send to the attorney general, in a form and manner prescribed by the attorney general, a notice disclosing such discovery. The deployer shall send such notice to the attorney general without unreasonable delay but in no event later than ninety (90) days after the date on which the deployer discovered such algorithmic discrimination.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) Nothing in subsections (b) through (h), inclusive, of this section shall be construed to require a deployer to disclose any information that is a trade secret or otherwise protected from disclosure under state or federal law. If a deployer withholds any information from a consumer under this subsection, the deployer shall send notice to the consumer disclosing:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) That the deployer is withholding such information from such consumer; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) The basis for the deployer&#39;s decision to withhold such information from such consumer.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(j) Beginning on October 1, 2026, the attorney general may require that a deployer, or a third party contracted by the deployer as set forth in subsection (c) of this section, as applicable, disclose to the attorney general, as part of an investigation conducted by the attorney general, not later than ninety (90) days after a request by the attorney general and in a form and manner prescribed by the attorney general, the risk management policy implemented pursuant to subsection (b) of this section, impact assessment completed pursuant to subsection (c) of this section or records maintained pursuant to the provisions of subsection (c) of this section. The attorney general may evaluate such risk management policy, impact assessment or records to ensure compliance with the provisions of this section. In disclosing such risk management policy, impact assessment or records to the attorney general pursuant to this subsection, the deployer or third-party contractor, as applicable, may designate such risk management policy, impact assessment or records as including any information that is exempt from disclosure under subsection (i) of this section or chapter 2 of title 38 (&quot;access to public records&quot;). To the extent such risk management policy, impact assessment or records include such information, such risk management policy, impact assessment or records shall be exempt from disclosure pursuant to the provisions of this chapter or title 38. To the extent any information contained in such risk management policy, impact assessment or record is subject to the attorney-client privilege or work product protection, such disclosure shall not constitute a waiver of such privilege or protection.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">\n     <b>\n      <u>6-61-6. Technical documentation. </u>\n     </b>\n    </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(a) Beginning on October 1, 2026, each developer of a general-purpose artificial intelligence model shall, except as provided in subsection (b) of this section:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(1)(i) Create and maintain technical documentation for the general-purpose artificial intelligence model, which technical documentation shall:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) Include the training and testing processes for such general-purpose artificial intelligence model;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) Include at least the following information, as appropriate, considering the size and risk profile of such general-purpose artificial intelligence model:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(I) The tasks such general-purpose artificial intelligence model is intended to perform;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(II) The type and nature of artificial intelligence systems in which such general-purpose artificial intelligence model is intended to be integrated;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(III) Acceptable use policies for such general-purpose artificial intelligence model;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(IV) The date such general-purpose artificial intelligence model is released;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(V) The methods by which such general-purpose artificial intelligence model is distributed; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(VI) The modality and format of inputs and outputs for such general-purpose artificial intelligence model.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(C) Include a description of the data that were used for purposes of training, testing and validation of such general-purpose artificial intelligence model, which description shall be appropriate considering the size and risk profile of such general-purpose artificial intelligence model and include, at a minimum, a description of the following:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(I) The type and provenance of such data;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(II) Curation methodologies used for such data;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(III) How such data were obtained and selected;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(IV) All measures used to identify unsuitable data sources; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(V) Where applicable, methods used to detect identifiable biases;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(D) Be reviewed and revised at least annually or more frequently as necessary to maintain the accuracy of such technical documentation;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(E) Establish, implement and maintain a policy to comply with federal and state copyright laws;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(F) Create, implement, maintain and make available to persons that intend to integrate such general-purpose artificial intelligence model into such persons&#39; artificial intelligence systems documentation and information that:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(2) Enables such persons to:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) Understand the capabilities and limitations of such general-purpose artificial intelligence model; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Comply with such persons&#39; obligations under this chapter;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(3) Discloses, at a minimum: </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) The technical means required for such general-purpose artificial intelligence model to be integrated into such persons&#39; artificial intelligence systems; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) The information listed in subsection (a)(1) of this section; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) The description required under subsection (a)(1)(i)(C) of this section; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(4) Except as provided in subsection (b) of this section, is reviewed and revised at least annually or more frequently as necessary to maintain the accuracy of such documentation and information.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b)(1) The provisions of subsection (a)(1) and (a)(2)(c) of this section shall not apply to a developer that develops, or intentionally and substantially modifies, a general-purpose artificial intelligence model on or after October 1, 2026, if:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) The developer releases such general-purpose artificial intelligence model under a free and open-source license that allows for:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) Access to, and modification, distribution and usage of, such general-purpose artificial intelligence model; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) The parameters of such general-purpose artificial intelligence model to be made publicly available as set forth in this subsection; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Unless such general-purpose artificial intelligence model is deployed as a high-risk artificial intelligence system, the parameters of such general-purpose artificial intelligence model including, but not limited to, the weights and information concerning the model architecture and model usage for such general-purpose artificial intelligence model, are made publicly available; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) The general-purpose artificial intelligence model is:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) Not offered for sale in the market; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) Not intended to interact with consumers; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(C) Solely utilized:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(I) For an entity&#39;s internal purposes; or </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(II) Under an agreement between multiple entities for such entities&#39; internal purposes.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(3) The provisions of this section shall not apply to a developer that develops, or intentionally and substantially modifies, a general-purpose artificial intelligence model on or after October 1, 2026, if such general purpose artificial intelligence model performs tasks exclusively related to an entity&#39;s internal management affairs including, but not limited to, ordering office supplies or processing payments.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(4) A developer that takes any action under an exemption established in this subsection shall bear the burden of demonstrating that such action qualifies for such exemption.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(5) A developer that is exempt under this subsection shall establish and maintain an artificial intelligence risk management framework, which framework shall:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) Be the product of an iterative process and ongoing efforts; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Include, at a minimum:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) An internal governance function; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) A map function that shall establish the context to frame risks; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(C) A risk management function; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(D) A function to measure identified risks by assessing, analyzing and tracking such risks.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(c) Nothing in subsection (a) of this section shall be construed to require a developer to disclose any information that is a trade secret or otherwise protected from disclosure under state or federal law.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(d) Beginning on October 1, 2026, the attorney general may require that a developer disclose to the attorney general, as part of an investigation conducted by the attorney general, not later than ninety (90) days after a request by the attorney general and in a form and manner prescribed by the attorney general, any documentation maintained pursuant to this section. The attorney general may evaluate such documentation to ensure compliance with the provisions of this section. In disclosing any documentation to the attorney general pursuant to this subsection, the developer may designate such documentation as including any information that is exempt from disclosure under subsection (c) of this section or chapter 2 of title 38 (&quot;access to public records&quot;). To the extent such documentation includes such information, such documentation shall be exempt from disclosure under the provision of this chapter or chapter 2 of title 38. To the extent any information contained in such documentation is subject to the attorney-client privilege or work product protection, such disclosure shall not constitute a waiver of such privilege or protection.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">\n     <b>\n      <u>6-61-7. Artificial intelligence system designation. </u>\n     </b>\n    </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(a) Beginning on October 1, 2026, and except as provided in subsections (b) and (c) of this section, the developer of an artificial intelligence system including, but not limited to, a general-purpose artificial intelligence model, that generates or manipulates synthetic digital content shall:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(1) Ensure that the outputs of such artificial intelligence system are marked and detectable as synthetic digital content, and that such outputs are so marked and detectable:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) Not later than the time that consumers who did not create such outputs first interact with, or are exposed to, such outputs; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) In a manner that: </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) Is detectable by consumers; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) Complies with any applicable accessibility requirements; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(2) As far as technically feasible and in a manner that is consistent with any nationally or internationally recognized technical standards, ensure that such developer&#39;s technical solutions are effective, interoperable, robust and reliable, considering: </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) The specificities and limitations of different types of synthetic digital content;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) The implementation costs; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) The generally acknowledged state of the art.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) If the synthetic digital content described in subsection (a) of this section is in an audio, image or video format, and such synthetic digital content forms part of an evidently artistic, creative, satirical, fictional analogous work or program, the disclosure required under said subsection shall be limited to a disclosure that does not hinder the display or enjoyment of such work or program.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(c) The provisions of subsection (a) of this section shall not apply to:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(1) Any synthetic digital content that:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) Consists exclusively of text; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Is published to inform the public on any matter of public interest; or </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) Is unlikely to mislead a reasonable person consuming such synthetic digital content; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(2) To the extent that any artificial intelligence system described in subsection (a) of this section:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) Performs an assistive function for standard editing; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Does not substantially alter the input data provided by the developer or the semantics thereof; or </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) Is used to detect, prevent a violation of the provisions of this chapter or other laws or regulations.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">\n     <b>\n      <u>6-61-8. Compliance with other laws. </u>\n     </b>\n    </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(a) Nothing in this chapter shall be construed to restrict a developer&#39;s, integrator&#39;s, deployer&#39;s or other person&#39;s ability to:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(1) Comply with federal, state or municipal law;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(2) Comply with a civil, criminal or regulatory inquiry, investigation, subpoena or summons by a federal, state, municipal or other governmental authority;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(3) Cooperate with a law enforcement agency concerning conduct or activity that the developer, integrator, deployer or other person reasonably and in good faith believes may violate federal, state or municipal law;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(4) Investigate, establish, exercise, prepare for or defend a legal claim;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(5) Take immediate steps to protect an interest that is essential for the life or physical safety of a consumer or another individual;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(6)(i) By any means other than facial recognition technology, prevent, detect, protect against or respond to:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) A security incident; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) A malicious or deceptive activity; or </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(C) Identity theft, fraud, harassment or any other illegal activity. </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Investigate, report or prosecute the persons responsible for any action described in a security incident; or </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) Preserve the integrity or security of systems;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(7) Engage in public or peer-reviewed scientific or statistical research in the public interest that:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) Adheres to all other applicable ethics and privacy laws; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Is conducted in accordance with:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) The provisions of 45 CFR Part 46, as amended from time to time; or </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) Relevant requirements established by the federal Food and Drug Administration;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(8) Conduct research, testing, development and integration activities regarding an artificial intelligence system or model, other than testing conducted under real world conditions, before such artificial intelligence system or model is placed on the market, deployed or put into service, as applicable;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(9) Effectuate a product recall;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(10) Identify and repair technical errors that impair existing or intended functionality; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(11) Assist another developer, integrator, deployer or person with any of the obligations imposed pursuant to the provisions of this chapter.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) The obligations imposed on developers, integrators, deployers or other persons under this chapter shall not apply where compliance by the developer, integrator, deployer or other person with said provisions of this chapter shall violate an evidentiary privilege under the laws of this state.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(c) Nothing in this chapter shall be construed to impose any obligation on a developer, integrator, deployer or other person that adversely affects the rights or freedoms of any person including, but not limited to, the rights of any person to freedom of speech or freedom of the press guaranteed in:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(1) The First Amendment to the United States Constitution; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(2) The Rhode Island Constitution, Article 1, &sect; 21.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(d) Nothing in this chapter shall be construed to apply to any developer, integrator, deployer, or other person:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(1) Insofar as such developer, integrator, deployer or other person develops, integrates, deploys, puts into service or intentionally and substantially modifies, as applicable, a high-risk artificial intelligence system:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) That has been approved, authorized, certified, cleared, developed, integrated or granted by:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) A federal agency, such as the federal Food and Drug Administration or the Federal Aviation Administration, acting within the scope of such federal agency&#39;s authority; or </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) A regulated entity subject to supervision and regulation by the Federal Housing Finance Agency; or </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) In compliance with standards that are:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) Established by:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(I) Any federal agency including, but not limited to, the federal Office of the National Coordinator for Health Information Technology; or </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(II) A regulated entity subject to supervision and regulation by the Federal Housing Finance Agency; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) Substantially equivalent to, and at least as stringent as, the standards established in this chapter;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(2) Conducting research to support an application:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) For approval or certification from any federal agency including, but not limited to, the Federal Aviation Administration, the Federal Communications Commission, or the federal Food and Drug Administration; or </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) That is otherwise subject to review by any federal agency;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(3) Performing work under, or in connection with, a contract with the United States Department of Commerce, the United States Department of Defense, or the National Aeronautics and Space Administration, unless such developer, integrator, deployer or other person is performing such work on a high-risk artificial intelligence system that is used to make, or as a substantial factor in making, a decision concerning employment or housing; or</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(4) That is a covered entity within the meaning of the Health Insurance Portability and Accountability Act of 1996, Pub. L. 104-191, and the regulations promulgated thereunder, as both may be amended from time to time, and providing healthcare recommendations that:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) Are generated by an artificial intelligence system; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Require a healthcare provider to take action to implement such recommendations; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) Are not considered to be high risk.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(e) Nothing in this chapter shall be construed to apply to any artificial intelligence system that is acquired by or for the federal government or any federal agency or department including, but not limited to, the United States Department of Commerce, the United States Department of Defense, or the National Aeronautics and Space Administration, unless such artificial intelligence system is a high-risk artificial intelligence system that is used to make, or as a substantial factor in making, a decision concerning employment or housing.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(f) Any insurer, subject to the provisions of title 27, fraternal benefit society, within the meaning of &sect; 27-25-1, or health carrier, as defined in &sect; 27-18.6-2, shall be deemed to be in full compliance with the provisions of this chapter if such insurer, fraternal benefit society or health carrier has implemented and maintains a written artificial intelligence systems program in accordance with all requirements established by the insurance commissioner defined in &sect; 27-2.4-2.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(g)(1) Any financial institution, out-of-state financial institution, Rhode Island credit union, federal credit union or out-of-state credit union, or any branch or subsidiary thereof, shall be deemed to be in full compliance with the provisions of this chapter if such financial institution, out-of-state financial institution, Rhode Island credit union, federal credit union, out-of-state credit union, branch or subsidiary is subject to examination by any state or federal prudential regulator under any published guidance or regulations that apply to the use of high-risk artificial intelligence systems and such guidance or regulations:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) Impose requirements that are substantially equivalent to, and at least as stringent as, the requirements set forth in this chapter; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) At a minimum, require such financial institution, out-of-state financial institution, Rhode Island credit union, federal credit union, out-of-state credit union, branch or subsidiary to:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) Regularly audit such financial institution&#39;s, out-of-state financial institution&#39;s, Rhode Island credit union&#39;s, federal credit union&#39;s, out-of-state credit union&#39;s, branch &#39;s or subsidiary&#39;s use of high-risk artificial intelligence systems for compliance with state and federal anti-discrimination laws and regulations applicable to such financial institution, out-of-state financial institution, Rhode Island credit union, federal credit union, out-of-state credit union, branch or subsidiary; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) Mitigate any algorithmic discrimination caused by the use of a high-risk artificial intelligence system or any risk of algorithmic discrimination that is reasonably foreseeable as a result of the use of a high-risk artificial intelligence system.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(2) For the purposes of this section, &quot;branch&quot;, &quot;financial institution&quot;, &quot;Rhode Island credit union&quot;, and &quot;federal credit union&quot; have the same meaning as provided in &sect; 19-1-1. </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(3) For the purposes of this section, &quot;out-of-state financial institution&quot; means a financial institution whose principal office is located in any other state.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(4) For the purposes of this section, &quot;out-of-state credit union&quot; means a credit union whose principal office is located in any other state.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(h) If a developer, integrator, deployer or other person engages in any action pursuant to an exemption set forth in subsections (a) through (g), inclusive, of this section, the developer, integrator, deployer or other person bears the burden of demonstrating that such action qualifies for such exemption.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">\n     <b>\n      <u>6-61-9. Enforcement. </u>\n     </b>\n    </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(a) The attorney general shall have exclusive authority to enforce the provisions of this chapter.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b) Except as provided in subsection (f) of this section, during the period beginning on October 1, 2026, and ending on September 30, 2027, the attorney general shall, prior to initiating any action for a violation of any provision of this chapter, issue a notice of violation to the developer, integrator, deployer, or other person if the attorney general determines that it is possible to cure such violation. If the developer, integrator, deployer or other person fails to cure such violation not later than sixty (60) days after receipt of the notice of violation, the attorney general may bring an action pursuant to this chapter.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(c) Except as provided in subsection (f) of this section, beginning on October 1, 2027, the attorney general may, in determining whether to grant a developer, integrator, deployer or other person the opportunity to cure a violation described in subsection (b) of this section, consider:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(1) The number of violations; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(2) The size and complexity of the developer, integrator, deployer or other person; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(3) The nature and extent of the developer&#39;s, integrator&#39;s, deployer&#39;s or other person&#39;s business; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(4) The substantial likelihood of injury to the public; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(5) The safety of persons or property; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(6) Whether such violation was likely caused by human or technical error.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(d) Nothing in this chapter shall be construed as providing the basis for a private right of action for violations of this chapter.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(e) Except as provided in subsections (a) through (d), inclusive, of this section and subsection (f) of this section, a violation of the requirements established in this chapter shall constitute an unfair trade practice for purposes of &sect; 6-13.1-5 and shall be enforced solely by the attorney general.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(f)(1) In any action commenced by the attorney general for any violation of this chapter, it shall be an affirmative defense that the developer, integrator, deployer, or other person:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(i) Discovered a violation of any provision of this chapter through red-teaming;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(ii) Not later than sixty (60) days after discovering the violation as set forth in subsection (f)(1)(i) of this section:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) Cures such violation; and </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) Provides to the attorney general, in a form and manner prescribed by the attorney general, notice that such violation has been cured and evidence that any harm caused by such violation has been mitigated; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(iii) Is otherwise in compliance with the latest version of: </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(A) The &quot;Artificial Intelligence Risk Management Framework&quot; published by the National Institute of Standards and Technology; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(B) ISO or IEC 42001 of the International Organization for Standardization; </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(C) A nationally or internationally recognized risk management framework for artificial intelligence systems, other than the risk management frameworks specified in this subsection, that imposes requirements that are substantially equivalent to, and at least as stringent as, the requirements set forth in this chapter; or </u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(D) Any risk management framework for artificial intelligence systems that is substantially equivalent to, and at least as stringent as, the risk management frameworks described in this subsection.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(2) The developer, integrator, deployer or other person bears the burden of demonstrating to the attorney general that the requirements established in subsection (f)(1) of this section have been satisfied.</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(3) Nothing in this this chapter including, but not limited to, the enforcement authority granted to the attorney general under this section, shall be construed to preempt or otherwise affect any right, claim, remedy, presumption or defense available at law or in equity. Any rebuttable presumption or affirmative defense established under this chapter shall apply only to an enforcement action brought by the attorney general pursuant to this section and shall not apply to any right, claim, remedy, presumption, or defense available at law or in equity.</u>\n   </p>\n   <p class=\"indent\">SECTION 2. This act shall take effect on October 1, 2025</p>\n  </div>\n  <a name=\"digest_document_section\"></a><div class=\"digest\">\n   <p class=\"center\">\n    <b>EXPLANATION</b>\n   </p>\n   <p class=\"center\">\n    <b>BY THE LEGISLATIVE COUNCIL</b>\n   </p>\n   <p class=\"center\">\n    <b>OF</b>\n   </p>\n   <p class=\"center\">\n    <b>AN ACT</b>\n   </p>\n   <p class=\"center\">\n    <b>RELATING TO COMMERCIAL LAW -- GENERAL REGULATORY PROVISIONS -- ARTIFICIAL INTELLIGENCE ACT</b>\n   </p>\n   <p class=\"indent\">This act would establish regulations to ensure the ethical development, integration, and deployment of high-risk Artificial Intelligence (AI) systems, particularly those influencing consequential decisions in areas like employment, education, lending, housing, healthcare, and legal services. It would require developers, integrators, and deployers to use reasonable care to prevent algorithmic discrimination, implement risk management policies, conduct regular impact assessments, and provide transparency regarding the use of AI systems. The act also would require developers to disclose known risks to the attorney general and affected parties, while deployers are required to notify consumers when AI is used in decision-making and offer avenues to appeal adverse outcomes. The act would further mandates that synthetic digital content generated by AI be clearly marked, with exceptions for informational content. Additionally, this act would provide exemptions for AI systems governed by equivalent federal standards, used for internal business purposes, or developed for specific federal agencies. The attorney general would hold exclusive enforcement authority, with a focus on encouraging compliance before pursuing legal action.</p>\n   <p class=\"indent\">This act would take effect on October 1, 2025</p>\n  </div>\n </div>\n    </div>\t\n<table cellpadding=0 cellspacing=0 width=\"100%\">\n   <tr>\n      <td>\n          Copyright &copy; 2025 State Net\n      </td>\n<BR>\n<!--???MOVED INTO resources.cgi      <td align=\"right\">\n          <img src=\"https://custom.statenet.com/network/poweredby.gif\" alt=\"Powered by State Net\">\n      </td>-->\n\n    </tr>\n</table>\n</body></html>\n",
      "markdown": "The following has special meaning: _green underline denotes added text_ ~~red struck out text denotes deleted text~~ | [![Powered by State Net](https://custom.statenet.com/network/poweredby.gif)](https://www.lexisnexis.com/statenet/)  \n---|---  \n  \n2025 RI S 627 | | Author: | DiPalma  \n---|---  \nVersion: | Introduced  \nVersion Date: | 03/07/2025  \n  \n**2025 - - S 0627**\n\n**STATE OF RHODE ISLAND**\n\n**IN GENERAL ASSEMBLY**\n\n**JANUARY SESSION, A.D. 2025**\n\n**____________**\n\n**AN ACT**\n\n**RELATING TO COMMERCIAL LAW - - GENERAL REGULATORY PROVISIONS - - ARTIFICIAL\nINTELLIGENCE ACT**\n\n**_Introduced By:_ ** Senators DiPalma, Gu, Burke, Paolino, Urso, Zurier, and\nPearson\n\n**_Date Introduced:_ ** March 07, 2025\n\n**_Referred To:_ ** Senate Artificial Intelligence & Emerging Tech\n\nIt is enacted by the General Assembly as follows:\n\nSECTION 1. Title 6 of the General Laws entitled \"COMMERCIAL LAW -- GENERAL\nREGULATORY PROVISIONS\" is hereby amended by adding thereto the following\nchapter:\n\n_**CHAPTER 61** _\n\n_**ARTIFICIAL INTELLIGENCE ACT** _\n\n_**_6-61-1. Short title._ ** _\n\n_This act shall be known and may be cited as the \"Artificial Intelligence\nAct\"_\n\n_**_6-61-2. Definitions._ ** _\n\n_As used in this chapter:_\n\n_(1) \"Algorithmic discrimination\" means: _\n\n_(i) Any use of an artificial intelligence system that results in any unlawful\ndifferential treatment or impact that disfavors any individual or group of\nindividuals on the basis of one or more classifications protected under the\nlaws of this state or federal law; and_\n\n_(ii) Does not include:_\n\n_(A) The offer, license or use of a high-risk artificial intelligence system\nby a developer, integrator or deployer for the sole purpose of:_\n\n_(I) The developer 's, integrator's or deployer's self-testing to identify,\nmitigate or prevent discrimination or otherwise ensure compliance with state\nand federal law; _\n\n_(II) Expanding an applicant, customer or participant pool to increase\ndiversity or redress historic discrimination; or_\n\n_(B) An act or omission by or on behalf of a private club or other\nestablishment not in fact open to the public, as set forth in Title II of the\nCivil Rights Act of 1964, 42 USC  2000a(e), as amended from time to time._\n\n_(2) \"Artificial intelligence system\" means any machine-based system that, for\nany explicit or implicit objective, infers from the inputs such system\nreceives how to generate outputs including, but not limited to, content,\ndecisions, predictions or recommendations, that can influence physical or\nvirtual environments._\n\n_(3) \"Consequential decision\" means any decision or judgment that has a legal,\nmaterial or similarly significant effect on a consumer with respect to: _\n\n_(i) Employment, including any such decision or judgment made:_\n\n_(A) Concerning hiring, termination, compensation or promotion; or_\n\n_(B) By way of any automated task allocation that limits, segregates or\nclassifies employees for the purpose of assigning or determining material\nterms or conditions of employment;_\n\n_(ii) Education or vocational training, including any such decision or\njudgment made concerning:_\n\n_(A) Assessments;_\n\n_(B) Student cheating or plagiarism detection;_\n\n_(C) Accreditation;_\n\n_(D) Certification;_\n\n_(E) Admissions; or_\n\n_(F) Financial aid or scholarships;_\n\n_(iii) The provision or denial, or terms and conditions, of:_\n\n_(A) Financial lending or credit services;_\n\n_(B) Housing or lodging including, but not limited to, rentals or short-term\nhousing or lodging;_\n\n_(C) Insurance; or_\n\n_(D) Legal services; or_\n\n_(iv) The provision or denial of:_\n\n_(A) Essential government services; or_\n\n_(B) Healthcare services._\n\n_(4) \"Consumer\" means any individual who is a resident of this state._\n\n_(5) \"Deploy\" means to use a high-risk artificial intelligence system to make,\nor as a substantial factor in making, a consequential decision._\n\n_(6) \"Deployer\" means any person doing business in this state that deploys a\nhigh-risk artificial intelligence system in this state._\n\n_(7) \"Developer\" means any person doing business in this state that develops,\nor intentionally and substantially modifies, an artificial intelligence\nsystem._\n\n_(8) \"General-purpose artificial intelligence model\" means:_\n\n_(i) Any form of artificial intelligence system that:_\n\n_(A) Displays significant generality;_\n\n_(B) Is capable of competently performing a wide range of distinct tasks;_\n\n_(C) Can be integrated into a variety of downstream applications or systems;\nand_\n\n_(ii) Does not include any artificial intelligence model that is used for\ndevelopment, prototyping and research activities before such artificial\nintelligence model is released on the market._\n\n_(9) \"High-risk artificial intelligence system\" means: _\n\n_(i) Any artificial intelligence system that, when deployed, makes, or is a\nsubstantial factor in making, a consequential decision; and_\n\n_(ii) Does not include:_\n\n_(A) Any artificial intelligence system that is intended to:_\n\n_(I) Perform any narrow procedural task; or_\n\n_(II) Detect decision-making patterns, or deviations from decision-making\npatterns, unless such artificial intelligence system is intended to replace or\ninfluence any assessment previously completed by an individual without\nsufficient human review; or_\n\n_(B) Unless the technology, when deployed, makes, or is a substantial factor\nin making, a consequential decision:_\n\n_(I) Any anti-fraud technology that does not make use of facial recognition\ntechnology;_\n\n_(II) Any artificial intelligence-enabled video game technology;_\n\n_(III) Any anti-malware, anti-virus, calculator, cybersecurity, database, data\nstorage, firewall, Internet domain registration, Internet-website loading,\nnetworking, robocall-filtering, spam-filtering, spellchecking, spreadsheet,\nweb-caching, web-hosting or similar technology;_\n\n_(IV) Any technology that performs tasks exclusively related to an entity 's\ninternal management affairs including, but not limited to, ordering office\nsupplies or processing payments; or _\n\n_(V) Any technology that communicates with consumers in natural language for\nthe purpose of providing users with information, making referrals or\nrecommendations and answering questions, and is subject to an accepted use\npolicy that prohibits generating content that is discriminatory or harmful;_\n\n_(10) \"Integrator\" means any person doing business in this state that, with\nrespect to a given high-risk artificial intelligence system: _\n\n_(i) Neither develops nor intentionally and substantially modifies the high-\nrisk artificial intelligence system; and_\n\n_(ii) Integrates the high-risk artificial intelligence system into a product\nor service such person offers to any other person._\n\n_(11) \"Intentional and substantial modification\" means: _\n\n_(i) Any deliberate change made to:_\n\n_(A) An artificial intelligence system that materially increases the risk of\nalgorithmic discrimination; or_\n\n_(B) A general-purpose artificial intelligence model that:_\n\n_(I) Affects compliance of the general-purpose artificial intelligence model;_\n\n_(II) Materially changes the purpose of the general-purpose artificial\nintelligence model; or_\n\n_(III) Materially increases the risk of algorithmic discrimination; and_\n\n_(ii) Does not include any change made to a high-risk artificial intelligence\nsystem, or the performance of a high-risk artificial intelligence system, if:_\n\n_(A) The high-risk artificial intelligence system continues to learn after\nsuch high-risk artificial intelligence system is:_\n\n_(I) Offered, sold, leased, licensed, given or otherwise made available to a\ndeployer; or_\n\n_(II) Is deployed; and_\n\n_(B) Such change:_\n\n_(I) Is made to such high-risk artificial intelligence system as a result of\nany learning described in subsection (11)(ii)(A) of this section;_\n\n_(II) Was predetermined by the deployer, or the third party contracted by the\ndeployer, when such deployer or third party completed the initial impact\nassessment of such high-risk artificial intelligence system pursuant to \n6-61-4(c); and _\n\n_(III) Is included in the technical documentation for such high-risk\nartificial intelligence system._\n\n_(12) \"Person\" means any individual, association, corporation, limited\nliability company, partnership, trust or other legal entity._\n\n_(13) \"Red-teaming\" means an exercise that is conducted to identify the\npotential adverse behaviors or outcomes of an artificial intelligence system,\nhow such behaviors or outcomes occur and stress test the safeguards against\nsuch behaviors or outcomes._\n\n_(14) \"Substantial factor\" means: _\n\n_(i) A factor that alters the outcome of a consequential decision and is\ngenerated by an artificial intelligence system; and_\n\n_(ii) Includes, but is not limited to, any use of an artificial intelligence\nsystem to generate any content, decision, prediction or recommendation\nconcerning a consumer that is used as a basis to make a consequential decision\nconcerning the consumer. Substantial factor does not include any output\nproduced by an artificial intelligence system where an individual was involved\nin the data processing that produced such output and such individual\nmeaningfully considered such data as part of such data processing and had the\nauthority to change or influence the output produced by such data processing._\n\n_(15) \"Synthetic digital content\" means any digital content including, but not\nlimited to, any audio, image, text or video, that is produced or manipulated\nby an artificial intelligence system including, but not limited to, a general-\npurpose artificial intelligence model._\n\n_(16) \"Trade secret\" means information, including a formula, pattern,\ncompilation, program, device, method, technique, or process, that:_\n\n_(i) Derives independent economic value, actual or potential, from not being\ngenerally known to, and not being readily ascertainable by proper means by,\nother persons who can obtain economic value from its disclosure or use; and_\n\n_(ii) Is the subject of efforts that are reasonable under the circumstances to\nmaintain its secrecy._\n\n_**_6-61-3. Artificial intelligence developers._ ** _\n\n_(a) Beginning on October 1, 2026, a developer of a high-risk artificial\nintelligence system shall use reasonable care to protect consumers from any\nknown or reasonably foreseeable risks of algorithmic discrimination arising\nfrom the intended and contracted uses of the high-risk artificial intelligence\nsystem. In any enforcement action brought on or after said date by the\nattorney general pursuant to the provisions of this chapter, there shall be a\nrebuttable presumption that a developer used reasonable care as required under\nthis section if the developer complied with the provisions of this section or,\nif the developer enters into a contract with an integrator as set forth in \n6-61-4(b), the developer and integrator complied with the provisions of this\nsection and  6-61-4._\n\n_(b) Except as provided in  6-61-4(c), a developer of a high-risk artificial\nintelligence system shall, beginning on October 1, 2026, make available to\neach deployer, or other developer, of the high-risk artificial intelligence\nsystem:_\n\n_(1) A general statement describing the reasonably foreseeable uses, and the\nknown harmful or inappropriate uses, of such high-risk artificial intelligence\nsystem;_\n\n_(2) Documentation disclosing:_\n\n_(i) High-level summaries of the type of data used to train such high-risk\nartificial intelligence system;_\n\n_(ii) The known or reasonably foreseeable limitations of such high-risk\nartificial intelligence system including, but not limited to, the known or\nreasonably foreseeable risks of algorithmic discrimination arising from the\nintended uses of such high-risk artificial intelligence system;_\n\n_(iii) The purpose of such high-risk artificial intelligence system;_\n\n_(iv) The intended benefits and uses of such high-risk artificial intelligence\nsystem; and_\n\n_(v) All other information necessary to enable such deployer to comply with\nthe provisions of this chapter;_\n\n_(3) Documentation describing:_\n\n_(i) How such high-risk artificial intelligence system was evaluated for\nperformance, and mitigation of algorithmic discrimination, before such high-\nrisk artificial intelligence system was offered, sold, leased, licensed, given\nor otherwise made available to such deployer;_\n\n_(ii) The data governance measures used to cover the training datasets and the\nmeasures used to examine the suitability of data sources, possible biases and\nappropriate mitigation;_\n\n_(iii) The intended outputs of such high-risk artificial intelligence system;_\n\n_(iv) The measures the developer has taken to mitigate any known or reasonably\nforeseeable risks of algorithmic discrimination that may arise from deployment\nof such high-risk artificial intelligence system; and_\n\n_(v) How such high-risk artificial intelligence system should be used, not be\nused and be monitored by an individual when such high-risk artificial\nintelligence system is used to make, or as a substantial factor in making, a\nconsequential decision._\n\n_(4) Any additional documentation that is reasonably necessary to assist a\ndeployer to:_\n\n_(i) Understand the outputs of such high-risk artificial intelligence system;\nand_\n\n_(ii) Monitor the performance of such high-risk artificial intelligence system\nfor risks of algorithmic discrimination._\n\n_(c)(1) Except as provided in  6-61-4(c), any developer that, on or after\nOctober 1, 2026, offers, sells, leases, licenses, gives or otherwise makes\navailable to a deployer or another developer a high-risk artificial\nintelligence system shall, to the extent feasible, make available to the\ndeployers and other developers of such high-risk artificial intelligence\nsystem the documentation and information necessary for a deployer, or the\nthird party contracted by a deployer, to complete an impact assessment\npursuant to  6-61-5(c). The developer shall make such documentation and\ninformation available through artifacts such as model cards, dataset cards or\nother impact assessments._\n\n_(2) A developer that also serves as a deployer for any high-risk artificial\nintelligence system shall not be required to generate the documentation\nrequired by this section unless such high-risk artificial intelligence system\nis provided to an unaffiliated entity acting as a deployer._\n\n_(d)(1) Beginning on October 1, 2026, each developer shall make available, in\na manner that is clear and readily available on such developer 's Internet\nwebsite or in a public use case inventory, a statement summarizing:_\n\n_(i) The types of high-risk artificial intelligence systems that such\ndeveloper:_\n\n_(A) Has developed or intentionally and substantially modified; and_\n\n_(B) Currently makes available to a deployer or another developer; and_\n\n_(ii) How such developer manages any known or reasonably foreseeable risks of\nalgorithmic discrimination that may arise from development or intentional and\nsubstantial modification of the types of high-risk artificial intelligence\nsystems described in subsection (d)(1)(i)(A) of this section._\n\n_(2) Each developer shall update the statement described in subsection (b)(1)\nof this section as necessary to ensure that such statement remains accurate,\nand not later than ninety (90) days after the developer intentionally and\nsubstantially modifies any high-risk artificial intelligence system described\nin subsection (d)(1)(i) of this section._\n\n_(e) Beginning on October 1, 2026, a developer of a high-risk artificial\nintelligence system shall disclose to the attorney general, in a form and\nmanner prescribed by the attorney general, and to all known deployers or other\ndevelopers of the high-risk artificial intelligence system, any known or\nreasonably foreseeable risks of algorithmic discrimination arising from the\nintended uses of such high-risk artificial intelligence system. The developer\nshall make such disclosures without unreasonable delay but in no event later\nthan ninety (90) days after the date on which:_\n\n_(1) The developer discovers, through the developer 's ongoing testing and\nanalysis, that the high-risk artificial intelligence system has:_\n\n_(i) Been deployed; and_\n\n_(ii) Caused, or is reasonably likely to have caused, algorithmic\ndiscrimination to at least one thousand (1,000) consumers; or_\n\n_(2) The developer receives, from a deployer of the high-risk artificial\nintelligence system, a credible report disclosing that such high-risk\nartificial intelligence system has:_\n\n_(i) Been deployed; and_\n\n_(ii) Caused algorithmic discrimination to at least one thousand (1,000)\nconsumers._\n\n_(f) The provisions of subsections (b) through (e), inclusive, of this section\nshall not be construed to require a developer to disclose any information:_\n\n_(1) That is a trade secret or otherwise protected from disclosure under state\nor federal law; or_\n\n_(2) The disclosure of which would present a security risk to the developer._\n\n_(g) Beginning on October 1, 2026, the attorney general may require that a\ndeveloper disclose to the attorney general, as part of an investigation\nconducted by the attorney general and in a form and manner prescribed by the\nattorney general, the general statement or documentation described in\nsubsection (b) of this section. The attorney general may evaluate such general\nstatement or documentation to ensure compliance with the provisions of this\nsection. In disclosing such general statement or documentation to the attorney\ngeneral pursuant to this subsection, the developer may designate such general\nstatement or documentation as including any information that is exempt from\ndisclosure under subsection (f) of this section or the provisions of title 38\n( \"access to public records\"). To the extent such general statement or\ndocumentation includes such information, such general statement or\ndocumentation shall be exempt from disclosure pursuant to the provisions of\nthis chapter or title 38. To the extent any information contained in such\ngeneral statement or documentation is subject to the attorney-client privilege\nor work product protection, such disclosure shall not constitute a waiver of\nsuch privilege or protection._\n\n_**_6-61-4. High-risk artificial intelligence system._ ** _\n\n_(a) Beginning on October 1, 2026, if an integrator integrates a high-risk\nartificial intelligence system into a product or service the integrator offers\nto any other person, such integrator shall use reasonable care to protect\nconsumers from any known or reasonably foreseeable risks of algorithmic\ndiscrimination arising from the intended and contracted uses of such\nintegrated high-risk artificial intelligence system. In any enforcement action\nbrought on or after said date by the attorney general pursuant to the\nprovisions of this chapter, there shall be a rebuttable presumption that the\nintegrator used reasonable care as required under this section if the\nintegrator complied with the provisions of this chapter._\n\n_(b) Beginning on October 1, 2026, no integrator shall integrate a high-risk\nartificial intelligence system into a product or service the integrator offers\nto any other person unless the integrator has entered into a contract with the\ndeveloper of the high-risk artificial intelligence system. The contract shall\nbe binding and clearly set forth the duties of the developer and integrator\nwith respect to the integrated high-risk artificial intelligence system\nincluding, but not limited to, whether the developer or integrator shall be\nresponsible for performing the developer 's duties of  6-61-3(b) and (c)._\n\n_(c) The provisions of  6-61-3(b) and (c) shall not apply to a developer of\nan integrated high-risk artificial intelligence system if, at all times while\nthe integrated high-risk artificial intelligence system is integrated into a\nproduct or service an integrator offers to any other person, the developer has\nentered into a contract with the integrator in which such integrator has\nagreed to assume the developer's duties under  6-61-3(b) and (c)._\n\n_(d)(1) Beginning on October 1, 2026, each integrator shall make available, in\na manner that is clear and readily available on such integrator 's Internet\nwebsite or in a public use case inventory, a statement summarizing:_\n\n_(i) The types of high-risk artificial intelligence systems that such\nintegrator has integrated into products or services such integrator currently\noffers to any other person; and_\n\n_(ii) How such integrator manages any known or reasonably foreseeable risks of\nalgorithmic discrimination that may arise from the types of high-risk\nartificial intelligence systems described in this chapter._\n\n_(2) Each integrator shall update the statement described in subsection (d)(1)\nof this section:_\n\n_(i) As necessary to ensure that such statement remains accurate; and_\n\n_(ii) Not later than ninety (90) days after any intentional and substantial\nmodification is made to any high-risk artificial intelligence system described\nin subsection (d)(1) of this section._\n\n_(e) The provisions of subsections (b) through (d), inclusive, of this section\nshall not be construed to require a developer or integrator to disclose any\ninformation:_\n\n_(1) That is a trade secret or otherwise protected from disclosure under state\nor federal law; or_\n\n_(2) The disclosure of which would present a security risk to the developer or\nintegrator._\n\n_(f) Beginning on October 1, 2026, the attorney general may require that a\ndeveloper disclose to the attorney general, as part of an investigation\nconducted by the attorney general and in a form and manner prescribed by the\nattorney general, the general statement or documentation described in\nsubsection (b) of this section. The attorney general may evaluate such general\nstatement or documentation to ensure compliance with the provisions of this\nsection. In disclosing such general statement or documentation to the attorney\ngeneral pursuant to this subsection, the developer may designate such general\nstatement or documentation as including any information that is exempt from\ndisclosure under subsection (e) of this section or the provisions of title 38\n( \"access to public records\"). To the extent such general statement or\ndocumentation includes such information, such general statement or\ndocumentation shall be exempt from disclosure pursuant to the provisions of\nthis chapter or title 38. To the extent any information contained in such\ngeneral statement or documentation is subject to the attorney-client privilege\nor work product protection, such disclosure shall not constitute a waiver of\nsuch privilege or protection._\n\n_**_6-61-5. Reasonable care to protect from foreseeable risks._ ** _\n\n_(a) Beginning on October 1, 2026, each deployer of a high-risk artificial\nintelligence system shall use reasonable care to protect consumers from any\nknown or reasonably foreseeable risks of algorithmic discrimination. In any\nenforcement action brought on or after said date by the attorney general\npursuant to the provisions of this chapter, there shall be a rebuttable\npresumption that a section of a high-risk artificial intelligence system used\nreasonable care as required under this subsection if the deployer complied\nwith the provisions of this chapter._\n\n_(b)(1) Beginning on October 1, 2026, and except as provided in subsection (g)\nof this section, each deployer of a high-risk artificial intelligence system\nshall implement and maintain a risk management policy and program to govern\nsuch deployer 's deployment of the high-risk artificial intelligence system.\nThe risk management policy and program shall specify and incorporate the\nprinciples, processes and personnel that the deployer shall use to identify,\ndocument and mitigate any known or reasonably foreseeable risks of algorithmic\ndiscrimination. The risk management policy shall be the product of an\niterative process, the risk management program shall be an iterative process\nand both the risk management policy and program shall be planned, implemented\nand regularly and systematically reviewed and updated over the lifecycle of\nthe high-risk artificial intelligence system. Each risk management policy and\nprogram implemented and maintained pursuant to this subsection shall be\nreasonable, considering:_\n\n_(i) The guidance and standards set forth in the latest version of:_\n\n_(A) The \"Artificial Intelligence Risk Management Framework\" published by the\nNational Institute of Standards and Technology; _\n\n_(B) ISO or IEC 42001 of the International Organization for Standardization;\nor_\n\n_(C) A nationally or internationally recognized risk management framework for\nartificial intelligence systems, other than the guidance and standards\nspecified in this subsection, that imposes requirements that are substantially\nequivalent to, and at least as stringent as, the requirements set forth in\nthis section for risk management policies and programs;_\n\n_(ii) The size and complexity of the deployer;_\n\n_(iii) The nature and scope of the high-risk artificial intelligence systems\ndeployed by the deployer including, but not limited to, the intended uses of\nsuch high-risk artificial intelligence systems; and_\n\n_(iv) The sensitivity and volume of data processed in connection with the\nhigh-risk artificial intelligence systems deployed by the deployer._\n\n_(2) A risk management policy and program implemented and maintained pursuant\nto subsection (b)(1) of this section may cover multiple high-risk artificial\nintelligence systems deployed by the deployer._\n\n_(c)(1) Except as provided in subsections (c)(3), (c)(4) and (g) of this\nsection:_\n\n_(i) A deployer that deploys a high-risk artificial intelligence system on or\nafter October 1, 2026, or a third party contracted by the deployer, shall\ncomplete an impact assessment of the high-risk artificial intelligence system;\nand_\n\n_(ii) Beginning on October 1, 2026, a deployer, or a third party contracted by\nthe deployer, shall complete an impact assessment of a deployed high-risk\nartificial intelligence system:_\n\n_(A) At least annually; and_\n\n_(B) Not later than ninety (90) days after an intentional and substantial\nmodification to such high-risk artificial intelligence system is made\navailable._\n\n_(2)(i) Each impact assessment completed pursuant to this subsection shall\ninclude, at a minimum and to the extent reasonably known by, or available to,\nthe deployer:_\n\n_(A) A statement by the deployer disclosing the purpose, intended use cases\nand deployment context of, and benefits afforded by, the high-risk artificial\nintelligence system;_\n\n_(B) An analysis of whether the deployment of the high-risk artificial\nintelligence system poses any known or reasonably foreseeable risks of\nalgorithmic discrimination and, if so, the nature of such algorithmic\ndiscrimination and the steps that have been taken to mitigate such risks;_\n\n_(C) A description of:_\n\n_(I) The categories of data the high-risk artificial intelligence system\nprocesses as inputs; and_\n\n_(II) The outputs such high-risk artificial intelligence system produces;_\n\n_(D) If the deployer used data to customize the high-risk artificial\nintelligence system, an overview of the categories of data the deployer used\nto customize such high-risk artificial intelligence system;_\n\n_(E) Any metrics used to evaluate the performance and known limitations of the\nhigh-risk artificial intelligence system;_\n\n_(F) A description of any transparency measures taken concerning the high-risk\nartificial intelligence system including, but not limited to, any measures\ntaken to disclose to a consumer that such high-risk artificial intelligence\nsystem is in use when such high-risk artificial intelligence system is in use;\nand_\n\n_(G) A description of the post-deployment monitoring and user safeguards\nprovided concerning such high-risk artificial intelligence system including,\nbut not limited to, the oversight, use and learning process established by the\ndeployer to address issues arising from deployment of such high-risk\nartificial intelligence system._\n\n_(ii) In addition to the statement, analysis, descriptions, overview and\nmetrics required under subsection (c)(2) of this section, an impact assessment\ncompleted pursuant to this subsection following an intentional and substantial\nmodification made to a high-risk artificial intelligence system on or after\nOctober 1, 2026, shall include a statement disclosing the extent to which the\nhigh-risk artificial intelligence system was used in a manner that was\nconsistent with, or varied from, the developer 's intended uses of such high-\nrisk artificial intelligence system._\n\n_(iii) A single impact assessment may address a comparable set of high-risk\nartificial intelligence systems deployed by a deployer._\n\n_(iv) If a deployer, or a third party contracted by the deployer, completes an\nimpact assessment for the purpose of complying with another applicable law or\nregulation, such impact assessment shall be deemed to satisfy the requirements\nestablished in this subsection if such impact assessment is reasonably similar\nin scope and effect to the impact assessment that would otherwise be completed\npursuant to this subsection._\n\n_(v) A deployer shall maintain the most recently completed impact assessment\nof a high-risk artificial intelligence system as required under this\nsubsection, all records concerning each such impact assessment and all prior\nimpact assessments, if any, for a period of at least three (3) years following\nthe final deployment of the high-risk artificial intelligence system._\n\n_(d) Except as provided in subsection (g) of this section, a deployer, or a\nthird party contracted by the deployer, shall review, not later than October\n1, 2026, and at least annually thereafter, the deployment of each high-risk\nartificial intelligence system deployed by the deployer to ensure that such\nhigh-risk artificial intelligence system is not causing algorithmic\ndiscrimination._\n\n_(e)(1) Beginning on October 1, 2026, and before a deployer deploys a high-\nrisk artificial intelligence system to make, or be a substantial factor in\nmaking, a consequential decision concerning a consumer, the deployer shall:_\n\n_(i) Notify the consumer that the deployer has deployed a high-risk artificial\nintelligence system to make, or be a substantial factor in making, such\nconsequential decision; and_\n\n_(ii) Provide to the consumer:_\n\n_(A) A statement disclosing:_\n\n_(I) The purpose of such high-risk artificial intelligence system; and_\n\n_(II) The nature of such consequential decision;_\n\n_(B) The right to opt-out of any automated decision-making based on the\nconsumer 's personal data; _\n\n_(C) Contact information for such deployer;_\n\n_(D) A description, in plain language, of such high-risk artificial\nintelligence system; and_\n\n_(E) Instructions on how to access the statement made available pursuant to\nsubsection (f) of this section._\n\n_(2) Beginning on October 1, 2026, a deployer that has deployed a high-risk\nartificial intelligence system to make, or as a substantial factor in making,\na consequential decision concerning a consumer shall, if such consequential\ndecision is adverse to the consumer, provide to such consumer:_\n\n_(i) A statement disclosing the principal reason or reasons for such adverse\nconsequential decision including, but not limited to:_\n\n_(A) The degree to which, and manner in which, the high-risk artificial\nintelligence system contributed to such adverse consequential decision;_\n\n_(B) The type of data that were processed by such high-risk artificial\nintelligence system in making such adverse consequential decision; and_\n\n_(C) The source of the data described in this subsection;_\n\n_(ii) An opportunity to:_\n\n_(A) Examine the personal data that the high-risk artificial intelligence\nsystem processed in making, or as a substantial factor in making, such adverse\nconsequential decision; and_\n\n_(B) Correct any incorrect personal data described in this subsection; and_\n\n_(3)(i) Except as provided in this subsection, an opportunity to appeal such\nadverse consequential decision if such adverse consequential decision is based\nupon inaccurate personal data, taking into account both the nature of such\npersonal data and the purpose for which such personal data was processed. Such\nappeal shall, if technically feasible, allow for human review._\n\n_(ii) No deployer shall be required to provide an opportunity to appeal\npursuant to subsection (e)(3)(i) of this section in any instance in which\nproviding such opportunity to appeal is not in the best interest of the\nconsumer including, but not limited to, in any instance in which any delay\nmight pose a risk to the life or safety of the consumer._\n\n_(iii) The deployer shall provide the notice, statements, information,\ndescription and instructions required under the provisions of this\nsubsection:_\n\n_(A) Directly to the consumer;_\n\n_(B) In plain language;_\n\n_(C) In all languages in which such deployer, in the ordinary course of such\ndeployer 's business, provides contracts, disclaimers, sale announcements and\nother information to consumers; and_\n\n_(D) In a format that is accessible to consumers with disabilities._\n\n_(f)(1) Beginning on October 1, 2026, and except as provided in subsection (g)\nof this section, each deployer shall make available, in a manner that is clear\nand readily available on such deployer 's Internet website, a statement\nsummarizing:_\n\n_(i) The types of high-risk artificial intelligence systems that are currently\ndeployed by such deployer;_\n\n_(ii) How such deployer manages any known or reasonably foreseeable risks of\nalgorithmic discrimination that may arise from deployment of each high-risk\nartificial intelligence system described in this subsection; and_\n\n_(iii) In detail, the nature, source and extent of the information collected\nand used by such deployer._\n\n_(2) Each deployer shall periodically update the statement described in\nsubsection(f)(1) of this section._\n\n_(g) The provisions of subsections (b) through (d), inclusive, of this section\nand subsection (f) of this section shall not apply to a deployer if, at the\ntime the deployer deploys a high-risk artificial intelligence system and at\nall times while the high-risk artificial intelligence system is deployed:_\n\n_(1) The deployer:_\n\n_(i) Has entered into a contract with the developer in which the developer has\nagreed to assume the deployer 's duties under subsections (b) through (d),\ninclusive, of this section and subsection (f) of this section and _\n\n_(ii) Does not exclusively use such deployer 's own data to train such high-\nrisk artificial intelligence system;_\n\n_(2) Such high-risk artificial intelligence system:_\n\n_(i) Is used for the intended uses that are disclosed to such deployer; and_\n\n_(ii) Continues learning based on a broad range of data sources and not solely\nbased on the deployer 's own data; and_\n\n_(3) Such deployer makes available to consumers any impact assessment that:_\n\n_(i) The developer of such high-risk artificial intelligence system has\ncompleted and provided to such deployer; and_\n\n_(ii) Includes information that is substantially similar to the information\nincluded in the statement, analysis, descriptions, overview and metrics\nrequired pursuant to the provisions of this section._\n\n_(h) If a deployer deploys a high-risk artificial intelligence system on or\nafter October 1, 2026, and subsequently discovers that the high-risk\nartificial intelligence system has caused algorithmic discrimination to at\nleast one thousand (1,000) consumers, the deployer shall send to the attorney\ngeneral, in a form and manner prescribed by the attorney general, a notice\ndisclosing such discovery. The deployer shall send such notice to the attorney\ngeneral without unreasonable delay but in no event later than ninety (90) days\nafter the date on which the deployer discovered such algorithmic\ndiscrimination._\n\n_(i) Nothing in subsections (b) through (h), inclusive, of this section shall\nbe construed to require a deployer to disclose any information that is a trade\nsecret or otherwise protected from disclosure under state or federal law. If a\ndeployer withholds any information from a consumer under this subsection, the\ndeployer shall send notice to the consumer disclosing:_\n\n_(A) That the deployer is withholding such information from such consumer;\nand_\n\n_(B) The basis for the deployer 's decision to withhold such information from\nsuch consumer._\n\n_(j) Beginning on October 1, 2026, the attorney general may require that a\ndeployer, or a third party contracted by the deployer as set forth in\nsubsection (c) of this section, as applicable, disclose to the attorney\ngeneral, as part of an investigation conducted by the attorney general, not\nlater than ninety (90) days after a request by the attorney general and in a\nform and manner prescribed by the attorney general, the risk management policy\nimplemented pursuant to subsection (b) of this section, impact assessment\ncompleted pursuant to subsection (c) of this section or records maintained\npursuant to the provisions of subsection (c) of this section. The attorney\ngeneral may evaluate such risk management policy, impact assessment or records\nto ensure compliance with the provisions of this section. In disclosing such\nrisk management policy, impact assessment or records to the attorney general\npursuant to this subsection, the deployer or third-party contractor, as\napplicable, may designate such risk management policy, impact assessment or\nrecords as including any information that is exempt from disclosure under\nsubsection (i) of this section or chapter 2 of title 38 ( \"access to public\nrecords\"). To the extent such risk management policy, impact assessment or\nrecords include such information, such risk management policy, impact\nassessment or records shall be exempt from disclosure pursuant to the\nprovisions of this chapter or title 38. To the extent any information\ncontained in such risk management policy, impact assessment or record is\nsubject to the attorney-client privilege or work product protection, such\ndisclosure shall not constitute a waiver of such privilege or protection._\n\n_**_6-61-6. Technical documentation._ ** _\n\n_(a) Beginning on October 1, 2026, each developer of a general-purpose\nartificial intelligence model shall, except as provided in subsection (b) of\nthis section:_\n\n_(1)(i) Create and maintain technical documentation for the general-purpose\nartificial intelligence model, which technical documentation shall:_\n\n_(A) Include the training and testing processes for such general-purpose\nartificial intelligence model;_\n\n_(B) Include at least the following information, as appropriate, considering\nthe size and risk profile of such general-purpose artificial intelligence\nmodel:_\n\n_(I) The tasks such general-purpose artificial intelligence model is intended\nto perform;_\n\n_(II) The type and nature of artificial intelligence systems in which such\ngeneral-purpose artificial intelligence model is intended to be integrated;_\n\n_(III) Acceptable use policies for such general-purpose artificial\nintelligence model;_\n\n_(IV) The date such general-purpose artificial intelligence model is\nreleased;_\n\n_(V) The methods by which such general-purpose artificial intelligence model\nis distributed; and_\n\n_(VI) The modality and format of inputs and outputs for such general-purpose\nartificial intelligence model._\n\n_(C) Include a description of the data that were used for purposes of\ntraining, testing and validation of such general-purpose artificial\nintelligence model, which description shall be appropriate considering the\nsize and risk profile of such general-purpose artificial intelligence model\nand include, at a minimum, a description of the following:_\n\n_(I) The type and provenance of such data;_\n\n_(II) Curation methodologies used for such data;_\n\n_(III) How such data were obtained and selected;_\n\n_(IV) All measures used to identify unsuitable data sources; and_\n\n_(V) Where applicable, methods used to detect identifiable biases;_\n\n_(D) Be reviewed and revised at least annually or more frequently as necessary\nto maintain the accuracy of such technical documentation;_\n\n_(E) Establish, implement and maintain a policy to comply with federal and\nstate copyright laws;_\n\n_(F) Create, implement, maintain and make available to persons that intend to\nintegrate such general-purpose artificial intelligence model into such persons\n' artificial intelligence systems documentation and information that:_\n\n_(2) Enables such persons to:_\n\n_(i) Understand the capabilities and limitations of such general-purpose\nartificial intelligence model; and_\n\n_(ii) Comply with such persons ' obligations under this chapter;_\n\n_(3) Discloses, at a minimum:_\n\n_(i) The technical means required for such general-purpose artificial\nintelligence model to be integrated into such persons ' artificial\nintelligence systems; _\n\n_(ii) The information listed in subsection (a)(1) of this section; and_\n\n_(iii) The description required under subsection (a)(1)(i)(C) of this section;\nand_\n\n_(4) Except as provided in subsection (b) of this section, is reviewed and\nrevised at least annually or more frequently as necessary to maintain the\naccuracy of such documentation and information._\n\n_(b)(1) The provisions of subsection (a)(1) and (a)(2)(c) of this section\nshall not apply to a developer that develops, or intentionally and\nsubstantially modifies, a general-purpose artificial intelligence model on or\nafter October 1, 2026, if:_\n\n_(i) The developer releases such general-purpose artificial intelligence model\nunder a free and open-source license that allows for:_\n\n_(A) Access to, and modification, distribution and usage of, such general-\npurpose artificial intelligence model; and_\n\n_(B) The parameters of such general-purpose artificial intelligence model to\nbe made publicly available as set forth in this subsection; and_\n\n_(ii) Unless such general-purpose artificial intelligence model is deployed as\na high-risk artificial intelligence system, the parameters of such general-\npurpose artificial intelligence model including, but not limited to, the\nweights and information concerning the model architecture and model usage for\nsuch general-purpose artificial intelligence model, are made publicly\navailable; or_\n\n_(iii) The general-purpose artificial intelligence model is:_\n\n_(A) Not offered for sale in the market;_\n\n_(B) Not intended to interact with consumers; and_\n\n_(C) Solely utilized:_\n\n_(I) For an entity 's internal purposes; or _\n\n_(II) Under an agreement between multiple entities for such entities '\ninternal purposes._\n\n_(3) The provisions of this section shall not apply to a developer that\ndevelops, or intentionally and substantially modifies, a general-purpose\nartificial intelligence model on or after October 1, 2026, if such general\npurpose artificial intelligence model performs tasks exclusively related to an\nentity 's internal management affairs including, but not limited to, ordering\noffice supplies or processing payments._\n\n_(4) A developer that takes any action under an exemption established in this\nsubsection shall bear the burden of demonstrating that such action qualifies\nfor such exemption._\n\n_(5) A developer that is exempt under this subsection shall establish and\nmaintain an artificial intelligence risk management framework, which framework\nshall:_\n\n_(i) Be the product of an iterative process and ongoing efforts; and_\n\n_(ii) Include, at a minimum:_\n\n_(A) An internal governance function;_\n\n_(B) A map function that shall establish the context to frame risks;_\n\n_(C) A risk management function; and_\n\n_(D) A function to measure identified risks by assessing, analyzing and\ntracking such risks._\n\n_(c) Nothing in subsection (a) of this section shall be construed to require a\ndeveloper to disclose any information that is a trade secret or otherwise\nprotected from disclosure under state or federal law._\n\n_(d) Beginning on October 1, 2026, the attorney general may require that a\ndeveloper disclose to the attorney general, as part of an investigation\nconducted by the attorney general, not later than ninety (90) days after a\nrequest by the attorney general and in a form and manner prescribed by the\nattorney general, any documentation maintained pursuant to this section. The\nattorney general may evaluate such documentation to ensure compliance with the\nprovisions of this section. In disclosing any documentation to the attorney\ngeneral pursuant to this subsection, the developer may designate such\ndocumentation as including any information that is exempt from disclosure\nunder subsection (c) of this section or chapter 2 of title 38 ( \"access to\npublic records\"). To the extent such documentation includes such information,\nsuch documentation shall be exempt from disclosure under the provision of this\nchapter or chapter 2 of title 38. To the extent any information contained in\nsuch documentation is subject to the attorney-client privilege or work product\nprotection, such disclosure shall not constitute a waiver of such privilege or\nprotection._\n\n_**_6-61-7. Artificial intelligence system designation._ ** _\n\n_(a) Beginning on October 1, 2026, and except as provided in subsections (b)\nand (c) of this section, the developer of an artificial intelligence system\nincluding, but not limited to, a general-purpose artificial intelligence\nmodel, that generates or manipulates synthetic digital content shall:_\n\n_(1) Ensure that the outputs of such artificial intelligence system are marked\nand detectable as synthetic digital content, and that such outputs are so\nmarked and detectable:_\n\n_(i) Not later than the time that consumers who did not create such outputs\nfirst interact with, or are exposed to, such outputs; and_\n\n_(ii) In a manner that:_\n\n_(A) Is detectable by consumers; and_\n\n_(B) Complies with any applicable accessibility requirements; and_\n\n_(2) As far as technically feasible and in a manner that is consistent with\nany nationally or internationally recognized technical standards, ensure that\nsuch developer 's technical solutions are effective, interoperable, robust and\nreliable, considering: _\n\n_(i) The specificities and limitations of different types of synthetic digital\ncontent;_\n\n_(ii) The implementation costs; and_\n\n_(iii) The generally acknowledged state of the art._\n\n_(b) If the synthetic digital content described in subsection (a) of this\nsection is in an audio, image or video format, and such synthetic digital\ncontent forms part of an evidently artistic, creative, satirical, fictional\nanalogous work or program, the disclosure required under said subsection shall\nbe limited to a disclosure that does not hinder the display or enjoyment of\nsuch work or program._\n\n_(c) The provisions of subsection (a) of this section shall not apply to:_\n\n_(1) Any synthetic digital content that:_\n\n_(i) Consists exclusively of text;_\n\n_(ii) Is published to inform the public on any matter of public interest; or_\n\n_(iii) Is unlikely to mislead a reasonable person consuming such synthetic\ndigital content; or_\n\n_(2) To the extent that any artificial intelligence system described in\nsubsection (a) of this section:_\n\n_(i) Performs an assistive function for standard editing;_\n\n_(ii) Does not substantially alter the input data provided by the developer or\nthe semantics thereof; or_\n\n_(iii) Is used to detect, prevent a violation of the provisions of this\nchapter or other laws or regulations._\n\n_**_6-61-8. Compliance with other laws._ ** _\n\n_(a) Nothing in this chapter shall be construed to restrict a developer 's,\nintegrator's, deployer's or other person's ability to:_\n\n_(1) Comply with federal, state or municipal law;_\n\n_(2) Comply with a civil, criminal or regulatory inquiry, investigation,\nsubpoena or summons by a federal, state, municipal or other governmental\nauthority;_\n\n_(3) Cooperate with a law enforcement agency concerning conduct or activity\nthat the developer, integrator, deployer or other person reasonably and in\ngood faith believes may violate federal, state or municipal law;_\n\n_(4) Investigate, establish, exercise, prepare for or defend a legal claim;_\n\n_(5) Take immediate steps to protect an interest that is essential for the\nlife or physical safety of a consumer or another individual;_\n\n_(6)(i) By any means other than facial recognition technology, prevent,\ndetect, protect against or respond to:_\n\n_(A) A security incident;_\n\n_(B) A malicious or deceptive activity; or_\n\n_(C) Identity theft, fraud, harassment or any other illegal activity._\n\n_(ii) Investigate, report or prosecute the persons responsible for any action\ndescribed in a security incident; or_\n\n_(iii) Preserve the integrity or security of systems;_\n\n_(7) Engage in public or peer-reviewed scientific or statistical research in\nthe public interest that:_\n\n_(i) Adheres to all other applicable ethics and privacy laws; and_\n\n_(ii) Is conducted in accordance with:_\n\n_(A) The provisions of 45 CFR Part 46, as amended from time to time; or_\n\n_(B) Relevant requirements established by the federal Food and Drug\nAdministration;_\n\n_(8) Conduct research, testing, development and integration activities\nregarding an artificial intelligence system or model, other than testing\nconducted under real world conditions, before such artificial intelligence\nsystem or model is placed on the market, deployed or put into service, as\napplicable;_\n\n_(9) Effectuate a product recall;_\n\n_(10) Identify and repair technical errors that impair existing or intended\nfunctionality; or_\n\n_(11) Assist another developer, integrator, deployer or person with any of the\nobligations imposed pursuant to the provisions of this chapter._\n\n_(b) The obligations imposed on developers, integrators, deployers or other\npersons under this chapter shall not apply where compliance by the developer,\nintegrator, deployer or other person with said provisions of this chapter\nshall violate an evidentiary privilege under the laws of this state._\n\n_(c) Nothing in this chapter shall be construed to impose any obligation on a\ndeveloper, integrator, deployer or other person that adversely affects the\nrights or freedoms of any person including, but not limited to, the rights of\nany person to freedom of speech or freedom of the press guaranteed in:_\n\n_(1) The First Amendment to the United States Constitution; and_\n\n_(2) The Rhode Island Constitution, Article 1,  21._\n\n_(d) Nothing in this chapter shall be construed to apply to any developer,\nintegrator, deployer, or other person:_\n\n_(1) Insofar as such developer, integrator, deployer or other person develops,\nintegrates, deploys, puts into service or intentionally and substantially\nmodifies, as applicable, a high-risk artificial intelligence system:_\n\n_(i) That has been approved, authorized, certified, cleared, developed,\nintegrated or granted by:_\n\n_(A) A federal agency, such as the federal Food and Drug Administration or the\nFederal Aviation Administration, acting within the scope of such federal\nagency 's authority; or _\n\n_(B) A regulated entity subject to supervision and regulation by the Federal\nHousing Finance Agency; or_\n\n_(ii) In compliance with standards that are:_\n\n_(A) Established by:_\n\n_(I) Any federal agency including, but not limited to, the federal Office of\nthe National Coordinator for Health Information Technology; or_\n\n_(II) A regulated entity subject to supervision and regulation by the Federal\nHousing Finance Agency; and_\n\n_(B) Substantially equivalent to, and at least as stringent as, the standards\nestablished in this chapter;_\n\n_(2) Conducting research to support an application:_\n\n_(i) For approval or certification from any federal agency including, but not\nlimited to, the Federal Aviation Administration, the Federal Communications\nCommission, or the federal Food and Drug Administration; or_\n\n_(ii) That is otherwise subject to review by any federal agency;_\n\n_(3) Performing work under, or in connection with, a contract with the United\nStates Department of Commerce, the United States Department of Defense, or the\nNational Aeronautics and Space Administration, unless such developer,\nintegrator, deployer or other person is performing such work on a high-risk\nartificial intelligence system that is used to make, or as a substantial\nfactor in making, a decision concerning employment or housing; or_\n\n_(4) That is a covered entity within the meaning of the Health Insurance\nPortability and Accountability Act of 1996, Pub. L. 104-191, and the\nregulations promulgated thereunder, as both may be amended from time to time,\nand providing healthcare recommendations that:_\n\n_(i) Are generated by an artificial intelligence system;_\n\n_(ii) Require a healthcare provider to take action to implement such\nrecommendations; and_\n\n_(iii) Are not considered to be high risk._\n\n_(e) Nothing in this chapter shall be construed to apply to any artificial\nintelligence system that is acquired by or for the federal government or any\nfederal agency or department including, but not limited to, the United States\nDepartment of Commerce, the United States Department of Defense, or the\nNational Aeronautics and Space Administration, unless such artificial\nintelligence system is a high-risk artificial intelligence system that is used\nto make, or as a substantial factor in making, a decision concerning\nemployment or housing._\n\n_(f) Any insurer, subject to the provisions of title 27, fraternal benefit\nsociety, within the meaning of  27-25-1, or health carrier, as defined in \n27-18.6-2, shall be deemed to be in full compliance with the provisions of\nthis chapter if such insurer, fraternal benefit society or health carrier has\nimplemented and maintains a written artificial intelligence systems program in\naccordance with all requirements established by the insurance commissioner\ndefined in  27-2.4-2._\n\n_(g)(1) Any financial institution, out-of-state financial institution, Rhode\nIsland credit union, federal credit union or out-of-state credit union, or any\nbranch or subsidiary thereof, shall be deemed to be in full compliance with\nthe provisions of this chapter if such financial institution, out-of-state\nfinancial institution, Rhode Island credit union, federal credit union, out-\nof-state credit union, branch or subsidiary is subject to examination by any\nstate or federal prudential regulator under any published guidance or\nregulations that apply to the use of high-risk artificial intelligence systems\nand such guidance or regulations:_\n\n_(i) Impose requirements that are substantially equivalent to, and at least as\nstringent as, the requirements set forth in this chapter; and_\n\n_(ii) At a minimum, require such financial institution, out-of-state financial\ninstitution, Rhode Island credit union, federal credit union, out-of-state\ncredit union, branch or subsidiary to:_\n\n_(A) Regularly audit such financial institution 's, out-of-state financial\ninstitution's, Rhode Island credit union's, federal credit union's, out-of-\nstate credit union's, branch 's or subsidiary's use of high-risk artificial\nintelligence systems for compliance with state and federal anti-discrimination\nlaws and regulations applicable to such financial institution, out-of-state\nfinancial institution, Rhode Island credit union, federal credit union, out-\nof-state credit union, branch or subsidiary; and _\n\n_(B) Mitigate any algorithmic discrimination caused by the use of a high-risk\nartificial intelligence system or any risk of algorithmic discrimination that\nis reasonably foreseeable as a result of the use of a high-risk artificial\nintelligence system._\n\n_(2) For the purposes of this section, \"branch\", \"financial institution\",\n\"Rhode Island credit union\", and \"federal credit union\" have the same meaning\nas provided in  19-1-1. _\n\n_(3) For the purposes of this section, \"out-of-state financial institution\"\nmeans a financial institution whose principal office is located in any other\nstate._\n\n_(4) For the purposes of this section, \"out-of-state credit union\" means a\ncredit union whose principal office is located in any other state._\n\n_(h) If a developer, integrator, deployer or other person engages in any\naction pursuant to an exemption set forth in subsections (a) through (g),\ninclusive, of this section, the developer, integrator, deployer or other\nperson bears the burden of demonstrating that such action qualifies for such\nexemption._\n\n_**_6-61-9. Enforcement._ ** _\n\n_(a) The attorney general shall have exclusive authority to enforce the\nprovisions of this chapter._\n\n_(b) Except as provided in subsection (f) of this section, during the period\nbeginning on October 1, 2026, and ending on September 30, 2027, the attorney\ngeneral shall, prior to initiating any action for a violation of any provision\nof this chapter, issue a notice of violation to the developer, integrator,\ndeployer, or other person if the attorney general determines that it is\npossible to cure such violation. If the developer, integrator, deployer or\nother person fails to cure such violation not later than sixty (60) days after\nreceipt of the notice of violation, the attorney general may bring an action\npursuant to this chapter._\n\n_(c) Except as provided in subsection (f) of this section, beginning on\nOctober 1, 2027, the attorney general may, in determining whether to grant a\ndeveloper, integrator, deployer or other person the opportunity to cure a\nviolation described in subsection (b) of this section, consider:_\n\n_(1) The number of violations;_\n\n_(2) The size and complexity of the developer, integrator, deployer or other\nperson;_\n\n_(3) The nature and extent of the developer 's, integrator's, deployer's or\nother person's business; _\n\n_(4) The substantial likelihood of injury to the public;_\n\n_(5) The safety of persons or property; and_\n\n_(6) Whether such violation was likely caused by human or technical error._\n\n_(d) Nothing in this chapter shall be construed as providing the basis for a\nprivate right of action for violations of this chapter._\n\n_(e) Except as provided in subsections (a) through (d), inclusive, of this\nsection and subsection (f) of this section, a violation of the requirements\nestablished in this chapter shall constitute an unfair trade practice for\npurposes of  6-13.1-5 and shall be enforced solely by the attorney general._\n\n_(f)(1) In any action commenced by the attorney general for any violation of\nthis chapter, it shall be an affirmative defense that the developer,\nintegrator, deployer, or other person:_\n\n_(i) Discovered a violation of any provision of this chapter through red-\nteaming;_\n\n_(ii) Not later than sixty (60) days after discovering the violation as set\nforth in subsection (f)(1)(i) of this section:_\n\n_(A) Cures such violation; and_\n\n_(B) Provides to the attorney general, in a form and manner prescribed by the\nattorney general, notice that such violation has been cured and evidence that\nany harm caused by such violation has been mitigated; and_\n\n_(iii) Is otherwise in compliance with the latest version of:_\n\n_(A) The \"Artificial Intelligence Risk Management Framework\" published by the\nNational Institute of Standards and Technology; _\n\n_(B) ISO or IEC 42001 of the International Organization for Standardization;_\n\n_(C) A nationally or internationally recognized risk management framework for\nartificial intelligence systems, other than the risk management frameworks\nspecified in this subsection, that imposes requirements that are substantially\nequivalent to, and at least as stringent as, the requirements set forth in\nthis chapter; or_\n\n_(D) Any risk management framework for artificial intelligence systems that is\nsubstantially equivalent to, and at least as stringent as, the risk management\nframeworks described in this subsection._\n\n_(2) The developer, integrator, deployer or other person bears the burden of\ndemonstrating to the attorney general that the requirements established in\nsubsection (f)(1) of this section have been satisfied._\n\n_(3) Nothing in this this chapter including, but not limited to, the\nenforcement authority granted to the attorney general under this section,\nshall be construed to preempt or otherwise affect any right, claim, remedy,\npresumption or defense available at law or in equity. Any rebuttable\npresumption or affirmative defense established under this chapter shall apply\nonly to an enforcement action brought by the attorney general pursuant to this\nsection and shall not apply to any right, claim, remedy, presumption, or\ndefense available at law or in equity._\n\nSECTION 2. This act shall take effect on October 1, 2025\n\n**EXPLANATION**\n\n**BY THE LEGISLATIVE COUNCIL**\n\n**OF**\n\n**AN ACT**\n\n**RELATING TO COMMERCIAL LAW -- GENERAL REGULATORY PROVISIONS -- ARTIFICIAL\nINTELLIGENCE ACT**\n\nThis act would establish regulations to ensure the ethical development,\nintegration, and deployment of high-risk Artificial Intelligence (AI) systems,\nparticularly those influencing consequential decisions in areas like\nemployment, education, lending, housing, healthcare, and legal services. It\nwould require developers, integrators, and deployers to use reasonable care to\nprevent algorithmic discrimination, implement risk management policies,\nconduct regular impact assessments, and provide transparency regarding the use\nof AI systems. The act also would require developers to disclose known risks\nto the attorney general and affected parties, while deployers are required to\nnotify consumers when AI is used in decision-making and offer avenues to\nappeal adverse outcomes. The act would further mandates that synthetic digital\ncontent generated by AI be clearly marked, with exceptions for informational\ncontent. Additionally, this act would provide exemptions for AI systems\ngoverned by equivalent federal standards, used for internal business purposes,\nor developed for specific federal agencies. The attorney general would hold\nexclusive enforcement authority, with a focus on encouraging compliance before\npursuing legal action.\n\nThis act would take effect on October 1, 2025\n\nCopyright (C) 2025 State Net  \n  \n---\n\n",
      "latest_version": true
    }
  ]
}