{
  "bill_id": "NJ2024000SR121",
  "source_url": "http://custom.statenet.com/public/resources.cgi?id=ID:bill:NJ2024000SR121&cuiq=93d84396-c63b-526a-b152-38b7f79b4cfd&client_md=e4f6fea4-27b4-5d41-b7d3-766fe52569f0",
  "versions": [
    {
      "date": "01/14/2025",
      "label": "Introduced",
      "url": "https://custom.statenet.com/public/resources.cgi?mode=show_text&id=ID:bill:NJ2024000SR121&verid=NJ2024000SR121_20250114_0_I&",
      "raw_html": "<html>\n<head>\n<title>Bill Resource</title>\n\n<!--   <link href=\"https://custom.statenet.com/network/Common/css/extregtext.css\" rel=\"stylesheet\" type=\"text/css\" />-->\n   <link href=\"https://custom.statenet.com/network/Common/css/xmltext-2.0.css\" rel=\"stylesheet\" type=\"text/css\" />\n   <link href=\"https://custom.statenet.com/network/Common/css/additional-text.css\" rel=\"stylesheet\" type=\"text/css\" />\n\n\t<style type=\"text/css\">\n<!--\n\ntd, body {\n     background-color: white;\n\tfont-family: Verdana, Arial, Helvetica, sans-serif;\n\tfont-size: 12px;\n}\n\n.resourceContainer {\n   border: 1px solid black;\n}\n-->\n</style>\n</head>\n<body>\n\n    <div style=\"width: 750px; margin: auto\">\n       <div style=\"font-size: .8em;margin-bottom: 10px\"><table width=\"100%\"><tr><td align=\"left\" style=\"font-size: .8em;\"><div>The following has special meaning:</div>\n<div><u class=\"amendmentInsertedText\">green underline denotes added text</u></div>\n<div><strike class=\"amendmentDeletedText\">red struck out text denotes deleted text</strike></div></td> <td align=\"right\"><a href=\"https://www.lexisnexis.com/statenet/\"><img alt=\"Powered by State Net\" src=\"https://custom.statenet.com/network/poweredby.gif\" /></a></td></tr></table></div><table id=\"text-identifier\"><tr><td class=\"key\">2024 NJ SR 121</td> <td><table><tr><td class=\"label\">Author:</td> <td>Mukherji</td></tr> <tr><td class=\"label\">Version:</td> <td>Introduced</td></tr> <tr><td class=\"label\">Version Date:</td> <td>01/14/2025</td></tr></table></td></tr></table><div class=\"documentBody\">\n  <a name=\"head_document_section\"></a><div class=\"head\">\n   <p class=\"center\">SENATE RESOLUTION No. 121 </p>\n   <p class=\"indent\">STATE OF NEW JERSEY</p>\n   <p class=\"center\">221st LEGISLATURE</p>\n   <p class=\"center\">INTRODUCED JANUARY 14, 2025</p>\n   <p class=\"indent\">Sponsored by:</p>\n   <p class=\"indent\">Senator RAJ MUKHERJI</p>\n   <p class=\"indent\">District 32 (Hudson)</p>\n   <p class=\"indent\">Senator JOSEPH A. LAGANA</p>\n   <p class=\"indent\">District 38 (Bergen)</p>\n   <p class=\"indent\">SYNOPSIS</p>\n   <p class=\"indent\"> Urges generative artificial intelligence companies to make voluntary commitments regarding employee whistleblower protections. </p>\n   <p class=\"indent\">CURRENT VERSION OF TEXT </p>\n   <p class=\"indent\"> As introduced.</p>\n  </div>\n  <a name=\"code_document_section\"></a><div class=\"code\">\n   <p class=\"indent\">A Senate Resolution urging generative artificial intelligence companies to make voluntary commitments regarding employee whistleblower protections.</p>\n  </div>\n  <a name=\"text_document_section\"></a><div class=\"text\">\n   <p class=\"indent\">Whereas, Artificial intelligence technology has the potential to provide unprecedented benefits to humanity, but it also poses serious risks; and </p>\n   <p class=\"indent\">Whereas, The risks associated with artificial intelligence technology are of grave concern and range from the further entrenchment of existing inequalities, to the manipulation and dissemination of misinformation; and</p>\n   <p class=\"indent\">Whereas, Many risks associated with artificial intelligence are currently unregulated, and existing whistleblower protections are inadequate to protect employees from retaliation for disclosing information regarding company risk-related concerns; and</p>\n   <p class=\"indent\">Whereas, In the absence of government oversight, employees of artificial intelligence companies possess the most comprehensive knowledge of the risks involved and are among the few individuals capable of holding the companies accountable; and</p>\n   <p class=\"indent\">Whereas, Broad confidentiality agreements prevent employees of artificial intelligence companies from voicing concerns beyond the company failing to address the issues; and </p>\n   <p class=\"indent\">Whereas, Artificial intelligence companies such as OpenAI, Anthropic, and Google have also acknowledged the risks posed by artificial intelligence technology; and</p>\n   <p class=\"indent\">Whereas, Independent evaluation is critical to identifying the risk posed by artificial intelligence systems, yet the terms of service and enforcement strategies used by artificial intelligence companies disincentive good faith safety evaluations for fear of legal reprisal or account suspension; and</p>\n   <p class=\"indent\">Whereas, To varying degrees, artificial companies provide legal safe harbor for system evaluation for security research but do not include technical safe harbor for good faith research that may lead to account termination, such as evaluating systems on the generation of hate speech, misinformation, or abusive imagery, thereby inhibiting the discovery of all forms of system flaws; and</p>\n   <p class=\"indent\">Whereas, Google, OpenAI, Microsoft, Anthropic, Amazon, and Meta participate in the Frontier Model Forum, enabling cross-organizational collaboration on artificial intelligence safety and responsibility and enabling independent, standardized evaluations, but do not address concerns of unbiased assessment that would be afforded through both legal and technical safe harbor; and</p>\n   <p class=\"indent\">Whereas, The risks of artificial intelligence may be mitigated by the commitment of artificial intelligence companies to certain principles concerning employee protections, transparency, and safety; now, therefore, </p>\n   <span>\n    <p class=\"indent\"> Be It Resolved by the Senate of the State of New Jersey:</p>\n   </span>\n   <p class=\"indent\"> 1. This House urges generative artificial intelligence companies to commit to the following principles:</p>\n   <p class=\"indent\"> a. The company shall not enter into or enforce any agreement prohibiting disparagement or criticism of the company for risk-related concerns or retaliate for risk-related criticism by hindering any vested economic benefit;</p>\n   <p class=\"indent\"> b. The company shall facilitate a verifiably anonymous process for current and former employees to raise risk-related concerns to the company board, to regulators, and to an appropriate independent organization with relevant expertise;</p>\n   <p class=\"indent\"> c. The company shall support a culture of open criticism and allow current and former employees to raise risk-related concerns about its technologies to the public, to the company board, to regulators, or an appropriate independent organization with relevant expertise, so long as trade secrets and other intellectual property interests are appropriately protected;</p>\n   <p class=\"indent\"> d. The company shall provide legal and technical safe harbor for good faith system evaluation, ensuring safety from legal reprisal, account suspension, or termination, while maintaining the protection of trade secrets and other intellectual property. Safe harbor should enable independent identification of all forms of risks posed by artificial intelligence systems;</p>\n   <p class=\"indent\"> e. The company shall not retaliate against current and former employees who publicly share risk-related confidential information after other processes have failed; and</p>\n   <p class=\"indent\"> f. Employees shall retain the freedom to publicly report concerns until the creation of an appropriate process for anonymously reporting concerns to the company board, regulators, and an independent organization with relevant expertise. Any effort to report risk-related concerns should avoid releasing confidential information unnecessarily. </p>\n   <p class=\"indent\"> 2. Copies of this resolution, as filed with the Secretary of State, shall be transmitted by the Secretary of the Senate to the Chief Executive Officers of leading generative artificial intelligence companies including, but not limited to, OpenAI, Anthropic, Google, Inflection, Meta, Midjourney, and Cohere.</p>\n  </div>\n  <a name=\"digest_document_section\"></a><div class=\"digest\">\n   <p class=\"center\">STATEMENT</p>\n   <p class=\"indent\"> This resolution urges generative artificial intelligence companies to make voluntary commitments to protect employees who raise risk-related concerns.</p>\n   <p class=\"indent\"> Artificial intelligence technology has the potential to provide unprecedented benefits to humanity but also poses serious risks, such as perpetuating inequalities, manipulation and misinformation, and the potential loss of control of autonomous artificial intelligence systems. Many risks associated with artificial intelligence are currently unregulated, and existing whistleblower protections are inadequate to protect employees from retaliation for publicly disclosing concerns. </p>\n   <p class=\"indent\"> In the absence of government oversight, employees of artificial intelligence companies are among the few individuals capable of holding the companies accountable. However, broad confidentiality agreements prevent employees from voicing concerns beyond the company failing to address the issues. </p>\n   <p class=\"indent\"> Additionally, independent evaluation is critical to identifying the risk posed by artificial intelligence systems, but is stymied by the lack of both legal and technical safe harbor, without which evaluators face legal reprisal or account suspension or termination. Legal safe harbor protects evaluators from legal reprisal, and technical safe harbor protects evaluators from account suspension or termination.</p>\n   <p class=\"indent\"> The resolution urges generative artificial intelligence companies to make voluntary commitments to mitigate the risks of artificial intelligence by adhering to the following principles:</p>\n   <p class=\"indent\"> (1) The company will not enter into or enforce any agreement prohibiting disparagement or criticism of the company for risk-related concerns or retaliate for risk-related criticism by hindering any vested economic benefit;</p>\n   <p class=\"indent\"> (2) The company will facilitate a verifiably anonymous process for current and former employees to raise risk-related concerns to the company board, to regulators, and to an appropriate independent organization with relevant expertise;</p>\n   <p class=\"indent\"> (3) The company will support a culture of open criticism and allow current and former employees to raise risk-related concerns about its technologies to the public, to the company board, to regulators, or to an appropriate independent organization with relevant expertise, so long as trade secrets and other intellectual property interests are appropriately protected;</p>\n   <p class=\"indent\"> (4) The company will provide legal and technical safe harbor for good faith system evaluation, ensuring safety from legal reprisal, account suspension, or termination, while maintaining the protection of trade secrets and other intellectual property. Safe harbor should enable independent identification of all forms of risks posed by artificial intelligence systems;</p>\n   <p class=\"indent\"> (5) The company will not retaliate against current and former employees who publicly share risk-related confidential information after other processes have failed. </p>\n   <p class=\"indent\"> (6) Current and former employees should retain the freedom to publicly report concerns until the creation of an adequate process for anonymously raising concerns. Efforts to report risk-related concerns should avoid releasing confidential information unnecessarily. </p>\n  </div>\n </div>\n    </div>\t\n<table cellpadding=0 cellspacing=0 width=\"100%\">\n   <tr>\n      <td>\n          Copyright &copy; 2025 State Net\n      </td>\n<BR>\n<!--???MOVED INTO resources.cgi      <td align=\"right\">\n          <img src=\"https://custom.statenet.com/network/poweredby.gif\" alt=\"Powered by State Net\">\n      </td>-->\n\n    </tr>\n</table>\n</body></html>\n",
      "markdown": "The following has special meaning: _green underline denotes added text_ ~~red struck out text denotes deleted text~~ | [![Powered by State Net](https://custom.statenet.com/network/poweredby.gif)](https://www.lexisnexis.com/statenet/)  \n---|---  \n  \n2024 NJ SR 121 | | Author: | Mukherji  \n---|---  \nVersion: | Introduced  \nVersion Date: | 01/14/2025  \n  \nSENATE RESOLUTION No. 121\n\nSTATE OF NEW JERSEY\n\n221st LEGISLATURE\n\nINTRODUCED JANUARY 14, 2025\n\nSponsored by:\n\nSenator RAJ MUKHERJI\n\nDistrict 32 (Hudson)\n\nSenator JOSEPH A. LAGANA\n\nDistrict 38 (Bergen)\n\nSYNOPSIS\n\nUrges generative artificial intelligence companies to make voluntary\ncommitments regarding employee whistleblower protections.\n\nCURRENT VERSION OF TEXT\n\nAs introduced.\n\nA Senate Resolution urging generative artificial intelligence companies to\nmake voluntary commitments regarding employee whistleblower protections.\n\nWhereas, Artificial intelligence technology has the potential to provide\nunprecedented benefits to humanity, but it also poses serious risks; and\n\nWhereas, The risks associated with artificial intelligence technology are of\ngrave concern and range from the further entrenchment of existing\ninequalities, to the manipulation and dissemination of misinformation; and\n\nWhereas, Many risks associated with artificial intelligence are currently\nunregulated, and existing whistleblower protections are inadequate to protect\nemployees from retaliation for disclosing information regarding company risk-\nrelated concerns; and\n\nWhereas, In the absence of government oversight, employees of artificial\nintelligence companies possess the most comprehensive knowledge of the risks\ninvolved and are among the few individuals capable of holding the companies\naccountable; and\n\nWhereas, Broad confidentiality agreements prevent employees of artificial\nintelligence companies from voicing concerns beyond the company failing to\naddress the issues; and\n\nWhereas, Artificial intelligence companies such as OpenAI, Anthropic, and\nGoogle have also acknowledged the risks posed by artificial intelligence\ntechnology; and\n\nWhereas, Independent evaluation is critical to identifying the risk posed by\nartificial intelligence systems, yet the terms of service and enforcement\nstrategies used by artificial intelligence companies disincentive good faith\nsafety evaluations for fear of legal reprisal or account suspension; and\n\nWhereas, To varying degrees, artificial companies provide legal safe harbor\nfor system evaluation for security research but do not include technical safe\nharbor for good faith research that may lead to account termination, such as\nevaluating systems on the generation of hate speech, misinformation, or\nabusive imagery, thereby inhibiting the discovery of all forms of system\nflaws; and\n\nWhereas, Google, OpenAI, Microsoft, Anthropic, Amazon, and Meta participate in\nthe Frontier Model Forum, enabling cross-organizational collaboration on\nartificial intelligence safety and responsibility and enabling independent,\nstandardized evaluations, but do not address concerns of unbiased assessment\nthat would be afforded through both legal and technical safe harbor; and\n\nWhereas, The risks of artificial intelligence may be mitigated by the\ncommitment of artificial intelligence companies to certain principles\nconcerning employee protections, transparency, and safety; now, therefore,\n\nBe It Resolved by the Senate of the State of New Jersey:\n\n1\\. This House urges generative artificial intelligence companies to commit to\nthe following principles:\n\na. The company shall not enter into or enforce any agreement prohibiting\ndisparagement or criticism of the company for risk-related concerns or\nretaliate for risk-related criticism by hindering any vested economic benefit;\n\nb. The company shall facilitate a verifiably anonymous process for current and\nformer employees to raise risk-related concerns to the company board, to\nregulators, and to an appropriate independent organization with relevant\nexpertise;\n\nc. The company shall support a culture of open criticism and allow current and\nformer employees to raise risk-related concerns about its technologies to the\npublic, to the company board, to regulators, or an appropriate independent\norganization with relevant expertise, so long as trade secrets and other\nintellectual property interests are appropriately protected;\n\nd. The company shall provide legal and technical safe harbor for good faith\nsystem evaluation, ensuring safety from legal reprisal, account suspension, or\ntermination, while maintaining the protection of trade secrets and other\nintellectual property. Safe harbor should enable independent identification of\nall forms of risks posed by artificial intelligence systems;\n\ne. The company shall not retaliate against current and former employees who\npublicly share risk-related confidential information after other processes\nhave failed; and\n\nf. Employees shall retain the freedom to publicly report concerns until the\ncreation of an appropriate process for anonymously reporting concerns to the\ncompany board, regulators, and an independent organization with relevant\nexpertise. Any effort to report risk-related concerns should avoid releasing\nconfidential information unnecessarily.\n\n2\\. Copies of this resolution, as filed with the Secretary of State, shall be\ntransmitted by the Secretary of the Senate to the Chief Executive Officers of\nleading generative artificial intelligence companies including, but not\nlimited to, OpenAI, Anthropic, Google, Inflection, Meta, Midjourney, and\nCohere.\n\nSTATEMENT\n\nThis resolution urges generative artificial intelligence companies to make\nvoluntary commitments to protect employees who raise risk-related concerns.\n\nArtificial intelligence technology has the potential to provide unprecedented\nbenefits to humanity but also poses serious risks, such as perpetuating\ninequalities, manipulation and misinformation, and the potential loss of\ncontrol of autonomous artificial intelligence systems. Many risks associated\nwith artificial intelligence are currently unregulated, and existing\nwhistleblower protections are inadequate to protect employees from retaliation\nfor publicly disclosing concerns.\n\nIn the absence of government oversight, employees of artificial intelligence\ncompanies are among the few individuals capable of holding the companies\naccountable. However, broad confidentiality agreements prevent employees from\nvoicing concerns beyond the company failing to address the issues.\n\nAdditionally, independent evaluation is critical to identifying the risk posed\nby artificial intelligence systems, but is stymied by the lack of both legal\nand technical safe harbor, without which evaluators face legal reprisal or\naccount suspension or termination. Legal safe harbor protects evaluators from\nlegal reprisal, and technical safe harbor protects evaluators from account\nsuspension or termination.\n\nThe resolution urges generative artificial intelligence companies to make\nvoluntary commitments to mitigate the risks of artificial intelligence by\nadhering to the following principles:\n\n(1) The company will not enter into or enforce any agreement prohibiting\ndisparagement or criticism of the company for risk-related concerns or\nretaliate for risk-related criticism by hindering any vested economic benefit;\n\n(2) The company will facilitate a verifiably anonymous process for current and\nformer employees to raise risk-related concerns to the company board, to\nregulators, and to an appropriate independent organization with relevant\nexpertise;\n\n(3) The company will support a culture of open criticism and allow current and\nformer employees to raise risk-related concerns about its technologies to the\npublic, to the company board, to regulators, or to an appropriate independent\norganization with relevant expertise, so long as trade secrets and other\nintellectual property interests are appropriately protected;\n\n(4) The company will provide legal and technical safe harbor for good faith\nsystem evaluation, ensuring safety from legal reprisal, account suspension, or\ntermination, while maintaining the protection of trade secrets and other\nintellectual property. Safe harbor should enable independent identification of\nall forms of risks posed by artificial intelligence systems;\n\n(5) The company will not retaliate against current and former employees who\npublicly share risk-related confidential information after other processes\nhave failed.\n\n(6) Current and former employees should retain the freedom to publicly report\nconcerns until the creation of an adequate process for anonymously raising\nconcerns. Efforts to report risk-related concerns should avoid releasing\nconfidential information unnecessarily.\n\nCopyright (C) 2025 State Net  \n  \n---\n\n",
      "latest_version": true
    }
  ]
}