{
  "bill_id": "CT2025000S2",
  "source_url": "http://custom.statenet.com/public/resources.cgi?id=ID:bill:CT2025000S2&cuiq=93d84396-c63b-526a-b152-38b7f79b4cfd&client_md=e4f6fea4-27b4-5d41-b7d3-766fe52569f0",
  "versions": [
    {
      "date": "01/08/2025",
      "label": "Introduced",
      "url": "https://custom.statenet.com/public/resources.cgi?mode=show_text&id=ID:bill:CT2025000S2&verid=CT2025000S2_20250108_0_I&",
      "raw_html": "<html>\n<head>\n<title>Bill Resource</title>\n\n<!--   <link href=\"https://custom.statenet.com/network/Common/css/extregtext.css\" rel=\"stylesheet\" type=\"text/css\" />-->\n   <link href=\"https://custom.statenet.com/network/Common/css/xmltext-2.0.css\" rel=\"stylesheet\" type=\"text/css\" />\n   <link href=\"https://custom.statenet.com/network/Common/css/additional-text.css\" rel=\"stylesheet\" type=\"text/css\" />\n\n\t<style type=\"text/css\">\n<!--\n\ntd, body {\n     background-color: white;\n\tfont-family: Verdana, Arial, Helvetica, sans-serif;\n\tfont-size: 12px;\n}\n\n.resourceContainer {\n   border: 1px solid black;\n}\n-->\n</style>\n</head>\n<body>\n\n    <div style=\"width: 750px; margin: auto\">\n       <div style=\"font-size: .8em;margin-bottom: 10px\"><table width=\"100%\"><tr><td align=\"left\" style=\"font-size: .8em;\"><div>The following has special meaning:</div>\n<div><u class=\"amendmentInsertedText\">green underline denotes added text</u></div>\n<div><strike class=\"amendmentDeletedText\">red struck out text denotes deleted text</strike></div></td> <td align=\"right\"><a href=\"https://www.lexisnexis.com/statenet/\"><img alt=\"Powered by State Net\" src=\"https://custom.statenet.com/network/poweredby.gif\" /></a></td></tr></table></div><table id=\"text-identifier\"><tr><td class=\"key\">2025 CT S 2</td> <td><table><tr><td class=\"label\">Author:</td> <td>Looney</td></tr> <tr><td class=\"label\">Version:</td> <td>Introduced</td></tr> <tr><td class=\"label\">Version Date:</td> <td>01/08/2025</td></tr></table></td></tr></table><div class=\"documentBody\">\n  <a name=\"head_document_section\"></a><div class=\"head\">\n   <p class=\"center\">\n    <b>STATE OF CONNECTICUT</b>\n   </p>\n   <p class=\"center\">General Assembly</p>\n   <p class=\"center\">\n    <b>Proposed Bill No. 2</b>\n   </p>\n   <p class=\"center\">\n    <b>January Session, 2025</b>\n   </p>\n   <p class=\"center\">LCO No. <b>987</b>\n   </p>\n   <p class=\"center\">*00987*</p>\n   <p class=\"center\">Referred to Committee on GENERAL LAW</p>\n   <p class=\"center\">Introduced by:</p>\n   <p class=\"center\">SEN. LOONEY, 11th Dist.</p>\n   <p class=\"center\">SEN. DUFF, 25th Dist.</p>\n   <p class=\"center\">SEN. ANWAR, 3rd Dist.</p>\n   <p class=\"center\">SEN. CABRERA, 17th Dist.</p>\n   <p class=\"center\">SEN. COHEN, 12th Dist.</p>\n   <p class=\"center\">SEN. FLEXER, 29th Dist.</p>\n   <p class=\"center\">SEN. GADKAR-WILCOX, 22nd Dist.</p>\n   <p class=\"center\">SEN. GASTON, 23rd Dist.</p>\n   <p class=\"center\">SEN. HOCHADEL, 13th Dist.</p>\n   <p class=\"center\">SEN. HONIG, 8th Dist.</p>\n   <p class=\"center\">SEN. KUSHNER, 24th Dist.</p>\n   <p class=\"center\">SEN. LESSER, 9th Dist.</p>\n   <p class=\"center\">SEN. LOPES, 6th Dist.</p>\n   <p class=\"center\">SEN. MAHER, 26th Dist.</p>\n   <p class=\"center\">SEN. MARONEY, 14th Dist.</p>\n   <p class=\"center\">SEN. MARX, 20th Dist.</p>\n   <p class=\"center\">SEN. MCCRORY, 2nd Dist.</p>\n   <p class=\"center\">SEN. MILLER P., 27th Dist.</p>\n   <p class=\"center\">SEN. NEEDLEMAN, 33rd Dist.</p>\n   <p class=\"center\">SEN. OSTEN, 19th Dist.</p>\n   <p class=\"center\">SEN. RAHMAN, 4th Dist.</p>\n   <p class=\"center\">SEN. SLAP, 5th Dist.</p>\n   <p class=\"center\">SEN. WINFIELD, 10th Dist.</p>\n  </div>\n  <a name=\"title_document_section\"></a><div class=\"title\">\n   <p class=\"indent\">AN ACT CONCERNING ARTIFICIAL INTELLIGENCE.</p>\n  </div>\n  <a name=\"text_document_section\"></a><div class=\"text\">\n   <span>\n    <p class=\"indent\">Be it enacted by the Senate and House of Representatives in General Assembly convened:</p>\n   </span>\n   <p class=\"indent\">That the general statutes be amended to protect consumers in this state from the risks of algorithmic discrimination and unfair treatment posed by artificial intelligence.</p>\n   <p class=\"indent\">\n    <b>Statement of Purpose: </b>\n   </p>\n   <p class=\"indent\">To protect consumers in this state from the risks of algorithmic discrimination and unfair treatment posed by artificial intelligence.</p>\n  </div>\n </div>\n    </div>\t\n<table cellpadding=0 cellspacing=0 width=\"100%\">\n   <tr>\n      <td>\n          Copyright &copy; 2025 State Net\n      </td>\n<BR>\n<!--???MOVED INTO resources.cgi      <td align=\"right\">\n          <img src=\"https://custom.statenet.com/network/poweredby.gif\" alt=\"Powered by State Net\">\n      </td>-->\n\n    </tr>\n</table>\n</body></html>\n",
      "markdown": "The following has special meaning: _green underline denotes added text_ ~~red struck out text denotes deleted text~~ | [![Powered by State Net](https://custom.statenet.com/network/poweredby.gif)](https://www.lexisnexis.com/statenet/)  \n---|---  \n  \n2025 CT S 2 | | Author: | Looney  \n---|---  \nVersion: | Introduced  \nVersion Date: | 01/08/2025  \n  \n**STATE OF CONNECTICUT**\n\nGeneral Assembly\n\n**Proposed Bill No. 2**\n\n**January Session, 2025**\n\nLCO No. **987**\n\n*00987*\n\nReferred to Committee on GENERAL LAW\n\nIntroduced by:\n\nSEN. LOONEY, 11th Dist.\n\nSEN. DUFF, 25th Dist.\n\nSEN. ANWAR, 3rd Dist.\n\nSEN. CABRERA, 17th Dist.\n\nSEN. COHEN, 12th Dist.\n\nSEN. FLEXER, 29th Dist.\n\nSEN. GADKAR-WILCOX, 22nd Dist.\n\nSEN. GASTON, 23rd Dist.\n\nSEN. HOCHADEL, 13th Dist.\n\nSEN. HONIG, 8th Dist.\n\nSEN. KUSHNER, 24th Dist.\n\nSEN. LESSER, 9th Dist.\n\nSEN. LOPES, 6th Dist.\n\nSEN. MAHER, 26th Dist.\n\nSEN. MARONEY, 14th Dist.\n\nSEN. MARX, 20th Dist.\n\nSEN. MCCRORY, 2nd Dist.\n\nSEN. MILLER P., 27th Dist.\n\nSEN. NEEDLEMAN, 33rd Dist.\n\nSEN. OSTEN, 19th Dist.\n\nSEN. RAHMAN, 4th Dist.\n\nSEN. SLAP, 5th Dist.\n\nSEN. WINFIELD, 10th Dist.\n\nAN ACT CONCERNING ARTIFICIAL INTELLIGENCE.\n\nBe it enacted by the Senate and House of Representatives in General Assembly\nconvened:\n\nThat the general statutes be amended to protect consumers in this state from\nthe risks of algorithmic discrimination and unfair treatment posed by\nartificial intelligence.\n\n**Statement of Purpose:**\n\nTo protect consumers in this state from the risks of algorithmic\ndiscrimination and unfair treatment posed by artificial intelligence.\n\nCopyright (C) 2025 State Net  \n  \n---\n\n",
      "latest_version": false
    },
    {
      "date": "02/19/2025",
      "label": "Drafted by Committee",
      "url": "https://custom.statenet.com/public/resources.cgi?mode=show_text&id=ID:bill:CT2025000S2&verid=CT2025000S2_20250219_0_DBC&",
      "raw_html": "<html>\n<head>\n<title>Bill Resource</title>\n\n<!--   <link href=\"https://custom.statenet.com/network/Common/css/extregtext.css\" rel=\"stylesheet\" type=\"text/css\" />-->\n   <link href=\"https://custom.statenet.com/network/Common/css/xmltext-2.0.css\" rel=\"stylesheet\" type=\"text/css\" />\n   <link href=\"https://custom.statenet.com/network/Common/css/additional-text.css\" rel=\"stylesheet\" type=\"text/css\" />\n\n\t<style type=\"text/css\">\n<!--\n\ntd, body {\n     background-color: white;\n\tfont-family: Verdana, Arial, Helvetica, sans-serif;\n\tfont-size: 12px;\n}\n\n.resourceContainer {\n   border: 1px solid black;\n}\n-->\n</style>\n</head>\n<body>\n\n    <div style=\"width: 750px; margin: auto\">\n       <div style=\"font-size: .8em;margin-bottom: 10px\"><table width=\"100%\"><tr><td align=\"left\" style=\"font-size: .8em;\"><div>The following has special meaning:</div>\n<div><u class=\"amendmentInsertedText\">green underline denotes added text</u></div>\n<div><strike class=\"amendmentDeletedText\">red struck out text denotes deleted text</strike></div></td> <td align=\"right\"><a href=\"https://www.lexisnexis.com/statenet/\"><img alt=\"Powered by State Net\" src=\"https://custom.statenet.com/network/poweredby.gif\" /></a></td></tr></table></div><table id=\"text-identifier\"><tr><td class=\"key\">2025 CT S 2</td> <td><table><tr><td class=\"label\">Author:</td> <td>Looney</td></tr> <tr><td class=\"label\">Version:</td> <td>Drafted by Committee</td></tr> <tr><td class=\"label\">Version Date:</td> <td>02/19/2025</td></tr></table></td></tr></table><div class=\"documentBody\">\n  <a name=\"head_document_section\"></a><div class=\"head\">\n   <p class=\"center\">\n    <b>STATE OF CONNECTICUT</b>\n   </p>\n   <p class=\"center\">General Assembly</p>\n   <p class=\"center\">\n    <b>Committee Bill No. 2</b>\n   </p>\n   <p class=\"center\">\n    <b>January Session, 2025</b>\n   </p>\n   <p class=\"center\">LCO No. <b>5014</b>\n   </p>\n   <p class=\"center\">*05014SB00002GL_*</p>\n   <p class=\"center\">Referred to Committee on GENERAL LAW</p>\n   <p class=\"center\">Introduced by:</p>\n   <p class=\"center\">(GL) </p>\n  </div>\n  <a name=\"title_document_section\"></a><div class=\"title\">\n   <p class=\"indent\">AN ACT CONCERNING ARTIFICIAL INTELLIGENCE.</p>\n  </div>\n  <a name=\"text_document_section\"></a><div class=\"text\">\n   <span>\n    <p class=\"indent\">Be it enacted by the Senate and House of Representatives in General Assembly convened:</p>\n   </span>\n   <p class=\"indent\">Section 1. (NEW) (Effective October 1, 2025) For the purposes of this section and sections 2 to 10, inclusive, of this act, unless the context otherwise requires:</p>\n   <p class=\"indent\">(1) &quot;Algorithmic discrimination&quot; (A) means any use of an artificial intelligence system that results in any unlawful differential treatment or impact that disfavors any individual or group of individuals on the basis of one or more classifications protected under the laws of this state or federal law, and (B) does not include (i) the offer, license or use of a high-risk artificial intelligence system by a developer, integrator or deployer for the sole purpose of (I) the developer&#39;s, integrator&#39;s or deployer&#39;s self-testing to identify, mitigate or prevent discrimination or otherwise ensure compliance with state and federal law, or (II) expanding an applicant, customer or participant pool to increase diversity or redress historic discrimination, or (ii) an act or omission by or on behalf of a private club or other establishment not in fact open to the public, as set forth in Title II of the Civil Rights Act of 1964, 42 USC 2000a(e), as amended from time to time;</p>\n   <p class=\"indent\">(2) &quot;Artificial intelligence system&quot; means any machine-based system that, for any explicit or implicit objective, infers from the inputs such system receives how to generate outputs, including, but not limited to, content, decisions, predictions or recommendations, that can influence physical or virtual environments;</p>\n   <p class=\"indent\">(3) &quot;Consequential decision&quot; means any decision or judgment that has a legal, material or similarly significant effect on a consumer with respect to (A) employment, including, but not limited to, any such decision or judgment made (i) concerning hiring, termination, compensation or promotion, or (ii) by way of any automated task allocation that limits, segregates or classifies employees for the purpose of assigning or determining material terms or conditions of employment, (B) education or vocational training, including, but not limited to, any such decision or judgment made concerning (i) assessments, (ii) student cheating or plagiarism detection, (iii) accreditation, (iv) certification, (v) admissions, or (vi) financial aid or scholarships, (C) the provision or denial, or terms and conditions, of (i) financial lending or credit services, (ii) housing or lodging, including, but not limited to, rentals or short-term housing or lodging, (iii) insurance, or (iv) legal services, or (D) the provision or denial of (i) essential government services, or (ii) health care services;</p>\n   <p class=\"indent\">(4) &quot;Consumer&quot; means any individual who is a resident of this state;</p>\n   <p class=\"indent\">(5) &quot;Deploy&quot; means to use a high-risk artificial intelligence system to make, or as a substantial factor in making, a consequential decision;</p>\n   <p class=\"indent\">(6) &quot;Deployer&quot; means any person doing business in this state that deploys a high-risk artificial intelligence system in this state;</p>\n   <p class=\"indent\">(7) &quot;Developer&quot; means any person doing business in this state that develops, or intentionally and substantially modifies, an artificial intelligence system;</p>\n   <p class=\"indent\">(8) &quot;General-purpose artificial intelligence model&quot; (A) means any form of artificial intelligence system that (i) displays significant generality, (ii) is capable of competently performing a wide range of distinct tasks, and (iii) can be integrated into a variety of downstream applications or systems, and (B) does not include any artificial intelligence model that is used for development, prototyping and research activities before such artificial intelligence model is released on the market;</p>\n   <p class=\"indent\">(9) &quot;High-risk artificial intelligence system&quot; (A) means any artificial intelligence system that, when deployed, makes, or is a substantial factor in making, a consequential decision, and (B) does not include (i) any artificial intelligence system that is intended to (I) perform any narrow procedural task, or (II) detect decision-making patterns, or deviations from decision-making patterns, unless such artificial intelligence system is intended to replace or influence any assessment previously completed by an individual without sufficient human review, or (ii) unless the technology, when deployed, makes, or is a substantial factor in making, a consequential decision, (I) any anti-fraud technology that does not make use of facial recognition technology, (II) any artificial intelligence-enabled video game technology, (III) any anti-malware, anti-virus, calculator, cybersecurity, database, data storage, firewall, Internet domain registration, Internet-web-site loading, networking, robocall-filtering, spam-filtering, spellchecking, spreadsheet, web-caching, web-hosting or similar technology, (IV) any technology that performs tasks exclusively related to an entity&#39;s internal management affairs, including, but not limited to, ordering office supplies or processing payments, or (V) any technology that communicates with consumers in natural language for the purpose of providing users with information, making referrals or recommendations and answering questions, and is subject to an accepted use policy that prohibits generating content that is discriminatory or harmful;</p>\n   <p class=\"indent\">(10) &quot;Integrator&quot; means any person doing business in this state that, with respect to a given high-risk artificial intelligence system, (A) neither develops nor intentionally and substantially modifies the high-risk artificial intelligence system, and (B) integrates the high-risk artificial intelligence system into a product or service such person offers to any other person;</p>\n   <p class=\"indent\">(11) &quot;Intentional and substantial modification&quot; (A) means any deliberate change made to (i) an artificial intelligence system that materially increases the risk of algorithmic discrimination, or (ii) a general-purpose artificial intelligence model that (I) affects compliance of the general-purpose artificial intelligence model, (II) materially changes the purpose of the general-purpose artificial intelligence model, or (III) materially increases the risk of algorithmic discrimination, and (B) does not include any change made to a high-risk artificial intelligence system, or the performance of a high-risk artificial intelligence system, if (i) the high-risk artificial intelligence system continues to learn after such high-risk artificial intelligence system is (I) offered, sold, leased, licensed, given or otherwise made available to a deployer, or (II) deployed, and (ii) such change (I) is made to such high-risk artificial intelligence system as a result of any learning described in subparagraph (B)(i) of this subdivision, (II) was predetermined by the deployer, or the third party contracted by the deployer, when such deployer or third party completed the initial impact assessment of such high-risk artificial intelligence system pursuant to subsection (c) of section 4 of this act, and (III) is included in the technical documentation for such high-risk artificial intelligence system;</p>\n   <p class=\"indent\">(12) &quot;Person&quot; means any individual, association, corporation, limited liability company, partnership, trust or other legal entity;</p>\n   <p class=\"indent\">(13) &quot;Red-teaming&quot; means an exercise that is conducted to identify the potential adverse behaviors or outcomes of an artificial intelligence system, how such behaviors or outcomes occur and stress test the safeguards against such behaviors or outcomes;</p>\n   <p class=\"indent\">(14) &quot;Substantial factor&quot; (A) means a factor that (i) alters the outcome of a consequential decision, and (ii) is generated by an artificial intelligence system, (B) includes, but is not limited to, any use of an artificial intelligence system to generate any content, decision, prediction or recommendation concerning a consumer that is used as a basis to make a consequential decision concerning the consumer, and (C) does not include any output produced by an artificial intelligence system where an individual was involved in the data processing that produced such output and such individual (i) meaningfully considered such data as part of such data processing, and (ii) had the authority to change or influence the output produced by such data processing;</p>\n   <p class=\"indent\">(15) &quot;Synthetic digital content&quot; means any digital content, including, but not limited to, any audio, image, text or video, that is produced or manipulated by an artificial intelligence system, including, but not limited to, a general-purpose artificial intelligence model; and</p>\n   <p class=\"indent\">(16) &quot;Trade secret&quot; has the same meaning as provided in section 35-51 of the general statutes.</p>\n   <p class=\"indent\">Sec. 2. (NEW) (Effective October 1, 2025) (a) Beginning on October 1, 2026, a developer of a high-risk artificial intelligence system shall use reasonable care to protect consumers from any known or reasonably foreseeable risks of algorithmic discrimination arising from the intended and contracted uses of the high-risk artificial intelligence system. In any enforcement action brought on or after said date by the Attorney General pursuant to section 10 of this act, there shall be a rebuttable presumption that a developer used reasonable care as required under this subsection if the developer complied with the provisions of this section or, if the developer enters into a contract with an integrator as set forth in subsection (b) of section 3 of this act, the developer and integrator complied with the provisions of this section and section 3 of this act.</p>\n   <p class=\"indent\">(b) Except as provided in subsection (c) of section 3 of this act, a developer of a high-risk artificial intelligence system shall, beginning on October 1, 2026, make available to each deployer, or other developer, of the high-risk artificial intelligence system:</p>\n   <p class=\"indent\">(1) A general statement describing the reasonably foreseeable uses, and the known harmful or inappropriate uses, of such high-risk artificial intelligence system;</p>\n   <p class=\"indent\">(2) Documentation disclosing (A) high-level summaries of the type of data used to train such high-risk artificial intelligence system, (B) the known or reasonably foreseeable limitations of such high-risk artificial intelligence system, including, but not limited to, the known or reasonably foreseeable risks of algorithmic discrimination arising from the intended uses of such high-risk artificial intelligence system, (C) the purpose of such high-risk artificial intelligence system, (D) the intended benefits and uses of such high-risk artificial intelligence system, and (E) all other information necessary to enable such deployer to comply with the provisions of section 4 of this act;</p>\n   <p class=\"indent\">(3) Documentation describing (A) how such high-risk artificial intelligence system was evaluated for performance, and mitigation of algorithmic discrimination, before such high-risk artificial intelligence system was offered, sold, leased, licensed, given or otherwise made available to such deployer, (B) the data governance measures used to cover the training datasets and the measures used to examine the suitability of data sources, possible biases and appropriate mitigation, (C) the intended outputs of such high-risk artificial intelligence system, (D) the measures the developer has taken to mitigate any known or reasonably foreseeable risks of algorithmic discrimination that may arise from deployment of such high-risk artificial intelligence system, and (E) how such high-risk artificial intelligence system should be used, not be used and be monitored by an individual when such high-risk artificial intelligence system is used to make, or as a substantial factor in making, a consequential decision; and</p>\n   <p class=\"indent\">(4) Any additional documentation that is reasonably necessary to assist a deployer to (A) understand the outputs of such high-risk artificial intelligence system, and (B) monitor the performance of such high-risk artificial intelligence system for risks of algorithmic discrimination.</p>\n   <p class=\"indent\">(c) (1) Except as provided in subsection (c) of section 3 of this act, any developer that, on or after October 1, 2026, offers, sells, leases, licenses, gives or otherwise makes available to a deployer or another developer a high-risk artificial intelligence system shall, to the extent feasible, make available to the deployers and other developers of such high-risk artificial intelligence system the documentation and information necessary for a deployer, or the third party contracted by a deployer, to complete an impact assessment pursuant to subsection (c) of section 4 of this act. The developer shall make such documentation and information available through artifacts such as model cards, dataset cards or other impact assessments.</p>\n   <p class=\"indent\">(2) A developer that also serves as a deployer for any high-risk artificial intelligence system shall not be required to generate the documentation required by this section unless such high-risk artificial intelligence system is provided to another person that serves as a deployer for such high-risk artificial intelligence system.</p>\n   <p class=\"indent\">(d) (1) Beginning on October 1, 2026, each developer shall make available, in a manner that is clear and readily available on such developer&#39;s Internet web site or in a public use case inventory, a statement summarizing:</p>\n   <p class=\"indent\">(A) The types of high-risk artificial intelligence systems that such developer (i) has developed or intentionally and substantially modified, and (ii) currently makes available to a deployer or another developer; and</p>\n   <p class=\"indent\">(B) How such developer manages any known or reasonably foreseeable risks of algorithmic discrimination that may arise from development or intentional and substantial modification of the types of high-risk artificial intelligence systems described in subparagraph (A) of this subdivision.</p>\n   <p class=\"indent\">(2) Each developer shall update the statement made available pursuant to subdivision (1) of this subsection (A) as necessary to ensure that such statement remains accurate, and (B) not later than ninety days after the developer intentionally and substantially modifies any high-risk artificial intelligence system described in subparagraph (A) of subdivision (1) of this subsection.</p>\n   <p class=\"indent\">(e) Beginning on October 1, 2026, a developer of a high-risk artificial intelligence system shall disclose to the Attorney General, in a form and manner prescribed by the Attorney General, and to all known deployers or other developers of the high-risk artificial intelligence system, any known or reasonably foreseeable risks of algorithmic discrimination arising from the intended uses of such high-risk artificial intelligence system. The developer shall make such disclosures without unreasonable delay but in no event later than ninety days after the date on which:</p>\n   <p class=\"indent\">(1) The developer discovers, through the developer&#39;s ongoing testing and analysis, that the high-risk artificial intelligence system has (A) been deployed, and (B) caused, or is reasonably likely to have caused, algorithmic discrimination to at least one thousand consumers; or</p>\n   <p class=\"indent\">(2) The developer receives, from a deployer of the high-risk artificial intelligence system, a credible report disclosing that such high-risk artificial intelligence system has (A) been deployed, and (B) caused algorithmic discrimination to at least one thousand consumers.</p>\n   <p class=\"indent\">(f) The provisions of subsections (b) to (e), inclusive, of this section shall not be construed to require a developer to disclose any information (1) that is a trade secret or otherwise protected from disclosure under state or federal law, or (2) the disclosure of which would present a security risk to the developer.</p>\n   <p class=\"indent\">(g) Beginning on October 1, 2026, the Attorney General may require that a developer disclose to the Attorney General, as part of an investigation conducted by the Attorney General and in a form and manner prescribed by the Attorney General, the general statement or documentation described in subsection (b) of this section. The Attorney General may evaluate such general statement or documentation to ensure compliance with the provisions of this section. In disclosing such general statement or documentation to the Attorney General pursuant to this subsection, the developer may designate such general statement or documentation as including any information that is exempt from disclosure under subsection (f) of this section or the Freedom of Information Act, as defined in section 1-200 of the general statutes. To the extent such general statement or documentation includes such information, such general statement or documentation shall be exempt from disclosure under subsection (f) of this section or said act. To the extent any information contained in such general statement or documentation is subject to the attorney-client privilege or work product protection, such disclosure shall not constitute a waiver of such privilege or protection.</p>\n   <p class=\"indent\">Sec. 3. (NEW) (Effective October 1, 2025) (a) Beginning on October 1, 2026, if an integrator integrates a high-risk artificial intelligence system into a product or service the integrator offers to any other person, such integrator shall use reasonable care to protect consumers from any known or reasonably foreseeable risks of algorithmic discrimination arising from the intended and contracted uses of such integrated high-risk artificial intelligence system. In any enforcement action brought on or after said date by the Attorney General pursuant to section 10 of this act, there shall be a rebuttable presumption that the integrator used reasonable care as required under this subsection if the integrator complied with the provisions of this section.</p>\n   <p class=\"indent\">(b) Beginning on October 1, 2026, no integrator shall integrate a high-risk artificial intelligence system into a product or service the integrator offers to any other person unless the integrator has entered into a contract with the developer of the high-risk artificial intelligence system. The contract shall be binding and clearly set forth the duties of the developer and integrator with respect to the integrated high-risk artificial intelligence system, including, but not limited to, whether the developer or integrator shall be responsible for performing the developer&#39;s duties under subsections (b) and (c) of section 2 of this act.</p>\n   <p class=\"indent\">(c) The provisions of subsections (b) and (c) of section 2 of this act shall not apply to a developer of an integrated high-risk artificial intelligence system if, at all times while the integrated high-risk artificial intelligence system is integrated into a product or service an integrator offers to any other person, the developer has entered into a contract with the integrator in which such integrator has agreed to assume the developer&#39;s duties under subsections (b) and (c) of section 2 of this act.</p>\n   <p class=\"indent\">(d) (1) Beginning on October 1, 2026, each integrator shall make available, in a manner that is clear and readily available on such integrator&#39;s Internet web site or in a public use case inventory, a statement summarizing:</p>\n   <p class=\"indent\">(A) The types of high-risk artificial intelligence systems that such integrator has integrated into products or services such integrator currently offers to any other person; and</p>\n   <p class=\"indent\">(B) How such integrator manages any known or reasonably foreseeable risks of algorithmic discrimination that may arise from the types of high-risk artificial intelligence systems described in subparagraph (A) of this subdivision.</p>\n   <p class=\"indent\">(2) Each integrator shall update the statement made available pursuant to subdivision (1) of this subsection (A) as necessary to ensure that such statement remains accurate, and (B) not later than ninety days after any intentional and substantial modification is made to any high-risk artificial intelligence system described in subparagraph (A) of subdivision (1) of this subsection.</p>\n   <p class=\"indent\">(e) The provisions of subsections (b) to (d), inclusive, of this section shall not be construed to require a developer or integrator to disclose any information (1) that is a trade secret or otherwise protected from disclosure under state or federal law, or (2) the disclosure of which would present a security risk to the developer or integrator.</p>\n   <p class=\"indent\">(f) Beginning on October 1, 2026, the Attorney General may require that an integrator which has assumed a developer&#39;s duties under subsection (c) of section 2 of this act to disclose to the Attorney General, as part of an investigation conducted by the Attorney General and in a form and manner prescribed by the Attorney General, the general statement or documentation described in said subsection. The Attorney General may evaluate such general statement or documentation to ensure compliance with the provisions of this section and section 2 of this act. In disclosing such general statement or documentation to the Attorney General pursuant to this subsection, the integrator may designate such general statement or documentation as including any information that is exempt from disclosure under subsection (e) of this section or the Freedom of Information Act, as defined in section 1-200 of the general statutes. To the extent such general statement or documentation includes such information, such general statement or documentation shall be exempt from disclosure under subsection (e) of this section or said act. To the extent any information contained in such general statement or documentation is subject to the attorney-client privilege or work product protection, such disclosure shall not constitute a waiver of such privilege or protection.</p>\n   <p class=\"indent\">Sec. 4. (NEW) (Effective October 1, 2025) (a) Beginning on October 1, 2026, each deployer of a high-risk artificial intelligence system shall use reasonable care to protect consumers from any known or reasonably foreseeable risks of algorithmic discrimination. In any enforcement action brought on or after said date by the Attorney General pursuant to section 10 of this act, there shall be a rebuttable presumption that a deployer of a high-risk artificial intelligence system used reasonable care as required under this subsection if the deployer complied with the provisions of this section.</p>\n   <p class=\"indent\">(b) (1) Beginning on October 1, 2026, and except as provided in subsection (g) of this section, each deployer of a high-risk artificial intelligence system shall implement and maintain a risk management policy and program to govern such deployer&#39;s deployment of the high-risk artificial intelligence system. The risk management policy and program shall specify and incorporate the principles, processes and personnel that the deployer shall use to identify, document and mitigate any known or reasonably foreseeable risks of algorithmic discrimination. The risk management policy shall be the product of an iterative process, the risk management program shall be an iterative process and both the risk management policy and program shall be planned, implemented and regularly and systematically reviewed and updated over the lifecycle of the high-risk artificial intelligence system. Each risk management policy and program implemented and maintained pursuant to this subsection shall be reasonable, considering:</p>\n   <p class=\"indent\">(A) The guidance and standards set forth in the latest version of (i) the &quot;Artificial Intelligence Risk Management Framework&quot; published by the National Institute of Standards and Technology, (ii) ISO or IEC 42001 of the International Organization for Standardization, or (iii) a nationally or internationally recognized risk management framework for artificial intelligence systems, other than the guidance and standards specified in subparagraphs (A)(i) and (A)(ii) of this subdivision, that imposes requirements that are substantially equivalent to, and at least as stringent as, the requirements set forth in this section for risk management policies and programs;</p>\n   <p class=\"indent\">(B) The size and complexity of the deployer;</p>\n   <p class=\"indent\">(C) The nature and scope of the high-risk artificial intelligence systems deployed by the deployer, including, but not limited to, the intended uses of such high-risk artificial intelligence systems; and</p>\n   <p class=\"indent\">(D) The sensitivity and volume of data processed in connection with the high-risk artificial intelligence systems deployed by the deployer.</p>\n   <p class=\"indent\">(2) A risk management policy and program implemented and maintained pursuant to subdivision (1) of this subsection may cover multiple high-risk artificial intelligence systems deployed by the deployer.</p>\n   <p class=\"indent\">(c) (1) Except as provided in subdivisions (3) and (4) of this subsection and subsection (g) of this section:</p>\n   <p class=\"indent\">(A) A deployer that deploys a high-risk artificial intelligence system on or after October 1, 2026, or a third party contracted by the deployer, shall complete an impact assessment of the high-risk artificial intelligence system; and</p>\n   <p class=\"indent\">(B) Beginning on October 1, 2026, a deployer, or a third party contracted by the deployer, shall complete an impact assessment of a deployed high-risk artificial intelligence system (i) at least annually, and (ii) not later than ninety days after an intentional and substantial modification to such high-risk artificial intelligence system is made available.</p>\n   <p class=\"indent\">(2) (A) Each impact assessment completed pursuant to this subsection shall include, at a minimum and to the extent reasonably known by, or available to, the deployer:</p>\n   <p class=\"indent\">(i) A statement by the deployer disclosing the purpose, intended use cases and deployment context of, and benefits afforded by, the high-risk artificial intelligence system;</p>\n   <p class=\"indent\">(ii) An analysis of whether the deployment of the high-risk artificial intelligence system poses any known or reasonably foreseeable risks of algorithmic discrimination and, if so, the nature of such algorithmic discrimination and the steps that have been taken to mitigate such risks;</p>\n   <p class=\"indent\">(iii) A description of (I) the categories of data the high-risk artificial intelligence system processes as inputs, and (II) the outputs such high-risk artificial intelligence system produces;</p>\n   <p class=\"indent\">(iv) If the deployer used data to customize the high-risk artificial intelligence system, an overview of the categories of data the deployer used to customize such high-risk artificial intelligence system;</p>\n   <p class=\"indent\">(v) Any metrics used to evaluate the performance and known limitations of the high-risk artificial intelligence system;</p>\n   <p class=\"indent\">(vi) A description of any transparency measures taken concerning the high-risk artificial intelligence system, including, but not limited to, any measures taken to disclose to a consumer that such high-risk artificial intelligence system is in use when such high-risk artificial intelligence system is in use; and</p>\n   <p class=\"indent\">(vii) A description of the post-deployment monitoring and user safeguards provided concerning such high-risk artificial intelligence system, including, but not limited to, the oversight, use and learning process established by the deployer to address issues arising from deployment of such high-risk artificial intelligence system.</p>\n   <p class=\"indent\">(B) In addition to the statement, analysis, descriptions, overview and metrics required under subparagraph (A) of this subdivision, an impact assessment completed pursuant to this subsection following an intentional and substantial modification made to a high-risk artificial intelligence system on or after October 1, 2026, shall include a statement disclosing the extent to which the high-risk artificial intelligence system was used in a manner that was consistent with, or varied from, the developer&#39;s intended uses of such high-risk artificial intelligence system.</p>\n   <p class=\"indent\">(3) A single impact assessment may address a comparable set of high-risk artificial intelligence systems deployed by a deployer.</p>\n   <p class=\"indent\">(4) If a deployer, or a third party contracted by the deployer, completes an impact assessment for the purpose of complying with another applicable law or regulation, such impact assessment shall be deemed to satisfy the requirements established in this subsection if such impact assessment is reasonably similar in scope and effect to the impact assessment that would otherwise be completed pursuant to this subsection.</p>\n   <p class=\"indent\">(5) A deployer shall maintain the most recently completed impact assessment of a high-risk artificial intelligence system as required under this subsection, all records concerning each such impact assessment and all prior impact assessments, if any, for a period of at least three years following the final deployment of the high-risk artificial intelligence system.</p>\n   <p class=\"indent\">(d) Except as provided in subsection (g) of this section, a deployer, or a third party contracted by the deployer, shall review, not later than October 1, 2026, and at least annually thereafter, the deployment of each high-risk artificial intelligence system deployed by the deployer to ensure that such high-risk artificial intelligence system is not causing algorithmic discrimination.</p>\n   <p class=\"indent\">(e) (1) Beginning on October 1, 2026, and before a deployer deploys a high-risk artificial intelligence system to make, or be a substantial factor in making, a consequential decision concerning a consumer, the deployer shall:</p>\n   <p class=\"indent\">(A) Notify the consumer that the deployer has deployed a high-risk artificial intelligence system to make, or be a substantial factor in making, such consequential decision; and</p>\n   <p class=\"indent\">(B) Provide to the consumer (i) a statement disclosing (I) the purpose of such high-risk artificial intelligence system, and (II) the nature of such consequential decision, (ii) the right to opt-out of any automated decision-making based on the consumer&#39;s personal data, (iii) contact information for such deployer, (iv) a description, in plain language, of such high-risk artificial intelligence system, and (v) instructions on how to access the statement made available pursuant to subdivision (1) of subsection (f) of this section.</p>\n   <p class=\"indent\">(2) Beginning on October 1, 2026, a deployer that has deployed a high-risk artificial intelligence system to make, or as a substantial factor in making, a consequential decision concerning a consumer shall, if such consequential decision is adverse to the consumer, provide to such consumer:</p>\n   <p class=\"indent\">(A) A statement disclosing the principal reason or reasons for such adverse consequential decision, including, but not limited to, (i) the degree to which, and manner in which, the high-risk artificial intelligence system contributed to such adverse consequential decision, (ii) the type of data that were processed by such high-risk artificial intelligence system in making such adverse consequential decision, and (iii) the source of the data described in subparagraph (A)(ii) of this subdivision;</p>\n   <p class=\"indent\">(B) An opportunity to (i) examine the personal data that the high-risk artificial intelligence system processed in making, or as a substantial factor in making, such adverse consequential decision, and (ii) correct any incorrect personal data described in subparagraph (B)(i) of this subdivision; and</p>\n   <p class=\"indent\">(C) (i) Except as provided in subparagraph (C)(ii) of this subdivision, an opportunity to appeal such adverse consequential decision if such adverse consequential decision is based upon inaccurate personal data, taking into account both the nature of such personal data and the purpose for which such personal data was processed. Such appeal shall, if technically feasible, allow for human review.</p>\n   <p class=\"indent\">(ii) No deployer shall be required to provide an opportunity to appeal pursuant to subparagraph (C)(i) of this subdivision in any instance in which providing such opportunity to appeal is not in the best interest of the consumer, including, but not limited to, in any instance in which any delay might pose a risk to the life or safety of the consumer.</p>\n   <p class=\"indent\">(3) The deployer shall provide the notice, statements, information, description and instructions required under subdivisions (1) and (2) of this subsection:</p>\n   <p class=\"indent\">(A) Directly to the consumer;</p>\n   <p class=\"indent\">(B) In plain language;</p>\n   <p class=\"indent\">(C) In all languages in which such deployer, in the ordinary course of such deployer&#39;s business, provides contracts, disclaimers, sale announcements and other information to consumers; and</p>\n   <p class=\"indent\">(D) In a format that is accessible to consumers with disabilities.</p>\n   <p class=\"indent\">(f) (1) Beginning on October 1, 2026, and except as provided in subsection (g) of this section, each deployer shall make available, in a manner that is clear and readily available on such deployer&#39;s Internet web site, a statement summarizing:</p>\n   <p class=\"indent\">(A) The types of high-risk artificial intelligence systems that are currently deployed by such deployer;</p>\n   <p class=\"indent\">(B) How such deployer manages any known or reasonably foreseeable risks of algorithmic discrimination that may arise from deployment of each high-risk artificial intelligence system described in subparagraph (A) of this subdivision; and</p>\n   <p class=\"indent\">(C) In detail, the nature, source and extent of the information collected and used by such deployer.</p>\n   <p class=\"indent\">(2) Each deployer shall periodically update the statement made available pursuant to subdivision (1) of this subsection.</p>\n   <p class=\"indent\">(g) The provisions of subsections (b) to (d), inclusive, of this section and subsection (f) of this section shall not apply to a deployer if, at the time the deployer deploys a high-risk artificial intelligence system and at all times while the high-risk artificial intelligence system is deployed:</p>\n   <p class=\"indent\">(1) The deployer (A) has entered into a contract with the developer in which the developer has agreed to assume the deployer&#39;s duties under subsections (b) to (d), inclusive, of this section and subsection (f) of this section, and (B) does not exclusively use such deployer&#39;s own data to train such high-risk artificial intelligence system;</p>\n   <p class=\"indent\">(2) Such high-risk artificial intelligence system (A) is used for the intended uses that are disclosed to such deployer as set forth in subparagraph (D) of subdivision (2) of subsection (b) of section 2 of this act, and (B) continues learning based on a broad range of data sources and not solely based on the deployer&#39;s own data; and</p>\n   <p class=\"indent\">(3) Such deployer makes available to consumers any impact assessment that (A) the developer of such high-risk artificial intelligence system has completed and provided to such deployer, and (B) includes information that is substantially similar to the information included in the statement, analysis, descriptions, overview and metrics required under subparagraph (A) of subdivision (2) of subsection (c) of this section.</p>\n   <p class=\"indent\">(h) If a deployer deploys a high-risk artificial intelligence system on or after October 1, 2026, and subsequently discovers that the high-risk artificial intelligence system has caused algorithmic discrimination to at least one thousand consumers, the deployer shall send to the Attorney General, in a form and manner prescribed by the Attorney General, a notice disclosing such discovery. The deployer shall send such notice to the Attorney General without unreasonable delay but in no event later than ninety days after the date on which the deployer discovered such algorithmic discrimination.</p>\n   <p class=\"indent\">(i) Nothing in subsections (b) to (h), inclusive, of this section shall be construed to require a deployer to disclose any information that is a trade secret or otherwise protected from disclosure under state or federal law. If a deployer withholds any information from a consumer under this subsection, the deployer shall send notice to the consumer disclosing (1) that the deployer is withholding such information from such consumer, and (2) the basis for the deployer&#39;s decision to withhold such information from such consumer.</p>\n   <p class=\"indent\">(j) Beginning on October 1, 2026, the Attorney General may require that a deployer, or a third party contracted by the deployer as set forth in subsection (c) of this section, as applicable, disclose to the Attorney General, as part of an investigation conducted by the Attorney General, not later than ninety days after a request by the Attorney General and in a form and manner prescribed by the Attorney General, the risk management policy implemented pursuant to subsection (b) of this section, impact assessment completed pursuant to subsection (c) of this section or records maintained pursuant to subdivision (5) of subsection (c) of this section. The Attorney General may evaluate such risk management policy, impact assessment or records to ensure compliance with the provisions of this section. In disclosing such risk management policy, impact assessment or records to the Attorney General pursuant to this subsection, the deployer or third-party contractor, as applicable, may designate such risk management policy, impact assessment or records as including any information that is exempt from disclosure under subsection (i) of this section or the Freedom of Information Act, as defined in section 1-200 of the general statutes. To the extent such risk management policy, impact assessment or records include such information, such risk management policy, impact assessment or records shall be exempt from disclosure under subsection (i) of this section or said act. To the extent any information contained in such risk management policy, impact assessment or record is subject to the attorney-client privilege or work product protection, such disclosure shall not constitute a waiver of such privilege or protection.</p>\n   <p class=\"indent\">Sec. 5. (NEW) (Effective October 1, 2025) (a) Beginning on October 1, 2026, each developer of a general-purpose artificial intelligence model shall, except as provided in subsection (b) of this section:</p>\n   <p class=\"indent\">(1) (A) Create and maintain technical documentation for the general-purpose artificial intelligence model, which technical documentation shall:</p>\n   <p class=\"indent\">(i) Include the training and testing processes for such general-purpose artificial intelligence model;</p>\n   <p class=\"indent\">(ii) Include at least the following information, as appropriate, considering the size and risk profile of such general-purpose artificial intelligence model:</p>\n   <p class=\"indent\">(I) The tasks such general-purpose artificial intelligence model is intended to perform;</p>\n   <p class=\"indent\">(II) The type and nature of artificial intelligence systems in which such general-purpose artificial intelligence model is intended to be integrated;</p>\n   <p class=\"indent\">(III) Acceptable use policies for such general-purpose artificial intelligence model;</p>\n   <p class=\"indent\">(IV) The date such general-purpose artificial intelligence model is released;</p>\n   <p class=\"indent\">(V) The methods by which such general-purpose artificial intelligence model is distributed; and</p>\n   <p class=\"indent\">(VI) The modality and format of inputs and outputs for such general-purpose artificial intelligence model;</p>\n   <p class=\"indent\">(iii) Include a description of the data that were used for purposes of training, testing and validation of such general-purpose artificial intelligence model, which description shall be appropriate considering the size and risk profile of such general-purpose artificial intelligence model and include, at a minimum, a description of the following:</p>\n   <p class=\"indent\">(I) The type and provenance of such data;</p>\n   <p class=\"indent\">(II) Curation methodologies used for such data;</p>\n   <p class=\"indent\">(III) How such data were obtained and selected;</p>\n   <p class=\"indent\">(IV) All measures used to identify unsuitable data sources; and</p>\n   <p class=\"indent\">(V) Where applicable, methods used to detect identifiable biases; and</p>\n   <p class=\"indent\">(iv) Be reviewed and revised at least annually or more frequently as necessary to maintain the accuracy of such technical documentation; and</p>\n   <p class=\"indent\">(B) Establish, implement and maintain a policy to comply with federal and state copyright laws; and</p>\n   <p class=\"indent\">(2) Create, implement, maintain and make available to persons that intend to integrate such general-purpose artificial intelligence model into such persons&#39; artificial intelligence systems documentation and information that:</p>\n   <p class=\"indent\">(A) Enables such persons to (i) understand the capabilities and limitations of such general-purpose artificial intelligence model, and (ii) comply with such persons&#39; obligations under sections 1 to 10, inclusive, of this act;</p>\n   <p class=\"indent\">(B) Discloses, at a minimum, (i) the technical means required for such general-purpose artificial intelligence model to be integrated into such persons&#39; artificial intelligence systems, (ii) the information listed in subparagraph (A)(ii) of subdivision (1) of this subsection, and (iii) the description required under subparagraph (A)(iii) of subdivision (1) of this subsection; and</p>\n   <p class=\"indent\">(C) Except as provided in subsection (b) of this section, is reviewed and revised at least annually or more frequently as necessary to maintain the accuracy of such documentation and information.</p>\n   <p class=\"indent\">(b) (1) The provisions of subdivision (1) of subsection (a) of this section and subparagraph (C) of subdivision (2) of subsection (a) of this section shall not apply to a developer that develops, or intentionally and substantially modifies, a general-purpose artificial intelligence model on or after October 1, 2026, if:</p>\n   <p class=\"indent\">(A) (i) The developer releases such general-purpose artificial intelligence model under a free and open-source license that allows for (I) access to, and modification, distribution and usage of, such general-purpose artificial intelligence model, and (II) the parameters of such general-purpose artificial intelligence model to be made publicly available as set forth in subparagraph (A)(ii) of this subdivision; and</p>\n   <p class=\"indent\">(ii) Unless such general-purpose artificial intelligence model is deployed as a high-risk artificial intelligence system, the parameters of such general-purpose artificial intelligence model, including, but not limited to, the weights and information concerning the model architecture and model usage for such general-purpose artificial intelligence model, are made publicly available; or</p>\n   <p class=\"indent\">(B) The general-purpose artificial intelligence model is (i) not offered for sale in the market, (ii) not intended to interact with consumers, and (iii) solely utilized (I) for an entity&#39;s internal purposes, or (II) under an agreement between multiple entities for such entities&#39; internal purposes.</p>\n   <p class=\"indent\">(2) The provisions of this section shall not apply to a developer that develops, or intentionally and substantially modifies, a general-purpose artificial intelligence model on or after October 1, 2026, if such general-purpose artificial intelligence model performs tasks exclusively related to an entity&#39;s internal management affairs, including, but not limited to, ordering office supplies or processing payments.</p>\n   <p class=\"indent\">(3) A developer that takes any action under an exemption established in subdivision (1) or (2) of this subsection shall bear the burden of demonstrating that such action qualifies for such exemption.</p>\n   <p class=\"indent\">(4) A developer that is exempt under subparagraph (B) of subdivision (1) of this subsection shall establish and maintain an artificial intelligence risk management framework, which framework shall (A) be the product of an iterative process and ongoing efforts, and (B) include, at a minimum, (i) an internal governance function, (ii) a map function that shall establish the context to frame risks, (iii) a risk management function, and (iv) a function to measure identified risks by assessing, analyzing and tracking such risks.</p>\n   <p class=\"indent\">(c) Nothing in subsection (a) of this section shall be construed to require a developer to disclose any information that is a trade secret or otherwise protected from disclosure under state or federal law.</p>\n   <p class=\"indent\">(d) Beginning on October 1, 2026, the Attorney General may require that a developer disclose to the Attorney General, as part of an investigation conducted by the Attorney General, not later than ninety days after a request by the Attorney General and in a form and manner prescribed by the Attorney General, any documentation maintained pursuant to this section. The Attorney General may evaluate such documentation to ensure compliance with the provisions of this section. In disclosing any documentation to the Attorney General pursuant to this subsection, the developer may designate such documentation as including any information that is exempt from disclosure under subsection (c) of this section or the Freedom of Information Act, as defined in section 1-200 of the general statutes. To the extent such documentation includes such information, such documentation shall be exempt from disclosure under subsection (c) of this section or said act. To the extent any information contained in such documentation is subject to the attorney-client privilege or work product protection, such disclosure shall not constitute a waiver of such privilege or protection.</p>\n   <p class=\"indent\">Sec. 6. (NEW) (Effective October 1, 2025) (a) Beginning on October 1, 2026, and except as provided in subsection (b) of this section, each person doing business in this state, including, but not limited to, each deployer that deploys, offers, sells, leases, licenses, gives or otherwise makes available, as applicable, any artificial intelligence system that is intended to interact with consumers shall ensure that it is disclosed to each consumer who interacts with such artificial intelligence system that such consumer is interacting with an artificial intelligence system.</p>\n   <p class=\"indent\">(b) No disclosure shall be required under subsection (a) of this section under circumstances in which a reasonable person would deem it obvious that such person is interacting with an artificial intelligence system.</p>\n   <p class=\"indent\">Sec. 7. (NEW) (Effective October 1, 2025) (a) Beginning on October 1, 2026, and except as provided in subsections (b) and (c) of this section, the developer of an artificial intelligence system, including, but not limited to, a general-purpose artificial intelligence model, that generates or manipulates synthetic digital content shall:</p>\n   <p class=\"indent\">(1) Ensure that the outputs of such artificial intelligence system are marked and detectable as synthetic digital content, and that such outputs are so marked and detectable (A) not later than the time that consumers who did not create such outputs first interact with, or are exposed to, such outputs, and (B) in a manner that (i) is detectable by consumers, and (ii) complies with any applicable accessibility requirements; and</p>\n   <p class=\"indent\">(2) As far as technically feasible and in a manner that is consistent with any nationally or internationally recognized technical standards, ensure that such developer&#39;s technical solutions are effective, interoperable, robust and reliable, considering (A) the specificities and limitations of different types of synthetic digital content, (B) the implementation costs, and (C) the generally acknowledged state of the art.</p>\n   <p class=\"indent\">(b) If the synthetic digital content described in subsection (a) of this section is in an audio, image or video format, and such synthetic digital content forms part of an evidently artistic, creative, satirical, fictional analogous work or program, the disclosure required under said subsection shall be limited to a disclosure that does not hinder the display or enjoyment of such work or program.</p>\n   <p class=\"indent\">(c) The provisions of subsection (a) of this section shall not apply:</p>\n   <p class=\"indent\">(1) To any synthetic digital content that (A) consists exclusively of text, (B) is published to inform the public on any matter of public interest, or (C) is unlikely to mislead a reasonable person consuming such synthetic digital content; or</p>\n   <p class=\"indent\">(2) To the extent that any artificial intelligence system described in subsection (a) of this section (A) performs an assistive function for standard editing, (B) does not substantially alter the input data provided by the developer or the semantics thereof, or (C) is used to detect, prevent, investigate or prosecute any crime where authorized by law.</p>\n   <p class=\"indent\">Sec. 8. (NEW) (Effective October 1, 2025) (a) Nothing in sections 1 to 10, inclusive, of this act shall be construed to restrict a developer&#39;s, integrator&#39;s, deployer&#39;s or other person&#39;s ability to:</p>\n   <p class=\"indent\">(1) Comply with federal, state or municipal law;</p>\n   <p class=\"indent\">(2) Comply with a civil, criminal or regulatory inquiry, investigation, subpoena or summons by a federal, state, municipal or other governmental authority;</p>\n   <p class=\"indent\">(3) Cooperate with a law enforcement agency concerning conduct or activity that the developer, integrator, deployer or other person reasonably and in good faith believes may violate federal, state or municipal law;</p>\n   <p class=\"indent\">(4) Investigate, establish, exercise, prepare for or defend a legal claim;</p>\n   <p class=\"indent\">(5) Take immediate steps to protect an interest that is essential for the life or physical safety of a consumer or another individual;</p>\n   <p class=\"indent\">(6) (A) By any means other than facial recognition technology, prevent, detect, protect against or respond to (i) a security incident, (ii) a malicious or deceptive activity, or (iii) identity theft, fraud, harassment or any other illegal activity, (B) investigate, report or prosecute the persons responsible for any action described in subparagraph (A) of this subdivision, or (C) preserve the integrity or security of systems;</p>\n   <p class=\"indent\">(7) Engage in public or peer-reviewed scientific or statistical research in the public interest that (A) adheres to all other applicable ethics and privacy laws, and (B) is conducted in accordance with (i) 45 CFR Part 46, as amended from time to time, or (ii) relevant requirements established by the federal Food and Drug Administration;</p>\n   <p class=\"indent\">(8) Conduct research, testing, development and integration activities regarding an artificial intelligence system or model, other than testing conducted under real world conditions, before such artificial intelligence system or model is placed on the market, deployed or put into service, as applicable;</p>\n   <p class=\"indent\">(9) Effectuate a product recall;</p>\n   <p class=\"indent\">(10) Identify and repair technical errors that impair existing or intended functionality; or</p>\n   <p class=\"indent\">(11) Assist another developer, integrator, deployer or person with any of the obligations imposed under sections 1 to 10, inclusive, of this act.</p>\n   <p class=\"indent\">(b) The obligations imposed on developers, integrators, deployers or other persons under sections 1 to 10, inclusive, of this act shall not apply where compliance by the developer, integrator, deployer or other person with said sections would violate an evidentiary privilege under the laws of this state.</p>\n   <p class=\"indent\">(c) Nothing in sections 1 to 10, inclusive, of this act shall be construed to impose any obligation on a developer, integrator, deployer or other person that adversely affects the rights or freedoms of any person, including, but not limited to, the rights of any person (1) to freedom of speech or freedom of the press guaranteed in (A) the First Amendment to the United States Constitution, and (B) section 5 of article first of the Constitution of the state, or (2) under section 52-146t of the general statutes.</p>\n   <p class=\"indent\">(d) Nothing in sections 1 to 10, inclusive, of this act shall be construed to apply to any developer, integrator, deployer or other person:</p>\n   <p class=\"indent\">(1) Insofar as such developer, integrator, deployer or other person develops, integrates, deploys, puts into service or intentionally and substantially modifies, as applicable, a high-risk artificial intelligence system (A) that has been approved, authorized, certified, cleared, developed, integrated or granted by (i) a federal agency, such as the federal Food and Drug Administration or the Federal Aviation Administration, acting within the scope of such federal agency&#39;s authority, or (ii) a regulated entity subject to supervision and regulation by the Federal Housing Finance Agency, or (B) in compliance with standards that are (i) established by (I) any federal agency, including, but not limited to, the federal Office of the National Coordinator for Health Information Technology, or (II) a regulated entity subject to supervision and regulation by the Federal Housing Finance Agency, and (ii) substantially equivalent to, and at least as stringent as, the standards established in sections 1 to 10, inclusive, of this act;</p>\n   <p class=\"indent\">(2) Conducting research to support an application (A) for approval or certification from any federal agency, including, but not limited to, the Federal Aviation Administration, the Federal Communications Commission or the federal Food and Drug Administration, or (B) that is otherwise subject to review by any federal agency;</p>\n   <p class=\"indent\">(3) Performing work under, or in connection with, a contract with the United States Department of Commerce, the United States Department of Defense or the National Aeronautics and Space Administration, unless such developer, integrator, deployer or other person is performing such work on a high-risk artificial intelligence system that is used to make, or as a substantial factor in making, a decision concerning employment or housing;</p>\n   <p class=\"indent\">(4) That is a covered entity within the meaning of the Health Insurance Portability and Accountability Act of 1996, P.L. 104-191, and the regulations promulgated thereunder, as both may be amended from time to time, and providing health care recommendations that (A) are generated by an artificial intelligence system, (B) require a health care provider to take action to implement such recommendations, and (C) are not considered to be high risk; or</p>\n   <p class=\"indent\">(5) Who is an active participant in the artificial intelligence regulatory sandbox program designed, established and administered under section 11 of this act, and is engaged in activities within the scope of such program in accordance with the provisions of section 11 of this act.</p>\n   <p class=\"indent\">(e) Nothing in sections 1 to 10, inclusive, of this act shall be construed to apply to any artificial intelligence system that is acquired by or for the federal government or any federal agency or department, including, but not limited to, the United States Department of Commerce, the United States Department of Defense or the National Aeronautics and Space Administration, unless such artificial intelligence system is a high-risk artificial intelligence system that is used to make, or as a substantial factor in making, a decision concerning employment or housing.</p>\n   <p class=\"indent\">(f) Any insurer, as defined in section 38a-1 of the general statutes, fraternal benefit society, as described in section 38a-595 of the general statutes, or health carrier, as defined in section 38a-591a of the general statutes, shall be deemed to be in full compliance with the provisions of sections 1 to 10, inclusive, of this act if such insurer, fraternal benefit society or health carrier has implemented and maintains a written artificial intelligence systems program in accordance with all requirements established by the Insurance Commissioner.</p>\n   <p class=\"indent\">(g) (1) Any bank, out-of-state bank, Connecticut credit union, federal credit union or out-of-state credit union, or any affiliate or subsidiary thereof, shall be deemed to be in full compliance with the provisions of sections 1 to 10, inclusive, of this act if such bank, out-of-state bank, Connecticut credit union, federal credit union, out-of-state credit union, affiliate or subsidiary is subject to examination by any state or federal prudential regulator under any published guidance or regulations that apply to the use of high-risk artificial intelligence systems and such guidance or regulations (A) impose requirements that are substantially equivalent to, and at least as stringent as, the requirements set forth in sections 1 to 10, inclusive, of this act, and (B) at a minimum, require such bank, out-of-state bank, Connecticut credit union, federal credit union, out-of-state credit union, affiliate or subsidiary to (i) regularly audit such bank&#39;s, out-of-state bank&#39;s, Connecticut credit union&#39;s, federal credit union&#39;s, out-of-state credit union&#39;s, affiliate&#39;s or subsidiary&#39;s use of high-risk artificial intelligence systems for compliance with state and federal anti-discrimination laws and regulations applicable to such bank, out-of-state bank, Connecticut credit union, federal credit union, out-of-state credit union, affiliate or subsidiary, and (ii) mitigate any algorithmic discrimination caused by the use of a high-risk artificial intelligence system or any risk of algorithmic discrimination that is reasonably foreseeable as a result of the use of a high-risk artificial intelligence system.</p>\n   <p class=\"indent\">(2) For the purposes of this subsection, &quot;affiliate&quot;, &quot;bank&quot;, &quot;Connecticut credit union&quot;, &quot;federal credit union&quot;, &quot;out-of-state bank&quot;, &quot;out-of-state credit union&quot; and &quot;subsidiary&quot; have the same meanings as provided in section 36a-2 of the general statutes.</p>\n   <p class=\"indent\">(h) If a developer, integrator, deployer or other person engages in any action pursuant to an exemption set forth in subsections (a) to (g), inclusive, of this section, the developer, integrator, deployer or other person bears the burden of demonstrating that such action qualifies for such exemption.</p>\n   <p class=\"indent\">Sec. 9. (NEW) (Effective October 1, 2025) Not later than January 1, 2026, the Attorney General shall, within available appropriations, develop and implement a comprehensive public education, outreach and assistance program for developers, integrators and deployers that are small businesses, as defined in section 4-168a of the general statutes. Such program shall, at a minimum, disseminate educational materials concerning (1) the requirements established in sections 1 to 10, inclusive, of this act, including, but not limited to, the duties of developers, integrators and deployers under sections 1 to 10, inclusive, of this act, (2) the impact assessments required under subsection (c) of section 4 of this act, (3) the Attorney General&#39;s powers under sections 1 to 10, inclusive, of this act, and (4) any other matters the Attorney General, in the Attorney General&#39;s discretion, deems relevant for the purposes of such program.</p>\n   <p class=\"indent\">Sec. 10. (NEW) (Effective October 1, 2025) (a) The Attorney General shall have exclusive authority to enforce the provisions of sections 1 to 9, inclusive, of this act.</p>\n   <p class=\"indent\">(b) Except as provided in subsection (f) of this section, during the period beginning on October 1, 2026, and ending on September 30, 2027, the Attorney General shall, prior to initiating any action for a violation of any provision of sections 1 to 9, inclusive, of this act, issue a notice of violation to the developer, integrator, deployer or other person if the Attorney General determines that it is possible to cure such violation. If the developer, integrator, deployer or other person fails to cure such violation not later than sixty days after receipt of the notice of violation, the Attorney General may bring an action pursuant to this section.</p>\n   <p class=\"indent\">(c) Except as provided in subsection (f) of this section, beginning on October 1, 2027, the Attorney General may, in determining whether to grant a developer, integrator, deployer or other person the opportunity to cure a violation described in subsection (b) of this section, consider: (1) The number of violations; (2) the size and complexity of the developer, integrator, deployer or other person; (3) the nature and extent of the developer&#39;s, integrator&#39;s, deployer&#39;s or other person&#39;s business; (4) the substantial likelihood of injury to the public; (5) the safety of persons or property; and (6) whether such violation was likely caused by human or technical error.</p>\n   <p class=\"indent\">(d) Nothing in sections 1 to 9, inclusive, of this act shall be construed as providing the basis for a private right of action for violations of said sections.</p>\n   <p class=\"indent\">(e) Except as provided in subsections (a) to (d), inclusive, of this section and subsection (f) of this section, a violation of the requirements established in sections 1 to 9, inclusive, of this act shall constitute an unfair trade practice for purposes of section 42-110b of the general statutes and shall be enforced solely by the Attorney General. The provisions of section 42-110g of the general statutes shall not apply to any such violation.</p>\n   <p class=\"indent\">(f) (1) In any action commenced by the Attorney General for any violation of sections 1 to 9, inclusive, of this act, it shall be an affirmative defense that the developer, integrator, deployer or other person:</p>\n   <p class=\"indent\">(A) Discovers a violation of any provision of sections 1 to 9, inclusive, of this act through red-teaming;</p>\n   <p class=\"indent\">(B) Not later than sixty days after discovering the violation as set forth in subparagraph (A) of this subdivision: (i) Cures such violation; and (ii) provides to the Attorney General, in a form and manner prescribed by the Attorney General, notice that such violation has been cured and evidence that any harm caused by such violation has been mitigated; and</p>\n   <p class=\"indent\">(C) Is otherwise in compliance with the latest version of: (i) The &quot;Artificial Intelligence Risk Management Framework&quot; published by the National Institute of Standards and Technology; (ii) ISO or IEC 42001 of the International Organization for Standardization; (iii) a nationally or internationally recognized risk management framework for artificial intelligence systems, other than the risk management frameworks specified in subparagraphs (C)(i) and (C)(ii) of this subdivision, that imposes requirements that are substantially equivalent to, and at least as stringent as, the requirements set forth in sections 1 to 9, inclusive, of this act; or (iv) any risk management framework for artificial intelligence systems that is substantially equivalent to, and at least as stringent as, the risk management frameworks described in subparagraphs (C)(i) to (C)(iii), inclusive, of this subdivision.</p>\n   <p class=\"indent\">(2) The developer, integrator, deployer or other person bears the burden of demonstrating to the Attorney General that the requirements established in subdivision (1) of this subsection have been satisfied.</p>\n   <p class=\"indent\">(3) Nothing in this section or sections 1 to 9, inclusive, of this act, including, but not limited to, the enforcement authority granted to the Attorney General under this section, shall be construed to preempt or otherwise affect any right, claim, remedy, presumption or defense available at law or in equity. Any rebuttable presumption or affirmative defense established under this section or sections 1 to 9, inclusive, of this act shall apply only to an enforcement action brought by the Attorney General pursuant to this section and shall not apply to any right, claim, remedy, presumption or defense available at law or in equity.</p>\n   <p class=\"indent\">Sec. 11. (NEW) (Effective October 1, 2025) (a) As used in this section:</p>\n   <p class=\"indent\">(1) &quot;Active participant&quot; means a person participating in the artificial intelligence regulatory sandbox program designed, established and administered in accordance with the provisions of this section;</p>\n   <p class=\"indent\">(2) &quot;Artificial intelligence system&quot; has the same meaning as provided in section 1 of this act;</p>\n   <p class=\"indent\">(3) &quot;Consumer&quot; has the same meaning as provided in section 1 of this act;</p>\n   <p class=\"indent\">(4) &quot;Deployer&quot; means any person doing business in this state that deploys an artificial intelligence system;</p>\n   <p class=\"indent\">(5) &quot;Developer&quot; has the same meaning as provided in section 1 of this act;</p>\n   <p class=\"indent\">(6) &quot;Person&quot; has the same meaning as provided in section 1 of this act; and</p>\n   <p class=\"indent\">(7) &quot;State agency&quot; has the same meaning as provided in section 1-79 of the general statutes.</p>\n   <p class=\"indent\">(b) The Department of Economic and Community Development, in coordination with the Chief Data Officer and the Connecticut Technology Advisory Board established under section 15 of this act, shall design, establish and administer an artificial intelligence regulatory sandbox program to facilitate the development, testing and deployment of innovative artificial intelligence systems in the state. The program shall be designed to (1) promote the safe and innovative use of artificial intelligence systems across various sectors, including, but not limited to, education, finance, health care and public service, (2) encourage the responsible deployment of artificial intelligence systems while balancing the need for consumer protection, privacy and public safety, and (3) provide clear guidelines for developers to test artificial intelligence systems while exempt from certain regulatory requirements during the period set forth in subsection (d) of this section.</p>\n   <p class=\"indent\">(c) (1) A person seeking to participate in the artificial intelligence regulatory sandbox program shall submit an application to the Department of Economic and Community Development in a form and manner prescribed by the Commissioner of Economic and Community Development. Each application shall include (A) a detailed description of the applicant&#39;s artificial intelligence system and its intended uses, (B) a risk assessment that addresses the potential impact of the applicant&#39;s artificial intelligence system on consumers, privacy and public safety, (C) a plan for mitigating any adverse consequences that may arise from the applicant&#39;s artificial intelligence system during the period set forth in subsection (d) of this section, (D) proof that the applicant and the applicant&#39;s artificial intelligence system are in compliance with all applicable federal laws and regulations concerning artificial intelligence systems, and (E) any other information the commissioner deems relevant for the purposes of this section or the program.</p>\n   <p class=\"indent\">(2) Not later than thirty days after the Department of Economic and Community Development receives an application submitted pursuant to subdivision (1) of this subsection, the department shall (A) approve or deny the application, and (B) send a notice to the applicant, in a form and manner prescribed by the Commissioner of Economic and Community Development, disclosing whether the department has approved or denied such application.</p>\n   <p class=\"indent\">(d) An active participant in the artificial intelligence regulatory sandbox program may test the applicant&#39;s artificial intelligence system as part of the program for a period not to exceed thirty-six months from the date on which the Department of Economic and Community Development sent notice approving the active participant&#39;s application pursuant to subdivision (2) of subsection (c) of this section, except the department may extend such period for good cause shown.</p>\n   <p class=\"indent\">(e) The Department of Economic and Community Development shall coordinate with all relevant state agencies to oversee the operations of active participants in the artificial intelligence regulatory sandbox program. Any state agency may recommend to the department that an active participant&#39;s participation in the program be revoked if the active participant&#39;s artificial intelligence system (1) poses an undue risk to the public health, safety or welfare, or (2) violates any federal law or regulation.</p>\n   <p class=\"indent\">(f) For the calendar quarter ending December 31, 2025, and for each calendar quarter thereafter, each active participant in the artificial intelligence regulatory sandbox program shall, not later than thirty days after the end of such calendar quarter, submit a report to the Department of Economic and Community Development disclosing (1) system performance metrics for such active participant&#39;s artificial intelligence system, (2) information concerning the manner in which such active participant&#39;s artificial intelligence system mitigated any risks associated with such artificial intelligence system, and (3) any feedback such active participant received from deployers, consumers and other users of such artificial intelligence system.</p>\n   <p class=\"indent\">(g) For the calendar year ending December 31, 2025, and for each calendar year thereafter, the Department of Economic and Community Development shall, not later than thirty days after the end of such calendar year, submit a report, in accordance with section 11-4a of the general statutes, to the joint standing committee of the General Assembly having cognizance of matters relating to consumer protection. Each report shall disclose (1) the number of persons who were active participants in the artificial intelligence regulatory sandbox program for the calendar year that is the subject of such report or any portion of such calendar year, (2) the overall performance and impact of artificial intelligence systems tested as part of the program, and (3) any recommendations regarding the adoption of legislation for the purposes of the program.</p>\n   <p class=\"indent\">Sec. 12. (NEW) (Effective July 1, 2025) (a) As used in this section, &quot;artificial intelligence&quot; means artificial intelligence system, as defined in section 1 of this act.</p>\n   <p class=\"indent\">(b) Not later than December 31, 2025, the Board of Regents for Higher Education shall establish, on behalf of Charter Oak State College and in consultation with the Labor Department, the State Board of Education, Workforce Investment Boards, employers and institutions of higher education in this state, a &quot;Connecticut AI Academy&quot;. The academy shall, at a minimum:</p>\n   <p class=\"indent\">(1) Curate and offer online courses concerning artificial intelligence and the responsible use of artificial intelligence;</p>\n   <p class=\"indent\">(2) Promote digital literacy;</p>\n   <p class=\"indent\">(3) Prepare students for careers in fields involving artificial intelligence;</p>\n   <p class=\"indent\">(4) Offer courses directed at individuals between thirteen and twenty years of age;</p>\n   <p class=\"indent\">(5) Offer courses that prepare small businesses and nonprofit organizations to utilize artificial intelligence to improve marketing and management efficiency;</p>\n   <p class=\"indent\">(6) Develop courses concerning artificial intelligence that the Labor Department and Workforce Investment Boards may incorporate into workforce training programs; and</p>\n   <p class=\"indent\">(7) Enable persons providing free or discounted public Internet access to distribute information and provide mentorship concerning artificial intelligence, the academy and methods available for the public to obtain free or discounted devices capable of accessing the Internet and utilizing artificial intelligence.</p>\n   <p class=\"indent\">(c) The Board of Regents for Higher Education shall, in consultation with Charter Oak State College, develop certificates and badges to be awarded to persons who successfully complete courses offered by the Connecticut AI Academy.</p>\n   <p class=\"indent\">Sec. 13. (NEW) (Effective July 1, 2025) The Labor Department shall provide a notice, in a form and manner prescribed by the Labor Commissioner, to each individual who makes a claim for unemployment compensation disclosing the existence of, and courses and services offered by, the Connecticut AI Academy established pursuant to section 12 of this act.</p>\n   <p class=\"indent\">Sec. 14. Subsection (b) of section 17b-751b of the general statutes is repealed and the following is substituted in lieu thereof (Effective July 1, 2025):</p>\n   <p class=\"indent\">(b) The commissioner shall: (1) Ensure that all home visiting programs <u class=\"amendmentInsertedText\">(A)</u> are one or more of the evidence-based home visiting models that meet the criteria for evidence of effectiveness developed by the federal Department of Health and Human Services<u class=\"amendmentInsertedText\">, and (B) provide information to parents regarding the Connecticut AI Academy established pursuant to section 12 of this act</u>; (2) provide oversight of home visiting programs to insure model fidelity; and (3) develop, issue and evaluate requests for proposals to procure the services required by this section. In evaluating the proposals, the commissioner shall take into consideration the most effective and consistent service delivery system allowing for the continuation of current public and private programs.</p>\n   <p class=\"indent\">Sec. 15. (NEW) (Effective July 1, 2025) (a) As used in this section, &quot;artificial intelligence&quot; means artificial intelligence system, as defined in section 1 of this act.</p>\n   <p class=\"indent\">(b) There is established, within available appropriations, a Connecticut Technology Advisory Board, which shall be part of the Legislative Department.</p>\n   <p class=\"indent\">(c) (1) The board shall consist of the following members: (A) Two appointed by the speaker of the House of Representatives; (B) two appointed by the president pro tempore of the Senate; (C) two appointed by the minority leader of the House of Representatives; and (D) two appointed by the minority leader of the Senate. All appointed members shall have professional experience or academic qualifications in the field of artificial intelligence or the field of technology, or another related field, and no such member shall be a member of the General Assembly.</p>\n   <p class=\"indent\">(2) The following persons or their designees shall serve as ex-officio, nonvoting members and chairpersons of the board: (A) The Commissioner of Economic and Community Development; (B) the executive director of the Connecticut Academy of Science and Engineering; and (C) the president of Charter Oak State College.</p>\n   <p class=\"indent\">(3) All initial appointments to the board shall be made not later than October 1, 2025. The term of an appointed member shall be coterminous with the term of the appointing authority for the appointed member. Any vacancy shall be filled by the appointing authority. Any vacancy occurring other than by expiration of a term shall be filled for the balance of the unexpired term. A member of the board may serve more than one term. The chairpersons shall schedule the first meeting of the board, which shall be held not later than November 1, 2025.</p>\n   <p class=\"indent\">(d) The administrative staff of the joint standing committees of the General Assembly having cognizance of matters relating to consumer protection and government administration shall serve as administrative staff of the board.</p>\n   <p class=\"indent\">(e) The board shall have the following powers and duties: (1) To develop and adopt a state technology strategy (A) for the purpose of promoting education, workforce development, economic development and consumer protection, and (B) that accounts for the rapid pace of technological development, including, but not limited to, in the field of artificial intelligence; (2) to update the state technology strategy developed and adopted pursuant to subdivision (1) of this subsection at least once every two years; (3) to issue reports and recommendations in accordance with section 11-4a of the general statutes; (4) upon the vote of a majority of the members of the board, to request any state agency data officer or state agency head to (A) appear before the board to answer questions, or (B) provide such assistance and data as may be necessary for the purpose of enabling the board to perform its duties; (5) to make recommendations to the Legislative Department, Executive Department or Judicial Department in accordance with the state technology strategy; and (6) to establish bylaws to govern the board&#39;s procedures.</p>\n   <p class=\"indent\">(f) The board shall meet at least twice annually and may meet at such other times as deemed necessary by the chairpersons or a majority of the members of the board.</p>\n   <p class=\"indent\">Sec. 16. (Effective July 1, 2025) (a) Not later than December 31, 2025, the Department of Economic and Community Development shall, within available appropriations and in collaboration with Charter Oak State College, develop a plan to establish a technology transfer program within Connecticut Innovations, Incorporated, for the purpose of supporting technology transfers by and among public and private institutions of higher education in this state.</p>\n   <p class=\"indent\">(b) Not later than January 1, 2026, the Commissioner of Economic and Community Development shall submit a report, in accordance with section 11-4a of the general statutes, to the joint standing committees of the General Assembly having cognizance of matters relating to consumer protection, commerce and higher education. Such report shall, at a minimum, include the plan developed pursuant to subsection (a) of this section.</p>\n   <p class=\"indent\">Sec. 17. (NEW) (Effective July 1, 2025) (a) Not later than December 31, 2025, the Department of Economic and Community Development shall, within available appropriations and in collaboration with the Office of Health Strategy, establish a confidential computing cluster for the purpose of fostering the exchange of health information in order to support academic and medical research.</p>\n   <p class=\"indent\">(b) (1) The confidential computing cluster established pursuant to subsection (a) of this section shall be overseen by a Connecticut Confidential Computing Cluster Policy Board, which shall be within the Department of Economic and Community Development for administrative purposes only. Said policy board shall consist of:</p>\n   <p class=\"indent\">(A) The chairperson of The University of Connecticut Health Center Board of Directors, or said chairperson&#39;s designee; and</p>\n   <p class=\"indent\">(B) A representative of the State-wide Health Information Exchange established pursuant to section 17b-59d of the general statutes, who shall be appointed by the Commissioner of Health Strategy.</p>\n   <p class=\"indent\">(2) The Connecticut Confidential Computing Cluster Policy Board shall direct the formulation of policies and operating procedures for the confidential computing cluster established pursuant to subsection (a) of this section.</p>\n   <p class=\"indent\">(3) The Connecticut Confidential Computing Cluster Policy Board may apply for and administer any federal, state, local or private appropriations or grant funds made available for the operation of the confidential computing cluster established pursuant to subsection (a) of this section.</p>\n   <p class=\"indent\">Sec. 18. Section 10-21l of the general statutes is repealed and the following is substituted in lieu thereof (Effective July 1, 2025):</p>\n   <p class=\"indent\">There is established an account to be known as the <strike class=\"amendmentDeletedText\">&quot;computer science education account&quot;</strike>\n    <u class=\"amendmentInsertedText\">&quot;computer science education and workforce development account&quot;</u>, which shall be a separate, nonlapsing account within the General Fund. The account shall contain any moneys required or permitted by law to be deposited in the account and any funds received from any public or private contributions, gifts, grants, donations, bequests or devises to the account. The Department of Education may make expenditures from the account <u class=\"amendmentInsertedText\">(1)</u> to support curriculum development, teacher professional development, capacity development for school districts <strike class=\"amendmentDeletedText\">,</strike> and other programs for the purposes of supporting computer science education<u class=\"amendmentInsertedText\">, and (2) in coordination with the Office of Workforce Strategy and the Board of Regents for Higher Education for the purpose of supporting workforce development initiatives in accordance with the state technology strategy adopted pursuant to subsection (e) of section 15 of this act</u>.</p>\n   <p class=\"indent\">Sec. 19. Section 32-7p of the general statutes is repealed and the following is substituted in lieu thereof (Effective July 1, 2025):</p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(a) As used in this section:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(1) &quot;Artificial intelligence&quot; means artificial intelligence system, as defined in section 1 of this act;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(2) &quot;Generative artificial intelligence&quot; means any form of artificial intelligence, including, but not limited to, a foundation model, that is able to produce synthetic digital content, as defined in section 1 of this act; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(3) &quot;Prompt engineering&quot; means the process of guiding generative artificial intelligence to generate a desired output.</u>\n   </p>\n   <p class=\"indent\">\n    <strike class=\"amendmentDeletedText\">(a)</strike>\n    <u class=\"amendmentInsertedText\">(b)</u> There shall be a Technology Talent <u class=\"amendmentInsertedText\">and Innovation Fund</u> Advisory Committee within the Department of Economic and Community Development. Such committee shall consist of members appointed by the Commissioner of Economic and Community Development, including, but not limited to, representatives of The University of Connecticut, the Board of Regents for Higher Education, independent institutions of higher education, the Office of Workforce Strategy and private industry. Such members shall be subject to term limits prescribed by the commissioner. Each member shall hold office until a successor is appointed.</p>\n   <p class=\"indent\">\n    <strike class=\"amendmentDeletedText\">(b)</strike>\n    <u class=\"amendmentInsertedText\">(c)</u> The commissioner shall call the first meeting of the advisory committee not later than October 15, 2016. The advisory committee shall meet not less than quarterly thereafter and at such other times as the chairperson deems necessary. The Technology Talent <u class=\"amendmentInsertedText\">and Innovation Fund</u> Advisory Committee shall designate the chairperson of the committee from among its members.</p>\n   <p class=\"indent\">\n    <strike class=\"amendmentDeletedText\">(c)</strike>\n    <u class=\"amendmentInsertedText\">(d)</u> No member of the advisory committee shall receive compensation for such member&#39;s service, except that each member shall be entitled to reimbursement for actual and necessary expenses incurred during the performance of such member&#39;s official duties.</p>\n   <p class=\"indent\">\n    <strike class=\"amendmentDeletedText\">(d)</strike>\n    <u class=\"amendmentInsertedText\">(e)</u> A majority of members of the advisory committee shall constitute a quorum for the transaction of any business or the exercise of any power of the advisory committee. The advisory committee may act by a majority of the members present at any meeting at which a quorum is in attendance, for the transaction of any business or the exercise of any power of the advisory committee, except as otherwise provided in this section.</p>\n   <p class=\"indent\">\n    <strike class=\"amendmentDeletedText\">(e)</strike>\n    <u class=\"amendmentInsertedText\">(f)</u> Notwithstanding any provision of the general statutes, it shall not constitute a conflict of interest for a trustee, director, partner or officer of any person, firm or corporation, or any individual having a financial interest in a person, firm or corporation, to serve as a member of the advisory committee, provided such trustee, director, partner, officer or individual complies with all applicable provisions of chapter 10. All members of the advisory committee shall be deemed public officials and shall adhere to the code of ethics for public officials set forth in chapter 10, except that no member shall be required to file a statement of financial interest as described in section 1-83.</p>\n   <p class=\"indent\">\n    <strike class=\"amendmentDeletedText\">(f) The Technology Talent Advisory Committee shall, in the following order of priority, (1) calculate the number of software developers and other persons (A) employed in technology-based fields where there is a shortage of qualified employees in this state for businesses to hire, including, but not limited to, data mining, data analysis and cybersecurity, and (B) employed by businesses located in Connecticut as of December 31, 2016; (2) develop pilot programs to recruit software developers to Connecticut and train residents of the state in software development and such other technology fields, with the goal of increasing the number of software developers and persons employed in such other technology fields residing in Connecticut and employed by businesses in Connecticut by at least double the number calculated pursuant to subdivision (1) of this subsection by January 1, 2026; and (3) identify other technology industries where there is a shortage of qualified employees in this state for growth stage businesses to hire.</strike>\n   </p>\n   <p class=\"indent\">(g) The Technology Talent <u class=\"amendmentInsertedText\">and Innovation Fund</u> Advisory Committee may <u class=\"amendmentInsertedText\">partner with institutions of higher education and other nonprofit organizations to</u> develop <strike class=\"amendmentDeletedText\">pilot</strike> programs <strike class=\"amendmentDeletedText\">for (1) marketing and publicity campaigns designed to recruit technology talent to the state; (2) student loan deferral or forgiveness for students who start businesses in the state; and (3) training, apprenticeship and gap-year initiatives</strike>\n    <u class=\"amendmentInsertedText\">to expand the technology talent pipeline in the state, including, but not limited to, in the fields of artificial intelligence and quantum computing</u>.</p>\n   <p class=\"indent\">\n    <strike class=\"amendmentDeletedText\">(h) The Technology Talent Advisory Committee shall report, in accordance with the provisions of section 11-4a, and present such report to the joint standing committees of the General Assembly having cognizance of matters relating to commerce, education, higher education and finance, revenue and bonding on or before January 1, 2017, concerning the (1) pilot programs developed pursuant to subsections (f) and (g) of this section, (2) number of software developers and persons employed in technology-based fields described in subsection (f) of this section targeted for recruitment pursuant to subsection (f) of this section, and (3) timeline and measures for reaching the recruitment target.</strike>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(h) Not later than July 1, 2026, the Technology Talent and Innovation Fund Advisory Committee shall partner with public and private institutions of higher education in the state and other training providers to develop programs in the field of artificial intelligence, including, but not limited to, in areas such as prompt engineering, artificial intelligence marketing for small businesses and artificial intelligence for small business operations.</u>\n   </p>\n   <p class=\"indent\">Sec. 20. Subsection (b) of section 32-235 of the general statutes is repealed and the following is substituted in lieu thereof (Effective July 1, 2025):</p>\n   <p class=\"indent\">(b) The proceeds of the sale of said bonds, to the extent of the amount stated in subsection (a) of this section, shall be used by the Department of Economic and Community Development (1) for the purposes of sections 32-220 to 32-234, inclusive, including economic cluster-related programs and activities, and for the Connecticut job training finance demonstration program pursuant to sections 32-23uu and 32-23vv, provided (A) three million dollars shall be used by said department solely for the purposes of section 32-23uu, (B) not less than one million dollars shall be used for an educational technology grant to the deployment center program and the nonprofit business consortium deployment center approved pursuant to section 32-41l, (C) not less than two million dollars shall be used by said department for the establishment of a pilot program to make grants to businesses in designated areas of the state for construction, renovation or improvement of small manufacturing facilities, provided such grants are matched by the business, a municipality or another financing entity. The Commissioner of Economic and Community Development shall designate areas of the state where manufacturing is a substantial part of the local economy and shall make grants under such pilot program which are likely to produce a significant economic development benefit for the designated area, (D) five million dollars may be used by said department for the manufacturing competitiveness grants program, (E) one million dollars shall be used by said department for the purpose of a grant to the Connecticut Center for Advanced Technology, for the purposes of subdivision (5) of subsection (a) of section 32-7f, (F) fifty million dollars shall be used by said department for the purpose of grants to the United States Department of the Navy, the United States Department of Defense or eligible applicants for projects related to the enhancement of infrastructure for long-term, on-going naval operations at the United States Naval Submarine Base-New London, located in Groton, which will increase the military value of said base. Such projects shall not be subject to the provisions of sections 4a-60 and 4a-60a, (G) two million dollars shall be used by said department for the purpose of a grant to the Connecticut Center for Advanced Technology, Inc., for manufacturing initiatives, including aerospace and defense, and (H) four million dollars shall be used by said department for the purpose of a grant to companies adversely impacted by the construction at the Quinnipiac Bridge, where such grant may be used to offset the increase in costs of commercial overland transportation of goods or materials brought to the port of New Haven by ship or vessel, (2) for the purposes of the small business assistance program established pursuant to section 32-9yy, provided fifteen million dollars shall be deposited in the small business assistance account established pursuant to said section 32-9yy, (3) to deposit twenty million dollars in the small business express assistance account established pursuant to section 32-7h, (4) to deposit four million nine hundred thousand dollars per year in each of the fiscal years ending June 30, 2017, to June 30, 2019, inclusive, and June 30, 2021, and nine million nine hundred thousand dollars in the fiscal year ending June 30, 2020, in the CTNext Fund established pursuant to section 32-39i, which shall be used by the Department of Economic and Community Development to provide grants-in-aid to designated innovation places, as defined in section 32-39f, planning grants-in-aid pursuant to section 32-39l, and grants-in-aid for projects that network innovation places pursuant to subsection (b) of section 32-39m, provided not more than three million dollars be used for grants-in-aid for such projects, and further provided any portion of any such deposit that remains unexpended in a fiscal year subsequent to the date of such deposit may be used by the Department of Economic and Community Development for any purpose described in subsection (e) of section 32-39i, (5) to deposit two million dollars per year in each of the fiscal years ending June 30, 2019, to June 30, 2021, inclusive, in the CTNext Fund established pursuant to section 32-39i, which shall be used by the Department of Economic and Community Development for the purpose of providing higher education entrepreneurship grants-in-aid pursuant to section 32-39g, provided any portion of any such deposit that remains unexpended in a fiscal year subsequent to the date of such deposit may be used by the Department of Economic and Community Development for any purpose described in subsection (e) of section 32-39i, (6) for the purpose of funding the costs of the Technology Talent <u class=\"amendmentInsertedText\">and Innovation Fund</u> Advisory Committee established pursuant to section 32-7p<u class=\"amendmentInsertedText\">, as amended by this act</u>, provided not more than ten million dollars may be used on or after July 1, 2023, for such purpose, (7) to provide (A) a grant-in-aid to the Connecticut Supplier Connection in an amount equal to two hundred fifty thousand dollars in each of the fiscal years ending June 30, 2017, to June 30, 2021, inclusive, and (B) a grant-in-aid to the Connecticut Procurement Technical Assistance Program in an amount equal to three hundred thousand dollars in each of the fiscal years ending June 30, 2017, to June 30, 2021, inclusive, (8) to deposit four hundred fifty thousand dollars per year, in each of the fiscal years ending June 30, 2017, to June 30, 2021, inclusive, in the CTNext Fund established pursuant to section 32-39i, which shall be used by the Department of Economic and Community Development to provide growth grants-in-aid pursuant to section 32-39g, provided any portion of any such deposit that remains unexpended in a fiscal year subsequent to the date of such deposit may be used by the Department of Economic and Community Development for any purpose described in subsection (e) of section 32-39i, (9) to transfer fifty million dollars to the Labor Department which shall be used by said department for the purpose of funding workforce pipeline programs selected pursuant to section 31-11rr, provided, notwithstanding the provisions of section 31-11rr, (A) not less than five million dollars shall be provided to the workforce development board in Bridgeport serving the southwest region, for purposes of such program, and the board shall distribute such money in proportion to population and need, and (B) not less than five million dollars shall be provided to the workforce development board in Hartford serving the north central region, for purposes of such program, (10) to transfer twenty million dollars to Connecticut Innovations, Incorporated, provided ten million dollars shall be used by Connecticut Innovations, Incorporated for the purpose of the proof of concept fund established pursuant to subsection (b) of section 32-39x and ten million dollars shall be used by Connecticut Innovations, Incorporated for the purpose of the venture capital fund program established pursuant to section 32-41oo, (11) to provide a grant to The University of Connecticut of eight million dollars for the establishment, development and operation of a center for sustainable aviation pursuant to subsection (a) of section 10a-110o, and (12) for up to twenty million dollars in investments in federally designated opportunity zones through an impact investment firm including, subject to the approval of the Governor, funding from the Economic Assistance Revolving Fund, established pursuant to section 32-231.</p>\n   <p class=\"indent\">Sec. 21. (Effective July 1, 2025) Not later than December 31, 2025, the Department of Economic and Community Development shall, within available appropriations, in partnership with public and private institutions of higher education in the state and in coordination with the artificial intelligence industry, conduct a &quot;CT AI Symposium&quot; to foster collaboration between academia, government and the artificial intelligence industry for the purpose of promoting the establishment and growth of artificial intelligence businesses in this state.</p>\n   <p class=\"indent\">Sec. 22. (Effective July 1, 2025) (a) As used in this section:</p>\n   <p class=\"indent\">(1) &quot;Artificial intelligence&quot; means artificial intelligence system, as defined in section 1 of this act;</p>\n   <p class=\"indent\">(2) &quot;Generative artificial intelligence&quot; means any form of artificial intelligence, including, but not limited to, a foundation model, that is able to produce synthetic digital content, as defined in section 1 of this act; and</p>\n   <p class=\"indent\">(3) &quot;State agency&quot; means any department, board, council, commission, institution or other executive branch agency of state government, including, but not limited to, each constituent unit and each public institution of higher education.</p>\n   <p class=\"indent\">(b) Each state agency shall, in consultation with the labor unions representing the employees of such state agency, study how generative artificial intelligence may be incorporated in its processes to improve efficiencies. Each state agency shall prepare for any such incorporation with input from the state agency&#39;s employees, including, but not limited to, any applicable collective bargaining unit that represents its employees, and appropriate experts from civil society organizations, academia and industry.</p>\n   <p class=\"indent\">(c) Not later than January 1, 2026, each state agency shall submit the results of such study to the Department of Administrative Services, including a request for approval of any potential pilot project utilizing generative artificial intelligence that the state agency intends to establish, provided such use is in accordance with the policies and procedures established by the Office of Policy and Management pursuant to subsection (b) of section 4-68jj of the general statutes. Any such pilot project shall measure how generative artificial intelligence (1) improves Connecticut residents&#39; experience with and access to government services, and (2) supports state agency employees in the performance of their duties in addition to any domain-specific impacts to be measured by the state agency. The Commissioner of Administrative Services shall assess any such proposed pilot project in accordance with the provisions of section 4a-2e of the general statutes, as amended by this act, and may disapprove any pilot project that fails such assessment or requires additional legislative authorization.</p>\n   <p class=\"indent\">(d) Not later than February 1, 2026, the Commissioner of Administrative Services shall submit a report, in accordance with section 11-4a of the general statutes, to the joint standing committees of the General Assembly having cognizance of matters relating to consumer protection and government administration. Such report shall include a summary of all pilot projects approved by the commissioner under this section and any recommendations for legislation necessary to implement additional pilot projects.</p>\n   <p class=\"indent\">Sec. 23. Section 32-39e of the general statutes is repealed and the following is substituted in lieu thereof (Effective July 1, 2025):</p>\n   <p class=\"indent\">(a) If, in the exercise of its powers under section 32-39, Connecticut Innovations, Incorporated (1) finds that the use of a certain technology, product or process<u class=\"amendmentInsertedText\">, including, but not limited to, an artificial intelligence system, as defined in section 1 of this act,</u> (A) would promote public health and safety, environmental protection or economic development, or (B) with regard to state services, would promote efficiency, reduce administrative burdens or otherwise improve such services, and (2) determines such technology, product or process was developed by a business (A) domiciled in this state to which the corporation has provided financial assistance or in which the corporation has invested, or (B) which has been certified as a small contractor or minority business enterprise by the Commissioner of Administrative Services under section 4a-60g, the corporation, upon application of such business, may recommend to the Secretary of the Office of Policy and Management that an agency of the state, including, but not limited to, any constituent unit of the state system of higher education, be authorized to test such technology, product or process by employing <strike class=\"amendmentDeletedText\">it</strike>\n    <u class=\"amendmentInsertedText\">such technology, product or process</u> in the operations of such agency on a trial basis. The purpose of such test program shall be to validate the commercial viability of such technology, product or process provided no business in which Connecticut Innovations, Incorporated has invested shall be required to participate in such program.</p>\n   <p class=\"indent\">(b) Connecticut Innovations, Incorporated shall make no such recommendation unless such business has submitted a viable business plan to Connecticut Innovations, Incorporated for manufacturing and marketing such technology, product or process and such business demonstrates that (1) the usage of such technology, product or process by the state agency will not adversely affect safety, (2) sufficient research and development has occurred to warrant participation in the test program, (3) the technology, product or process has potential for commercialization not later than two years following the completion of any test program involving a state agency under this section, and (4) such technology, product or process will have a positive economic impact in the state, including the prospective addition of jobs and economic activity upon such commercialization.</p>\n   <p class=\"indent\">(c) If the Secretary of the Office of Policy and Management finds that employing such technology, product or process would be feasible in the operations of a state agency and would not have any detrimental effect on such operations, said secretary, notwithstanding the requirement of chapter 58, may direct an agency of the state to accept delivery of such technology, product or process and to undertake such a test program. The Secretary of the Office of Policy and Management, in consultation with the Commissioner of Administrative Services, the chief executive officer of Connecticut Innovations, Incorporated and the department head of the testing agency, shall determine, on a case-by-case basis, whether the costs associated with the acquisition and use of such technology, product or process by the testing agency shall be borne by Connecticut Innovations, Incorporated, the business or by any investor or participant in such business. The acquisition of any technology, product or process for purposes of the test program established pursuant to this section shall not be deemed to be a purchase under the provisions of the state procurement policy. The testing agency, on behalf of Connecticut Innovations, Incorporated shall maintain records related to such test program, as requested by Connecticut Innovations, Incorporated and shall make such records and any other information derived from such test program available to Connecticut Innovations, Incorporated and the business. Any proprietary information derived from such test program shall be exempt from the provisions of subsection (a) of section 1-210.</p>\n   <p class=\"indent\">(d) If the Secretary of the Office of Policy and Management, in consultation with the Commissioner of Administrative Services, the chief executive officer of Connecticut Innovations, Incorporated and the department head of the testing agency, determines that the test program sufficiently demonstrates that the technology, product or process promotes public health and safety, environmental protection, economic development or efficiency, reduces administrative burdens or otherwise improves state services, the Commissioner of Administrative Services may procure such technology, product or process for use by any or all state agencies pursuant to subsection (b) of section 4a-58.</p>\n   <p class=\"indent\">(e) The Secretary of the Office of Policy and Management, the Commissioner of Administrative Services and Connecticut Innovations, Incorporated may develop a program to recognize state agencies that help to promote public health and safety, environmental protection, economic development or efficiency, reduce administrative burdens or improve state services by participating in a testing program under this section. Such program may include the creation of a fund established with savings accrued by the testing agency during its participation in the testing program established under this section. Such fund shall only be used to implement the program of recognition established by the Secretary of the Office of Policy and Management, the Commissioner of Administrative Services and Connecticut Innovations, Incorporated, under the provisions of this subsection.</p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(f) The Secretary of the Office of Policy and Management, the Commissioner of Administrative Services, Connecticut Innovations, Incorporated, and the Chief Information Officer shall, within available appropriations, establish an artificial intelligence systems fellowship program for the purpose of assisting the Chief Information Officer and state agencies to implement artificial intelligence systems procured pursuant to subsection (b) of section 4a-58. The program shall be within the Office of Policy and Management for administrative purposes only. Not later than January 1, 2026, the Governor shall appoint three artificial intelligence technology fellows in consultation with the Chief Information Officer. Each artificial intelligence technology fellow shall have professional experience or academic qualifications in the field of artificial intelligence, and shall perform such artificial intelligence technology fellow&#39;s duties under the supervision of the Chief Information Officer. The initial term for each artificial intelligence technology fellow shall expire on January 31, 2029. Terms following initial terms shall be for two years, and any artificial intelligence technology fellow may serve more than one term. The Governor shall fill any vacancy in consultation with the Chief Information Officer not later than thirty days after the appointment becomes vacant. For the purposes of this subsection, &quot;artificial intelligence system&quot; has the same meaning as provided in section 1 of this act.</u>\n   </p>\n   <p class=\"indent\">Sec. 24. (Effective July 1, 2025) (a) For the purposes of this section:</p>\n   <p class=\"indent\">(1) &quot;Artificial intelligence&quot; means artificial intelligence system, as defined in section 1 of this act;</p>\n   <p class=\"indent\">(2) &quot;General-purpose artificial intelligence&quot; means general-purpose artificial intelligence model, as defined in section 1 of this act; and</p>\n   <p class=\"indent\">(3) &quot;Synthetic digital content&quot; has the same meaning as provided in section 1 of this act.</p>\n   <p class=\"indent\">(b) There is established a working group to engage stakeholders and experts to:</p>\n   <p class=\"indent\">(1) Make recommendations concerning:</p>\n   <p class=\"indent\">(A) The best practices to avoid the negative impacts, and to maximize the positive impacts, on services and state employees in connection with the implementation of new digital technologies and artificial intelligence;</p>\n   <p class=\"indent\">(B) The collection of reports, recommendations and plans from state agencies considering the implementation of artificial intelligence, and the assessment of such reports, recommendations and plans against the best practices described in subparagraph (A) of this subdivision; and</p>\n   <p class=\"indent\">(C) Any other matters which the working group may deem relevant for the purposes of avoiding the negative impacts, and maximizing the positive impacts, described in subparagraph (A) of this subdivision;</p>\n   <p class=\"indent\">(2) Make recommendations concerning methods to create resources for the purpose of assisting small businesses to adopt artificial intelligence to improve their efficiency and operations;</p>\n   <p class=\"indent\">(3) Propose legislation to (A) regulate the use of general-purpose artificial intelligence, and (B) require social media platforms to provide a signal when such social media platforms are displaying synthetic digital content;</p>\n   <p class=\"indent\">(4) After reviewing the laws and regulations, and any proposed legislation or regulations, of other states concerning artificial intelligence, propose legislation concerning artificial intelligence;</p>\n   <p class=\"indent\">(5) Develop an outreach plan for the purpose of bridging the digital divide and providing workforce training to persons who do not have high-speed Internet access;</p>\n   <p class=\"indent\">(6) Evaluate and make recommendations concerning:</p>\n   <p class=\"indent\">(A) The establishment of testbeds to support safeguards and systems to prevent the misuse of artificial intelligence;</p>\n   <p class=\"indent\">(B) Risk assessments for the misuse of artificial intelligence;</p>\n   <p class=\"indent\">(C) Evaluation strategies for artificial intelligence; and</p>\n   <p class=\"indent\">(D) The development, testing and evaluation of resources to support state oversight of artificial intelligence;</p>\n   <p class=\"indent\">(7) Review the protections afforded to trade secrets and other proprietary information under existing state law and make recommendations concerning such protections;</p>\n   <p class=\"indent\">(8) Study definitions concerning artificial intelligence, including, but not limited to, the definition of high-risk artificial intelligence system set forth in section 1 of this act, and make recommendations concerning the inclusion of language providing that no artificial intelligence system shall be considered to be a high-risk artificial intelligence system if such artificial intelligence system does not pose a significant risk of harm to the health, safety or fundamental rights of individuals, including, but not limited to, by not materially influencing the outcome of any decision-making;</p>\n   <p class=\"indent\">(9) Make recommendations concerning the establishment and membership of a permanent artificial intelligence advisory council; and</p>\n   <p class=\"indent\">(10) Make such other recommendations concerning artificial intelligence which the working group may deem appropriate.</p>\n   <p class=\"indent\">(c) (1) (A) The working group shall be part of the Legislative Department and consist of the following voting members: (i) One appointed by the speaker of the House of Representatives, who shall be a representative of the industries that are developing artificial intelligence; (ii) one appointed by the president pro tempore of the Senate, who shall be a representative of the industries that are using artificial intelligence; (iii) one appointed by the majority leader of the House of Representatives, who shall be an academic with a concentration in the study of technology and technology policy; (iv) one appointed by the majority leader of the Senate, who shall be an academic with a concentration in the study of government and public policy; (v) one appointed by the minority leader of the House of Representatives, who shall be a representative of an industry association representing the industries that are developing artificial intelligence; (vi) one appointed by the minority leader of the Senate, who shall be a representative of an industry association representing the industries that are using artificial intelligence; (vii) one appointed by the House chairperson of the joint standing committee of the General Assembly having cognizance of matters relating to consumer protection; (viii) one appointed by the Senate chairperson of the joint standing committee of the General Assembly having cognizance of matters relating to consumer protection; (ix) one appointed by the House ranking member of the joint standing committee of the General Assembly having cognizance of matters relating to consumer protection, who shall be a representative of the artificial intelligence industry or a related industry; (x) one appointed by the Senate ranking member of the joint standing committee of the General Assembly having cognizance of matters relating to consumer protection, who shall be a representative of the artificial intelligence industry or a related industry; (xi) one appointed by the House chairperson of the joint standing committee of the General Assembly having cognizance of matters relating to labor, who shall be a representative of a labor organization; (xii) one appointed by the Senate chairperson of the joint standing committee of the General Assembly having cognizance of matters relating to labor, who shall be a representative of a labor organization; (xiii) one appointed by the House ranking member of the joint standing committee of the General Assembly having cognizance of matters relating to labor, who shall be a representative of a small business; (xiv) one appointed by the Senate ranking member of the joint standing committee of the General Assembly having cognizance of matters relating to labor, who shall be a representative of a small business; and (xv) two appointed by the Governor, who shall be members of the Connecticut Academy of Science and Engineering.</p>\n   <p class=\"indent\">(B) All voting members of the working group appointed pursuant to subparagraph (A) of this subdivision shall have professional experience or academic qualifications in matters pertaining to artificial intelligence, automated systems, government policy or another related field.</p>\n   <p class=\"indent\">(C) All initial appointments to the working group shall be made not later than July 31, 2025. Any vacancy shall be filled by the appointing authority.</p>\n   <p class=\"indent\">(D) Any action taken by the working group shall be taken by a majority vote of all members present who are entitled to vote, provided no such action may be taken unless at least fifty per cent of such members are present.</p>\n   <p class=\"indent\">(2) The working group shall include the following nonvoting, ex-officio members: (A) The House chairperson of the joint standing committee of the General Assembly having cognizance of matters relating to consumer protection; (B) the Senate chairperson of the joint standing committee of the General Assembly having cognizance of matters relating to consumer protection; (C) the House chairperson of the joint standing committee of the General Assembly having cognizance of matters relating to labor; (D) the Senate chairperson of the joint standing committee of the General Assembly having cognizance of matters relating to labor; (E) the Attorney General, or the Attorney General&#39;s designee; (F) the Comptroller, or the Comptroller&#39;s designee; (G) the Treasurer, or the Treasurer&#39;s designee; (H) the Commissioner of Administrative Services, or said commissioner&#39;s designee; (I) the Chief Data Officer, or said officer&#39;s designee; (J) the executive director of the Freedom of Information Commission, or said executive director&#39;s designee; (K) the executive director of the Commission on Women, Children, Seniors, Equity and Opportunity, or said executive director&#39;s designee; (L) the Chief Court Administrator, or said administrator&#39;s designee; and (M) the executive director of the Connecticut Academy of Science and Engineering, or said executive director&#39;s designee.</p>\n   <p class=\"indent\">(d) The chairpersons of the joint standing committee of the General Assembly having cognizance of matters relating to consumer protection and the executive director of the Connecticut Academy of Science and Engineering shall serve as chairpersons of the working group. Such chairpersons shall schedule the first meeting of the working group, which shall be held not later than August 31, 2025.</p>\n   <p class=\"indent\">(e) The administrative staff of the joint standing committee of the General Assembly having cognizance of matters relating to consumer protection shall serve as administrative staff of the working group.</p>\n   <p class=\"indent\">(f) Not later than February 1, 2026, the working group shall submit a report on its findings and recommendations to the joint standing committee of the General Assembly having cognizance of matters relating to consumer protection, in accordance with section 11-4a of the general statutes. The working group shall terminate on the date that the working group submits such report or February 1, 2026, whichever is later.</p>\n   <p class=\"indent\">Sec. 25. Section 4a-2e of the general statutes is repealed and the following is substituted in lieu thereof (Effective July 1, 2025):</p>\n   <p class=\"indent\">(a) For the purposes of this section:</p>\n   <p class=\"indent\">(1) &quot;Artificial intelligence&quot; means <strike class=\"amendmentDeletedText\">(A) an artificial system that (i) performs tasks under varying and unpredictable circumstances without significant human oversight or can learn from experience and improve such performance when exposed to data sets, (ii) is developed in any context, including, but not limited to, software or physical hardware, and solves tasks requiring human-like perception, cognition, planning, learning, communication or physical action, or (iii) is designed to (I) think or act like a human, including, but not limited to, a cognitive architecture or neural network, or (II) act rationally, including, but not limited to, an intelligent software agent or embodied robot that achieves goals using perception, planning, reasoning, learning, communication, decision-making or action, or (B) a set of techniques, including, but not limited to, machine learning, that is designed to approximate a cognitive task; and</strike>\n    <u class=\"amendmentInsertedText\">artificial intelligence system, as defined in section 1 of this act;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(2) &quot;Generative artificial intelligence&quot; means any form of artificial intelligence, including, but not limited to, a foundation model, that is able to produce synthetic digital content, as defined in section 1 of this act; and</u>\n   </p>\n   <p class=\"indent\">\n    <strike class=\"amendmentDeletedText\">(2)</strike>\n    <u class=\"amendmentInsertedText\">(3)</u> &quot;State agency&quot; has the same meaning as provided in section 4d-1.</p>\n   <p class=\"indent\">(b) (1) Not later than December 31, 2023, and annually thereafter, the <strike class=\"amendmentDeletedText\">Department</strike>\n    <u class=\"amendmentInsertedText\">Commissioner</u> of Administrative Services shall conduct an inventory of all systems that employ artificial intelligence and are in use by any state agency. Each such inventory shall include at least the following information for each such system:</p>\n   <p class=\"indent\">(A) The name of such system and the vendor, if any, that provided such system;</p>\n   <p class=\"indent\">(B) A description of the general capabilities and uses of such system;</p>\n   <p class=\"indent\">(C) Whether such system was used to independently make, inform or materially support a conclusion, decision or judgment; and</p>\n   <p class=\"indent\">(D) Whether such system underwent an impact assessment prior to implementation.</p>\n   <p class=\"indent\">(2) The <strike class=\"amendmentDeletedText\">Department</strike>\n    <u class=\"amendmentInsertedText\">Commissioner</u> of Administrative Services shall make each inventory conducted pursuant to subdivision (1) of this subsection publicly available on the state&#39;s open data portal.</p>\n   <p class=\"indent\">(c) Beginning on February 1, 2024, the <strike class=\"amendmentDeletedText\">Department</strike>\n    <u class=\"amendmentInsertedText\">Commissioner</u> of Administrative Services shall perform ongoing assessments of systems that employ artificial intelligence and are in use by state agencies to ensure that no such system shall result in any unlawful discrimination or disparate impact described in subparagraph (B) of subdivision (1) of subsection (b) of section 4-68jj. The <strike class=\"amendmentDeletedText\">department</strike>\n    <u class=\"amendmentInsertedText\">commissioner</u> shall perform such assessment in accordance with the policies and procedures established by the Office of Policy and Management pursuant to subsection (b) of section 4-68jj.</p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(d) The Commissioner of Administrative Services shall, in consultation with other state agencies, collective bargaining units that represent state agency employees and industry experts, develop trainings for state agency employees on (1) the use of generative artificial intelligence tools that are determined by the commissioner, pursuant to the assessment performed under subsection (c) of this section, to achieve equitable outcomes, and (2) methods for identifying and mitigating potential output inaccuracies, fabricated text, hallucinations and biases of generative artificial intelligence while respecting the privacy of the public and complying with all applicable state laws and policies. Beginning on July 1, 2026, the commissioner shall make such trainings available to state agency employees not less frequently than annually.</u>\n   </p>\n   <p class=\"indent\">Sec. 26. (NEW) (Effective July 1, 2025) The Department of Economic and Community Development shall, within available appropriations, design an algorithmic computer model for the purpose of simulating and assessing various public policy decisions, proposed public policy decisions and the actual or potential effects of such policy decisions. The department shall design such model in collaboration with public and private institutions of higher education in this state, the Department of Energy and Environmental Protection and any other state agency the Commissioner of Economic and Community Development, in the commissioner&#39;s discretion, deems relevant for the purposes of this section. Such model shall, at a minimum, be designed to (1) function as a digital twin of the population of the state, (2) algorithmically model (A) the actual or potential effects of planning and development decisions or proposed planning and development decisions, and (B) the actual or potential socioeconomic effects of macroeconomic shocks on businesses and families in the state, (3) utilize large quantities of data to support the development of public policies concerning coastline resiliency, family assistance and workforce development, and (4) enable data-driven governance by optimizing resource allocation and policy efficiency for the purpose of furthering economic resilience and social equity.</p>\n   <p class=\"indent\">Sec. 27. Section 53a-189c of the general statutes is repealed and the following is substituted in lieu thereof (Effective October 1, 2025):</p>\n   <p class=\"indent\">(a) A person is guilty of unlawful dissemination of an intimate image when (1) such person intentionally disseminates by electronic or other means a photograph, film, videotape or other recorded image <u class=\"amendmentInsertedText\">or synthetic image</u> of (A) the genitals, pubic area or buttocks of another person with less than a fully opaque covering of such body part, or the breast of such other person who is female with less than a fully opaque covering of any portion of such breast below the top of the nipple, or (B) another person engaged in sexual intercourse, as defined in section 53a-193, (2) such person disseminates such image <strike class=\"amendmentDeletedText\">without the consent of such other person,</strike> knowing that such other person <strike class=\"amendmentDeletedText\">understood that the image would not be so disseminated</strike>\n    <u class=\"amendmentInsertedText\">did not consent to such dissemination</u>, and (3) such other person suffers harm as a result of such dissemination.</p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b)</u> For purposes of this <strike class=\"amendmentDeletedText\">subsection, &quot;disseminate&quot;</strike>\n    <u class=\"amendmentInsertedText\">section:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(1) &quot;Disseminate&quot;</u> means to sell, give, provide, lend, trade, mail, deliver, transfer, publish, distribute, circulate, present, exhibit, advertise or otherwise offer<u class=\"amendmentInsertedText\">;</u>\n    <strike class=\"amendmentDeletedText\">, and &quot;harm&quot;</strike>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(2) &quot;Harm&quot;</u> includes, but is not limited to, subjecting such other person to hatred, contempt, ridicule, physical injury, financial injury, psychological harm or serious emotional distress<u class=\"amendmentInsertedText\">; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(3) &quot;Synthetic image&quot; means any photograph, film, videotape or other image that (A) is not wholly recorded by a camera, (B) is either partially or wholly generated by a computer system, and (C) depicts, and is virtually indistinguishable from an actual representation of, an identifiable person</u>.</p>\n   <p class=\"indent\">\n    <strike class=\"amendmentDeletedText\">(b)</strike>\n    <u class=\"amendmentInsertedText\">(c)</u> The provisions of subsection (a) of this <strike class=\"amendmentDeletedText\">subsection</strike>\n    <u class=\"amendmentInsertedText\">section</u> shall not apply to:</p>\n   <p class=\"indent\">(1) Any image described in subsection (a) of this section of such other person if such image resulted from voluntary exposure or engagement in sexual intercourse by such other person, in a public place, as defined in section 53a-181, or in a commercial setting;</p>\n   <p class=\"indent\">(2) Any image described in subsection (a) of this section of such other person, if such other person is not clearly identifiable, unless other personally identifying information is associated with or accompanies the image; or</p>\n   <p class=\"indent\">(3) Any image described in subsection (a) of this section of such other person, if the dissemination of such image serves the public interest.</p>\n   <p class=\"indent\">\n    <strike class=\"amendmentDeletedText\">(c)</strike>\n    <u class=\"amendmentInsertedText\">(d)</u> Unlawful dissemination of an intimate image to (1) a person by any means is a class A misdemeanor, and (2) more than one person by means of an interactive computer service, as defined in 47 USC 230, an information service, as defined in 47 USC 153, or a telecommunications service, as defined in section 16-247a, is a class D felony.</p>\n   <p class=\"indent\">\n    <strike class=\"amendmentDeletedText\">(d)</strike>\n    <u class=\"amendmentInsertedText\">(e)</u> Nothing in this section shall be construed to impose liability on the provider of an interactive computer service, as defined in 47 USC 230, an information service, as defined in 47 USC 153, or a telecommunications service, as defined in section 16-247a, for content provided by another person.</p>\n   <table>\n    <tr>\n     <td colspan=\"3\">This act shall take effect as follows and shall amend the following sections:<br/>\n     </td>\n    </tr>\n    <tr>\n     <td>Section 1</td>\n     <td>October 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 2</td>\n     <td>October 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 3</td>\n     <td>October 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 4</td>\n     <td>October 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 5</td>\n     <td>October 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 6</td>\n     <td>October 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 7</td>\n     <td>October 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 8</td>\n     <td>October 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 9</td>\n     <td>October 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 10</td>\n     <td>October 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 11</td>\n     <td>October 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 12</td>\n     <td>July 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 13</td>\n     <td>July 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 14</td>\n     <td>July 1, 2025</td>\n     <td>17b-751b(b)</td>\n    </tr>\n    <tr>\n     <td>Sec. 15</td>\n     <td>July 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 16</td>\n     <td>July 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 17</td>\n     <td>July 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 18</td>\n     <td>July 1, 2025</td>\n     <td>10-21l</td>\n    </tr>\n    <tr>\n     <td>Sec. 19</td>\n     <td>July 1, 2025</td>\n     <td>32-7p</td>\n    </tr>\n    <tr>\n     <td>Sec. 20</td>\n     <td>July 1, 2025</td>\n     <td>32-235(b)</td>\n    </tr>\n    <tr>\n     <td>Sec. 21</td>\n     <td>July 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 22</td>\n     <td>July 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 23</td>\n     <td>July 1, 2025</td>\n     <td>32-39e</td>\n    </tr>\n    <tr>\n     <td>Sec. 24</td>\n     <td>July 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 25</td>\n     <td>July 1, 2025</td>\n     <td>4a-2e</td>\n    </tr>\n    <tr>\n     <td>Sec. 26</td>\n     <td>July 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 27</td>\n     <td>October 1, 2025</td>\n     <td>53a-189c</td>\n    </tr>\n   </table>\n   <p class=\"indent\">\n    <b>Statement of Purpose: </b>\n   </p>\n   <p class=\"indent\">To (1) establish various requirements concerning artificial intelligence systems, (2) require the Department of Economic and Community Development to (A) establish an artificial intelligence regulatory sandbox program, (B) plan to establish a technology transfer program, (C) establish a confidential computing cluster, (D) conduct a &quot;CT AI Symposium&quot;, and (E) design an algorithmic computer model, (3) require the Board of Regents for Higher Education to establish a &quot;Connecticut AI Academy&quot; and require the Labor Department, and home visiting programs overseen by the Commissioner of Early Childhood, to provide information concerning said academy, (4) establish a Connecticut Technology Advisory Board, (5) modify the &quot;computer science education and workforce development account&quot;, (6) modify the Technology Talent and Innovation Fund Advisory Committee, (7) establish an artificial intelligence systems fellowship program, (8) establish an artificial intelligence task force, (9) require state agencies to take various actions regarding generative artificial intelligence, and (10) prohibit dissemination of certain synthetic images.</p>\n   <table>\n    <tr>\n     <td>Co-Sponsors:</td>\n     <td>SEN. LOONEY, 11th Dist.; SEN. DUFF, 25th Dist.<br/>SEN. ANWAR, 3rd Dist.; SEN. CABRERA, 17th Dist.<br/>SEN. COHEN, 12th Dist.; SEN. FLEXER, 29th Dist.<br/>SEN. GADKAR-WILCOX, 22nd Dist.; SEN. GASTON, 23rd Dist.<br/>SEN. HOCHADEL, 13th Dist.; SEN. HONIG, 8th Dist.<br/>SEN. KUSHNER, 24th Dist.; SEN. LESSER, 9th Dist.<br/>SEN. LOPES, 6th Dist.; SEN. MAHER, 26th Dist.<br/>SEN. MARONEY, 14th Dist.; SEN. MARX, 20th Dist.<br/>SEN. MCCRORY, 2nd Dist.; SEN. MILLER P., 27th Dist.<br/>SEN. NEEDLEMAN, 33rd Dist.; SEN. OSTEN, 19th Dist.<br/>SEN. RAHMAN, 4th Dist.; SEN. SLAP, 5th Dist.<br/>SEN. WINFIELD, 10th Dist.; REP. REYES, 75th Dist.<br/>REP. DELNICKI, 14th Dist.; REP. GAUTHIER, 38th Dist.<br/>REP. MARTINEZ, 22nd Dist.; REP. LEMAR, 96th Dist.<br/>REP. BROWN M., 127th Dist.</td>\n    </tr>\n   </table>\n   <p class=\"indent\">S.B. 2 </p>\n  </div>\n </div>\n    </div>\t\n<table cellpadding=0 cellspacing=0 width=\"100%\">\n   <tr>\n      <td>\n          Copyright &copy; 2025 State Net\n      </td>\n<BR>\n<!--???MOVED INTO resources.cgi      <td align=\"right\">\n          <img src=\"https://custom.statenet.com/network/poweredby.gif\" alt=\"Powered by State Net\">\n      </td>-->\n\n    </tr>\n</table>\n</body></html>\n",
      "markdown": "The following has special meaning: _green underline denotes added text_ ~~red struck out text denotes deleted text~~ | [![Powered by State Net](https://custom.statenet.com/network/poweredby.gif)](https://www.lexisnexis.com/statenet/)  \n---|---  \n  \n2025 CT S 2 | | Author: | Looney  \n---|---  \nVersion: | Drafted by Committee  \nVersion Date: | 02/19/2025  \n  \n**STATE OF CONNECTICUT**\n\nGeneral Assembly\n\n**Committee Bill No. 2**\n\n**January Session, 2025**\n\nLCO No. **5014**\n\n*05014SB00002GL_*\n\nReferred to Committee on GENERAL LAW\n\nIntroduced by:\n\n(GL)\n\nAN ACT CONCERNING ARTIFICIAL INTELLIGENCE.\n\nBe it enacted by the Senate and House of Representatives in General Assembly\nconvened:\n\nSection 1. (NEW) (Effective October 1, 2025) For the purposes of this section\nand sections 2 to 10, inclusive, of this act, unless the context otherwise\nrequires:\n\n(1) \"Algorithmic discrimination\" (A) means any use of an artificial\nintelligence system that results in any unlawful differential treatment or\nimpact that disfavors any individual or group of individuals on the basis of\none or more classifications protected under the laws of this state or federal\nlaw, and (B) does not include (i) the offer, license or use of a high-risk\nartificial intelligence system by a developer, integrator or deployer for the\nsole purpose of (I) the developer's, integrator's or deployer's self-testing\nto identify, mitigate or prevent discrimination or otherwise ensure compliance\nwith state and federal law, or (II) expanding an applicant, customer or\nparticipant pool to increase diversity or redress historic discrimination, or\n(ii) an act or omission by or on behalf of a private club or other\nestablishment not in fact open to the public, as set forth in Title II of the\nCivil Rights Act of 1964, 42 USC 2000a(e), as amended from time to time;\n\n(2) \"Artificial intelligence system\" means any machine-based system that, for\nany explicit or implicit objective, infers from the inputs such system\nreceives how to generate outputs, including, but not limited to, content,\ndecisions, predictions or recommendations, that can influence physical or\nvirtual environments;\n\n(3) \"Consequential decision\" means any decision or judgment that has a legal,\nmaterial or similarly significant effect on a consumer with respect to (A)\nemployment, including, but not limited to, any such decision or judgment made\n(i) concerning hiring, termination, compensation or promotion, or (ii) by way\nof any automated task allocation that limits, segregates or classifies\nemployees for the purpose of assigning or determining material terms or\nconditions of employment, (B) education or vocational training, including, but\nnot limited to, any such decision or judgment made concerning (i) assessments,\n(ii) student cheating or plagiarism detection, (iii) accreditation, (iv)\ncertification, (v) admissions, or (vi) financial aid or scholarships, (C) the\nprovision or denial, or terms and conditions, of (i) financial lending or\ncredit services, (ii) housing or lodging, including, but not limited to,\nrentals or short-term housing or lodging, (iii) insurance, or (iv) legal\nservices, or (D) the provision or denial of (i) essential government services,\nor (ii) health care services;\n\n(4) \"Consumer\" means any individual who is a resident of this state;\n\n(5) \"Deploy\" means to use a high-risk artificial intelligence system to make,\nor as a substantial factor in making, a consequential decision;\n\n(6) \"Deployer\" means any person doing business in this state that deploys a\nhigh-risk artificial intelligence system in this state;\n\n(7) \"Developer\" means any person doing business in this state that develops,\nor intentionally and substantially modifies, an artificial intelligence\nsystem;\n\n(8) \"General-purpose artificial intelligence model\" (A) means any form of\nartificial intelligence system that (i) displays significant generality, (ii)\nis capable of competently performing a wide range of distinct tasks, and (iii)\ncan be integrated into a variety of downstream applications or systems, and\n(B) does not include any artificial intelligence model that is used for\ndevelopment, prototyping and research activities before such artificial\nintelligence model is released on the market;\n\n(9) \"High-risk artificial intelligence system\" (A) means any artificial\nintelligence system that, when deployed, makes, or is a substantial factor in\nmaking, a consequential decision, and (B) does not include (i) any artificial\nintelligence system that is intended to (I) perform any narrow procedural\ntask, or (II) detect decision-making patterns, or deviations from decision-\nmaking patterns, unless such artificial intelligence system is intended to\nreplace or influence any assessment previously completed by an individual\nwithout sufficient human review, or (ii) unless the technology, when deployed,\nmakes, or is a substantial factor in making, a consequential decision, (I) any\nanti-fraud technology that does not make use of facial recognition technology,\n(II) any artificial intelligence-enabled video game technology, (III) any\nanti-malware, anti-virus, calculator, cybersecurity, database, data storage,\nfirewall, Internet domain registration, Internet-web-site loading, networking,\nrobocall-filtering, spam-filtering, spellchecking, spreadsheet, web-caching,\nweb-hosting or similar technology, (IV) any technology that performs tasks\nexclusively related to an entity's internal management affairs, including, but\nnot limited to, ordering office supplies or processing payments, or (V) any\ntechnology that communicates with consumers in natural language for the\npurpose of providing users with information, making referrals or\nrecommendations and answering questions, and is subject to an accepted use\npolicy that prohibits generating content that is discriminatory or harmful;\n\n(10) \"Integrator\" means any person doing business in this state that, with\nrespect to a given high-risk artificial intelligence system, (A) neither\ndevelops nor intentionally and substantially modifies the high-risk artificial\nintelligence system, and (B) integrates the high-risk artificial intelligence\nsystem into a product or service such person offers to any other person;\n\n(11) \"Intentional and substantial modification\" (A) means any deliberate\nchange made to (i) an artificial intelligence system that materially increases\nthe risk of algorithmic discrimination, or (ii) a general-purpose artificial\nintelligence model that (I) affects compliance of the general-purpose\nartificial intelligence model, (II) materially changes the purpose of the\ngeneral-purpose artificial intelligence model, or (III) materially increases\nthe risk of algorithmic discrimination, and (B) does not include any change\nmade to a high-risk artificial intelligence system, or the performance of a\nhigh-risk artificial intelligence system, if (i) the high-risk artificial\nintelligence system continues to learn after such high-risk artificial\nintelligence system is (I) offered, sold, leased, licensed, given or otherwise\nmade available to a deployer, or (II) deployed, and (ii) such change (I) is\nmade to such high-risk artificial intelligence system as a result of any\nlearning described in subparagraph (B)(i) of this subdivision, (II) was\npredetermined by the deployer, or the third party contracted by the deployer,\nwhen such deployer or third party completed the initial impact assessment of\nsuch high-risk artificial intelligence system pursuant to subsection (c) of\nsection 4 of this act, and (III) is included in the technical documentation\nfor such high-risk artificial intelligence system;\n\n(12) \"Person\" means any individual, association, corporation, limited\nliability company, partnership, trust or other legal entity;\n\n(13) \"Red-teaming\" means an exercise that is conducted to identify the\npotential adverse behaviors or outcomes of an artificial intelligence system,\nhow such behaviors or outcomes occur and stress test the safeguards against\nsuch behaviors or outcomes;\n\n(14) \"Substantial factor\" (A) means a factor that (i) alters the outcome of a\nconsequential decision, and (ii) is generated by an artificial intelligence\nsystem, (B) includes, but is not limited to, any use of an artificial\nintelligence system to generate any content, decision, prediction or\nrecommendation concerning a consumer that is used as a basis to make a\nconsequential decision concerning the consumer, and (C) does not include any\noutput produced by an artificial intelligence system where an individual was\ninvolved in the data processing that produced such output and such individual\n(i) meaningfully considered such data as part of such data processing, and\n(ii) had the authority to change or influence the output produced by such data\nprocessing;\n\n(15) \"Synthetic digital content\" means any digital content, including, but not\nlimited to, any audio, image, text or video, that is produced or manipulated\nby an artificial intelligence system, including, but not limited to, a\ngeneral-purpose artificial intelligence model; and\n\n(16) \"Trade secret\" has the same meaning as provided in section 35-51 of the\ngeneral statutes.\n\nSec. 2. (NEW) (Effective October 1, 2025) (a) Beginning on October 1, 2026, a\ndeveloper of a high-risk artificial intelligence system shall use reasonable\ncare to protect consumers from any known or reasonably foreseeable risks of\nalgorithmic discrimination arising from the intended and contracted uses of\nthe high-risk artificial intelligence system. In any enforcement action\nbrought on or after said date by the Attorney General pursuant to section 10\nof this act, there shall be a rebuttable presumption that a developer used\nreasonable care as required under this subsection if the developer complied\nwith the provisions of this section or, if the developer enters into a\ncontract with an integrator as set forth in subsection (b) of section 3 of\nthis act, the developer and integrator complied with the provisions of this\nsection and section 3 of this act.\n\n(b) Except as provided in subsection (c) of section 3 of this act, a developer\nof a high-risk artificial intelligence system shall, beginning on October 1,\n2026, make available to each deployer, or other developer, of the high-risk\nartificial intelligence system:\n\n(1) A general statement describing the reasonably foreseeable uses, and the\nknown harmful or inappropriate uses, of such high-risk artificial intelligence\nsystem;\n\n(2) Documentation disclosing (A) high-level summaries of the type of data used\nto train such high-risk artificial intelligence system, (B) the known or\nreasonably foreseeable limitations of such high-risk artificial intelligence\nsystem, including, but not limited to, the known or reasonably foreseeable\nrisks of algorithmic discrimination arising from the intended uses of such\nhigh-risk artificial intelligence system, (C) the purpose of such high-risk\nartificial intelligence system, (D) the intended benefits and uses of such\nhigh-risk artificial intelligence system, and (E) all other information\nnecessary to enable such deployer to comply with the provisions of section 4\nof this act;\n\n(3) Documentation describing (A) how such high-risk artificial intelligence\nsystem was evaluated for performance, and mitigation of algorithmic\ndiscrimination, before such high-risk artificial intelligence system was\noffered, sold, leased, licensed, given or otherwise made available to such\ndeployer, (B) the data governance measures used to cover the training datasets\nand the measures used to examine the suitability of data sources, possible\nbiases and appropriate mitigation, (C) the intended outputs of such high-risk\nartificial intelligence system, (D) the measures the developer has taken to\nmitigate any known or reasonably foreseeable risks of algorithmic\ndiscrimination that may arise from deployment of such high-risk artificial\nintelligence system, and (E) how such high-risk artificial intelligence system\nshould be used, not be used and be monitored by an individual when such high-\nrisk artificial intelligence system is used to make, or as a substantial\nfactor in making, a consequential decision; and\n\n(4) Any additional documentation that is reasonably necessary to assist a\ndeployer to (A) understand the outputs of such high-risk artificial\nintelligence system, and (B) monitor the performance of such high-risk\nartificial intelligence system for risks of algorithmic discrimination.\n\n(c) (1) Except as provided in subsection (c) of section 3 of this act, any\ndeveloper that, on or after October 1, 2026, offers, sells, leases, licenses,\ngives or otherwise makes available to a deployer or another developer a high-\nrisk artificial intelligence system shall, to the extent feasible, make\navailable to the deployers and other developers of such high-risk artificial\nintelligence system the documentation and information necessary for a\ndeployer, or the third party contracted by a deployer, to complete an impact\nassessment pursuant to subsection (c) of section 4 of this act. The developer\nshall make such documentation and information available through artifacts such\nas model cards, dataset cards or other impact assessments.\n\n(2) A developer that also serves as a deployer for any high-risk artificial\nintelligence system shall not be required to generate the documentation\nrequired by this section unless such high-risk artificial intelligence system\nis provided to another person that serves as a deployer for such high-risk\nartificial intelligence system.\n\n(d) (1) Beginning on October 1, 2026, each developer shall make available, in\na manner that is clear and readily available on such developer's Internet web\nsite or in a public use case inventory, a statement summarizing:\n\n(A) The types of high-risk artificial intelligence systems that such developer\n(i) has developed or intentionally and substantially modified, and (ii)\ncurrently makes available to a deployer or another developer; and\n\n(B) How such developer manages any known or reasonably foreseeable risks of\nalgorithmic discrimination that may arise from development or intentional and\nsubstantial modification of the types of high-risk artificial intelligence\nsystems described in subparagraph (A) of this subdivision.\n\n(2) Each developer shall update the statement made available pursuant to\nsubdivision (1) of this subsection (A) as necessary to ensure that such\nstatement remains accurate, and (B) not later than ninety days after the\ndeveloper intentionally and substantially modifies any high-risk artificial\nintelligence system described in subparagraph (A) of subdivision (1) of this\nsubsection.\n\n(e) Beginning on October 1, 2026, a developer of a high-risk artificial\nintelligence system shall disclose to the Attorney General, in a form and\nmanner prescribed by the Attorney General, and to all known deployers or other\ndevelopers of the high-risk artificial intelligence system, any known or\nreasonably foreseeable risks of algorithmic discrimination arising from the\nintended uses of such high-risk artificial intelligence system. The developer\nshall make such disclosures without unreasonable delay but in no event later\nthan ninety days after the date on which:\n\n(1) The developer discovers, through the developer's ongoing testing and\nanalysis, that the high-risk artificial intelligence system has (A) been\ndeployed, and (B) caused, or is reasonably likely to have caused, algorithmic\ndiscrimination to at least one thousand consumers; or\n\n(2) The developer receives, from a deployer of the high-risk artificial\nintelligence system, a credible report disclosing that such high-risk\nartificial intelligence system has (A) been deployed, and (B) caused\nalgorithmic discrimination to at least one thousand consumers.\n\n(f) The provisions of subsections (b) to (e), inclusive, of this section shall\nnot be construed to require a developer to disclose any information (1) that\nis a trade secret or otherwise protected from disclosure under state or\nfederal law, or (2) the disclosure of which would present a security risk to\nthe developer.\n\n(g) Beginning on October 1, 2026, the Attorney General may require that a\ndeveloper disclose to the Attorney General, as part of an investigation\nconducted by the Attorney General and in a form and manner prescribed by the\nAttorney General, the general statement or documentation described in\nsubsection (b) of this section. The Attorney General may evaluate such general\nstatement or documentation to ensure compliance with the provisions of this\nsection. In disclosing such general statement or documentation to the Attorney\nGeneral pursuant to this subsection, the developer may designate such general\nstatement or documentation as including any information that is exempt from\ndisclosure under subsection (f) of this section or the Freedom of Information\nAct, as defined in section 1-200 of the general statutes. To the extent such\ngeneral statement or documentation includes such information, such general\nstatement or documentation shall be exempt from disclosure under subsection\n(f) of this section or said act. To the extent any information contained in\nsuch general statement or documentation is subject to the attorney-client\nprivilege or work product protection, such disclosure shall not constitute a\nwaiver of such privilege or protection.\n\nSec. 3. (NEW) (Effective October 1, 2025) (a) Beginning on October 1, 2026, if\nan integrator integrates a high-risk artificial intelligence system into a\nproduct or service the integrator offers to any other person, such integrator\nshall use reasonable care to protect consumers from any known or reasonably\nforeseeable risks of algorithmic discrimination arising from the intended and\ncontracted uses of such integrated high-risk artificial intelligence system.\nIn any enforcement action brought on or after said date by the Attorney\nGeneral pursuant to section 10 of this act, there shall be a rebuttable\npresumption that the integrator used reasonable care as required under this\nsubsection if the integrator complied with the provisions of this section.\n\n(b) Beginning on October 1, 2026, no integrator shall integrate a high-risk\nartificial intelligence system into a product or service the integrator offers\nto any other person unless the integrator has entered into a contract with the\ndeveloper of the high-risk artificial intelligence system. The contract shall\nbe binding and clearly set forth the duties of the developer and integrator\nwith respect to the integrated high-risk artificial intelligence system,\nincluding, but not limited to, whether the developer or integrator shall be\nresponsible for performing the developer's duties under subsections (b) and\n(c) of section 2 of this act.\n\n(c) The provisions of subsections (b) and (c) of section 2 of this act shall\nnot apply to a developer of an integrated high-risk artificial intelligence\nsystem if, at all times while the integrated high-risk artificial intelligence\nsystem is integrated into a product or service an integrator offers to any\nother person, the developer has entered into a contract with the integrator in\nwhich such integrator has agreed to assume the developer's duties under\nsubsections (b) and (c) of section 2 of this act.\n\n(d) (1) Beginning on October 1, 2026, each integrator shall make available, in\na manner that is clear and readily available on such integrator's Internet web\nsite or in a public use case inventory, a statement summarizing:\n\n(A) The types of high-risk artificial intelligence systems that such\nintegrator has integrated into products or services such integrator currently\noffers to any other person; and\n\n(B) How such integrator manages any known or reasonably foreseeable risks of\nalgorithmic discrimination that may arise from the types of high-risk\nartificial intelligence systems described in subparagraph (A) of this\nsubdivision.\n\n(2) Each integrator shall update the statement made available pursuant to\nsubdivision (1) of this subsection (A) as necessary to ensure that such\nstatement remains accurate, and (B) not later than ninety days after any\nintentional and substantial modification is made to any high-risk artificial\nintelligence system described in subparagraph (A) of subdivision (1) of this\nsubsection.\n\n(e) The provisions of subsections (b) to (d), inclusive, of this section shall\nnot be construed to require a developer or integrator to disclose any\ninformation (1) that is a trade secret or otherwise protected from disclosure\nunder state or federal law, or (2) the disclosure of which would present a\nsecurity risk to the developer or integrator.\n\n(f) Beginning on October 1, 2026, the Attorney General may require that an\nintegrator which has assumed a developer's duties under subsection (c) of\nsection 2 of this act to disclose to the Attorney General, as part of an\ninvestigation conducted by the Attorney General and in a form and manner\nprescribed by the Attorney General, the general statement or documentation\ndescribed in said subsection. The Attorney General may evaluate such general\nstatement or documentation to ensure compliance with the provisions of this\nsection and section 2 of this act. In disclosing such general statement or\ndocumentation to the Attorney General pursuant to this subsection, the\nintegrator may designate such general statement or documentation as including\nany information that is exempt from disclosure under subsection (e) of this\nsection or the Freedom of Information Act, as defined in section 1-200 of the\ngeneral statutes. To the extent such general statement or documentation\nincludes such information, such general statement or documentation shall be\nexempt from disclosure under subsection (e) of this section or said act. To\nthe extent any information contained in such general statement or\ndocumentation is subject to the attorney-client privilege or work product\nprotection, such disclosure shall not constitute a waiver of such privilege or\nprotection.\n\nSec. 4. (NEW) (Effective October 1, 2025) (a) Beginning on October 1, 2026,\neach deployer of a high-risk artificial intelligence system shall use\nreasonable care to protect consumers from any known or reasonably foreseeable\nrisks of algorithmic discrimination. In any enforcement action brought on or\nafter said date by the Attorney General pursuant to section 10 of this act,\nthere shall be a rebuttable presumption that a deployer of a high-risk\nartificial intelligence system used reasonable care as required under this\nsubsection if the deployer complied with the provisions of this section.\n\n(b) (1) Beginning on October 1, 2026, and except as provided in subsection (g)\nof this section, each deployer of a high-risk artificial intelligence system\nshall implement and maintain a risk management policy and program to govern\nsuch deployer's deployment of the high-risk artificial intelligence system.\nThe risk management policy and program shall specify and incorporate the\nprinciples, processes and personnel that the deployer shall use to identify,\ndocument and mitigate any known or reasonably foreseeable risks of algorithmic\ndiscrimination. The risk management policy shall be the product of an\niterative process, the risk management program shall be an iterative process\nand both the risk management policy and program shall be planned, implemented\nand regularly and systematically reviewed and updated over the lifecycle of\nthe high-risk artificial intelligence system. Each risk management policy and\nprogram implemented and maintained pursuant to this subsection shall be\nreasonable, considering:\n\n(A) The guidance and standards set forth in the latest version of (i) the\n\"Artificial Intelligence Risk Management Framework\" published by the National\nInstitute of Standards and Technology, (ii) ISO or IEC 42001 of the\nInternational Organization for Standardization, or (iii) a nationally or\ninternationally recognized risk management framework for artificial\nintelligence systems, other than the guidance and standards specified in\nsubparagraphs (A)(i) and (A)(ii) of this subdivision, that imposes\nrequirements that are substantially equivalent to, and at least as stringent\nas, the requirements set forth in this section for risk management policies\nand programs;\n\n(B) The size and complexity of the deployer;\n\n(C) The nature and scope of the high-risk artificial intelligence systems\ndeployed by the deployer, including, but not limited to, the intended uses of\nsuch high-risk artificial intelligence systems; and\n\n(D) The sensitivity and volume of data processed in connection with the high-\nrisk artificial intelligence systems deployed by the deployer.\n\n(2) A risk management policy and program implemented and maintained pursuant\nto subdivision (1) of this subsection may cover multiple high-risk artificial\nintelligence systems deployed by the deployer.\n\n(c) (1) Except as provided in subdivisions (3) and (4) of this subsection and\nsubsection (g) of this section:\n\n(A) A deployer that deploys a high-risk artificial intelligence system on or\nafter October 1, 2026, or a third party contracted by the deployer, shall\ncomplete an impact assessment of the high-risk artificial intelligence system;\nand\n\n(B) Beginning on October 1, 2026, a deployer, or a third party contracted by\nthe deployer, shall complete an impact assessment of a deployed high-risk\nartificial intelligence system (i) at least annually, and (ii) not later than\nninety days after an intentional and substantial modification to such high-\nrisk artificial intelligence system is made available.\n\n(2) (A) Each impact assessment completed pursuant to this subsection shall\ninclude, at a minimum and to the extent reasonably known by, or available to,\nthe deployer:\n\n(i) A statement by the deployer disclosing the purpose, intended use cases and\ndeployment context of, and benefits afforded by, the high-risk artificial\nintelligence system;\n\n(ii) An analysis of whether the deployment of the high-risk artificial\nintelligence system poses any known or reasonably foreseeable risks of\nalgorithmic discrimination and, if so, the nature of such algorithmic\ndiscrimination and the steps that have been taken to mitigate such risks;\n\n(iii) A description of (I) the categories of data the high-risk artificial\nintelligence system processes as inputs, and (II) the outputs such high-risk\nartificial intelligence system produces;\n\n(iv) If the deployer used data to customize the high-risk artificial\nintelligence system, an overview of the categories of data the deployer used\nto customize such high-risk artificial intelligence system;\n\n(v) Any metrics used to evaluate the performance and known limitations of the\nhigh-risk artificial intelligence system;\n\n(vi) A description of any transparency measures taken concerning the high-risk\nartificial intelligence system, including, but not limited to, any measures\ntaken to disclose to a consumer that such high-risk artificial intelligence\nsystem is in use when such high-risk artificial intelligence system is in use;\nand\n\n(vii) A description of the post-deployment monitoring and user safeguards\nprovided concerning such high-risk artificial intelligence system, including,\nbut not limited to, the oversight, use and learning process established by the\ndeployer to address issues arising from deployment of such high-risk\nartificial intelligence system.\n\n(B) In addition to the statement, analysis, descriptions, overview and metrics\nrequired under subparagraph (A) of this subdivision, an impact assessment\ncompleted pursuant to this subsection following an intentional and substantial\nmodification made to a high-risk artificial intelligence system on or after\nOctober 1, 2026, shall include a statement disclosing the extent to which the\nhigh-risk artificial intelligence system was used in a manner that was\nconsistent with, or varied from, the developer's intended uses of such high-\nrisk artificial intelligence system.\n\n(3) A single impact assessment may address a comparable set of high-risk\nartificial intelligence systems deployed by a deployer.\n\n(4) If a deployer, or a third party contracted by the deployer, completes an\nimpact assessment for the purpose of complying with another applicable law or\nregulation, such impact assessment shall be deemed to satisfy the requirements\nestablished in this subsection if such impact assessment is reasonably similar\nin scope and effect to the impact assessment that would otherwise be completed\npursuant to this subsection.\n\n(5) A deployer shall maintain the most recently completed impact assessment of\na high-risk artificial intelligence system as required under this subsection,\nall records concerning each such impact assessment and all prior impact\nassessments, if any, for a period of at least three years following the final\ndeployment of the high-risk artificial intelligence system.\n\n(d) Except as provided in subsection (g) of this section, a deployer, or a\nthird party contracted by the deployer, shall review, not later than October\n1, 2026, and at least annually thereafter, the deployment of each high-risk\nartificial intelligence system deployed by the deployer to ensure that such\nhigh-risk artificial intelligence system is not causing algorithmic\ndiscrimination.\n\n(e) (1) Beginning on October 1, 2026, and before a deployer deploys a high-\nrisk artificial intelligence system to make, or be a substantial factor in\nmaking, a consequential decision concerning a consumer, the deployer shall:\n\n(A) Notify the consumer that the deployer has deployed a high-risk artificial\nintelligence system to make, or be a substantial factor in making, such\nconsequential decision; and\n\n(B) Provide to the consumer (i) a statement disclosing (I) the purpose of such\nhigh-risk artificial intelligence system, and (II) the nature of such\nconsequential decision, (ii) the right to opt-out of any automated decision-\nmaking based on the consumer's personal data, (iii) contact information for\nsuch deployer, (iv) a description, in plain language, of such high-risk\nartificial intelligence system, and (v) instructions on how to access the\nstatement made available pursuant to subdivision (1) of subsection (f) of this\nsection.\n\n(2) Beginning on October 1, 2026, a deployer that has deployed a high-risk\nartificial intelligence system to make, or as a substantial factor in making,\na consequential decision concerning a consumer shall, if such consequential\ndecision is adverse to the consumer, provide to such consumer:\n\n(A) A statement disclosing the principal reason or reasons for such adverse\nconsequential decision, including, but not limited to, (i) the degree to\nwhich, and manner in which, the high-risk artificial intelligence system\ncontributed to such adverse consequential decision, (ii) the type of data that\nwere processed by such high-risk artificial intelligence system in making such\nadverse consequential decision, and (iii) the source of the data described in\nsubparagraph (A)(ii) of this subdivision;\n\n(B) An opportunity to (i) examine the personal data that the high-risk\nartificial intelligence system processed in making, or as a substantial factor\nin making, such adverse consequential decision, and (ii) correct any incorrect\npersonal data described in subparagraph (B)(i) of this subdivision; and\n\n(C) (i) Except as provided in subparagraph (C)(ii) of this subdivision, an\nopportunity to appeal such adverse consequential decision if such adverse\nconsequential decision is based upon inaccurate personal data, taking into\naccount both the nature of such personal data and the purpose for which such\npersonal data was processed. Such appeal shall, if technically feasible, allow\nfor human review.\n\n(ii) No deployer shall be required to provide an opportunity to appeal\npursuant to subparagraph (C)(i) of this subdivision in any instance in which\nproviding such opportunity to appeal is not in the best interest of the\nconsumer, including, but not limited to, in any instance in which any delay\nmight pose a risk to the life or safety of the consumer.\n\n(3) The deployer shall provide the notice, statements, information,\ndescription and instructions required under subdivisions (1) and (2) of this\nsubsection:\n\n(A) Directly to the consumer;\n\n(B) In plain language;\n\n(C) In all languages in which such deployer, in the ordinary course of such\ndeployer's business, provides contracts, disclaimers, sale announcements and\nother information to consumers; and\n\n(D) In a format that is accessible to consumers with disabilities.\n\n(f) (1) Beginning on October 1, 2026, and except as provided in subsection (g)\nof this section, each deployer shall make available, in a manner that is clear\nand readily available on such deployer's Internet web site, a statement\nsummarizing:\n\n(A) The types of high-risk artificial intelligence systems that are currently\ndeployed by such deployer;\n\n(B) How such deployer manages any known or reasonably foreseeable risks of\nalgorithmic discrimination that may arise from deployment of each high-risk\nartificial intelligence system described in subparagraph (A) of this\nsubdivision; and\n\n(C) In detail, the nature, source and extent of the information collected and\nused by such deployer.\n\n(2) Each deployer shall periodically update the statement made available\npursuant to subdivision (1) of this subsection.\n\n(g) The provisions of subsections (b) to (d), inclusive, of this section and\nsubsection (f) of this section shall not apply to a deployer if, at the time\nthe deployer deploys a high-risk artificial intelligence system and at all\ntimes while the high-risk artificial intelligence system is deployed:\n\n(1) The deployer (A) has entered into a contract with the developer in which\nthe developer has agreed to assume the deployer's duties under subsections (b)\nto (d), inclusive, of this section and subsection (f) of this section, and (B)\ndoes not exclusively use such deployer's own data to train such high-risk\nartificial intelligence system;\n\n(2) Such high-risk artificial intelligence system (A) is used for the intended\nuses that are disclosed to such deployer as set forth in subparagraph (D) of\nsubdivision (2) of subsection (b) of section 2 of this act, and (B) continues\nlearning based on a broad range of data sources and not solely based on the\ndeployer's own data; and\n\n(3) Such deployer makes available to consumers any impact assessment that (A)\nthe developer of such high-risk artificial intelligence system has completed\nand provided to such deployer, and (B) includes information that is\nsubstantially similar to the information included in the statement, analysis,\ndescriptions, overview and metrics required under subparagraph (A) of\nsubdivision (2) of subsection (c) of this section.\n\n(h) If a deployer deploys a high-risk artificial intelligence system on or\nafter October 1, 2026, and subsequently discovers that the high-risk\nartificial intelligence system has caused algorithmic discrimination to at\nleast one thousand consumers, the deployer shall send to the Attorney General,\nin a form and manner prescribed by the Attorney General, a notice disclosing\nsuch discovery. The deployer shall send such notice to the Attorney General\nwithout unreasonable delay but in no event later than ninety days after the\ndate on which the deployer discovered such algorithmic discrimination.\n\n(i) Nothing in subsections (b) to (h), inclusive, of this section shall be\nconstrued to require a deployer to disclose any information that is a trade\nsecret or otherwise protected from disclosure under state or federal law. If a\ndeployer withholds any information from a consumer under this subsection, the\ndeployer shall send notice to the consumer disclosing (1) that the deployer is\nwithholding such information from such consumer, and (2) the basis for the\ndeployer's decision to withhold such information from such consumer.\n\n(j) Beginning on October 1, 2026, the Attorney General may require that a\ndeployer, or a third party contracted by the deployer as set forth in\nsubsection (c) of this section, as applicable, disclose to the Attorney\nGeneral, as part of an investigation conducted by the Attorney General, not\nlater than ninety days after a request by the Attorney General and in a form\nand manner prescribed by the Attorney General, the risk management policy\nimplemented pursuant to subsection (b) of this section, impact assessment\ncompleted pursuant to subsection (c) of this section or records maintained\npursuant to subdivision (5) of subsection (c) of this section. The Attorney\nGeneral may evaluate such risk management policy, impact assessment or records\nto ensure compliance with the provisions of this section. In disclosing such\nrisk management policy, impact assessment or records to the Attorney General\npursuant to this subsection, the deployer or third-party contractor, as\napplicable, may designate such risk management policy, impact assessment or\nrecords as including any information that is exempt from disclosure under\nsubsection (i) of this section or the Freedom of Information Act, as defined\nin section 1-200 of the general statutes. To the extent such risk management\npolicy, impact assessment or records include such information, such risk\nmanagement policy, impact assessment or records shall be exempt from\ndisclosure under subsection (i) of this section or said act. To the extent any\ninformation contained in such risk management policy, impact assessment or\nrecord is subject to the attorney-client privilege or work product protection,\nsuch disclosure shall not constitute a waiver of such privilege or protection.\n\nSec. 5. (NEW) (Effective October 1, 2025) (a) Beginning on October 1, 2026,\neach developer of a general-purpose artificial intelligence model shall,\nexcept as provided in subsection (b) of this section:\n\n(1) (A) Create and maintain technical documentation for the general-purpose\nartificial intelligence model, which technical documentation shall:\n\n(i) Include the training and testing processes for such general-purpose\nartificial intelligence model;\n\n(ii) Include at least the following information, as appropriate, considering\nthe size and risk profile of such general-purpose artificial intelligence\nmodel:\n\n(I) The tasks such general-purpose artificial intelligence model is intended\nto perform;\n\n(II) The type and nature of artificial intelligence systems in which such\ngeneral-purpose artificial intelligence model is intended to be integrated;\n\n(III) Acceptable use policies for such general-purpose artificial intelligence\nmodel;\n\n(IV) The date such general-purpose artificial intelligence model is released;\n\n(V) The methods by which such general-purpose artificial intelligence model is\ndistributed; and\n\n(VI) The modality and format of inputs and outputs for such general-purpose\nartificial intelligence model;\n\n(iii) Include a description of the data that were used for purposes of\ntraining, testing and validation of such general-purpose artificial\nintelligence model, which description shall be appropriate considering the\nsize and risk profile of such general-purpose artificial intelligence model\nand include, at a minimum, a description of the following:\n\n(I) The type and provenance of such data;\n\n(II) Curation methodologies used for such data;\n\n(III) How such data were obtained and selected;\n\n(IV) All measures used to identify unsuitable data sources; and\n\n(V) Where applicable, methods used to detect identifiable biases; and\n\n(iv) Be reviewed and revised at least annually or more frequently as necessary\nto maintain the accuracy of such technical documentation; and\n\n(B) Establish, implement and maintain a policy to comply with federal and\nstate copyright laws; and\n\n(2) Create, implement, maintain and make available to persons that intend to\nintegrate such general-purpose artificial intelligence model into such\npersons' artificial intelligence systems documentation and information that:\n\n(A) Enables such persons to (i) understand the capabilities and limitations of\nsuch general-purpose artificial intelligence model, and (ii) comply with such\npersons' obligations under sections 1 to 10, inclusive, of this act;\n\n(B) Discloses, at a minimum, (i) the technical means required for such\ngeneral-purpose artificial intelligence model to be integrated into such\npersons' artificial intelligence systems, (ii) the information listed in\nsubparagraph (A)(ii) of subdivision (1) of this subsection, and (iii) the\ndescription required under subparagraph (A)(iii) of subdivision (1) of this\nsubsection; and\n\n(C) Except as provided in subsection (b) of this section, is reviewed and\nrevised at least annually or more frequently as necessary to maintain the\naccuracy of such documentation and information.\n\n(b) (1) The provisions of subdivision (1) of subsection (a) of this section\nand subparagraph (C) of subdivision (2) of subsection (a) of this section\nshall not apply to a developer that develops, or intentionally and\nsubstantially modifies, a general-purpose artificial intelligence model on or\nafter October 1, 2026, if:\n\n(A) (i) The developer releases such general-purpose artificial intelligence\nmodel under a free and open-source license that allows for (I) access to, and\nmodification, distribution and usage of, such general-purpose artificial\nintelligence model, and (II) the parameters of such general-purpose artificial\nintelligence model to be made publicly available as set forth in subparagraph\n(A)(ii) of this subdivision; and\n\n(ii) Unless such general-purpose artificial intelligence model is deployed as\na high-risk artificial intelligence system, the parameters of such general-\npurpose artificial intelligence model, including, but not limited to, the\nweights and information concerning the model architecture and model usage for\nsuch general-purpose artificial intelligence model, are made publicly\navailable; or\n\n(B) The general-purpose artificial intelligence model is (i) not offered for\nsale in the market, (ii) not intended to interact with consumers, and (iii)\nsolely utilized (I) for an entity's internal purposes, or (II) under an\nagreement between multiple entities for such entities' internal purposes.\n\n(2) The provisions of this section shall not apply to a developer that\ndevelops, or intentionally and substantially modifies, a general-purpose\nartificial intelligence model on or after October 1, 2026, if such general-\npurpose artificial intelligence model performs tasks exclusively related to an\nentity's internal management affairs, including, but not limited to, ordering\noffice supplies or processing payments.\n\n(3) A developer that takes any action under an exemption established in\nsubdivision (1) or (2) of this subsection shall bear the burden of\ndemonstrating that such action qualifies for such exemption.\n\n(4) A developer that is exempt under subparagraph (B) of subdivision (1) of\nthis subsection shall establish and maintain an artificial intelligence risk\nmanagement framework, which framework shall (A) be the product of an iterative\nprocess and ongoing efforts, and (B) include, at a minimum, (i) an internal\ngovernance function, (ii) a map function that shall establish the context to\nframe risks, (iii) a risk management function, and (iv) a function to measure\nidentified risks by assessing, analyzing and tracking such risks.\n\n(c) Nothing in subsection (a) of this section shall be construed to require a\ndeveloper to disclose any information that is a trade secret or otherwise\nprotected from disclosure under state or federal law.\n\n(d) Beginning on October 1, 2026, the Attorney General may require that a\ndeveloper disclose to the Attorney General, as part of an investigation\nconducted by the Attorney General, not later than ninety days after a request\nby the Attorney General and in a form and manner prescribed by the Attorney\nGeneral, any documentation maintained pursuant to this section. The Attorney\nGeneral may evaluate such documentation to ensure compliance with the\nprovisions of this section. In disclosing any documentation to the Attorney\nGeneral pursuant to this subsection, the developer may designate such\ndocumentation as including any information that is exempt from disclosure\nunder subsection (c) of this section or the Freedom of Information Act, as\ndefined in section 1-200 of the general statutes. To the extent such\ndocumentation includes such information, such documentation shall be exempt\nfrom disclosure under subsection (c) of this section or said act. To the\nextent any information contained in such documentation is subject to the\nattorney-client privilege or work product protection, such disclosure shall\nnot constitute a waiver of such privilege or protection.\n\nSec. 6. (NEW) (Effective October 1, 2025) (a) Beginning on October 1, 2026,\nand except as provided in subsection (b) of this section, each person doing\nbusiness in this state, including, but not limited to, each deployer that\ndeploys, offers, sells, leases, licenses, gives or otherwise makes available,\nas applicable, any artificial intelligence system that is intended to interact\nwith consumers shall ensure that it is disclosed to each consumer who\ninteracts with such artificial intelligence system that such consumer is\ninteracting with an artificial intelligence system.\n\n(b) No disclosure shall be required under subsection (a) of this section under\ncircumstances in which a reasonable person would deem it obvious that such\nperson is interacting with an artificial intelligence system.\n\nSec. 7. (NEW) (Effective October 1, 2025) (a) Beginning on October 1, 2026,\nand except as provided in subsections (b) and (c) of this section, the\ndeveloper of an artificial intelligence system, including, but not limited to,\na general-purpose artificial intelligence model, that generates or manipulates\nsynthetic digital content shall:\n\n(1) Ensure that the outputs of such artificial intelligence system are marked\nand detectable as synthetic digital content, and that such outputs are so\nmarked and detectable (A) not later than the time that consumers who did not\ncreate such outputs first interact with, or are exposed to, such outputs, and\n(B) in a manner that (i) is detectable by consumers, and (ii) complies with\nany applicable accessibility requirements; and\n\n(2) As far as technically feasible and in a manner that is consistent with any\nnationally or internationally recognized technical standards, ensure that such\ndeveloper's technical solutions are effective, interoperable, robust and\nreliable, considering (A) the specificities and limitations of different types\nof synthetic digital content, (B) the implementation costs, and (C) the\ngenerally acknowledged state of the art.\n\n(b) If the synthetic digital content described in subsection (a) of this\nsection is in an audio, image or video format, and such synthetic digital\ncontent forms part of an evidently artistic, creative, satirical, fictional\nanalogous work or program, the disclosure required under said subsection shall\nbe limited to a disclosure that does not hinder the display or enjoyment of\nsuch work or program.\n\n(c) The provisions of subsection (a) of this section shall not apply:\n\n(1) To any synthetic digital content that (A) consists exclusively of text,\n(B) is published to inform the public on any matter of public interest, or (C)\nis unlikely to mislead a reasonable person consuming such synthetic digital\ncontent; or\n\n(2) To the extent that any artificial intelligence system described in\nsubsection (a) of this section (A) performs an assistive function for standard\nediting, (B) does not substantially alter the input data provided by the\ndeveloper or the semantics thereof, or (C) is used to detect, prevent,\ninvestigate or prosecute any crime where authorized by law.\n\nSec. 8. (NEW) (Effective October 1, 2025) (a) Nothing in sections 1 to 10,\ninclusive, of this act shall be construed to restrict a developer's,\nintegrator's, deployer's or other person's ability to:\n\n(1) Comply with federal, state or municipal law;\n\n(2) Comply with a civil, criminal or regulatory inquiry, investigation,\nsubpoena or summons by a federal, state, municipal or other governmental\nauthority;\n\n(3) Cooperate with a law enforcement agency concerning conduct or activity\nthat the developer, integrator, deployer or other person reasonably and in\ngood faith believes may violate federal, state or municipal law;\n\n(4) Investigate, establish, exercise, prepare for or defend a legal claim;\n\n(5) Take immediate steps to protect an interest that is essential for the life\nor physical safety of a consumer or another individual;\n\n(6) (A) By any means other than facial recognition technology, prevent,\ndetect, protect against or respond to (i) a security incident, (ii) a\nmalicious or deceptive activity, or (iii) identity theft, fraud, harassment or\nany other illegal activity, (B) investigate, report or prosecute the persons\nresponsible for any action described in subparagraph (A) of this subdivision,\nor (C) preserve the integrity or security of systems;\n\n(7) Engage in public or peer-reviewed scientific or statistical research in\nthe public interest that (A) adheres to all other applicable ethics and\nprivacy laws, and (B) is conducted in accordance with (i) 45 CFR Part 46, as\namended from time to time, or (ii) relevant requirements established by the\nfederal Food and Drug Administration;\n\n(8) Conduct research, testing, development and integration activities\nregarding an artificial intelligence system or model, other than testing\nconducted under real world conditions, before such artificial intelligence\nsystem or model is placed on the market, deployed or put into service, as\napplicable;\n\n(9) Effectuate a product recall;\n\n(10) Identify and repair technical errors that impair existing or intended\nfunctionality; or\n\n(11) Assist another developer, integrator, deployer or person with any of the\nobligations imposed under sections 1 to 10, inclusive, of this act.\n\n(b) The obligations imposed on developers, integrators, deployers or other\npersons under sections 1 to 10, inclusive, of this act shall not apply where\ncompliance by the developer, integrator, deployer or other person with said\nsections would violate an evidentiary privilege under the laws of this state.\n\n(c) Nothing in sections 1 to 10, inclusive, of this act shall be construed to\nimpose any obligation on a developer, integrator, deployer or other person\nthat adversely affects the rights or freedoms of any person, including, but\nnot limited to, the rights of any person (1) to freedom of speech or freedom\nof the press guaranteed in (A) the First Amendment to the United States\nConstitution, and (B) section 5 of article first of the Constitution of the\nstate, or (2) under section 52-146t of the general statutes.\n\n(d) Nothing in sections 1 to 10, inclusive, of this act shall be construed to\napply to any developer, integrator, deployer or other person:\n\n(1) Insofar as such developer, integrator, deployer or other person develops,\nintegrates, deploys, puts into service or intentionally and substantially\nmodifies, as applicable, a high-risk artificial intelligence system (A) that\nhas been approved, authorized, certified, cleared, developed, integrated or\ngranted by (i) a federal agency, such as the federal Food and Drug\nAdministration or the Federal Aviation Administration, acting within the scope\nof such federal agency's authority, or (ii) a regulated entity subject to\nsupervision and regulation by the Federal Housing Finance Agency, or (B) in\ncompliance with standards that are (i) established by (I) any federal agency,\nincluding, but not limited to, the federal Office of the National Coordinator\nfor Health Information Technology, or (II) a regulated entity subject to\nsupervision and regulation by the Federal Housing Finance Agency, and (ii)\nsubstantially equivalent to, and at least as stringent as, the standards\nestablished in sections 1 to 10, inclusive, of this act;\n\n(2) Conducting research to support an application (A) for approval or\ncertification from any federal agency, including, but not limited to, the\nFederal Aviation Administration, the Federal Communications Commission or the\nfederal Food and Drug Administration, or (B) that is otherwise subject to\nreview by any federal agency;\n\n(3) Performing work under, or in connection with, a contract with the United\nStates Department of Commerce, the United States Department of Defense or the\nNational Aeronautics and Space Administration, unless such developer,\nintegrator, deployer or other person is performing such work on a high-risk\nartificial intelligence system that is used to make, or as a substantial\nfactor in making, a decision concerning employment or housing;\n\n(4) That is a covered entity within the meaning of the Health Insurance\nPortability and Accountability Act of 1996, P.L. 104-191, and the regulations\npromulgated thereunder, as both may be amended from time to time, and\nproviding health care recommendations that (A) are generated by an artificial\nintelligence system, (B) require a health care provider to take action to\nimplement such recommendations, and (C) are not considered to be high risk; or\n\n(5) Who is an active participant in the artificial intelligence regulatory\nsandbox program designed, established and administered under section 11 of\nthis act, and is engaged in activities within the scope of such program in\naccordance with the provisions of section 11 of this act.\n\n(e) Nothing in sections 1 to 10, inclusive, of this act shall be construed to\napply to any artificial intelligence system that is acquired by or for the\nfederal government or any federal agency or department, including, but not\nlimited to, the United States Department of Commerce, the United States\nDepartment of Defense or the National Aeronautics and Space Administration,\nunless such artificial intelligence system is a high-risk artificial\nintelligence system that is used to make, or as a substantial factor in\nmaking, a decision concerning employment or housing.\n\n(f) Any insurer, as defined in section 38a-1 of the general statutes,\nfraternal benefit society, as described in section 38a-595 of the general\nstatutes, or health carrier, as defined in section 38a-591a of the general\nstatutes, shall be deemed to be in full compliance with the provisions of\nsections 1 to 10, inclusive, of this act if such insurer, fraternal benefit\nsociety or health carrier has implemented and maintains a written artificial\nintelligence systems program in accordance with all requirements established\nby the Insurance Commissioner.\n\n(g) (1) Any bank, out-of-state bank, Connecticut credit union, federal credit\nunion or out-of-state credit union, or any affiliate or subsidiary thereof,\nshall be deemed to be in full compliance with the provisions of sections 1 to\n10, inclusive, of this act if such bank, out-of-state bank, Connecticut credit\nunion, federal credit union, out-of-state credit union, affiliate or\nsubsidiary is subject to examination by any state or federal prudential\nregulator under any published guidance or regulations that apply to the use of\nhigh-risk artificial intelligence systems and such guidance or regulations (A)\nimpose requirements that are substantially equivalent to, and at least as\nstringent as, the requirements set forth in sections 1 to 10, inclusive, of\nthis act, and (B) at a minimum, require such bank, out-of-state bank,\nConnecticut credit union, federal credit union, out-of-state credit union,\naffiliate or subsidiary to (i) regularly audit such bank's, out-of-state\nbank's, Connecticut credit union's, federal credit union's, out-of-state\ncredit union's, affiliate's or subsidiary's use of high-risk artificial\nintelligence systems for compliance with state and federal anti-discrimination\nlaws and regulations applicable to such bank, out-of-state bank, Connecticut\ncredit union, federal credit union, out-of-state credit union, affiliate or\nsubsidiary, and (ii) mitigate any algorithmic discrimination caused by the use\nof a high-risk artificial intelligence system or any risk of algorithmic\ndiscrimination that is reasonably foreseeable as a result of the use of a\nhigh-risk artificial intelligence system.\n\n(2) For the purposes of this subsection, \"affiliate\", \"bank\", \"Connecticut\ncredit union\", \"federal credit union\", \"out-of-state bank\", \"out-of-state\ncredit union\" and \"subsidiary\" have the same meanings as provided in section\n36a-2 of the general statutes.\n\n(h) If a developer, integrator, deployer or other person engages in any action\npursuant to an exemption set forth in subsections (a) to (g), inclusive, of\nthis section, the developer, integrator, deployer or other person bears the\nburden of demonstrating that such action qualifies for such exemption.\n\nSec. 9. (NEW) (Effective October 1, 2025) Not later than January 1, 2026, the\nAttorney General shall, within available appropriations, develop and implement\na comprehensive public education, outreach and assistance program for\ndevelopers, integrators and deployers that are small businesses, as defined in\nsection 4-168a of the general statutes. Such program shall, at a minimum,\ndisseminate educational materials concerning (1) the requirements established\nin sections 1 to 10, inclusive, of this act, including, but not limited to,\nthe duties of developers, integrators and deployers under sections 1 to 10,\ninclusive, of this act, (2) the impact assessments required under subsection\n(c) of section 4 of this act, (3) the Attorney General's powers under sections\n1 to 10, inclusive, of this act, and (4) any other matters the Attorney\nGeneral, in the Attorney General's discretion, deems relevant for the purposes\nof such program.\n\nSec. 10. (NEW) (Effective October 1, 2025) (a) The Attorney General shall have\nexclusive authority to enforce the provisions of sections 1 to 9, inclusive,\nof this act.\n\n(b) Except as provided in subsection (f) of this section, during the period\nbeginning on October 1, 2026, and ending on September 30, 2027, the Attorney\nGeneral shall, prior to initiating any action for a violation of any provision\nof sections 1 to 9, inclusive, of this act, issue a notice of violation to the\ndeveloper, integrator, deployer or other person if the Attorney General\ndetermines that it is possible to cure such violation. If the developer,\nintegrator, deployer or other person fails to cure such violation not later\nthan sixty days after receipt of the notice of violation, the Attorney General\nmay bring an action pursuant to this section.\n\n(c) Except as provided in subsection (f) of this section, beginning on October\n1, 2027, the Attorney General may, in determining whether to grant a\ndeveloper, integrator, deployer or other person the opportunity to cure a\nviolation described in subsection (b) of this section, consider: (1) The\nnumber of violations; (2) the size and complexity of the developer,\nintegrator, deployer or other person; (3) the nature and extent of the\ndeveloper's, integrator's, deployer's or other person's business; (4) the\nsubstantial likelihood of injury to the public; (5) the safety of persons or\nproperty; and (6) whether such violation was likely caused by human or\ntechnical error.\n\n(d) Nothing in sections 1 to 9, inclusive, of this act shall be construed as\nproviding the basis for a private right of action for violations of said\nsections.\n\n(e) Except as provided in subsections (a) to (d), inclusive, of this section\nand subsection (f) of this section, a violation of the requirements\nestablished in sections 1 to 9, inclusive, of this act shall constitute an\nunfair trade practice for purposes of section 42-110b of the general statutes\nand shall be enforced solely by the Attorney General. The provisions of\nsection 42-110g of the general statutes shall not apply to any such violation.\n\n(f) (1) In any action commenced by the Attorney General for any violation of\nsections 1 to 9, inclusive, of this act, it shall be an affirmative defense\nthat the developer, integrator, deployer or other person:\n\n(A) Discovers a violation of any provision of sections 1 to 9, inclusive, of\nthis act through red-teaming;\n\n(B) Not later than sixty days after discovering the violation as set forth in\nsubparagraph (A) of this subdivision: (i) Cures such violation; and (ii)\nprovides to the Attorney General, in a form and manner prescribed by the\nAttorney General, notice that such violation has been cured and evidence that\nany harm caused by such violation has been mitigated; and\n\n(C) Is otherwise in compliance with the latest version of: (i) The \"Artificial\nIntelligence Risk Management Framework\" published by the National Institute of\nStandards and Technology; (ii) ISO or IEC 42001 of the International\nOrganization for Standardization; (iii) a nationally or internationally\nrecognized risk management framework for artificial intelligence systems,\nother than the risk management frameworks specified in subparagraphs (C)(i)\nand (C)(ii) of this subdivision, that imposes requirements that are\nsubstantially equivalent to, and at least as stringent as, the requirements\nset forth in sections 1 to 9, inclusive, of this act; or (iv) any risk\nmanagement framework for artificial intelligence systems that is substantially\nequivalent to, and at least as stringent as, the risk management frameworks\ndescribed in subparagraphs (C)(i) to (C)(iii), inclusive, of this subdivision.\n\n(2) The developer, integrator, deployer or other person bears the burden of\ndemonstrating to the Attorney General that the requirements established in\nsubdivision (1) of this subsection have been satisfied.\n\n(3) Nothing in this section or sections 1 to 9, inclusive, of this act,\nincluding, but not limited to, the enforcement authority granted to the\nAttorney General under this section, shall be construed to preempt or\notherwise affect any right, claim, remedy, presumption or defense available at\nlaw or in equity. Any rebuttable presumption or affirmative defense\nestablished under this section or sections 1 to 9, inclusive, of this act\nshall apply only to an enforcement action brought by the Attorney General\npursuant to this section and shall not apply to any right, claim, remedy,\npresumption or defense available at law or in equity.\n\nSec. 11. (NEW) (Effective October 1, 2025) (a) As used in this section:\n\n(1) \"Active participant\" means a person participating in the artificial\nintelligence regulatory sandbox program designed, established and administered\nin accordance with the provisions of this section;\n\n(2) \"Artificial intelligence system\" has the same meaning as provided in\nsection 1 of this act;\n\n(3) \"Consumer\" has the same meaning as provided in section 1 of this act;\n\n(4) \"Deployer\" means any person doing business in this state that deploys an\nartificial intelligence system;\n\n(5) \"Developer\" has the same meaning as provided in section 1 of this act;\n\n(6) \"Person\" has the same meaning as provided in section 1 of this act; and\n\n(7) \"State agency\" has the same meaning as provided in section 1-79 of the\ngeneral statutes.\n\n(b) The Department of Economic and Community Development, in coordination with\nthe Chief Data Officer and the Connecticut Technology Advisory Board\nestablished under section 15 of this act, shall design, establish and\nadminister an artificial intelligence regulatory sandbox program to facilitate\nthe development, testing and deployment of innovative artificial intelligence\nsystems in the state. The program shall be designed to (1) promote the safe\nand innovative use of artificial intelligence systems across various sectors,\nincluding, but not limited to, education, finance, health care and public\nservice, (2) encourage the responsible deployment of artificial intelligence\nsystems while balancing the need for consumer protection, privacy and public\nsafety, and (3) provide clear guidelines for developers to test artificial\nintelligence systems while exempt from certain regulatory requirements during\nthe period set forth in subsection (d) of this section.\n\n(c) (1) A person seeking to participate in the artificial intelligence\nregulatory sandbox program shall submit an application to the Department of\nEconomic and Community Development in a form and manner prescribed by the\nCommissioner of Economic and Community Development. Each application shall\ninclude (A) a detailed description of the applicant's artificial intelligence\nsystem and its intended uses, (B) a risk assessment that addresses the\npotential impact of the applicant's artificial intelligence system on\nconsumers, privacy and public safety, (C) a plan for mitigating any adverse\nconsequences that may arise from the applicant's artificial intelligence\nsystem during the period set forth in subsection (d) of this section, (D)\nproof that the applicant and the applicant's artificial intelligence system\nare in compliance with all applicable federal laws and regulations concerning\nartificial intelligence systems, and (E) any other information the\ncommissioner deems relevant for the purposes of this section or the program.\n\n(2) Not later than thirty days after the Department of Economic and Community\nDevelopment receives an application submitted pursuant to subdivision (1) of\nthis subsection, the department shall (A) approve or deny the application, and\n(B) send a notice to the applicant, in a form and manner prescribed by the\nCommissioner of Economic and Community Development, disclosing whether the\ndepartment has approved or denied such application.\n\n(d) An active participant in the artificial intelligence regulatory sandbox\nprogram may test the applicant's artificial intelligence system as part of the\nprogram for a period not to exceed thirty-six months from the date on which\nthe Department of Economic and Community Development sent notice approving the\nactive participant's application pursuant to subdivision (2) of subsection (c)\nof this section, except the department may extend such period for good cause\nshown.\n\n(e) The Department of Economic and Community Development shall coordinate with\nall relevant state agencies to oversee the operations of active participants\nin the artificial intelligence regulatory sandbox program. Any state agency\nmay recommend to the department that an active participant's participation in\nthe program be revoked if the active participant's artificial intelligence\nsystem (1) poses an undue risk to the public health, safety or welfare, or (2)\nviolates any federal law or regulation.\n\n(f) For the calendar quarter ending December 31, 2025, and for each calendar\nquarter thereafter, each active participant in the artificial intelligence\nregulatory sandbox program shall, not later than thirty days after the end of\nsuch calendar quarter, submit a report to the Department of Economic and\nCommunity Development disclosing (1) system performance metrics for such\nactive participant's artificial intelligence system, (2) information\nconcerning the manner in which such active participant's artificial\nintelligence system mitigated any risks associated with such artificial\nintelligence system, and (3) any feedback such active participant received\nfrom deployers, consumers and other users of such artificial intelligence\nsystem.\n\n(g) For the calendar year ending December 31, 2025, and for each calendar year\nthereafter, the Department of Economic and Community Development shall, not\nlater than thirty days after the end of such calendar year, submit a report,\nin accordance with section 11-4a of the general statutes, to the joint\nstanding committee of the General Assembly having cognizance of matters\nrelating to consumer protection. Each report shall disclose (1) the number of\npersons who were active participants in the artificial intelligence regulatory\nsandbox program for the calendar year that is the subject of such report or\nany portion of such calendar year, (2) the overall performance and impact of\nartificial intelligence systems tested as part of the program, and (3) any\nrecommendations regarding the adoption of legislation for the purposes of the\nprogram.\n\nSec. 12. (NEW) (Effective July 1, 2025) (a) As used in this section,\n\"artificial intelligence\" means artificial intelligence system, as defined in\nsection 1 of this act.\n\n(b) Not later than December 31, 2025, the Board of Regents for Higher\nEducation shall establish, on behalf of Charter Oak State College and in\nconsultation with the Labor Department, the State Board of Education,\nWorkforce Investment Boards, employers and institutions of higher education in\nthis state, a \"Connecticut AI Academy\". The academy shall, at a minimum:\n\n(1) Curate and offer online courses concerning artificial intelligence and the\nresponsible use of artificial intelligence;\n\n(2) Promote digital literacy;\n\n(3) Prepare students for careers in fields involving artificial intelligence;\n\n(4) Offer courses directed at individuals between thirteen and twenty years of\nage;\n\n(5) Offer courses that prepare small businesses and nonprofit organizations to\nutilize artificial intelligence to improve marketing and management\nefficiency;\n\n(6) Develop courses concerning artificial intelligence that the Labor\nDepartment and Workforce Investment Boards may incorporate into workforce\ntraining programs; and\n\n(7) Enable persons providing free or discounted public Internet access to\ndistribute information and provide mentorship concerning artificial\nintelligence, the academy and methods available for the public to obtain free\nor discounted devices capable of accessing the Internet and utilizing\nartificial intelligence.\n\n(c) The Board of Regents for Higher Education shall, in consultation with\nCharter Oak State College, develop certificates and badges to be awarded to\npersons who successfully complete courses offered by the Connecticut AI\nAcademy.\n\nSec. 13. (NEW) (Effective July 1, 2025) The Labor Department shall provide a\nnotice, in a form and manner prescribed by the Labor Commissioner, to each\nindividual who makes a claim for unemployment compensation disclosing the\nexistence of, and courses and services offered by, the Connecticut AI Academy\nestablished pursuant to section 12 of this act.\n\nSec. 14. Subsection (b) of section 17b-751b of the general statutes is\nrepealed and the following is substituted in lieu thereof (Effective July 1,\n2025):\n\n(b) The commissioner shall: (1) Ensure that all home visiting programs _(A)_\nare one or more of the evidence-based home visiting models that meet the\ncriteria for evidence of effectiveness developed by the federal Department of\nHealth and Human Services _, and (B) provide information to parents regarding\nthe Connecticut AI Academy established pursuant to section 12 of this act_ ;\n(2) provide oversight of home visiting programs to insure model fidelity; and\n(3) develop, issue and evaluate requests for proposals to procure the services\nrequired by this section. In evaluating the proposals, the commissioner shall\ntake into consideration the most effective and consistent service delivery\nsystem allowing for the continuation of current public and private programs.\n\nSec. 15. (NEW) (Effective July 1, 2025) (a) As used in this section,\n\"artificial intelligence\" means artificial intelligence system, as defined in\nsection 1 of this act.\n\n(b) There is established, within available appropriations, a Connecticut\nTechnology Advisory Board, which shall be part of the Legislative Department.\n\n(c) (1) The board shall consist of the following members: (A) Two appointed by\nthe speaker of the House of Representatives; (B) two appointed by the\npresident pro tempore of the Senate; (C) two appointed by the minority leader\nof the House of Representatives; and (D) two appointed by the minority leader\nof the Senate. All appointed members shall have professional experience or\nacademic qualifications in the field of artificial intelligence or the field\nof technology, or another related field, and no such member shall be a member\nof the General Assembly.\n\n(2) The following persons or their designees shall serve as ex-officio,\nnonvoting members and chairpersons of the board: (A) The Commissioner of\nEconomic and Community Development; (B) the executive director of the\nConnecticut Academy of Science and Engineering; and (C) the president of\nCharter Oak State College.\n\n(3) All initial appointments to the board shall be made not later than October\n1, 2025. The term of an appointed member shall be coterminous with the term of\nthe appointing authority for the appointed member. Any vacancy shall be filled\nby the appointing authority. Any vacancy occurring other than by expiration of\na term shall be filled for the balance of the unexpired term. A member of the\nboard may serve more than one term. The chairpersons shall schedule the first\nmeeting of the board, which shall be held not later than November 1, 2025.\n\n(d) The administrative staff of the joint standing committees of the General\nAssembly having cognizance of matters relating to consumer protection and\ngovernment administration shall serve as administrative staff of the board.\n\n(e) The board shall have the following powers and duties: (1) To develop and\nadopt a state technology strategy (A) for the purpose of promoting education,\nworkforce development, economic development and consumer protection, and (B)\nthat accounts for the rapid pace of technological development, including, but\nnot limited to, in the field of artificial intelligence; (2) to update the\nstate technology strategy developed and adopted pursuant to subdivision (1) of\nthis subsection at least once every two years; (3) to issue reports and\nrecommendations in accordance with section 11-4a of the general statutes; (4)\nupon the vote of a majority of the members of the board, to request any state\nagency data officer or state agency head to (A) appear before the board to\nanswer questions, or (B) provide such assistance and data as may be necessary\nfor the purpose of enabling the board to perform its duties; (5) to make\nrecommendations to the Legislative Department, Executive Department or\nJudicial Department in accordance with the state technology strategy; and (6)\nto establish bylaws to govern the board's procedures.\n\n(f) The board shall meet at least twice annually and may meet at such other\ntimes as deemed necessary by the chairpersons or a majority of the members of\nthe board.\n\nSec. 16. (Effective July 1, 2025) (a) Not later than December 31, 2025, the\nDepartment of Economic and Community Development shall, within available\nappropriations and in collaboration with Charter Oak State College, develop a\nplan to establish a technology transfer program within Connecticut\nInnovations, Incorporated, for the purpose of supporting technology transfers\nby and among public and private institutions of higher education in this\nstate.\n\n(b) Not later than January 1, 2026, the Commissioner of Economic and Community\nDevelopment shall submit a report, in accordance with section 11-4a of the\ngeneral statutes, to the joint standing committees of the General Assembly\nhaving cognizance of matters relating to consumer protection, commerce and\nhigher education. Such report shall, at a minimum, include the plan developed\npursuant to subsection (a) of this section.\n\nSec. 17. (NEW) (Effective July 1, 2025) (a) Not later than December 31, 2025,\nthe Department of Economic and Community Development shall, within available\nappropriations and in collaboration with the Office of Health Strategy,\nestablish a confidential computing cluster for the purpose of fostering the\nexchange of health information in order to support academic and medical\nresearch.\n\n(b) (1) The confidential computing cluster established pursuant to subsection\n(a) of this section shall be overseen by a Connecticut Confidential Computing\nCluster Policy Board, which shall be within the Department of Economic and\nCommunity Development for administrative purposes only. Said policy board\nshall consist of:\n\n(A) The chairperson of The University of Connecticut Health Center Board of\nDirectors, or said chairperson's designee; and\n\n(B) A representative of the State-wide Health Information Exchange established\npursuant to section 17b-59d of the general statutes, who shall be appointed by\nthe Commissioner of Health Strategy.\n\n(2) The Connecticut Confidential Computing Cluster Policy Board shall direct\nthe formulation of policies and operating procedures for the confidential\ncomputing cluster established pursuant to subsection (a) of this section.\n\n(3) The Connecticut Confidential Computing Cluster Policy Board may apply for\nand administer any federal, state, local or private appropriations or grant\nfunds made available for the operation of the confidential computing cluster\nestablished pursuant to subsection (a) of this section.\n\nSec. 18. Section 10-21l of the general statutes is repealed and the following\nis substituted in lieu thereof (Effective July 1, 2025):\n\nThere is established an account to be known as the ~~\" computer science\neducation account\"~~ _\" computer science education and workforce development\naccount\"_, which shall be a separate, nonlapsing account within the General\nFund. The account shall contain any moneys required or permitted by law to be\ndeposited in the account and any funds received from any public or private\ncontributions, gifts, grants, donations, bequests or devises to the account.\nThe Department of Education may make expenditures from the account _(1)_ to\nsupport curriculum development, teacher professional development, capacity\ndevelopment for school districts ~~,~~ and other programs for the purposes of\nsupporting computer science education _, and (2) in coordination with the\nOffice of Workforce Strategy and the Board of Regents for Higher Education for\nthe purpose of supporting workforce development initiatives in accordance with\nthe state technology strategy adopted pursuant to subsection (e) of section 15\nof this act_.\n\nSec. 19. Section 32-7p of the general statutes is repealed and the following\nis substituted in lieu thereof (Effective July 1, 2025):\n\n_(a) As used in this section:_\n\n_(1) \"Artificial intelligence\" means artificial intelligence system, as\ndefined in section 1 of this act;_\n\n_(2) \"Generative artificial intelligence\" means any form of artificial\nintelligence, including, but not limited to, a foundation model, that is able\nto produce synthetic digital content, as defined in section 1 of this act;\nand_\n\n_(3) \"Prompt engineering\" means the process of guiding generative artificial\nintelligence to generate a desired output._\n\n~~(a)~~ _(b)_ There shall be a Technology Talent _and Innovation Fund_\nAdvisory Committee within the Department of Economic and Community\nDevelopment. Such committee shall consist of members appointed by the\nCommissioner of Economic and Community Development, including, but not limited\nto, representatives of The University of Connecticut, the Board of Regents for\nHigher Education, independent institutions of higher education, the Office of\nWorkforce Strategy and private industry. Such members shall be subject to term\nlimits prescribed by the commissioner. Each member shall hold office until a\nsuccessor is appointed.\n\n~~(b)~~ _(c)_ The commissioner shall call the first meeting of the advisory\ncommittee not later than October 15, 2016. The advisory committee shall meet\nnot less than quarterly thereafter and at such other times as the chairperson\ndeems necessary. The Technology Talent _and Innovation Fund_ Advisory\nCommittee shall designate the chairperson of the committee from among its\nmembers.\n\n~~(c)~~ _(d)_ No member of the advisory committee shall receive compensation\nfor such member's service, except that each member shall be entitled to\nreimbursement for actual and necessary expenses incurred during the\nperformance of such member's official duties.\n\n~~(d)~~ _(e)_ A majority of members of the advisory committee shall constitute\na quorum for the transaction of any business or the exercise of any power of\nthe advisory committee. The advisory committee may act by a majority of the\nmembers present at any meeting at which a quorum is in attendance, for the\ntransaction of any business or the exercise of any power of the advisory\ncommittee, except as otherwise provided in this section.\n\n~~(e)~~ _(f)_ Notwithstanding any provision of the general statutes, it shall\nnot constitute a conflict of interest for a trustee, director, partner or\nofficer of any person, firm or corporation, or any individual having a\nfinancial interest in a person, firm or corporation, to serve as a member of\nthe advisory committee, provided such trustee, director, partner, officer or\nindividual complies with all applicable provisions of chapter 10. All members\nof the advisory committee shall be deemed public officials and shall adhere to\nthe code of ethics for public officials set forth in chapter 10, except that\nno member shall be required to file a statement of financial interest as\ndescribed in section 1-83.\n\n~~(f) The Technology Talent Advisory Committee shall, in the following order\nof priority, (1) calculate the number of software developers and other persons\n(A) employed in technology-based fields where there is a shortage of qualified\nemployees in this state for businesses to hire, including, but not limited to,\ndata mining, data analysis and cybersecurity, and (B) employed by businesses\nlocated in Connecticut as of December 31, 2016; (2) develop pilot programs to\nrecruit software developers to Connecticut and train residents of the state in\nsoftware development and such other technology fields, with the goal of\nincreasing the number of software developers and persons employed in such\nother technology fields residing in Connecticut and employed by businesses in\nConnecticut by at least double the number calculated pursuant to subdivision\n(1) of this subsection by January 1, 2026; and (3) identify other technology\nindustries where there is a shortage of qualified employees in this state for\ngrowth stage businesses to hire.~~\n\n(g) The Technology Talent _and Innovation Fund_ Advisory Committee may\n_partner with institutions of higher education and other nonprofit\norganizations to_ develop ~~pilot~~ programs ~~for (1) marketing and publicity\ncampaigns designed to recruit technology talent to the state; (2) student loan\ndeferral or forgiveness for students who start businesses in the state; and\n(3) training, apprenticeship and gap-year initiatives~~ _to expand the\ntechnology talent pipeline in the state, including, but not limited to, in the\nfields of artificial intelligence and quantum computing_.\n\n~~(h) The Technology Talent Advisory Committee shall report, in accordance\nwith the provisions of section 11-4a, and present such report to the joint\nstanding committees of the General Assembly having cognizance of matters\nrelating to commerce, education, higher education and finance, revenue and\nbonding on or before January 1, 2017, concerning the (1) pilot programs\ndeveloped pursuant to subsections (f) and (g) of this section, (2) number of\nsoftware developers and persons employed in technology-based fields described\nin subsection (f) of this section targeted for recruitment pursuant to\nsubsection (f) of this section, and (3) timeline and measures for reaching the\nrecruitment target.~~\n\n_(h) Not later than July 1, 2026, the Technology Talent and Innovation Fund\nAdvisory Committee shall partner with public and private institutions of\nhigher education in the state and other training providers to develop programs\nin the field of artificial intelligence, including, but not limited to, in\nareas such as prompt engineering, artificial intelligence marketing for small\nbusinesses and artificial intelligence for small business operations._\n\nSec. 20. Subsection (b) of section 32-235 of the general statutes is repealed\nand the following is substituted in lieu thereof (Effective July 1, 2025):\n\n(b) The proceeds of the sale of said bonds, to the extent of the amount stated\nin subsection (a) of this section, shall be used by the Department of Economic\nand Community Development (1) for the purposes of sections 32-220 to 32-234,\ninclusive, including economic cluster-related programs and activities, and for\nthe Connecticut job training finance demonstration program pursuant to\nsections 32-23uu and 32-23vv, provided (A) three million dollars shall be used\nby said department solely for the purposes of section 32-23uu, (B) not less\nthan one million dollars shall be used for an educational technology grant to\nthe deployment center program and the nonprofit business consortium deployment\ncenter approved pursuant to section 32-41l, (C) not less than two million\ndollars shall be used by said department for the establishment of a pilot\nprogram to make grants to businesses in designated areas of the state for\nconstruction, renovation or improvement of small manufacturing facilities,\nprovided such grants are matched by the business, a municipality or another\nfinancing entity. The Commissioner of Economic and Community Development shall\ndesignate areas of the state where manufacturing is a substantial part of the\nlocal economy and shall make grants under such pilot program which are likely\nto produce a significant economic development benefit for the designated area,\n(D) five million dollars may be used by said department for the manufacturing\ncompetitiveness grants program, (E) one million dollars shall be used by said\ndepartment for the purpose of a grant to the Connecticut Center for Advanced\nTechnology, for the purposes of subdivision (5) of subsection (a) of section\n32-7f, (F) fifty million dollars shall be used by said department for the\npurpose of grants to the United States Department of the Navy, the United\nStates Department of Defense or eligible applicants for projects related to\nthe enhancement of infrastructure for long-term, on-going naval operations at\nthe United States Naval Submarine Base-New London, located in Groton, which\nwill increase the military value of said base. Such projects shall not be\nsubject to the provisions of sections 4a-60 and 4a-60a, (G) two million\ndollars shall be used by said department for the purpose of a grant to the\nConnecticut Center for Advanced Technology, Inc., for manufacturing\ninitiatives, including aerospace and defense, and (H) four million dollars\nshall be used by said department for the purpose of a grant to companies\nadversely impacted by the construction at the Quinnipiac Bridge, where such\ngrant may be used to offset the increase in costs of commercial overland\ntransportation of goods or materials brought to the port of New Haven by ship\nor vessel, (2) for the purposes of the small business assistance program\nestablished pursuant to section 32-9yy, provided fifteen million dollars shall\nbe deposited in the small business assistance account established pursuant to\nsaid section 32-9yy, (3) to deposit twenty million dollars in the small\nbusiness express assistance account established pursuant to section 32-7h, (4)\nto deposit four million nine hundred thousand dollars per year in each of the\nfiscal years ending June 30, 2017, to June 30, 2019, inclusive, and June 30,\n2021, and nine million nine hundred thousand dollars in the fiscal year ending\nJune 30, 2020, in the CTNext Fund established pursuant to section 32-39i,\nwhich shall be used by the Department of Economic and Community Development to\nprovide grants-in-aid to designated innovation places, as defined in section\n32-39f, planning grants-in-aid pursuant to section 32-39l, and grants-in-aid\nfor projects that network innovation places pursuant to subsection (b) of\nsection 32-39m, provided not more than three million dollars be used for\ngrants-in-aid for such projects, and further provided any portion of any such\ndeposit that remains unexpended in a fiscal year subsequent to the date of\nsuch deposit may be used by the Department of Economic and Community\nDevelopment for any purpose described in subsection (e) of section 32-39i, (5)\nto deposit two million dollars per year in each of the fiscal years ending\nJune 30, 2019, to June 30, 2021, inclusive, in the CTNext Fund established\npursuant to section 32-39i, which shall be used by the Department of Economic\nand Community Development for the purpose of providing higher education\nentrepreneurship grants-in-aid pursuant to section 32-39g, provided any\nportion of any such deposit that remains unexpended in a fiscal year\nsubsequent to the date of such deposit may be used by the Department of\nEconomic and Community Development for any purpose described in subsection (e)\nof section 32-39i, (6) for the purpose of funding the costs of the Technology\nTalent _and Innovation Fund_ Advisory Committee established pursuant to\nsection 32-7p _, as amended by this act_ , provided not more than ten million\ndollars may be used on or after July 1, 2023, for such purpose, (7) to provide\n(A) a grant-in-aid to the Connecticut Supplier Connection in an amount equal\nto two hundred fifty thousand dollars in each of the fiscal years ending June\n30, 2017, to June 30, 2021, inclusive, and (B) a grant-in-aid to the\nConnecticut Procurement Technical Assistance Program in an amount equal to\nthree hundred thousand dollars in each of the fiscal years ending June 30,\n2017, to June 30, 2021, inclusive, (8) to deposit four hundred fifty thousand\ndollars per year, in each of the fiscal years ending June 30, 2017, to June\n30, 2021, inclusive, in the CTNext Fund established pursuant to section\n32-39i, which shall be used by the Department of Economic and Community\nDevelopment to provide growth grants-in-aid pursuant to section 32-39g,\nprovided any portion of any such deposit that remains unexpended in a fiscal\nyear subsequent to the date of such deposit may be used by the Department of\nEconomic and Community Development for any purpose described in subsection (e)\nof section 32-39i, (9) to transfer fifty million dollars to the Labor\nDepartment which shall be used by said department for the purpose of funding\nworkforce pipeline programs selected pursuant to section 31-11rr, provided,\nnotwithstanding the provisions of section 31-11rr, (A) not less than five\nmillion dollars shall be provided to the workforce development board in\nBridgeport serving the southwest region, for purposes of such program, and the\nboard shall distribute such money in proportion to population and need, and\n(B) not less than five million dollars shall be provided to the workforce\ndevelopment board in Hartford serving the north central region, for purposes\nof such program, (10) to transfer twenty million dollars to Connecticut\nInnovations, Incorporated, provided ten million dollars shall be used by\nConnecticut Innovations, Incorporated for the purpose of the proof of concept\nfund established pursuant to subsection (b) of section 32-39x and ten million\ndollars shall be used by Connecticut Innovations, Incorporated for the purpose\nof the venture capital fund program established pursuant to section 32-41oo,\n(11) to provide a grant to The University of Connecticut of eight million\ndollars for the establishment, development and operation of a center for\nsustainable aviation pursuant to subsection (a) of section 10a-110o, and (12)\nfor up to twenty million dollars in investments in federally designated\nopportunity zones through an impact investment firm including, subject to the\napproval of the Governor, funding from the Economic Assistance Revolving Fund,\nestablished pursuant to section 32-231.\n\nSec. 21. (Effective July 1, 2025) Not later than December 31, 2025, the\nDepartment of Economic and Community Development shall, within available\nappropriations, in partnership with public and private institutions of higher\neducation in the state and in coordination with the artificial intelligence\nindustry, conduct a \"CT AI Symposium\" to foster collaboration between\nacademia, government and the artificial intelligence industry for the purpose\nof promoting the establishment and growth of artificial intelligence\nbusinesses in this state.\n\nSec. 22. (Effective July 1, 2025) (a) As used in this section:\n\n(1) \"Artificial intelligence\" means artificial intelligence system, as defined\nin section 1 of this act;\n\n(2) \"Generative artificial intelligence\" means any form of artificial\nintelligence, including, but not limited to, a foundation model, that is able\nto produce synthetic digital content, as defined in section 1 of this act; and\n\n(3) \"State agency\" means any department, board, council, commission,\ninstitution or other executive branch agency of state government, including,\nbut not limited to, each constituent unit and each public institution of\nhigher education.\n\n(b) Each state agency shall, in consultation with the labor unions\nrepresenting the employees of such state agency, study how generative\nartificial intelligence may be incorporated in its processes to improve\nefficiencies. Each state agency shall prepare for any such incorporation with\ninput from the state agency's employees, including, but not limited to, any\napplicable collective bargaining unit that represents its employees, and\nappropriate experts from civil society organizations, academia and industry.\n\n(c) Not later than January 1, 2026, each state agency shall submit the results\nof such study to the Department of Administrative Services, including a\nrequest for approval of any potential pilot project utilizing generative\nartificial intelligence that the state agency intends to establish, provided\nsuch use is in accordance with the policies and procedures established by the\nOffice of Policy and Management pursuant to subsection (b) of section 4-68jj\nof the general statutes. Any such pilot project shall measure how generative\nartificial intelligence (1) improves Connecticut residents' experience with\nand access to government services, and (2) supports state agency employees in\nthe performance of their duties in addition to any domain-specific impacts to\nbe measured by the state agency. The Commissioner of Administrative Services\nshall assess any such proposed pilot project in accordance with the provisions\nof section 4a-2e of the general statutes, as amended by this act, and may\ndisapprove any pilot project that fails such assessment or requires additional\nlegislative authorization.\n\n(d) Not later than February 1, 2026, the Commissioner of Administrative\nServices shall submit a report, in accordance with section 11-4a of the\ngeneral statutes, to the joint standing committees of the General Assembly\nhaving cognizance of matters relating to consumer protection and government\nadministration. Such report shall include a summary of all pilot projects\napproved by the commissioner under this section and any recommendations for\nlegislation necessary to implement additional pilot projects.\n\nSec. 23. Section 32-39e of the general statutes is repealed and the following\nis substituted in lieu thereof (Effective July 1, 2025):\n\n(a) If, in the exercise of its powers under section 32-39, Connecticut\nInnovations, Incorporated (1) finds that the use of a certain technology,\nproduct or process _, including, but not limited to, an artificial\nintelligence system, as defined in section 1 of this act,_ (A) would promote\npublic health and safety, environmental protection or economic development, or\n(B) with regard to state services, would promote efficiency, reduce\nadministrative burdens or otherwise improve such services, and (2) determines\nsuch technology, product or process was developed by a business (A) domiciled\nin this state to which the corporation has provided financial assistance or in\nwhich the corporation has invested, or (B) which has been certified as a small\ncontractor or minority business enterprise by the Commissioner of\nAdministrative Services under section 4a-60g, the corporation, upon\napplication of such business, may recommend to the Secretary of the Office of\nPolicy and Management that an agency of the state, including, but not limited\nto, any constituent unit of the state system of higher education, be\nauthorized to test such technology, product or process by employing ~~it~~\n_such technology, product or process_ in the operations of such agency on a\ntrial basis. The purpose of such test program shall be to validate the\ncommercial viability of such technology, product or process provided no\nbusiness in which Connecticut Innovations, Incorporated has invested shall be\nrequired to participate in such program.\n\n(b) Connecticut Innovations, Incorporated shall make no such recommendation\nunless such business has submitted a viable business plan to Connecticut\nInnovations, Incorporated for manufacturing and marketing such technology,\nproduct or process and such business demonstrates that (1) the usage of such\ntechnology, product or process by the state agency will not adversely affect\nsafety, (2) sufficient research and development has occurred to warrant\nparticipation in the test program, (3) the technology, product or process has\npotential for commercialization not later than two years following the\ncompletion of any test program involving a state agency under this section,\nand (4) such technology, product or process will have a positive economic\nimpact in the state, including the prospective addition of jobs and economic\nactivity upon such commercialization.\n\n(c) If the Secretary of the Office of Policy and Management finds that\nemploying such technology, product or process would be feasible in the\noperations of a state agency and would not have any detrimental effect on such\noperations, said secretary, notwithstanding the requirement of chapter 58, may\ndirect an agency of the state to accept delivery of such technology, product\nor process and to undertake such a test program. The Secretary of the Office\nof Policy and Management, in consultation with the Commissioner of\nAdministrative Services, the chief executive officer of Connecticut\nInnovations, Incorporated and the department head of the testing agency, shall\ndetermine, on a case-by-case basis, whether the costs associated with the\nacquisition and use of such technology, product or process by the testing\nagency shall be borne by Connecticut Innovations, Incorporated, the business\nor by any investor or participant in such business. The acquisition of any\ntechnology, product or process for purposes of the test program established\npursuant to this section shall not be deemed to be a purchase under the\nprovisions of the state procurement policy. The testing agency, on behalf of\nConnecticut Innovations, Incorporated shall maintain records related to such\ntest program, as requested by Connecticut Innovations, Incorporated and shall\nmake such records and any other information derived from such test program\navailable to Connecticut Innovations, Incorporated and the business. Any\nproprietary information derived from such test program shall be exempt from\nthe provisions of subsection (a) of section 1-210.\n\n(d) If the Secretary of the Office of Policy and Management, in consultation\nwith the Commissioner of Administrative Services, the chief executive officer\nof Connecticut Innovations, Incorporated and the department head of the\ntesting agency, determines that the test program sufficiently demonstrates\nthat the technology, product or process promotes public health and safety,\nenvironmental protection, economic development or efficiency, reduces\nadministrative burdens or otherwise improves state services, the Commissioner\nof Administrative Services may procure such technology, product or process for\nuse by any or all state agencies pursuant to subsection (b) of section 4a-58.\n\n(e) The Secretary of the Office of Policy and Management, the Commissioner of\nAdministrative Services and Connecticut Innovations, Incorporated may develop\na program to recognize state agencies that help to promote public health and\nsafety, environmental protection, economic development or efficiency, reduce\nadministrative burdens or improve state services by participating in a testing\nprogram under this section. Such program may include the creation of a fund\nestablished with savings accrued by the testing agency during its\nparticipation in the testing program established under this section. Such fund\nshall only be used to implement the program of recognition established by the\nSecretary of the Office of Policy and Management, the Commissioner of\nAdministrative Services and Connecticut Innovations, Incorporated, under the\nprovisions of this subsection.\n\n_(f) The Secretary of the Office of Policy and Management, the Commissioner of\nAdministrative Services, Connecticut Innovations, Incorporated, and the Chief\nInformation Officer shall, within available appropriations, establish an\nartificial intelligence systems fellowship program for the purpose of\nassisting the Chief Information Officer and state agencies to implement\nartificial intelligence systems procured pursuant to subsection (b) of section\n4a-58. The program shall be within the Office of Policy and Management for\nadministrative purposes only. Not later than January 1, 2026, the Governor\nshall appoint three artificial intelligence technology fellows in consultation\nwith the Chief Information Officer. Each artificial intelligence technology\nfellow shall have professional experience or academic qualifications in the\nfield of artificial intelligence, and shall perform such artificial\nintelligence technology fellow 's duties under the supervision of the Chief\nInformation Officer. The initial term for each artificial intelligence\ntechnology fellow shall expire on January 31, 2029. Terms following initial\nterms shall be for two years, and any artificial intelligence technology\nfellow may serve more than one term. The Governor shall fill any vacancy in\nconsultation with the Chief Information Officer not later than thirty days\nafter the appointment becomes vacant. For the purposes of this subsection,\n\"artificial intelligence system\" has the same meaning as provided in section 1\nof this act._\n\nSec. 24. (Effective July 1, 2025) (a) For the purposes of this section:\n\n(1) \"Artificial intelligence\" means artificial intelligence system, as defined\nin section 1 of this act;\n\n(2) \"General-purpose artificial intelligence\" means general-purpose artificial\nintelligence model, as defined in section 1 of this act; and\n\n(3) \"Synthetic digital content\" has the same meaning as provided in section 1\nof this act.\n\n(b) There is established a working group to engage stakeholders and experts\nto:\n\n(1) Make recommendations concerning:\n\n(A) The best practices to avoid the negative impacts, and to maximize the\npositive impacts, on services and state employees in connection with the\nimplementation of new digital technologies and artificial intelligence;\n\n(B) The collection of reports, recommendations and plans from state agencies\nconsidering the implementation of artificial intelligence, and the assessment\nof such reports, recommendations and plans against the best practices\ndescribed in subparagraph (A) of this subdivision; and\n\n(C) Any other matters which the working group may deem relevant for the\npurposes of avoiding the negative impacts, and maximizing the positive\nimpacts, described in subparagraph (A) of this subdivision;\n\n(2) Make recommendations concerning methods to create resources for the\npurpose of assisting small businesses to adopt artificial intelligence to\nimprove their efficiency and operations;\n\n(3) Propose legislation to (A) regulate the use of general-purpose artificial\nintelligence, and (B) require social media platforms to provide a signal when\nsuch social media platforms are displaying synthetic digital content;\n\n(4) After reviewing the laws and regulations, and any proposed legislation or\nregulations, of other states concerning artificial intelligence, propose\nlegislation concerning artificial intelligence;\n\n(5) Develop an outreach plan for the purpose of bridging the digital divide\nand providing workforce training to persons who do not have high-speed\nInternet access;\n\n(6) Evaluate and make recommendations concerning:\n\n(A) The establishment of testbeds to support safeguards and systems to prevent\nthe misuse of artificial intelligence;\n\n(B) Risk assessments for the misuse of artificial intelligence;\n\n(C) Evaluation strategies for artificial intelligence; and\n\n(D) The development, testing and evaluation of resources to support state\noversight of artificial intelligence;\n\n(7) Review the protections afforded to trade secrets and other proprietary\ninformation under existing state law and make recommendations concerning such\nprotections;\n\n(8) Study definitions concerning artificial intelligence, including, but not\nlimited to, the definition of high-risk artificial intelligence system set\nforth in section 1 of this act, and make recommendations concerning the\ninclusion of language providing that no artificial intelligence system shall\nbe considered to be a high-risk artificial intelligence system if such\nartificial intelligence system does not pose a significant risk of harm to the\nhealth, safety or fundamental rights of individuals, including, but not\nlimited to, by not materially influencing the outcome of any decision-making;\n\n(9) Make recommendations concerning the establishment and membership of a\npermanent artificial intelligence advisory council; and\n\n(10) Make such other recommendations concerning artificial intelligence which\nthe working group may deem appropriate.\n\n(c) (1) (A) The working group shall be part of the Legislative Department and\nconsist of the following voting members: (i) One appointed by the speaker of\nthe House of Representatives, who shall be a representative of the industries\nthat are developing artificial intelligence; (ii) one appointed by the\npresident pro tempore of the Senate, who shall be a representative of the\nindustries that are using artificial intelligence; (iii) one appointed by the\nmajority leader of the House of Representatives, who shall be an academic with\na concentration in the study of technology and technology policy; (iv) one\nappointed by the majority leader of the Senate, who shall be an academic with\na concentration in the study of government and public policy; (v) one\nappointed by the minority leader of the House of Representatives, who shall be\na representative of an industry association representing the industries that\nare developing artificial intelligence; (vi) one appointed by the minority\nleader of the Senate, who shall be a representative of an industry association\nrepresenting the industries that are using artificial intelligence; (vii) one\nappointed by the House chairperson of the joint standing committee of the\nGeneral Assembly having cognizance of matters relating to consumer protection;\n(viii) one appointed by the Senate chairperson of the joint standing committee\nof the General Assembly having cognizance of matters relating to consumer\nprotection; (ix) one appointed by the House ranking member of the joint\nstanding committee of the General Assembly having cognizance of matters\nrelating to consumer protection, who shall be a representative of the\nartificial intelligence industry or a related industry; (x) one appointed by\nthe Senate ranking member of the joint standing committee of the General\nAssembly having cognizance of matters relating to consumer protection, who\nshall be a representative of the artificial intelligence industry or a related\nindustry; (xi) one appointed by the House chairperson of the joint standing\ncommittee of the General Assembly having cognizance of matters relating to\nlabor, who shall be a representative of a labor organization; (xii) one\nappointed by the Senate chairperson of the joint standing committee of the\nGeneral Assembly having cognizance of matters relating to labor, who shall be\na representative of a labor organization; (xiii) one appointed by the House\nranking member of the joint standing committee of the General Assembly having\ncognizance of matters relating to labor, who shall be a representative of a\nsmall business; (xiv) one appointed by the Senate ranking member of the joint\nstanding committee of the General Assembly having cognizance of matters\nrelating to labor, who shall be a representative of a small business; and (xv)\ntwo appointed by the Governor, who shall be members of the Connecticut Academy\nof Science and Engineering.\n\n(B) All voting members of the working group appointed pursuant to subparagraph\n(A) of this subdivision shall have professional experience or academic\nqualifications in matters pertaining to artificial intelligence, automated\nsystems, government policy or another related field.\n\n(C) All initial appointments to the working group shall be made not later than\nJuly 31, 2025. Any vacancy shall be filled by the appointing authority.\n\n(D) Any action taken by the working group shall be taken by a majority vote of\nall members present who are entitled to vote, provided no such action may be\ntaken unless at least fifty per cent of such members are present.\n\n(2) The working group shall include the following nonvoting, ex-officio\nmembers: (A) The House chairperson of the joint standing committee of the\nGeneral Assembly having cognizance of matters relating to consumer protection;\n(B) the Senate chairperson of the joint standing committee of the General\nAssembly having cognizance of matters relating to consumer protection; (C) the\nHouse chairperson of the joint standing committee of the General Assembly\nhaving cognizance of matters relating to labor; (D) the Senate chairperson of\nthe joint standing committee of the General Assembly having cognizance of\nmatters relating to labor; (E) the Attorney General, or the Attorney General's\ndesignee; (F) the Comptroller, or the Comptroller's designee; (G) the\nTreasurer, or the Treasurer's designee; (H) the Commissioner of Administrative\nServices, or said commissioner's designee; (I) the Chief Data Officer, or said\nofficer's designee; (J) the executive director of the Freedom of Information\nCommission, or said executive director's designee; (K) the executive director\nof the Commission on Women, Children, Seniors, Equity and Opportunity, or said\nexecutive director's designee; (L) the Chief Court Administrator, or said\nadministrator's designee; and (M) the executive director of the Connecticut\nAcademy of Science and Engineering, or said executive director's designee.\n\n(d) The chairpersons of the joint standing committee of the General Assembly\nhaving cognizance of matters relating to consumer protection and the executive\ndirector of the Connecticut Academy of Science and Engineering shall serve as\nchairpersons of the working group. Such chairpersons shall schedule the first\nmeeting of the working group, which shall be held not later than August 31,\n2025.\n\n(e) The administrative staff of the joint standing committee of the General\nAssembly having cognizance of matters relating to consumer protection shall\nserve as administrative staff of the working group.\n\n(f) Not later than February 1, 2026, the working group shall submit a report\non its findings and recommendations to the joint standing committee of the\nGeneral Assembly having cognizance of matters relating to consumer protection,\nin accordance with section 11-4a of the general statutes. The working group\nshall terminate on the date that the working group submits such report or\nFebruary 1, 2026, whichever is later.\n\nSec. 25. Section 4a-2e of the general statutes is repealed and the following\nis substituted in lieu thereof (Effective July 1, 2025):\n\n(a) For the purposes of this section:\n\n(1) \"Artificial intelligence\" means ~~(A) an artificial system that (i)\nperforms tasks under varying and unpredictable circumstances without\nsignificant human oversight or can learn from experience and improve such\nperformance when exposed to data sets, (ii) is developed in any context,\nincluding, but not limited to, software or physical hardware, and solves tasks\nrequiring human-like perception, cognition, planning, learning, communication\nor physical action, or (iii) is designed to (I) think or act like a human,\nincluding, but not limited to, a cognitive architecture or neural network, or\n(II) act rationally, including, but not limited to, an intelligent software\nagent or embodied robot that achieves goals using perception, planning,\nreasoning, learning, communication, decision-making or action, or (B) a set of\ntechniques, including, but not limited to, machine learning, that is designed\nto approximate a cognitive task; and~~ _artificial intelligence system, as\ndefined in section 1 of this act;_\n\n_(2) \"Generative artificial intelligence\" means any form of artificial\nintelligence, including, but not limited to, a foundation model, that is able\nto produce synthetic digital content, as defined in section 1 of this act;\nand_\n\n~~(2)~~ _(3)_ \"State agency\" has the same meaning as provided in section 4d-1.\n\n(b) (1) Not later than December 31, 2023, and annually thereafter, the\n~~Department~~ _Commissioner_ of Administrative Services shall conduct an\ninventory of all systems that employ artificial intelligence and are in use by\nany state agency. Each such inventory shall include at least the following\ninformation for each such system:\n\n(A) The name of such system and the vendor, if any, that provided such system;\n\n(B) A description of the general capabilities and uses of such system;\n\n(C) Whether such system was used to independently make, inform or materially\nsupport a conclusion, decision or judgment; and\n\n(D) Whether such system underwent an impact assessment prior to\nimplementation.\n\n(2) The ~~Department~~ _Commissioner_ of Administrative Services shall make\neach inventory conducted pursuant to subdivision (1) of this subsection\npublicly available on the state's open data portal.\n\n(c) Beginning on February 1, 2024, the ~~Department~~ _Commissioner_ of\nAdministrative Services shall perform ongoing assessments of systems that\nemploy artificial intelligence and are in use by state agencies to ensure that\nno such system shall result in any unlawful discrimination or disparate impact\ndescribed in subparagraph (B) of subdivision (1) of subsection (b) of section\n4-68jj. The ~~department~~ _commissioner_ shall perform such assessment in\naccordance with the policies and procedures established by the Office of\nPolicy and Management pursuant to subsection (b) of section 4-68jj.\n\n_(d) The Commissioner of Administrative Services shall, in consultation with\nother state agencies, collective bargaining units that represent state agency\nemployees and industry experts, develop trainings for state agency employees\non (1) the use of generative artificial intelligence tools that are determined\nby the commissioner, pursuant to the assessment performed under subsection (c)\nof this section, to achieve equitable outcomes, and (2) methods for\nidentifying and mitigating potential output inaccuracies, fabricated text,\nhallucinations and biases of generative artificial intelligence while\nrespecting the privacy of the public and complying with all applicable state\nlaws and policies. Beginning on July 1, 2026, the commissioner shall make such\ntrainings available to state agency employees not less frequently than\nannually._\n\nSec. 26. (NEW) (Effective July 1, 2025) The Department of Economic and\nCommunity Development shall, within available appropriations, design an\nalgorithmic computer model for the purpose of simulating and assessing various\npublic policy decisions, proposed public policy decisions and the actual or\npotential effects of such policy decisions. The department shall design such\nmodel in collaboration with public and private institutions of higher\neducation in this state, the Department of Energy and Environmental Protection\nand any other state agency the Commissioner of Economic and Community\nDevelopment, in the commissioner's discretion, deems relevant for the purposes\nof this section. Such model shall, at a minimum, be designed to (1) function\nas a digital twin of the population of the state, (2) algorithmically model\n(A) the actual or potential effects of planning and development decisions or\nproposed planning and development decisions, and (B) the actual or potential\nsocioeconomic effects of macroeconomic shocks on businesses and families in\nthe state, (3) utilize large quantities of data to support the development of\npublic policies concerning coastline resiliency, family assistance and\nworkforce development, and (4) enable data-driven governance by optimizing\nresource allocation and policy efficiency for the purpose of furthering\neconomic resilience and social equity.\n\nSec. 27. Section 53a-189c of the general statutes is repealed and the\nfollowing is substituted in lieu thereof (Effective October 1, 2025):\n\n(a) A person is guilty of unlawful dissemination of an intimate image when (1)\nsuch person intentionally disseminates by electronic or other means a\nphotograph, film, videotape or other recorded image _or synthetic image_ of\n(A) the genitals, pubic area or buttocks of another person with less than a\nfully opaque covering of such body part, or the breast of such other person\nwho is female with less than a fully opaque covering of any portion of such\nbreast below the top of the nipple, or (B) another person engaged in sexual\nintercourse, as defined in section 53a-193, (2) such person disseminates such\nimage ~~without the consent of such other person,~~ knowing that such other\nperson ~~understood that the image would not be so disseminated~~ _did not\nconsent to such dissemination_ , and (3) such other person suffers harm as a\nresult of such dissemination.\n\n_(b)_ For purposes of this ~~subsection, \"disseminate\"~~ _section:_\n\n_(1) \"Disseminate\"_ means to sell, give, provide, lend, trade, mail, deliver,\ntransfer, publish, distribute, circulate, present, exhibit, advertise or\notherwise offer _;_ ~~, and \"harm\"~~\n\n_(2) \"Harm\"_ includes, but is not limited to, subjecting such other person to\nhatred, contempt, ridicule, physical injury, financial injury, psychological\nharm or serious emotional distress _; and_\n\n_(3) \"Synthetic image\" means any photograph, film, videotape or other image\nthat (A) is not wholly recorded by a camera, (B) is either partially or wholly\ngenerated by a computer system, and (C) depicts, and is virtually\nindistinguishable from an actual representation of, an identifiable person_.\n\n~~(b)~~ _(c)_ The provisions of subsection (a) of this ~~subsection~~\n_section_ shall not apply to:\n\n(1) Any image described in subsection (a) of this section of such other person\nif such image resulted from voluntary exposure or engagement in sexual\nintercourse by such other person, in a public place, as defined in section\n53a-181, or in a commercial setting;\n\n(2) Any image described in subsection (a) of this section of such other\nperson, if such other person is not clearly identifiable, unless other\npersonally identifying information is associated with or accompanies the\nimage; or\n\n(3) Any image described in subsection (a) of this section of such other\nperson, if the dissemination of such image serves the public interest.\n\n~~(c)~~ _(d)_ Unlawful dissemination of an intimate image to (1) a person by\nany means is a class A misdemeanor, and (2) more than one person by means of\nan interactive computer service, as defined in 47 USC 230, an information\nservice, as defined in 47 USC 153, or a telecommunications service, as defined\nin section 16-247a, is a class D felony.\n\n~~(d)~~ _(e)_ Nothing in this section shall be construed to impose liability\non the provider of an interactive computer service, as defined in 47 USC 230,\nan information service, as defined in 47 USC 153, or a telecommunications\nservice, as defined in section 16-247a, for content provided by another\nperson.\n\nThis act shall take effect as follows and shall amend the following sections:  \n  \n---  \nSection 1 | October 1, 2025 | New section  \nSec. 2 | October 1, 2025 | New section  \nSec. 3 | October 1, 2025 | New section  \nSec. 4 | October 1, 2025 | New section  \nSec. 5 | October 1, 2025 | New section  \nSec. 6 | October 1, 2025 | New section  \nSec. 7 | October 1, 2025 | New section  \nSec. 8 | October 1, 2025 | New section  \nSec. 9 | October 1, 2025 | New section  \nSec. 10 | October 1, 2025 | New section  \nSec. 11 | October 1, 2025 | New section  \nSec. 12 | July 1, 2025 | New section  \nSec. 13 | July 1, 2025 | New section  \nSec. 14 | July 1, 2025 | 17b-751b(b)  \nSec. 15 | July 1, 2025 | New section  \nSec. 16 | July 1, 2025 | New section  \nSec. 17 | July 1, 2025 | New section  \nSec. 18 | July 1, 2025 | 10-21l  \nSec. 19 | July 1, 2025 | 32-7p  \nSec. 20 | July 1, 2025 | 32-235(b)  \nSec. 21 | July 1, 2025 | New section  \nSec. 22 | July 1, 2025 | New section  \nSec. 23 | July 1, 2025 | 32-39e  \nSec. 24 | July 1, 2025 | New section  \nSec. 25 | July 1, 2025 | 4a-2e  \nSec. 26 | July 1, 2025 | New section  \nSec. 27 | October 1, 2025 | 53a-189c  \n  \n**Statement of Purpose:**\n\nTo (1) establish various requirements concerning artificial intelligence\nsystems, (2) require the Department of Economic and Community Development to\n(A) establish an artificial intelligence regulatory sandbox program, (B) plan\nto establish a technology transfer program, (C) establish a confidential\ncomputing cluster, (D) conduct a \"CT AI Symposium\", and (E) design an\nalgorithmic computer model, (3) require the Board of Regents for Higher\nEducation to establish a \"Connecticut AI Academy\" and require the Labor\nDepartment, and home visiting programs overseen by the Commissioner of Early\nChildhood, to provide information concerning said academy, (4) establish a\nConnecticut Technology Advisory Board, (5) modify the \"computer science\neducation and workforce development account\", (6) modify the Technology Talent\nand Innovation Fund Advisory Committee, (7) establish an artificial\nintelligence systems fellowship program, (8) establish an artificial\nintelligence task force, (9) require state agencies to take various actions\nregarding generative artificial intelligence, and (10) prohibit dissemination\nof certain synthetic images.\n\nCo-Sponsors: | SEN. LOONEY, 11th Dist.; SEN. DUFF, 25th Dist.  \nSEN. ANWAR, 3rd Dist.; SEN. CABRERA, 17th Dist.  \nSEN. COHEN, 12th Dist.; SEN. FLEXER, 29th Dist.  \nSEN. GADKAR-WILCOX, 22nd Dist.; SEN. GASTON, 23rd Dist.  \nSEN. HOCHADEL, 13th Dist.; SEN. HONIG, 8th Dist.  \nSEN. KUSHNER, 24th Dist.; SEN. LESSER, 9th Dist.  \nSEN. LOPES, 6th Dist.; SEN. MAHER, 26th Dist.  \nSEN. MARONEY, 14th Dist.; SEN. MARX, 20th Dist.  \nSEN. MCCRORY, 2nd Dist.; SEN. MILLER P., 27th Dist.  \nSEN. NEEDLEMAN, 33rd Dist.; SEN. OSTEN, 19th Dist.  \nSEN. RAHMAN, 4th Dist.; SEN. SLAP, 5th Dist.  \nSEN. WINFIELD, 10th Dist.; REP. REYES, 75th Dist.  \nREP. DELNICKI, 14th Dist.; REP. GAUTHIER, 38th Dist.  \nREP. MARTINEZ, 22nd Dist.; REP. LEMAR, 96th Dist.  \nREP. BROWN M., 127th Dist.  \n---|---  \n  \nS.B. 2\n\nCopyright (C) 2025 State Net  \n  \n---\n\n",
      "latest_version": false
    },
    {
      "date": "04/09/2025",
      "label": "Reissued",
      "url": "https://custom.statenet.com/public/resources.cgi?mode=show_text&id=ID:bill:CT2025000S2&verid=CT2025000S2_20250409_0_RI&",
      "raw_html": "<html>\n<head>\n<title>Bill Resource</title>\n\n<!--   <link href=\"https://custom.statenet.com/network/Common/css/extregtext.css\" rel=\"stylesheet\" type=\"text/css\" />-->\n   <link href=\"https://custom.statenet.com/network/Common/css/xmltext-2.0.css\" rel=\"stylesheet\" type=\"text/css\" />\n   <link href=\"https://custom.statenet.com/network/Common/css/additional-text.css\" rel=\"stylesheet\" type=\"text/css\" />\n\n\t<style type=\"text/css\">\n<!--\n\ntd, body {\n     background-color: white;\n\tfont-family: Verdana, Arial, Helvetica, sans-serif;\n\tfont-size: 12px;\n}\n\n.resourceContainer {\n   border: 1px solid black;\n}\n-->\n</style>\n</head>\n<body>\n\n    <div style=\"width: 750px; margin: auto\">\n       <div style=\"font-size: .8em;margin-bottom: 10px\"><table width=\"100%\"><tr><td align=\"left\" style=\"font-size: .8em;\"><div>The following has special meaning:</div>\n<div><u class=\"amendmentInsertedText\">green underline denotes added text</u></div>\n<div><strike class=\"amendmentDeletedText\">red struck out text denotes deleted text</strike></div></td> <td align=\"right\"><a href=\"https://www.lexisnexis.com/statenet/\"><img alt=\"Powered by State Net\" src=\"https://custom.statenet.com/network/poweredby.gif\" /></a></td></tr></table></div><table id=\"text-identifier\"><tr><td class=\"key\">2025 CT S 2</td> <td><table><tr><td class=\"label\">Author:</td> <td>Looney</td></tr> <tr><td class=\"label\">Version:</td> <td>Reissued</td></tr> <tr><td class=\"label\">Version Date:</td> <td>04/09/2025</td></tr></table></td></tr></table><div class=\"documentBody\">\n  <a name=\"head_document_section\"></a><div class=\"head\">\n   <p class=\"center\">\n    <b>STATE OF CONNECTICUT</b>\n   </p>\n   <p class=\"center\">General Assembly</p>\n   <p class=\"center\">File No. 603</p>\n   <p class=\"center\">\n    <b>January Session, 2025</b>\n   </p>\n   <p class=\"center\">Substitute Senate Bill No. 2</p>\n   <p class=\"center\">Senate, April 9, 2025</p>\n   <p class=\"center\">The Committee on General Law reported through SEN. MARONEY of the 14th Dist., Chairperson of the Committee on the part of the Senate, that the substitute bill ought to pass.</p>\n  </div>\n  <a name=\"title_document_section\"></a><div class=\"title\">\n   <p class=\"indent\">AN ACT CONCERNING ARTIFICIAL INTELLIGENCE.</p>\n  </div>\n  <a name=\"text_document_section\"></a><div class=\"text\">\n   <span>\n    <p class=\"indent\">Be it enacted by the Senate and House of Representatives in General Assembly convened:</p>\n   </span>\n   <p class=\"indent\">Section 1. (NEW) (Effective October 1, 2025) For the purposes of this section and sections 2 to 10, inclusive, of this act, unless the context otherwise requires:</p>\n   <p class=\"indent\">(1) &quot;Algorithmic discrimination&quot; (A) means any use of an artificial intelligence system that results in any unlawful differential treatment or impact that disfavors any individual or group of individuals on the basis of one or more classifications protected under the laws of this state or federal law, and (B) does not include (i) the offer, license or use of a high-risk artificial intelligence system by a developer, integrator or deployer for the sole purpose of (I) the developer&#39;s, integrator&#39;s or deployer&#39;s testing to identify, mitigate or prevent discrimination or otherwise ensure compliance with state and federal law, or (II) expanding an applicant, customer or participant pool to increase diversity or redress historic discrimination, or (ii) an act or omission by or on behalf of a private club or other establishment not in fact open to the public, as set forth in Title II of the Civil Rights Act of 1964, 42 USC 2000a(e), as amended from time to time;</p>\n   <p class=\"indent\">(2) &quot;Artificial intelligence system&quot; means any machine-based system that, for any explicit or implicit objective, infers from the inputs such system receives how to generate outputs, including, but not limited to, content, decisions, predictions or recommendations, that can influence physical or virtual environments;</p>\n   <p class=\"indent\">(3) &quot;Consequential decision&quot; means any decision or judgment that has a material legal or similarly significant effect on a consumer with respect to (A) access to employment, including, but not limited to, any such decision or judgment made concerning hiring, termination, compensation or promotion, (B) access to education or vocational training, including, but not limited to, any such decision or judgment made concerning admissions, financial aid or scholarships, (C) the provision or denial, or terms and conditions, of (i) financial lending or credit services, (ii) housing or lodging, including, but not limited to, rentals or short-term housing or lodging, (iii) insurance, or (iv) legal services, or (D) access to (i) essential government services, or (ii) health care services;</p>\n   <p class=\"indent\">(4) &quot;Consumer&quot; means any individual who is a resident of this state;</p>\n   <p class=\"indent\">(5) &quot;Deploy&quot; means to put a high-risk artificial intelligence system into use;</p>\n   <p class=\"indent\">(6) &quot;Deployer&quot; means any person doing business in this state that deploys a high-risk artificial intelligence system in this state;</p>\n   <p class=\"indent\">(7) &quot;Developer&quot; means any person doing business in this state that develops, or intentionally and substantially modifies, an artificial intelligence system;</p>\n   <p class=\"indent\">(8) &quot;General-purpose artificial intelligence model&quot; (A) means a model used by an artificial intelligence system that (i) displays significant generality, (ii) is capable of competently performing a wide range of distinct tasks, and (iii) can be integrated into a variety of downstream applications or systems, and (B) does not include any artificial intelligence model that is used for development, prototyping and research activities before such artificial intelligence model is released on the market;</p>\n   <p class=\"indent\">(9) &quot;High-risk artificial intelligence system&quot; (A) means any artificial intelligence system that is intended, when deployed, to make, or be a substantial factor in making, a consequential decision, and (B) unless the technology or system, when deployed, makes, or is a substantial factor in making, a consequential decision, does not include (i) any anti-fraud technology that does not make use of facial recognition technology, (ii) any artificial intelligence-enabled video game technology, (iii) any anti-malware, anti-virus, calculator, cybersecurity, database, data storage, firewall, Internet domain registration, Internet-web-site loading, networking, robocall-filtering, spam-filtering, spellchecking, spreadsheet, web-caching, web-hosting or similar technology, (iv) any technology that performs tasks exclusively related to an entity&#39;s internal management affairs, including, but not limited to, ordering office supplies or processing payments, (v) any system that classifies incoming documents into categories, is used to detect duplicate applications among a large number of applications or otherwise performs narrow tasks of such a limited nature that performance of such tasks poses a limited risk of algorithmic discrimination, (vi) any technology that merely detects decision-making patterns or deviations from prior decision-making patterns following a previously completed human assessment that such technology is not meant to replace or influence without sufficient human review, including, but not limited to, any technology that analyzes a particular decision-maker&#39;s prior pattern of decisions and flags potential inconsistencies or anomalies, or (vii) any technology that communicates with consumers in natural language for the purpose of providing users with information, making referrals or recommendations and answering questions, and is subject to an acceptable use policy that prohibits generating content that is discriminatory or harmful;</p>\n   <p class=\"indent\">(10) &quot;Integrator&quot; means any person doing business in this state that, with respect to a given high-risk artificial intelligence system, (A) neither develops nor intentionally and substantially modifies the high-risk artificial intelligence system, and (B) integrates the high-risk artificial intelligence system into a product or service such person offers to any other person;</p>\n   <p class=\"indent\">(11) &quot;Intentional and substantial modification&quot; (A) means any deliberate material change made to (i) an artificial intelligence system that was not predetermined by a developer and materially increases the risk of algorithmic discrimination, or (ii) a general-purpose artificial intelligence model that (I) affects compliance of the general-purpose artificial intelligence model, (II) materially changes the purpose of the general-purpose artificial intelligence model, or (III) materially increases the risk of algorithmic discrimination, and (B) does not include any change made to a high-risk artificial intelligence system, or the performance of a high-risk artificial intelligence system, if (i) the high-risk artificial intelligence system continues to learn after such high-risk artificial intelligence system is (I) offered, sold, leased, licensed, given or otherwise made available to a deployer, or (II) deployed, and (ii) such change (I) is made to such high-risk artificial intelligence system as a result of any learning described in subparagraph (B)(i) of this subdivision, (II) was predetermined by the deployer, or the third party contracted by the deployer, when such deployer or third party completed the initial impact assessment of such high-risk artificial intelligence system pursuant to subsection (c) of section 4 of this act, and (III) is included in the technical documentation for such high-risk artificial intelligence system;</p>\n   <p class=\"indent\">(12) &quot;Person&quot; means any individual, association, corporation, limited liability company, partnership, trust or other legal entity;</p>\n   <p class=\"indent\">(13) &quot;Red-teaming&quot; means an adversarial exercise that is conducted to identify the potential adverse behaviors or outcomes of an artificial intelligence system, identify how such behaviors or outcomes occur and stress test the safeguards against such behaviors or outcomes;</p>\n   <p class=\"indent\">(14) &quot;Substantial factor&quot; (A) means a factor that (i) alters the outcome of a consequential decision, and (ii) is generated by an artificial intelligence system, (B) includes, but is not limited to, any use of an artificial intelligence system to generate any content, decision, prediction or recommendation concerning a consumer that is used as a basis to make a consequential decision concerning the consumer, and (C) does not include any output produced by an artificial intelligence system where an individual was involved in the data processing that produced such output and such individual (i) meaningfully considered such data as part of such data processing, and (ii) had the authority to change or influence the output produced by such data processing;</p>\n   <p class=\"indent\">(15) &quot;Synthetic digital content&quot; means any digital content, including, but not limited to, any audio, image, text or video, that is produced or manipulated by an artificial intelligence system, including, but not limited to, a general-purpose artificial intelligence model; and</p>\n   <p class=\"indent\">(16) &quot;Trade secret&quot; has the same meaning as provided in section 35-51 of the general statutes.</p>\n   <p class=\"indent\">Sec. 2. (NEW) (Effective October 1, 2025) (a) Beginning on October 1, 2026, a developer of a high-risk artificial intelligence system shall use reasonable care to protect consumers from any known or reasonably foreseeable risks of algorithmic discrimination arising from the intended and contracted uses of the high-risk artificial intelligence system. In any enforcement action brought on or after said date by the Attorney General pursuant to section 10 of this act, there shall be a rebuttable presumption that a developer used reasonable care as required under this subsection if the developer complied with the provisions of this section or, if the developer enters into a contract with an integrator as set forth in subsection (b) of section 3 of this act, the developer and integrator complied with the provisions of this section and section 3 of this act.</p>\n   <p class=\"indent\">(b) Except as provided in subsection (c) of section 3 of this act, a developer of a high-risk artificial intelligence system shall, beginning on October 1, 2026, make available to each deployer, or other developer, of the high-risk artificial intelligence system:</p>\n   <p class=\"indent\">(1) A general statement describing the intended uses, and the known harmful or inappropriate uses, of such high-risk artificial intelligence system;</p>\n   <p class=\"indent\">(2) (A) Documentation disclosing (i) high-level summaries of the type of data used to train such high-risk artificial intelligence system, (ii) the known or reasonably foreseeable limitations of such high-risk artificial intelligence system, including, but not limited to, the known or reasonably foreseeable risks of algorithmic discrimination arising from the intended uses of such high-risk artificial intelligence system, (iii) the purpose of such high-risk artificial intelligence system, and (iv) the intended benefits and uses of such high-risk artificial intelligence system, and (B) any additional documentation that is reasonably necessary to assist such deployer or other developer to understand the outputs, and monitor the performance, of such high-risk artificial intelligence system to enable such deployer or other developer to comply with the provisions of sections 1 to 10, inclusive, of this act; and</p>\n   <p class=\"indent\">(3) Documentation describing (A) how such high-risk artificial intelligence system was evaluated for performance, and mitigation of algorithmic discrimination, before such high-risk artificial intelligence system was offered, sold, leased, licensed, given or otherwise made available to such deployer, (B) the data governance measures used to cover the training datasets and the measures used to examine the suitability of data sources, possible biases and appropriate mitigation, (C) the intended outputs of such high-risk artificial intelligence system, (D) the measures the developer has taken to mitigate any known or reasonably foreseeable risks of algorithmic discrimination that may arise from deployment of such high-risk artificial intelligence system, and (E) how such high-risk artificial intelligence system is intended to be used, based on known or reasonably foreseeable harmful or inappropriate applications, and be monitored by an individual when such high-risk artificial intelligence system is used to make, or as a substantial factor in making, a consequential decision.</p>\n   <p class=\"indent\">(c) (1) Except as provided in subsection (c) of section 3 of this act, any developer that, on or after October 1, 2026, offers, sells, leases, licenses, gives or otherwise makes available to a deployer or another developer a high-risk artificial intelligence system shall, to the extent feasible, make available to the deployers and other developers of such high-risk artificial intelligence system the documentation and information necessary for a deployer, or the third party contracted by a deployer, to complete an impact assessment pursuant to subsection (c) of section 4 of this act. The developer shall make such documentation and information available through artifacts such as system cards or other impact assessments.</p>\n   <p class=\"indent\">(2) A developer that also serves as a deployer for any high-risk artificial intelligence system shall not be required to generate the documentation required by this section unless such high-risk artificial intelligence system is provided to another person that serves as a deployer for such high-risk artificial intelligence system.</p>\n   <p class=\"indent\">(d) (1) Beginning on October 1, 2026, each developer shall make available, in a manner that is clear and readily available on such developer&#39;s Internet web site or in a public use case inventory, a statement summarizing:</p>\n   <p class=\"indent\">(A) The types of high-risk artificial intelligence systems that such developer (i) has developed or intentionally and substantially modified, and (ii) currently makes available to a deployer or another developer; and</p>\n   <p class=\"indent\">(B) How such developer manages any known or reasonably foreseeable risks of algorithmic discrimination that may arise from the intended uses of the types of high-risk artificial intelligence systems described in subparagraph (A) of this subdivision.</p>\n   <p class=\"indent\">(2) Each developer shall update the statement made available pursuant to subdivision (1) of this subsection (A) as necessary to ensure that such statement remains accurate, and (B) not later than ninety days after the developer intentionally and substantially modifies any high-risk artificial intelligence system described in subparagraph (A) of subdivision (1) of this subsection.</p>\n   <p class=\"indent\">(3) Where multiple developers contribute to the development of a high-risk artificial intelligence system, each developer shall be subject to the obligations applicable to developers under sections 1 to 10, inclusive, of this act solely with respect to the activities the developer performed in contributing to the development of such high-risk artificial intelligence system.</p>\n   <p class=\"indent\">(e) Beginning on October 1, 2026, a developer of a high-risk artificial intelligence system shall disclose to the Attorney General, in a form and manner prescribed by the Attorney General, and to all known deployers or other developers of the high-risk artificial intelligence system, any previously disclosed known or reasonably foreseeable risks of algorithmic discrimination arising from the intended uses of such high-risk artificial intelligence system. The developer shall make such disclosures without unreasonable delay but in no event later than ninety days after the date on which:</p>\n   <p class=\"indent\">(1) The developer discovers, through the developer&#39;s ongoing testing and analysis, that the high-risk artificial intelligence system has (A) been deployed, and (B) caused, or is reasonably likely to have caused, algorithmic discrimination to at least one thousand consumers; or</p>\n   <p class=\"indent\">(2) The developer receives, from a deployer of the high-risk artificial intelligence system, a credible report disclosing that such high-risk artificial intelligence system has (A) been deployed, and (B) caused algorithmic discrimination to at least one thousand consumers.</p>\n   <p class=\"indent\">(f) The provisions of subsections (b) to (e), inclusive, of this section shall not be construed to require a developer to disclose any information (1) that is a trade secret or otherwise protected from disclosure under state or federal law, or (2) the disclosure of which would present a security risk to the developer.</p>\n   <p class=\"indent\">(g) Notwithstanding the provisions of subsections (a) to (f), inclusive, of this section, (1) any documentation a developer completes for the purpose of complying with another applicable law or regulation shall be deemed to satisfy the requirements established in this section if such documentation is reasonably similar in scope and effect to the documentation the developer would otherwise be required to complete pursuant to this section, and (2) a developer may contract with a third party to fulfill the developer&#39;s duties under this section.</p>\n   <p class=\"indent\">(h) Beginning on October 1, 2026, the Attorney General may require that a developer disclose to the Attorney General, as part of an investigation conducted by the Attorney General regarding a suspected violation of any provision of sections 1 to 10, inclusive, of this act and in a form and manner prescribed by the Attorney General, the general statement or documentation described in subsection (b) of this section. The Attorney General may evaluate such general statement or documentation to ensure compliance with the provisions of this section. In disclosing such general statement or documentation to the Attorney General pursuant to this subsection, the developer may designate such general statement or documentation as including any information that is exempt from disclosure under subsection (f) of this section or the Freedom of Information Act, as defined in section 1-200 of the general statutes. To the extent such general statement or documentation includes such information, such general statement or documentation shall be exempt from disclosure under subsection (f) of this section or said act. To the extent any information contained in such general statement or documentation is subject to the attorney-client privilege or work product protection, such disclosure shall not constitute a waiver of such privilege or protection.</p>\n   <p class=\"indent\">Sec. 3. (NEW) (Effective October 1, 2025) (a) Beginning on October 1, 2026, if an integrator integrates a high-risk artificial intelligence system into a product or service the integrator offers to any other person, such integrator shall use reasonable care to protect consumers from any known or reasonably foreseeable risks of algorithmic discrimination arising from the intended and contracted uses of such integrated high-risk artificial intelligence system. In any enforcement action brought on or after said date by the Attorney General pursuant to section 10 of this act, there shall be a rebuttable presumption that the integrator used reasonable care as required under this subsection if the integrator complied with the provisions of this section.</p>\n   <p class=\"indent\">(b) Beginning on October 1, 2026, no integrator shall integrate a high-risk artificial intelligence system into a product or service the integrator offers to any other person unless the integrator has entered into a contract with the developer of the high-risk artificial intelligence system. The contract shall be binding and clearly set forth the duties of the developer and integrator with respect to the integrated high-risk artificial intelligence system, including, but not limited to, whether the developer or integrator shall be responsible for performing the developer&#39;s duties under subsections (b) and (c) of section 2 of this act.</p>\n   <p class=\"indent\">(c) The provisions of subsections (b) and (c) of section 2 of this act shall not apply to a developer of an integrated high-risk artificial intelligence system if, at all times while the integrated high-risk artificial intelligence system is integrated into a product or service an integrator offers to any other person, the developer has entered into a contract with the integrator in which such integrator has agreed to assume the developer&#39;s duties under subsections (b) and (c) of section 2 of this act.</p>\n   <p class=\"indent\">(d) (1) Beginning on October 1, 2026, each integrator shall make available, in a manner that is clear and readily available on such integrator&#39;s Internet web site or in a public use case inventory, a statement summarizing:</p>\n   <p class=\"indent\">(A) The types of high-risk artificial intelligence systems that such integrator has integrated into products or services such integrator currently offers to any other person; and</p>\n   <p class=\"indent\">(B) How such integrator manages any known or reasonably foreseeable risks of algorithmic discrimination that may arise from the types of high-risk artificial intelligence systems described in subparagraph (A) of this subdivision.</p>\n   <p class=\"indent\">(2) Each integrator shall update the statement made available pursuant to subdivision (1) of this subsection (A) as necessary to ensure that such statement remains accurate, and (B) not later than ninety days after an intentional and substantial modification is made to any high-risk artificial intelligence system described in subparagraph (A) of subdivision (1) of this subsection.</p>\n   <p class=\"indent\">(e) The provisions of subsections (b) to (d), inclusive, of this section shall not be construed to require a developer or integrator to disclose any information (1) that is a trade secret or otherwise protected from disclosure under state or federal law, or (2) the disclosure of which would present a security risk to the developer or integrator.</p>\n   <p class=\"indent\">(f) Beginning on October 1, 2026, the Attorney General may require that an integrator which has assumed a developer&#39;s duties under subsection (c) of section 2 of this act disclose to the Attorney General, as part of an investigation conducted by the Attorney General regarding a suspected violation of any provision of sections 1 to 10, inclusive, of this act and in a form and manner prescribed by the Attorney General, the general statement or documentation described in said subsection. The Attorney General may evaluate such general statement or documentation to ensure compliance with the provisions of this section and section 2 of this act. In disclosing such general statement or documentation to the Attorney General pursuant to this subsection, the integrator may designate such general statement or documentation as including any information that is exempt from disclosure under subsection (e) of this section or the Freedom of Information Act, as defined in section 1-200 of the general statutes. To the extent such general statement or documentation includes such information, such general statement or documentation shall be exempt from disclosure under subsection (e) of this section or said act. To the extent any information contained in such general statement or documentation is subject to the attorney-client privilege or work product protection, such disclosure shall not constitute a waiver of such privilege or protection.</p>\n   <p class=\"indent\">Sec. 4. (NEW) (Effective October 1, 2025) (a) Beginning on October 1, 2026, each deployer of a high-risk artificial intelligence system shall use reasonable care to protect consumers from any known or reasonably foreseeable risks of algorithmic discrimination. In any enforcement action brought on or after said date by the Attorney General pursuant to section 10 of this act, there shall be a rebuttable presumption that a deployer of a high-risk artificial intelligence system used reasonable care as required under this subsection if the deployer complied with the provisions of this section.</p>\n   <p class=\"indent\">(b) (1) Beginning on October 1, 2026, and except as provided in subsection (g) of this section, each deployer of a high-risk artificial intelligence system shall implement and maintain a risk management policy and program to govern such deployer&#39;s deployment of the high-risk artificial intelligence system. The risk management policy and program shall specify and incorporate the principles, processes and personnel that the deployer shall use to identify, document and mitigate any known or reasonably foreseeable risks of algorithmic discrimination. The risk management policy shall be the product of an iterative process, the risk management program shall be an iterative process and both the risk management policy and program shall be planned, implemented and regularly and systematically reviewed and updated over the lifecycle of the high-risk artificial intelligence system. Each risk management policy and program implemented and maintained pursuant to this subsection shall be reasonable, considering:</p>\n   <p class=\"indent\">(A) The guidance and standards set forth in the latest version of (i) the &quot;Artificial Intelligence Risk Management Framework&quot; published by the National Institute of Standards and Technology, (ii) ISO or IEC 42001 of the International Organization for Standardization, or (iii) a nationally or internationally recognized risk management framework for artificial intelligence systems, other than the guidance and standards specified in subparagraphs (A)(i) and (A)(ii) of this subdivision, that imposes requirements that are substantially equivalent to, and at least as stringent as, the requirements set forth in this section for risk management policies and programs;</p>\n   <p class=\"indent\">(B) The size and complexity of the deployer;</p>\n   <p class=\"indent\">(C) The nature and scope of the high-risk artificial intelligence systems deployed by the deployer, including, but not limited to, the intended uses of such high-risk artificial intelligence systems; and</p>\n   <p class=\"indent\">(D) The sensitivity and volume of data processed in connection with the high-risk artificial intelligence systems deployed by the deployer.</p>\n   <p class=\"indent\">(2) A risk management policy and program implemented and maintained pursuant to subdivision (1) of this subsection may cover multiple high-risk artificial intelligence systems deployed by the deployer.</p>\n   <p class=\"indent\">(c) (1) Except as provided in subdivisions (3) and (4) of this subsection and subsection (g) of this section:</p>\n   <p class=\"indent\">(A) A deployer that deploys a high-risk artificial intelligence system on or after October 1, 2026, or a third party contracted by the deployer, shall complete an impact assessment of the high-risk artificial intelligence system; and</p>\n   <p class=\"indent\">(B) Beginning on October 1, 2026, a deployer, or a third party contracted by the deployer, shall complete an impact assessment of a deployed high-risk artificial intelligence system (i) at least annually, and (ii) not later than ninety days after an intentional and substantial modification to such high-risk artificial intelligence system is made available.</p>\n   <p class=\"indent\">(2) (A) Each impact assessment completed pursuant to this subsection shall include, at a minimum and to the extent reasonably known by, or available to, the deployer:</p>\n   <p class=\"indent\">(i) A statement by the deployer disclosing the purpose, intended use cases and deployment context of, and benefits afforded by, the high-risk artificial intelligence system;</p>\n   <p class=\"indent\">(ii) An analysis of whether the deployment of the high-risk artificial intelligence system poses any known or reasonably foreseeable risks of algorithmic discrimination and, if so, the nature of such algorithmic discrimination and the steps that have been taken to mitigate such risks;</p>\n   <p class=\"indent\">(iii) A description of (I) the categories of data the high-risk artificial intelligence system processes as inputs, and (II) the outputs such high-risk artificial intelligence system produces;</p>\n   <p class=\"indent\">(iv) If the deployer used data to customize the high-risk artificial intelligence system, an overview of the categories of data the deployer used to customize such high-risk artificial intelligence system;</p>\n   <p class=\"indent\">(v) Any metrics used to evaluate the performance and known limitations of the high-risk artificial intelligence system;</p>\n   <p class=\"indent\">(vi) A high-level description of any transparency measures taken concerning the high-risk artificial intelligence system, including, but not limited to, any measures taken to disclose to a consumer that such high-risk artificial intelligence system is in use when such high-risk artificial intelligence system is in use; and</p>\n   <p class=\"indent\">(vii) A high-level description of the post-deployment monitoring and user safeguards provided concerning such high-risk artificial intelligence system, including, but not limited to, the oversight, use and learning process established by the deployer to address issues arising from deployment of such high-risk artificial intelligence system.</p>\n   <p class=\"indent\">(B) In addition to the statement, analysis, descriptions, overview and metrics required under subparagraph (A) of this subdivision, an impact assessment completed pursuant to this subsection following an intentional and substantial modification made to a high-risk artificial intelligence system on or after October 1, 2026, shall include a high-level statement disclosing the extent to which the high-risk artificial intelligence system was used in a manner that was consistent with, or varied from, the developer&#39;s intended uses of such high-risk artificial intelligence system.</p>\n   <p class=\"indent\">(3) A single impact assessment may address a comparable set of high-risk artificial intelligence systems deployed by a deployer.</p>\n   <p class=\"indent\">(4) If a deployer, or a third party contracted by the deployer, completes an impact assessment for the purpose of complying with another applicable law or regulation, such impact assessment shall be deemed to satisfy the requirements established in this subsection if such impact assessment is reasonably similar in scope and effect to the impact assessment that would otherwise be completed pursuant to this subsection.</p>\n   <p class=\"indent\">(5) A deployer shall maintain the most recently completed impact assessment of a high-risk artificial intelligence system as required under this subsection, all records concerning each such impact assessment and all prior impact assessments, if any, for a period of at least three years following the final deployment of the high-risk artificial intelligence system.</p>\n   <p class=\"indent\">(d) Except as provided in subsection (g) of this section, a deployer, or a third party contracted by the deployer, shall review, not later than October 1, 2026, and at least annually thereafter, the deployment of each high-risk artificial intelligence system deployed by the deployer to ensure that such high-risk artificial intelligence system is not causing algorithmic discrimination.</p>\n   <p class=\"indent\">(e) (1) Beginning on October 1, 2026, and before a deployer deploys a high-risk artificial intelligence system to make, or be a substantial factor in making, a consequential decision concerning a consumer, the deployer shall:</p>\n   <p class=\"indent\">(A) Notify the consumer that the deployer has deployed a high-risk artificial intelligence system to make, or be a substantial factor in making, such consequential decision; and</p>\n   <p class=\"indent\">(B) Provide to the consumer (i) a statement disclosing (I) the purpose of such high-risk artificial intelligence system, and (II) the nature of such consequential decision, (ii) if applicable, information concerning the consumer&#39;s right, under subparagraph (C) of subdivision (5) of subsection (a) of section 42-518 of the general statutes, to opt-out of the processing of the consumer&#39;s personal data for the purposes set forth in said subparagraph, (iii) contact information for such deployer, (iv) a description, in plain language, of such high-risk artificial intelligence system, and (v) instructions on how to access the statement made available pursuant to subdivision (1) of subsection (f) of this section.</p>\n   <p class=\"indent\">(2) Beginning on October 1, 2026, a deployer that has deployed a high-risk artificial intelligence system to make, or as a substantial factor in making, a consequential decision concerning a consumer shall, if such consequential decision is adverse to the consumer, provide to such consumer:</p>\n   <p class=\"indent\">(A) A high-level statement disclosing the principal reason or reasons for such adverse consequential decision, including, but not limited to, (i) the degree to which, and manner in which, the high-risk artificial intelligence system contributed to such adverse consequential decision, (ii) the type of data that were processed by such high-risk artificial intelligence system in making such adverse consequential decision, and (iii) the source of the data described in subparagraph (A)(ii) of this subdivision;</p>\n   <p class=\"indent\">(B) An opportunity to (i) examine the personal data that the high-risk artificial intelligence system processed in making, or as a substantial factor in making, such adverse consequential decision, and (ii) correct any incorrect personal data described in subparagraph (B)(i) of this subdivision; and</p>\n   <p class=\"indent\">(C) (i) Except as provided in subparagraph (C)(ii) of this subdivision, an opportunity to appeal such adverse consequential decision if such adverse consequential decision is based upon inaccurate personal data, taking into account both the nature of such personal data and the purpose for which such personal data was processed. Such appeal shall, if technically feasible, allow for human review.</p>\n   <p class=\"indent\">(ii) No deployer shall be required to provide an opportunity to appeal pursuant to subparagraph (C)(i) of this subdivision in any instance in which providing such opportunity to appeal is not in the best interest of the consumer, including, but not limited to, in any instance in which any delay might pose a risk to the life or safety of the consumer.</p>\n   <p class=\"indent\">(3) The deployer shall provide the notice, statements, information, description and instructions required under subdivisions (1) and (2) of this subsection:</p>\n   <p class=\"indent\">(A) Directly to the consumer;</p>\n   <p class=\"indent\">(B) In plain language;</p>\n   <p class=\"indent\">(C) In all languages in which such deployer, in the ordinary course of such deployer&#39;s business, provides contracts, disclaimers, sale announcements and other information to consumers; and</p>\n   <p class=\"indent\">(D) In a format that is accessible to consumers with disabilities.</p>\n   <p class=\"indent\">(f) (1) Beginning on October 1, 2026, and except as provided in subsection (g) of this section, each deployer shall make available, in a manner that is clear and readily available on such deployer&#39;s Internet web site, a statement summarizing:</p>\n   <p class=\"indent\">(A) The types of high-risk artificial intelligence systems that are currently deployed by such deployer;</p>\n   <p class=\"indent\">(B) How such deployer manages any known or reasonably foreseeable risks of algorithmic discrimination that may arise from deployment of each high-risk artificial intelligence system described in subparagraph (A) of this subdivision;</p>\n   <p class=\"indent\">(C) In detail, the nature, source and extent of the information collected and used by such deployer; and</p>\n   <p class=\"indent\">(D) How the consumer may exercise rights under section 42-518 of the general statutes by the secure and reliable means established and described pursuant to subsection (b) of section 42-518 of the general statutes.</p>\n   <p class=\"indent\">(2) Each deployer shall periodically update the statement made available pursuant to subdivision (1) of this subsection.</p>\n   <p class=\"indent\">(g) The provisions of subsections (b) to (d), inclusive, of this section and subsection (f) of this section shall not apply to a deployer if, at the time the deployer deploys a high-risk artificial intelligence system and at all times while the high-risk artificial intelligence system is deployed:</p>\n   <p class=\"indent\">(1) The deployer (A) has entered into a contract with the developer in which the developer has agreed to assume the deployer&#39;s duties under subsections (b) to (d), inclusive, of this section and subsection (f) of this section, and (B) does not exclusively use such deployer&#39;s own data to train such high-risk artificial intelligence system;</p>\n   <p class=\"indent\">(2) Such high-risk artificial intelligence system (A) is used for the intended uses that are disclosed to such deployer as set forth in subparagraph (A)(iv) of subdivision (2) of subsection (b) of section 2 of this act, and (B) continues learning based on a broad range of data sources and not solely based on the deployer&#39;s own data; and</p>\n   <p class=\"indent\">(3) Such deployer makes available to consumers any impact assessment that (A) the developer of such high-risk artificial intelligence system has completed and provided to such deployer, and (B) includes information that is substantially similar to the information included in the statement, analysis, descriptions, overview and metrics required under subparagraph (A) of subdivision (2) of subsection (c) of this section.</p>\n   <p class=\"indent\">(h) If a deployer deploys a high-risk artificial intelligence system on or after October 1, 2026, and subsequently discovers that the high-risk artificial intelligence system has caused algorithmic discrimination to at least one thousand consumers, the deployer shall send to the Attorney General, in a form and manner prescribed by the Attorney General, a notice disclosing such discovery. The deployer shall send such notice to the Attorney General without unreasonable delay but in no event later than ninety days after the date on which the deployer discovered such algorithmic discrimination.</p>\n   <p class=\"indent\">(i) Nothing in subsections (b) to (h), inclusive, of this section shall be construed to require a deployer to disclose any information that is a trade secret or otherwise protected from disclosure under state or federal law. If a deployer withholds any information from a consumer under this subsection, the deployer shall send notice to the consumer disclosing (1) that the deployer is withholding such information from such consumer, and (2) the basis for the deployer&#39;s decision to withhold such information from such consumer.</p>\n   <p class=\"indent\">(j) Beginning on October 1, 2026, the Attorney General may require that a deployer, or a third party contracted by the deployer as set forth in subsection (c) of this section, as applicable, disclose to the Attorney General, as part of an investigation conducted by the Attorney General regarding a suspected violation of any provision of sections 1 to 10, inclusive, of this act, not later than ninety days after a request by the Attorney General and in a form and manner prescribed by the Attorney General, the risk management policy implemented pursuant to subsection (b) of this section, impact assessment completed pursuant to subsection (c) of this section or records maintained pursuant to subdivision (5) of subsection (c) of this section. The Attorney General may evaluate such risk management policy, impact assessment or records to ensure compliance with the provisions of this section. In disclosing such risk management policy, impact assessment or records to the Attorney General pursuant to this subsection, the deployer or third-party contractor, as applicable, may designate such risk management policy, impact assessment or records as including any information that is exempt from disclosure under subsection (i) of this section or the Freedom of Information Act, as defined in section 1-200 of the general statutes. To the extent such risk management policy, impact assessment or records include such information, such risk management policy, impact assessment or records shall be exempt from disclosure under subsection (i) of this section or said act. To the extent any information contained in such risk management policy, impact assessment or record is subject to the attorney-client privilege or work product protection, such disclosure shall not constitute a waiver of such privilege or protection.</p>\n   <p class=\"indent\">Sec. 5. (NEW) (Effective October 1, 2025) (a) Beginning on October 1, 2026, each developer of a general-purpose artificial intelligence model that is capable of being used by a high-risk artificial intelligence system shall, to the extent feasible and except as provided in subsection (b) of this section, make available to:</p>\n   <p class=\"indent\">(1) Each deployer of such general-purpose artificial intelligence model, through artifacts such as system cards or other impact assessments, the documentation and information necessary for such deployer, or a third party contracted by such deployer, to complete an impact assessment pursuant to subsection (c) of section 4 of this act; and</p>\n   <p class=\"indent\">(2) Each deployer or other developer of such general-purpose artificial intelligence model any additional documentation that is reasonably necessary to assist such deployer or other developer to understand the outputs, and monitor the performance, of the general-purpose artificial intelligence model to enable such deployer or other developer to comply with the provisions of sections 1 to 10, inclusive, of this act.</p>\n   <p class=\"indent\">(b) (1) The provisions of subsection (a) of this section shall not apply to a developer that develops, or intentionally and substantially modifies, a general-purpose artificial intelligence model on or after October 1, 2026, if:</p>\n   <p class=\"indent\">(A) (i) The developer releases such general-purpose artificial intelligence model under a free and open-source license that allows for (I) access to, and modification, distribution and usage of, such general-purpose artificial intelligence model, and (II) the parameters of such general-purpose artificial intelligence model to be made publicly available as set forth in subparagraph (A)(ii) of this subdivision; and</p>\n   <p class=\"indent\">(ii) Unless such general-purpose artificial intelligence model is deployed as a high-risk artificial intelligence system, the parameters of such general-purpose artificial intelligence model, including, but not limited to, the weights and information concerning the model architecture and model usage for such general-purpose artificial intelligence model, are made publicly available; or</p>\n   <p class=\"indent\">(B) The general-purpose artificial intelligence model is (i) not offered for sale in the market, (ii) not intended to interact with consumers, and (iii) solely utilized (I) for an entity&#39;s internal purposes, or (II) under an agreement between multiple entities for such entities&#39; internal purposes.</p>\n   <p class=\"indent\">(2) The provisions of this section shall not apply to a developer that develops, or intentionally and substantially modifies, a general-purpose artificial intelligence model on or after October 1, 2026, if such general-purpose artificial intelligence model performs tasks exclusively related to an entity&#39;s internal management affairs, including, but not limited to, ordering office supplies or processing payments.</p>\n   <p class=\"indent\">(3) A developer that takes any action under an exemption established in subdivision (1) or (2) of this subsection shall bear the burden of demonstrating that such action qualifies for such exemption.</p>\n   <p class=\"indent\">(4) A developer that is exempt under subparagraph (B) of subdivision (1) of this subsection shall establish and maintain an artificial intelligence risk management framework, which framework shall (A) be the product of an iterative process and ongoing efforts, and (B) include, at a minimum, (i) an internal governance function, (ii) a map function that shall establish the context to frame risks, (iii) a risk management function, and (iv) a function to measure identified risks by assessing, analyzing and tracking such risks.</p>\n   <p class=\"indent\">(c) Nothing in subsection (a) of this section shall be construed to require a developer to disclose any information that is a trade secret or otherwise protected from disclosure under state or federal law.</p>\n   <p class=\"indent\">(d) Beginning on October 1, 2026, the Attorney General may require that a developer disclose to the Attorney General, as part of an investigation conducted by the Attorney General regarding a suspected violation of any provision of sections 1 to 10, inclusive, of this act, not later than ninety days after a request by the Attorney General and in a form and manner prescribed by the Attorney General, any documentation maintained pursuant to this section. The Attorney General may evaluate such documentation to ensure compliance with the provisions of this section. In disclosing any documentation to the Attorney General pursuant to this subsection, the developer may designate such documentation as including any information that is exempt from disclosure under subsection (c) of this section or the Freedom of Information Act, as defined in section 1-200 of the general statutes. To the extent such documentation includes such information, such documentation shall be exempt from disclosure under subsection (c) of this section or said act. To the extent any information contained in such documentation is subject to the attorney-client privilege or work product protection, such disclosure shall not constitute a waiver of such privilege or protection.</p>\n   <p class=\"indent\">Sec. 6. (NEW) (Effective October 1, 2025) (a) Beginning on October 1, 2026, and except as provided in subsection (b) of this section, each person doing business in this state, including, but not limited to, each deployer that deploys, offers, sells, leases, licenses, gives or otherwise makes available, as applicable, any artificial intelligence system that is intended to interact with consumers shall ensure that it is disclosed to each consumer who interacts with such artificial intelligence system that such consumer is interacting with an artificial intelligence system.</p>\n   <p class=\"indent\">(b) No disclosure shall be required under subsection (a) of this section under circumstances in which a reasonable person would deem it obvious that such person is interacting with an artificial intelligence system.</p>\n   <p class=\"indent\">Sec. 7. (NEW) (Effective October 1, 2025) (a) Beginning on October 1, 2026, and except as provided in subsections (b) and (c) of this section, the developer of an artificial intelligence system, including, but not limited to, a general-purpose artificial intelligence model, that is capable of generating synthetic digital content shall:</p>\n   <p class=\"indent\">(1) Ensure that the outputs of such artificial intelligence system are marked and detectable as synthetic digital content, and that such outputs are so marked and detectable (A) not later than the time that consumers who did not create such outputs first interact with, or are exposed to, such outputs, and (B) in a manner that (i) is detectable by consumers, and (ii) complies with any applicable accessibility requirements; and</p>\n   <p class=\"indent\">(2) As far as technically feasible and in a manner that is consistent with any nationally or internationally recognized technical standards, ensure that such developer&#39;s technical solutions are effective, interoperable, robust and reliable, considering (A) the specificities and limitations of different types of synthetic digital content, (B) the implementation costs, and (C) the generally acknowledged state of the art.</p>\n   <p class=\"indent\">(b) If the synthetic digital content described in subsection (a) of this section is in an audio, image or video format, and such synthetic digital content forms part of an evidently artistic, creative, satirical, fictional analogous work or program, the disclosure required under said subsection shall be limited to a disclosure that does not hinder the display or enjoyment of such work or program.</p>\n   <p class=\"indent\">(c) The provisions of subsection (a) of this section shall not apply:</p>\n   <p class=\"indent\">(1) To any synthetic digital content that (A) consists exclusively of text, (B) is published to inform the public on any matter of public interest, or (C) is unlikely to mislead a reasonable person consuming such synthetic digital content; or</p>\n   <p class=\"indent\">(2) To the extent that any artificial intelligence system described in subsection (a) of this section (A) performs an assistive function for standard editing, (B) does not substantially alter the input data provided by the developer or the semantics thereof, or (C) is used to detect, prevent, investigate or prosecute any crime where authorized by law.</p>\n   <p class=\"indent\">Sec. 8. (NEW) (Effective October 1, 2025) (a) Nothing in sections 1 to 10, inclusive, of this act shall be construed to restrict a developer&#39;s, integrator&#39;s, deployer&#39;s or other person&#39;s ability to:</p>\n   <p class=\"indent\">(1) Comply with any federal, state or municipal law, ordinance or regulation;</p>\n   <p class=\"indent\">(2) Comply with a civil, criminal or regulatory inquiry, investigation, subpoena or summons by a federal, state, municipal or other governmental authority;</p>\n   <p class=\"indent\">(3) Cooperate with a law enforcement agency concerning conduct or activity that the developer, integrator, deployer or other person reasonably and in good faith believes may violate federal, state or municipal law;</p>\n   <p class=\"indent\">(4) Investigate, establish, exercise, prepare for or defend a legal claim;</p>\n   <p class=\"indent\">(5) Take immediate steps to protect an interest that is essential for the life or physical safety of a consumer or another individual;</p>\n   <p class=\"indent\">(6) (A) By any means other than facial recognition technology, prevent, detect, protect against or respond to (i) a security incident, (ii) a malicious or deceptive activity, or (iii) identity theft, fraud, harassment or any other illegal activity, (B) investigate, report or prosecute the persons responsible for any action described in subparagraph (A) of this subdivision, or (C) preserve the integrity or security of systems;</p>\n   <p class=\"indent\">(7) Engage in public or peer-reviewed scientific or statistical research in the public interest that (A) adheres to all other applicable ethics and privacy laws, and (B) is conducted in accordance with (i) 45 CFR Part 46, as amended from time to time, or (ii) relevant requirements established by the federal Food and Drug Administration;</p>\n   <p class=\"indent\">(8) Conduct research, testing, development and integration activities regarding an artificial intelligence system or model, other than testing conducted under real world conditions, before such artificial intelligence system or model is placed on the market, deployed or put into service, as applicable;</p>\n   <p class=\"indent\">(9) Effectuate a product recall;</p>\n   <p class=\"indent\">(10) Identify and repair technical errors that impair existing or intended functionality; or</p>\n   <p class=\"indent\">(11) Assist another developer, integrator, deployer or person with any of the obligations imposed under sections 1 to 10, inclusive, of this act.</p>\n   <p class=\"indent\">(b) The obligations imposed on developers, integrators, deployers or other persons under sections 1 to 10, inclusive, of this act shall not apply where compliance by the developer, integrator, deployer or other person with said sections would violate an evidentiary privilege under the laws of this state.</p>\n   <p class=\"indent\">(c) Nothing in sections 1 to 10, inclusive, of this act shall be construed to impose any obligation on a developer, integrator, deployer or other person that adversely affects the rights or freedoms of any person, including, but not limited to, the rights of any person (1) to freedom of speech or freedom of the press guaranteed in (A) the First Amendment to the United States Constitution, and (B) section 5 of article first of the Constitution of the state, or (2) under section 52-146t of the general statutes.</p>\n   <p class=\"indent\">(d) Nothing in sections 1 to 10, inclusive, of this act shall be construed to apply to any developer, integrator, deployer or other person:</p>\n   <p class=\"indent\">(1) Insofar as such developer, integrator, deployer or other person develops, integrates, deploys, puts into service or intentionally and substantially modifies, as applicable, a high-risk artificial intelligence system (A) that has been approved, authorized, certified, cleared, developed, integrated or granted by (i) a federal agency, such as the federal Food and Drug Administration or the Federal Aviation Administration, acting within the scope of such federal agency&#39;s authority, or (ii) a regulated entity subject to supervision and regulation by the Federal Housing Finance Agency, or (B) in compliance with standards that are (i) established by (I) any federal agency, including, but not limited to, the federal Office of the National Coordinator for Health Information Technology, or (II) a regulated entity subject to supervision and regulation by the Federal Housing Finance Agency, and (ii) substantially equivalent to, and at least as stringent as, the standards established in sections 1 to 10, inclusive, of this act;</p>\n   <p class=\"indent\">(2) Conducting research to support an application (A) for approval or certification from any federal agency, including, but not limited to, the Federal Aviation Administration, the Federal Communications Commission or the federal Food and Drug Administration, or (B) that is otherwise subject to review by any federal agency;</p>\n   <p class=\"indent\">(3) Performing work under, or in connection with, a contract with the United States Department of Commerce, the United States Department of Defense or the National Aeronautics and Space Administration, unless such developer, integrator, deployer or other person is performing such work on a high-risk artificial intelligence system that is used to make, or as a substantial factor in making, a decision concerning employment or housing;</p>\n   <p class=\"indent\">(4) That facilitates or engages in the provision of telehealth services or is a covered entity within the meaning of the Health Insurance Portability and Accountability Act of 1996, P.L. 104-191, and the regulations promulgated thereunder, as both may be amended from time to time, and providing health care recommendations that (A) are generated by an artificial intelligence system, (B) require a health care provider to take action to implement such recommendations, and (C) are not considered to be high risk; or</p>\n   <p class=\"indent\">(5) Who is an active participant in the artificial intelligence regulatory sandbox program designed, established and administered under section 12 of this act, and is engaged in activities within the scope of such program in accordance with the provisions of section 12 of this act.</p>\n   <p class=\"indent\">(e) Nothing in sections 1 to 10, inclusive, of this act shall be construed to apply to any artificial intelligence system that is acquired by or for the federal government or any federal agency or department, including, but not limited to, the United States Department of Commerce, the United States Department of Defense or the National Aeronautics and Space Administration, unless such artificial intelligence system is a high-risk artificial intelligence system that is used to make, or as a substantial factor in making, a decision concerning employment or housing.</p>\n   <p class=\"indent\">(f) Any insurer, as defined in section 38a-1 of the general statutes, fraternal benefit society, as described in section 38a-595 of the general statutes, or health carrier, as defined in section 38a-591a of the general statutes, shall be deemed to be in full compliance with the provisions of sections 1 to 10, inclusive, of this act if such insurer, fraternal benefit society or health carrier has implemented and maintains a written artificial intelligence systems program in accordance with all requirements established by the Insurance Commissioner.</p>\n   <p class=\"indent\">(g) (1) Any bank, out-of-state bank, Connecticut credit union, federal credit union, mortgage lender or out-of-state credit union, or any affiliate, subsidiary or service provider thereof, shall be deemed to be in full compliance with the provisions of sections 1 to 10, inclusive, of this act if such bank, out-of-state bank, Connecticut credit union, federal credit union, mortgage lender, out-of-state credit union, affiliate, subsidiary or service provider is subject to examination by any state or federal prudential regulator under any published guidance or regulations that apply to the use of high-risk artificial intelligence systems and such guidance or regulations (A) impose requirements that are substantially equivalent to, and at least as stringent as, the requirements set forth in sections 1 to 10, inclusive, of this act, and (B) at a minimum, require such bank, out-of-state bank, Connecticut credit union, federal credit union, mortgage lender, out-of-state credit union, affiliate, subsidiary or service provider to (i) regularly audit such bank&#39;s, out-of-state bank&#39;s, Connecticut credit union&#39;s, federal credit union&#39;s, mortgage lender&#39;s, out-of-state credit union&#39;s, affiliate&#39;s, subsidiary&#39;s or service provider&#39;s use of high-risk artificial intelligence systems for compliance with state and federal anti-discrimination laws and regulations applicable to such bank, out-of-state bank, Connecticut credit union, federal credit union, mortgage lender, out-of-state credit union, affiliate, subsidiary or service provider, and (ii) mitigate any algorithmic discrimination caused by the use of a high-risk artificial intelligence system or any risk of algorithmic discrimination that is reasonably foreseeable as a result of the use of a high-risk artificial intelligence system.</p>\n   <p class=\"indent\">(2) For the purposes of this subsection, (A) &quot;affiliate&quot;, &quot;bank&quot;, &quot;Connecticut credit union&quot;, &quot;federal credit union&quot;, &quot;out-of-state bank&quot;, &quot;out-of-state credit union&quot; and &quot;subsidiary&quot; have the same meanings as provided in section 36a-2 of the general statutes, and (B) &quot;mortgage lender&quot; has the same meaning as provided in section 36a-705 of the general statutes.</p>\n   <p class=\"indent\">(h) If a developer, integrator, deployer or other person engages in any action pursuant to an exemption set forth in subsections (a) to (g), inclusive, of this section, the developer, integrator, deployer or other person bears the burden of demonstrating that such action qualifies for such exemption.</p>\n   <p class=\"indent\">Sec. 9. (NEW) (Effective October 1, 2025) Not later than January 1, 2026, the Attorney General shall, within available appropriations, develop and implement a comprehensive public education, outreach and assistance program for developers, integrators and deployers that are small businesses, as defined in section 4-168a of the general statutes. Such program shall, at a minimum, disseminate educational materials concerning (1) the requirements established in sections 1 to 10, inclusive, of this act, including, but not limited to, the duties of developers, integrators and deployers under sections 1 to 10, inclusive, of this act, (2) the impact assessments required under subsection (c) of section 4 of this act, (3) the Attorney General&#39;s powers under sections 1 to 10, inclusive, of this act, and (4) any other matters the Attorney General, in the Attorney General&#39;s discretion, deems relevant for the purposes of such program.</p>\n   <p class=\"indent\">Sec. 10. (NEW) (Effective October 1, 2025) (a) The Attorney General shall have exclusive authority to enforce the provisions of sections 1 to 9, inclusive, of this act.</p>\n   <p class=\"indent\">(b) Except as provided in subsection (f) of this section, during the period beginning on October 1, 2026, and ending on September 30, 2027, the Attorney General shall, prior to initiating any action for a violation of any provision of sections 1 to 9, inclusive, of this act, issue a notice of violation to the developer, integrator, deployer or other person if the Attorney General determines that it is possible to cure such violation. If the developer, integrator, deployer or other person fails to cure such violation not later than sixty days after receipt of the notice of violation, the Attorney General may bring an action pursuant to this section.</p>\n   <p class=\"indent\">(c) Except as provided in subsection (f) of this section, beginning on October 1, 2027, the Attorney General may, in determining whether to grant a developer, integrator, deployer or other person the opportunity to cure a violation described in subsection (b) of this section, consider: (1) The number of violations; (2) the size and complexity of the developer, integrator, deployer or other person; (3) the nature and extent of the developer&#39;s, integrator&#39;s, deployer&#39;s or other person&#39;s business; (4) the substantial likelihood of injury to the public; (5) the safety of persons or property; and (6) whether such violation was likely caused by human or technical error.</p>\n   <p class=\"indent\">(d) Nothing in sections 1 to 9, inclusive, of this act shall be construed as providing the basis for a private right of action for violations of said sections.</p>\n   <p class=\"indent\">(e) Except as provided in subsections (a) to (d), inclusive, of this section and subsection (f) of this section, a violation of the requirements established in sections 1 to 9, inclusive, of this act shall constitute an unfair trade practice for purposes of section 42-110b of the general statutes and shall be enforced solely by the Attorney General. The provisions of section 42-110g of the general statutes shall not apply to any such violation.</p>\n   <p class=\"indent\">(f) (1) In any action commenced by the Attorney General for any violation of sections 1 to 9, inclusive, of this act, it shall be an affirmative defense that the developer, integrator, deployer or other person:</p>\n   <p class=\"indent\">(A) Discovers a violation of any provision of sections 1 to 9, inclusive, of this act through red-teaming;</p>\n   <p class=\"indent\">(B) Not later than sixty days after discovering the violation as set forth in subparagraph (A) of this subdivision: (i) Cures such violation; and (ii) provides to the Attorney General, in a form and manner prescribed by the Attorney General, notice that such violation has been cured and evidence that any harm caused by such violation has been mitigated; and</p>\n   <p class=\"indent\">(C) Is otherwise in compliance with the latest version of: (i) The &quot;Artificial Intelligence Risk Management Framework&quot; published by the National Institute of Standards and Technology; (ii) ISO or IEC 42001 of the International Organization for Standardization; (iii) a nationally or internationally recognized risk management framework for artificial intelligence systems, other than the risk management frameworks specified in subparagraphs (C)(i) and (C)(ii) of this subdivision, that imposes requirements that are substantially equivalent to, and at least as stringent as, the requirements set forth in sections 1 to 9, inclusive, of this act; or (iv) any risk management framework for artificial intelligence systems that is substantially equivalent to, and at least as stringent as, the risk management frameworks described in subparagraphs (C)(i) to (C)(iii), inclusive, of this subdivision.</p>\n   <p class=\"indent\">(2) The developer, integrator, deployer or other person bears the burden of demonstrating to the Attorney General that the requirements established in subdivision (1) of this subsection have been satisfied.</p>\n   <p class=\"indent\">(3) Nothing in this section or sections 1 to 9, inclusive, of this act, including, but not limited to, the enforcement authority granted to the Attorney General under this section, shall be construed to preempt or otherwise affect any right, claim, remedy, presumption or defense available at law or in equity. Any rebuttable presumption or affirmative defense established under this section or sections 1 to 9, inclusive, of this act shall apply only to an enforcement action brought by the Attorney General pursuant to this section and shall not apply to any right, claim, remedy, presumption or defense available at law or in equity.</p>\n   <p class=\"indent\">Sec. 11. (NEW) (Effective October 1, 2025) (a) For the purposes of this section, &quot;legislative leader&quot; has the same meaning as provided in subsection (b) of section 4-9d of the general statutes.</p>\n   <p class=\"indent\">(b) Each legislative leader may request that the executive director of the Connecticut Academy of Science and Engineering designate a member of said academy to serve as such legislative leader&#39;s liaison with said academy, the Office of the Attorney General and the Department of Economic and Community Development for the purpose of:</p>\n   <p class=\"indent\">(1) Designing a tool to enable any person to determine whether such person is in compliance with the provisions of sections 1 to 10, inclusive, of this act;</p>\n   <p class=\"indent\">(2) Designing a tool to assist a deployer, or a third party contracted by a deployer, to complete an impact assessment pursuant to subsection (c) of section 4 of this act;</p>\n   <p class=\"indent\">(3) Conducting meetings with relevant stakeholders to formulate a plan to utilize The University of Connecticut School of Law&#39;s Intellectual Property and Entrepreneurship Law Clinic to assist small businesses and startups in their efforts to comply with the provisions of sections 1 to 10, inclusive, of this act;</p>\n   <p class=\"indent\">(4) Making recommendations concerning establishing a framework to provide a controlled and supervised environment in which artificial intelligence systems may be tested, which recommendations shall include, at a minimum, recommendations concerning the establishment of (A) an office to oversee such framework and environment, and (B) a program that would enable consultations between the state, businesses and other stakeholders concerning such framework and environment;</p>\n   <p class=\"indent\">(5) Evaluating (A) the adoption of artificial intelligence systems by businesses, (B) the challenges posed to, and needs of, businesses in (i) adopting artificial intelligence systems, and (ii) understanding laws and regulations concerning artificial intelligence systems, and (C) how businesses that use artificial intelligence systems hire employees with necessary skills concerning artificial intelligence systems;</p>\n   <p class=\"indent\">(6) Creating a plan for the state to provide high-performance computing services to businesses and researchers in the state;</p>\n   <p class=\"indent\">(7) Evaluating the benefits of creating a state-wide research collaborative among health care providers to enable the development of advanced analytics, ethical and trustworthy artificial intelligence systems and hands-on workforce education while using methods that protect patient privacy; and</p>\n   <p class=\"indent\">(8) Evaluating, and making recommendations concerning, (A) the establishment of testbeds to support safeguards and systems to prevent the misuse of artificial intelligence systems, (B) risk assessments for the misuse of artificial intelligence systems, (C) evaluation strategies for artificial intelligence systems, and (D) the development, testing and evaluation of resources to support state oversight of artificial intelligence systems.</p>\n   <p class=\"indent\">(c) No member of the Connecticut Academy of Science and Engineering designated pursuant to subsection (b) of this section shall be deemed a state employee, or receive any compensation from the state, for performing such member&#39;s duties under said subsection.</p>\n   <p class=\"indent\">Sec. 12. (NEW) (Effective October 1, 2025) (a) As used in this section:</p>\n   <p class=\"indent\">(1) &quot;Active participant&quot; means a person participating in the artificial intelligence regulatory sandbox program designed, established and administered in accordance with the provisions of this section;</p>\n   <p class=\"indent\">(2) &quot;Artificial intelligence system&quot; has the same meaning as provided in section 1 of this act;</p>\n   <p class=\"indent\">(3) &quot;Consumer&quot; has the same meaning as provided in section 1 of this act;</p>\n   <p class=\"indent\">(4) &quot;Deployer&quot; means any person doing business in this state that deploys an artificial intelligence system;</p>\n   <p class=\"indent\">(5) &quot;Developer&quot; has the same meaning as provided in section 1 of this act;</p>\n   <p class=\"indent\">(6) &quot;Person&quot; has the same meaning as provided in section 1 of this act; and</p>\n   <p class=\"indent\">(7) &quot;State agency&quot; has the same meaning as provided in section 1-79 of the general statutes.</p>\n   <p class=\"indent\">(b) The Department of Economic and Community Development, in coordination with the Chief Data Officer and the Connecticut Technology Advisory Board established under section 16 of this act, shall design, establish and administer an artificial intelligence regulatory sandbox program to facilitate the development, testing and deployment of innovative artificial intelligence systems in the state. The program shall be designed to (1) promote the safe and innovative use of artificial intelligence systems across various sectors, including, but not limited to, education, finance, health care and public service, (2) encourage the responsible deployment of artificial intelligence systems while balancing the need for consumer protection, privacy and public safety, and (3) provide clear guidelines for developers to test artificial intelligence systems while being exempt from certain regulatory requirements during the period set forth in subsection (d) of this section.</p>\n   <p class=\"indent\">(c) (1) A person seeking to participate in the artificial intelligence regulatory sandbox program shall submit an application to the Department of Economic and Community Development in a form and manner prescribed by the Commissioner of Economic and Community Development. Each application shall include (A) a detailed description of the applicant&#39;s artificial intelligence system and its intended uses, (B) a risk assessment that addresses the potential impact of the applicant&#39;s artificial intelligence system on consumers, privacy and public safety, (C) a plan for mitigating any adverse consequences that may arise from the applicant&#39;s artificial intelligence system during the period set forth in subsection (d) of this section, (D) proof that the applicant and the applicant&#39;s artificial intelligence system are in compliance with all applicable federal laws and regulations concerning artificial intelligence systems, and (E) any other information the commissioner deems relevant for the purposes of this section or the program.</p>\n   <p class=\"indent\">(2) Not later than thirty days after the Department of Economic and Community Development receives an application submitted pursuant to subdivision (1) of this subsection, the department shall (A) approve or deny the application, and (B) send a notice to the applicant, in a form and manner prescribed by the Commissioner of Economic and Community Development, disclosing whether the department has approved or denied such application.</p>\n   <p class=\"indent\">(d) An active participant in the artificial intelligence regulatory sandbox program may test the applicant&#39;s artificial intelligence system as part of the program for a period not to exceed eighteen months from the date on which the Department of Economic and Community Development sent notice approving the active participant&#39;s application pursuant to subparagraph (B) of subdivision (2) of subsection (c) of this section, except the department may extend such period for good cause shown.</p>\n   <p class=\"indent\">(e) The Department of Economic and Community Development shall coordinate with all relevant state agencies to oversee the operations of active participants in the artificial intelligence regulatory sandbox program. Any state agency may recommend to the department that an active participant&#39;s participation in the program be revoked if the active participant&#39;s artificial intelligence system (1) poses an undue risk to the public health, safety or welfare, or (2) violates any federal law or regulation.</p>\n   <p class=\"indent\">(f) For the calendar quarter ending December 31, 2025, and for each calendar quarter thereafter, each active participant in the artificial intelligence regulatory sandbox program shall, not later than thirty days after the end of such calendar quarter, submit a report to the Department of Economic and Community Development disclosing (1) system performance metrics for such active participant&#39;s artificial intelligence system, (2) information concerning the manner in which such active participant&#39;s artificial intelligence system mitigated any risks associated with such artificial intelligence system, and (3) any feedback such active participant received from deployers, consumers and other users of such artificial intelligence system.</p>\n   <p class=\"indent\">(g) For the calendar year ending December 31, 2025, and for each calendar year thereafter, the Department of Economic and Community Development shall, not later than thirty days after the end of such calendar year, submit a report, in accordance with the provisions of section 11-4a of the general statutes, to the joint standing committee of the General Assembly having cognizance of matters relating to consumer protection. Each report shall disclose (1) the number of persons who were active participants in the artificial intelligence regulatory sandbox program for the calendar year that is the subject of such report or any portion of such calendar year, (2) the overall performance and impact of artificial intelligence systems tested as part of the program, and (3) any recommendations regarding the adoption of legislation for the purposes of the program.</p>\n   <p class=\"indent\">Sec. 13. (NEW) (Effective July 1, 2025) (a) As used in this section, &quot;artificial intelligence&quot; means artificial intelligence system, as defined in section 1 of this act.</p>\n   <p class=\"indent\">(b) Not later than December 31, 2025, the Board of Regents for Higher Education shall establish, on behalf of Charter Oak State College and in consultation with the Labor Department, the State Board of Education, Workforce Investment Boards, employers and institutions of higher education in this state, a &quot;Connecticut AI Academy&quot;. The academy shall, at a minimum:</p>\n   <p class=\"indent\">(1) Curate and offer online courses concerning artificial intelligence and the responsible use of artificial intelligence;</p>\n   <p class=\"indent\">(2) Promote digital literacy;</p>\n   <p class=\"indent\">(3) Prepare students for careers in fields involving artificial intelligence;</p>\n   <p class=\"indent\">(4) Offer courses directed at individuals between thirteen and twenty years of age;</p>\n   <p class=\"indent\">(5) Offer courses that prepare small businesses and nonprofit organizations to utilize artificial intelligence to improve marketing and management efficiency;</p>\n   <p class=\"indent\">(6) Develop courses concerning artificial intelligence that the Labor Department and Workforce Investment Boards may incorporate into workforce training programs; and</p>\n   <p class=\"indent\">(7) Enable persons providing free or discounted public Internet access to distribute information and provide mentorship concerning artificial intelligence, the academy and methods available for the public to obtain free or discounted devices capable of accessing the Internet and utilizing artificial intelligence.</p>\n   <p class=\"indent\">(c) The Board of Regents for Higher Education shall, in consultation with Charter Oak State College, develop certificates and badges to be awarded to persons who successfully complete courses offered by the Connecticut AI Academy.</p>\n   <p class=\"indent\">Sec. 14. (NEW) (Effective July 1, 2025) The Labor Department shall provide a notice, in a form and manner prescribed by the Labor Commissioner, to each individual who makes a claim for unemployment compensation disclosing the existence of, and courses and services offered by, the Connecticut AI Academy established pursuant to section 13 of this act.</p>\n   <p class=\"indent\">Sec. 15. Subsection (b) of section 17b-751b of the general statutes is repealed and the following is substituted in lieu thereof (Effective July 1, 2025):</p>\n   <p class=\"indent\">(b) The commissioner shall: (1) Ensure that all home visiting programs <u class=\"amendmentInsertedText\">(A)</u> are one or more of the evidence-based home visiting models that meet the criteria for evidence of effectiveness developed by the federal Department of Health and Human Services<u class=\"amendmentInsertedText\">, and (B) provide information to parents regarding the Connecticut AI Academy established pursuant to section 13 of this act</u>; (2) provide oversight of home visiting programs to insure model fidelity; and (3) develop, issue and evaluate requests for proposals to procure the services required by this section. In evaluating the proposals, the commissioner shall take into consideration the most effective and consistent service delivery system allowing for the continuation of current public and private programs.</p>\n   <p class=\"indent\">Sec. 16. (NEW) (Effective July 1, 2025) (a) As used in this section, &quot;artificial intelligence&quot; means artificial intelligence system, as defined in section 1 of this act.</p>\n   <p class=\"indent\">(b) There is established, within available appropriations, a Connecticut Technology Advisory Board, which shall be part of the Legislative Department.</p>\n   <p class=\"indent\">(c) (1) The board shall consist of the following members: (A) Two appointed by the speaker of the House of Representatives; (B) two appointed by the president pro tempore of the Senate; (C) two appointed by the minority leader of the House of Representatives; and (D) two appointed by the minority leader of the Senate. All appointed members shall have professional experience or academic qualifications in the field of artificial intelligence or the field of technology, or another related field, and no such member shall be a member of the General Assembly.</p>\n   <p class=\"indent\">(2) The following persons or their designees shall serve as ex-officio, nonvoting members and chairpersons of the board: (A) The Commissioner of Economic and Community Development; (B) the executive director of the Connecticut Academy of Science and Engineering; and (C) the president of Charter Oak State College.</p>\n   <p class=\"indent\">(3) All initial appointments to the board shall be made not later than October 1, 2025. The term of an appointed member shall be coterminous with the term of the appointing authority for the appointed member. Any vacancy shall be filled by the appointing authority. Any vacancy occurring other than by expiration of a term shall be filled for the balance of the unexpired term. A member of the board may serve more than one term. The chairpersons shall schedule the first meeting of the board, which shall be held not later than November 1, 2025.</p>\n   <p class=\"indent\">(d) The administrative staff of the joint standing committees of the General Assembly having cognizance of matters relating to consumer protection and government administration shall serve as administrative staff of the board.</p>\n   <p class=\"indent\">(e) The board shall have the following powers and duties: (1) To develop and adopt a state technology strategy (A) for the purpose of promoting education, workforce development, economic development and consumer protection, and (B) that accounts for the rapid pace of technological development, including, but not limited to, in the field of artificial intelligence; (2) to update the state technology strategy developed and adopted pursuant to subdivision (1) of this subsection at least once every two years; (3) to issue reports and recommendations in accordance with the provisions of section 11-4a of the general statutes; (4) upon the vote of a majority of the members of the board, to request any state agency data officer or state agency head to (A) appear before the board to answer questions, or (B) provide such assistance and data as may be necessary for the purpose of enabling the board to perform its duties; (5) to make recommendations to the Legislative Department, Executive Department or Judicial Department in accordance with the state technology strategy; and (6) to establish bylaws to govern the board&#39;s procedures.</p>\n   <p class=\"indent\">(f) The board shall meet at least twice annually and may meet at such other times as deemed necessary by the chairpersons or a majority of the members of the board.</p>\n   <p class=\"indent\">Sec. 17. (Effective July 1, 2025) (a) Not later than December 31, 2025, the Department of Economic and Community Development shall, within available appropriations and in collaboration with Charter Oak State College, develop a plan to establish a technology transfer program within Connecticut Innovations, Incorporated, for the purpose of supporting technology transfers by and among public and private institutions of higher education in this state.</p>\n   <p class=\"indent\">(b) Not later than January 1, 2026, the Commissioner of Economic and Community Development shall submit a report, in accordance with the provisions of section 11-4a of the general statutes, to the joint standing committees of the General Assembly having cognizance of matters relating to consumer protection, commerce and higher education. Such report shall, at a minimum, include the plan developed pursuant to subsection (a) of this section.</p>\n   <p class=\"indent\">Sec. 18. (NEW) (Effective July 1, 2025) (a) Not later than December 31, 2025, the Department of Economic and Community Development shall, within available appropriations and in collaboration with the Office of Health Strategy, establish a confidential computing cluster for the purpose of fostering the exchange of health information in order to support academic and medical research.</p>\n   <p class=\"indent\">(b) (1) The confidential computing cluster established pursuant to subsection (a) of this section shall be overseen by a Connecticut Confidential Computing Cluster Policy Board, which shall be within the Department of Economic and Community Development for administrative purposes only. Said policy board shall consist of:</p>\n   <p class=\"indent\">(A) The chairperson of The University of Connecticut Health Center Board of Directors, or said chairperson&#39;s designee; and</p>\n   <p class=\"indent\">(B) A representative of the State-wide Health Information Exchange established pursuant to section 17b-59d of the general statutes, who shall be appointed by the Commissioner of Health Strategy.</p>\n   <p class=\"indent\">(2) The Connecticut Confidential Computing Cluster Policy Board shall direct the formulation of policies and operating procedures for the confidential computing cluster established pursuant to subsection (a) of this section.</p>\n   <p class=\"indent\">(3) The Connecticut Confidential Computing Cluster Policy Board may apply for and administer any federal, state, local or private appropriations or grant funds made available for the operation of the confidential computing cluster established pursuant to subsection (a) of this section.</p>\n   <p class=\"indent\">Sec. 19. Section 10-21l of the general statutes is repealed and the following is substituted in lieu thereof (Effective July 1, 2025):</p>\n   <p class=\"indent\">There is established an account to be known as the <strike class=\"amendmentDeletedText\">&quot;computer science education account&quot;</strike>\n    <u class=\"amendmentInsertedText\">&quot;computer science education and workforce development account&quot;</u>, which shall be a separate, nonlapsing account within the General Fund. The account shall contain any moneys required or permitted by law to be deposited in the account and any funds received from any public or private contributions, gifts, grants, donations, bequests or devises to the account. The Department of Education may make expenditures from the account <u class=\"amendmentInsertedText\">(1)</u> to support curriculum development, teacher professional development, capacity development for school districts <strike class=\"amendmentDeletedText\">,</strike> and other programs for the purposes of supporting computer science education<u class=\"amendmentInsertedText\">, and (2) in coordination with the Office of Workforce Strategy and the Board of Regents for Higher Education for the purpose of supporting workforce development initiatives in accordance with the state technology strategy adopted pursuant to subsection (e) of section 16 of this act</u>.</p>\n   <p class=\"indent\">Sec. 20. Section 32-7p of the general statutes is repealed and the following is substituted in lieu thereof (Effective July 1, 2025):</p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(a) As used in this section:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(1) &quot;Artificial intelligence&quot; means artificial intelligence system, as defined in section 1 of this act;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(2) &quot;Generative artificial intelligence&quot; means any form of artificial intelligence, including, but not limited to, a foundation model, that is able to produce synthetic digital content, as defined in section 1 of this act; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(3) &quot;Prompt engineering&quot; means the process of guiding generative artificial intelligence to generate a desired output.</u>\n   </p>\n   <p class=\"indent\">\n    <strike class=\"amendmentDeletedText\">(a)</strike>\n    <u class=\"amendmentInsertedText\">(b)</u> There shall be a Technology Talent <u class=\"amendmentInsertedText\">and Innovation Fund</u> Advisory Committee within the Department of Economic and Community Development. Such committee shall consist of members appointed by the Commissioner of Economic and Community Development, including, but not limited to, representatives of The University of Connecticut, the Board of Regents for Higher Education, independent institutions of higher education, the Office of Workforce Strategy and private industry. Such members shall be subject to term limits prescribed by the commissioner. Each member shall hold office until a successor is appointed.</p>\n   <p class=\"indent\">\n    <strike class=\"amendmentDeletedText\">(b)</strike>\n    <u class=\"amendmentInsertedText\">(c)</u> The commissioner shall call the first meeting of the advisory committee not later than October 15, 2016. The advisory committee shall meet not less than quarterly thereafter and at such other times as the chairperson deems necessary. The Technology Talent <u class=\"amendmentInsertedText\">and Innovation Fund</u> Advisory Committee shall designate the chairperson of the committee from among its members.</p>\n   <p class=\"indent\">\n    <strike class=\"amendmentDeletedText\">(c)</strike>\n    <u class=\"amendmentInsertedText\">(d)</u> No member of the advisory committee shall receive compensation for such member&#39;s service, except that each member shall be entitled to reimbursement for actual and necessary expenses incurred during the performance of such member&#39;s official duties.</p>\n   <p class=\"indent\">\n    <strike class=\"amendmentDeletedText\">(d)</strike>\n    <u class=\"amendmentInsertedText\">(e)</u> A majority of members of the advisory committee shall constitute a quorum for the transaction of any business or the exercise of any power of the advisory committee. The advisory committee may act by a majority of the members present at any meeting at which a quorum is in attendance, for the transaction of any business or the exercise of any power of the advisory committee, except as otherwise provided in this section.</p>\n   <p class=\"indent\">\n    <strike class=\"amendmentDeletedText\">(e)</strike>\n    <u class=\"amendmentInsertedText\">(f)</u> Notwithstanding any provision of the general statutes, it shall not constitute a conflict of interest for a trustee, director, partner or officer of any person, firm or corporation, or any individual having a financial interest in a person, firm or corporation, to serve as a member of the advisory committee, provided such trustee, director, partner, officer or individual complies with all applicable provisions of chapter 10. All members of the advisory committee shall be deemed public officials and shall adhere to the code of ethics for public officials set forth in chapter 10, except that no member shall be required to file a statement of financial interest as described in section 1-83.</p>\n   <p class=\"indent\">\n    <strike class=\"amendmentDeletedText\">(f) The Technology Talent Advisory Committee shall, in the following order of priority, (1) calculate the number of software developers and other persons (A) employed in technology-based fields where there is a shortage of qualified employees in this state for businesses to hire, including, but not limited to, data mining, data analysis and cybersecurity, and (B) employed by businesses located in Connecticut as of December 31, 2016; (2) develop pilot programs to recruit software developers to Connecticut and train residents of the state in software development and such other technology fields, with the goal of increasing the number of software developers and persons employed in such other technology fields residing in Connecticut and employed by businesses in Connecticut by at least double the number calculated pursuant to subdivision (1) of this subsection by January 1, 2026; and (3) identify other technology industries where there is a shortage of qualified employees in this state for growth stage businesses to hire.</strike>\n   </p>\n   <p class=\"indent\">(g) The Technology Talent <u class=\"amendmentInsertedText\">and Innovation Fund</u> Advisory Committee may <u class=\"amendmentInsertedText\">partner with institutions of higher education and other nonprofit organizations to</u> develop <strike class=\"amendmentDeletedText\">pilot</strike> programs <strike class=\"amendmentDeletedText\">for (1) marketing and publicity campaigns designed to recruit technology talent to the state; (2) student loan deferral or forgiveness for students who start businesses in the state; and (3) training, apprenticeship and gap-year initiatives</strike>\n    <u class=\"amendmentInsertedText\">to expand the technology talent pipeline in the state, including, but not limited to, in the fields of artificial intelligence and quantum computing</u>.</p>\n   <p class=\"indent\">\n    <strike class=\"amendmentDeletedText\">(h) The Technology Talent Advisory Committee shall report, in accordance with the provisions of section 11-4a, and present such report to the joint standing committees of the General Assembly having cognizance of matters relating to commerce, education, higher education and finance, revenue and bonding on or before January 1, 2017, concerning the (1) pilot programs developed pursuant to subsections (f) and (g) of this section, (2) number of software developers and persons employed in technology-based fields described in subsection (f) of this section targeted for recruitment pursuant to subsection (f) of this section, and (3) timeline and measures for reaching the recruitment target.</strike>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(h) Not later than July 1, 2026, the Technology Talent and Innovation Fund Advisory Committee shall partner with public and private institutions of higher education in the state and other training providers to develop programs in the field of artificial intelligence, including, but not limited to, in areas such as prompt engineering, artificial intelligence marketing for small businesses and artificial intelligence for small business operations.</u>\n   </p>\n   <p class=\"indent\">Sec. 21. Subsection (b) of section 32-235 of the general statutes is repealed and the following is substituted in lieu thereof (Effective July 1, 2025):</p>\n   <p class=\"indent\">(b) The proceeds of the sale of said bonds, to the extent of the amount stated in subsection (a) of this section, shall be used by the Department of Economic and Community Development (1) for the purposes of sections 32-220 to 32-234, inclusive, including economic cluster-related programs and activities, and for the Connecticut job training finance demonstration program pursuant to sections 32-23uu and 32-23vv, provided (A) three million dollars shall be used by said department solely for the purposes of section 32-23uu, (B) not less than one million dollars shall be used for an educational technology grant to the deployment center program and the nonprofit business consortium deployment center approved pursuant to section 32-41l, (C) not less than two million dollars shall be used by said department for the establishment of a pilot program to make grants to businesses in designated areas of the state for construction, renovation or improvement of small manufacturing facilities, provided such grants are matched by the business, a municipality or another financing entity. The Commissioner of Economic and Community Development shall designate areas of the state where manufacturing is a substantial part of the local economy and shall make grants under such pilot program which are likely to produce a significant economic development benefit for the designated area, (D) five million dollars may be used by said department for the manufacturing competitiveness grants program, (E) one million dollars shall be used by said department for the purpose of a grant to the Connecticut Center for Advanced Technology, for the purposes of subdivision (5) of subsection (a) of section 32-7f, (F) fifty million dollars shall be used by said department for the purpose of grants to the United States Department of the Navy, the United States Department of Defense or eligible applicants for projects related to the enhancement of infrastructure for long-term, on-going naval operations at the United States Naval Submarine Base-New London, located in Groton, which will increase the military value of said base. Such projects shall not be subject to the provisions of sections 4a-60 and 4a-60a, (G) two million dollars shall be used by said department for the purpose of a grant to the Connecticut Center for Advanced Technology, Inc., for manufacturing initiatives, including aerospace and defense, and (H) four million dollars shall be used by said department for the purpose of a grant to companies adversely impacted by the construction at the Quinnipiac Bridge, where such grant may be used to offset the increase in costs of commercial overland transportation of goods or materials brought to the port of New Haven by ship or vessel, (2) for the purposes of the small business assistance program established pursuant to section 32-9yy, provided fifteen million dollars shall be deposited in the small business assistance account established pursuant to said section 32-9yy, (3) to deposit twenty million dollars in the small business express assistance account established pursuant to section 32-7h, (4) to deposit four million nine hundred thousand dollars per year in each of the fiscal years ending June 30, 2017, to June 30, 2019, inclusive, and June 30, 2021, and nine million nine hundred thousand dollars in the fiscal year ending June 30, 2020, in the CTNext Fund established pursuant to section 32-39i, which shall be used by the Department of Economic and Community Development to provide grants-in-aid to designated innovation places, as defined in section 32-39f, planning grants-in-aid pursuant to section 32-39l, and grants-in-aid for projects that network innovation places pursuant to subsection (b) of section 32-39m, provided not more than three million dollars be used for grants-in-aid for such projects, and further provided any portion of any such deposit that remains unexpended in a fiscal year subsequent to the date of such deposit may be used by the Department of Economic and Community Development for any purpose described in subsection (e) of section 32-39i, (5) to deposit two million dollars per year in each of the fiscal years ending June 30, 2019, to June 30, 2021, inclusive, in the CTNext Fund established pursuant to section 32-39i, which shall be used by the Department of Economic and Community Development for the purpose of providing higher education entrepreneurship grants-in-aid pursuant to section 32-39g, provided any portion of any such deposit that remains unexpended in a fiscal year subsequent to the date of such deposit may be used by the Department of Economic and Community Development for any purpose described in subsection (e) of section 32-39i, (6) for the purpose of funding the costs of the Technology Talent <u class=\"amendmentInsertedText\">and Innovation Fund</u> Advisory Committee established pursuant to section 32-7p<u class=\"amendmentInsertedText\">, as amended by this act</u>, provided not more than ten million dollars may be used on or after July 1, 2023, for such purpose, (7) to provide (A) a grant-in-aid to the Connecticut Supplier Connection in an amount equal to two hundred fifty thousand dollars in each of the fiscal years ending June 30, 2017, to June 30, 2021, inclusive, and (B) a grant-in-aid to the Connecticut Procurement Technical Assistance Program in an amount equal to three hundred thousand dollars in each of the fiscal years ending June 30, 2017, to June 30, 2021, inclusive, (8) to deposit four hundred fifty thousand dollars per year, in each of the fiscal years ending June 30, 2017, to June 30, 2021, inclusive, in the CTNext Fund established pursuant to section 32-39i, which shall be used by the Department of Economic and Community Development to provide growth grants-in-aid pursuant to section 32-39g, provided any portion of any such deposit that remains unexpended in a fiscal year subsequent to the date of such deposit may be used by the Department of Economic and Community Development for any purpose described in subsection (e) of section 32-39i, (9) to transfer fifty million dollars to the Labor Department which shall be used by said department for the purpose of funding workforce pipeline programs selected pursuant to section 31-11rr, provided, notwithstanding the provisions of section 31-11rr, (A) not less than five million dollars shall be provided to the workforce development board in Bridgeport serving the southwest region, for purposes of such program, and the board shall distribute such money in proportion to population and need, and (B) not less than five million dollars shall be provided to the workforce development board in Hartford serving the north central region, for purposes of such program, (10) to transfer twenty million dollars to Connecticut Innovations, Incorporated, provided ten million dollars shall be used by Connecticut Innovations, Incorporated for the purpose of the proof of concept fund established pursuant to subsection (b) of section 32-39x and ten million dollars shall be used by Connecticut Innovations, Incorporated for the purpose of the venture capital fund program established pursuant to section 32-41oo, (11) to provide a grant to The University of Connecticut of eight million dollars for the establishment, development and operation of a center for sustainable aviation pursuant to subsection (a) of section 10a-110o, and (12) for up to twenty million dollars in investments in federally designated opportunity zones through an impact investment firm including, subject to the approval of the Governor, funding from the Economic Assistance Revolving Fund, established pursuant to section 32-231.</p>\n   <p class=\"indent\">Sec. 22. (Effective July 1, 2025) Not later than December 31, 2025, the Department of Economic and Community Development shall, within available appropriations, in partnership with public and private institutions of higher education in the state and in coordination with the artificial intelligence industry, conduct a &quot;CT AI Symposium&quot; to foster collaboration between academia, government and the artificial intelligence industry for the purpose of promoting the establishment and growth of artificial intelligence businesses in this state.</p>\n   <p class=\"indent\">Sec. 23. (Effective July 1, 2025) (a) As used in this section:</p>\n   <p class=\"indent\">(1) &quot;Artificial intelligence&quot; means artificial intelligence system, as defined in section 1 of this act;</p>\n   <p class=\"indent\">(2) &quot;Generative artificial intelligence&quot; means any form of artificial intelligence, including, but not limited to, a foundation model, that is able to produce synthetic digital content, as defined in section 1 of this act; and</p>\n   <p class=\"indent\">(3) &quot;State agency&quot; means any department, board, council, commission, institution or other executive branch agency of state government, including, but not limited to, each constituent unit and each public institution of higher education.</p>\n   <p class=\"indent\">(b) Each state agency shall, in consultation with the labor unions representing the employees of such state agency, study how generative artificial intelligence may be incorporated in its processes to improve efficiencies. Each state agency shall prepare for any such incorporation with input from the state agency&#39;s employees, including, but not limited to, any applicable collective bargaining unit that represents its employees, and appropriate experts from civil society organizations, academia and industry.</p>\n   <p class=\"indent\">(c) Not later than January 1, 2026, each state agency shall submit the results of such study to the Department of Administrative Services, including a request for approval of any potential pilot project utilizing generative artificial intelligence that the state agency intends to establish, provided such use is in accordance with the policies and procedures established by the Office of Policy and Management pursuant to subsection (b) of section 4-68jj of the general statutes. Any such pilot project shall measure how generative artificial intelligence (1) improves Connecticut residents&#39; experience with and access to government services, and (2) supports state agency employees in the performance of their duties in addition to any domain-specific impacts to be measured by the state agency. The Commissioner of Administrative Services shall assess any such proposed pilot project in accordance with the provisions of section 4a-2e of the general statutes, as amended by this act, and may disapprove any pilot project that fails such assessment or requires additional legislative authorization.</p>\n   <p class=\"indent\">(d) Not later than February 1, 2026, the Commissioner of Administrative Services shall submit a report, in accordance with the provisions of section 11-4a of the general statutes, to the joint standing committees of the General Assembly having cognizance of matters relating to consumer protection and government administration. Such report shall include a summary of all pilot projects approved by the commissioner under this section and any recommendations for legislation necessary to implement additional pilot projects.</p>\n   <p class=\"indent\">Sec. 24. Section 32-39e of the general statutes is repealed and the following is substituted in lieu thereof (Effective July 1, 2025):</p>\n   <p class=\"indent\">(a) If, in the exercise of its powers under section 32-39, Connecticut Innovations, Incorporated (1) finds that the use of a certain technology, product or process<u class=\"amendmentInsertedText\">, including, but not limited to, an artificial intelligence system, as defined in section 1 of this act,</u> (A) would promote public health and safety, environmental protection or economic development, or (B) with regard to state services, would promote efficiency, reduce administrative burdens or otherwise improve such services, and (2) determines such technology, product or process was developed by a business (A) domiciled in this state to which the corporation has provided financial assistance or in which the corporation has invested, or (B) which has been certified as a small contractor or minority business enterprise by the Commissioner of Administrative Services under section 4a-60g, the corporation, upon application of such business, may recommend to the Secretary of the Office of Policy and Management that an agency of the state, including, but not limited to, any constituent unit of the state system of higher education, be authorized to test such technology, product or process by employing <strike class=\"amendmentDeletedText\">it</strike>\n    <u class=\"amendmentInsertedText\">such technology, product or process</u> in the operations of such agency on a trial basis. The purpose of such test program shall be to validate the commercial viability of such technology, product or process provided no business in which Connecticut Innovations, Incorporated has invested shall be required to participate in such program.</p>\n   <p class=\"indent\">(b) Connecticut Innovations, Incorporated shall make no such recommendation unless such business has submitted a viable business plan to Connecticut Innovations, Incorporated for manufacturing and marketing such technology, product or process and such business demonstrates that (1) the usage of such technology, product or process by the state agency will not adversely affect safety, (2) sufficient research and development has occurred to warrant participation in the test program, (3) the technology, product or process has potential for commercialization not later than two years following the completion of any test program involving a state agency under this section, and (4) such technology, product or process will have a positive economic impact in the state, including the prospective addition of jobs and economic activity upon such commercialization.</p>\n   <p class=\"indent\">(c) If the Secretary of the Office of Policy and Management finds that employing such technology, product or process would be feasible in the operations of a state agency and would not have any detrimental effect on such operations, said secretary, notwithstanding the requirement of chapter 58, may direct an agency of the state to accept delivery of such technology, product or process and to undertake such a test program. The Secretary of the Office of Policy and Management, in consultation with the Commissioner of Administrative Services, the chief executive officer of Connecticut Innovations, Incorporated and the department head of the testing agency, shall determine, on a case-by-case basis, whether the costs associated with the acquisition and use of such technology, product or process by the testing agency shall be borne by Connecticut Innovations, Incorporated, the business or by any investor or participant in such business. The acquisition of any technology, product or process for purposes of the test program established pursuant to this section shall not be deemed to be a purchase under the provisions of the state procurement policy. The testing agency, on behalf of Connecticut Innovations, Incorporated shall maintain records related to such test program, as requested by Connecticut Innovations, Incorporated and shall make such records and any other information derived from such test program available to Connecticut Innovations, Incorporated and the business. Any proprietary information derived from such test program shall be exempt from the provisions of subsection (a) of section 1-210.</p>\n   <p class=\"indent\">(d) If the Secretary of the Office of Policy and Management, in consultation with the Commissioner of Administrative Services, the chief executive officer of Connecticut Innovations, Incorporated and the department head of the testing agency, determines that the test program sufficiently demonstrates that the technology, product or process promotes public health and safety, environmental protection, economic development or efficiency, reduces administrative burdens or otherwise improves state services, the Commissioner of Administrative Services may procure such technology, product or process for use by any or all state agencies pursuant to subsection (b) of section 4a-58.</p>\n   <p class=\"indent\">(e) The Secretary of the Office of Policy and Management, the Commissioner of Administrative Services and Connecticut Innovations, Incorporated may develop a program to recognize state agencies that help to promote public health and safety, environmental protection, economic development or efficiency, reduce administrative burdens or improve state services by participating in a testing program under this section. Such program may include the creation of a fund established with savings accrued by the testing agency during its participation in the testing program established under this section. Such fund shall only be used to implement the program of recognition established by the Secretary of the Office of Policy and Management, the Commissioner of Administrative Services and Connecticut Innovations, Incorporated, under the provisions of this subsection.</p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(f) The Secretary of the Office of Policy and Management, the Commissioner of Administrative Services, Connecticut Innovations, Incorporated, and the Chief Information Officer shall, within available appropriations, establish an artificial intelligence systems fellowship program for the purpose of assisting the Chief Information Officer and state agencies to implement artificial intelligence systems procured pursuant to subsection (b) of section 4a-58. The program shall be within the Office of Policy and Management for administrative purposes only. Not later than January 1, 2026, the Governor shall appoint three artificial intelligence technology fellows in consultation with the Chief Information Officer. Each artificial intelligence technology fellow shall have professional experience or academic qualifications in the field of artificial intelligence, and shall perform such artificial intelligence technology fellow&#39;s duties under the supervision of the Chief Information Officer. The initial term for each artificial intelligence technology fellow shall expire on January 31, 2029. Terms following initial terms shall be for two years, and any artificial intelligence technology fellow may serve more than one term. The Governor shall fill any vacancy in consultation with the Chief Information Officer not later than thirty days after the appointment becomes vacant. For the purposes of this subsection, &quot;artificial intelligence system&quot; has the same meaning as provided in section 1 of this act.</u>\n   </p>\n   <p class=\"indent\">Sec. 25. (Effective July 1, 2025) (a) For the purposes of this section:</p>\n   <p class=\"indent\">(1) &quot;Artificial intelligence&quot; means artificial intelligence system, as defined in section 1 of this act;</p>\n   <p class=\"indent\">(2) &quot;General-purpose artificial intelligence&quot; means general-purpose artificial intelligence model, as defined in section 1 of this act; and</p>\n   <p class=\"indent\">(3) &quot;Synthetic digital content&quot; has the same meaning as provided in section 1 of this act.</p>\n   <p class=\"indent\">(b) There is established a working group to engage stakeholders and experts to:</p>\n   <p class=\"indent\">(1) Make recommendations concerning:</p>\n   <p class=\"indent\">(A) The best practices to avoid the negative impacts, and to maximize the positive impacts, on services and state employees in connection with the implementation of new digital technologies and artificial intelligence;</p>\n   <p class=\"indent\">(B) The collection of reports, recommendations and plans from state agencies considering the implementation of artificial intelligence, and the assessment of such reports, recommendations and plans against the best practices described in subparagraph (A) of this subdivision; and</p>\n   <p class=\"indent\">(C) Any other matters that the working group may deem relevant for the purposes of avoiding the negative impacts, and maximizing the positive impacts, described in subparagraph (A) of this subdivision;</p>\n   <p class=\"indent\">(2) Make recommendations concerning methods to create resources for the purpose of assisting small businesses to adopt artificial intelligence to improve their efficiency and operations;</p>\n   <p class=\"indent\">(3) Propose legislation to (A) regulate the use of general-purpose artificial intelligence, and (B) require social media platforms to provide a signal when such social media platforms are displaying synthetic digital content;</p>\n   <p class=\"indent\">(4) After reviewing the laws and regulations, and any proposed legislation or regulations, of other states concerning artificial intelligence, propose legislation concerning artificial intelligence;</p>\n   <p class=\"indent\">(5) Develop an outreach plan for the purpose of bridging the digital divide and providing workforce training to persons who do not have high-speed Internet access;</p>\n   <p class=\"indent\">(6) Evaluate and make recommendations concerning:</p>\n   <p class=\"indent\">(A) The establishment of testbeds to support safeguards and systems to prevent the misuse of artificial intelligence;</p>\n   <p class=\"indent\">(B) Risk assessments for the misuse of artificial intelligence;</p>\n   <p class=\"indent\">(C) Evaluation strategies for artificial intelligence; and</p>\n   <p class=\"indent\">(D) The development, testing and evaluation of resources to support state oversight of artificial intelligence;</p>\n   <p class=\"indent\">(7) Review the protections afforded to trade secrets and other proprietary information under existing state law and make recommendations concerning such protections;</p>\n   <p class=\"indent\">(8) Study definitions concerning artificial intelligence, including, but not limited to, the definition of high-risk artificial intelligence system set forth in section 1 of this act, and make recommendations concerning the inclusion of language providing that no artificial intelligence system shall be considered to be a high-risk artificial intelligence system if such artificial intelligence system does not pose a significant risk of harm to the health, safety or fundamental rights of individuals, including, but not limited to, by not materially influencing the outcome of any decision-making;</p>\n   <p class=\"indent\">(9) Make recommendations concerning the establishment and membership of a permanent artificial intelligence advisory council; and</p>\n   <p class=\"indent\">(10) Make such other recommendations concerning artificial intelligence that the working group may deem appropriate.</p>\n   <p class=\"indent\">(c) (1) (A) The working group shall be part of the Legislative Department and consist of the following voting members: (i) One appointed by the speaker of the House of Representatives, who shall be a representative of the industries that are developing artificial intelligence; (ii) one appointed by the president pro tempore of the Senate, who shall be a representative of the industries that are using artificial intelligence; (iii) one appointed by the majority leader of the House of Representatives, who shall be an academic with a concentration in the study of technology and technology policy; (iv) one appointed by the majority leader of the Senate, who shall be an academic with a concentration in the study of government and public policy; (v) one appointed by the minority leader of the House of Representatives, who shall be a representative of an industry association representing the industries that are developing artificial intelligence; (vi) one appointed by the minority leader of the Senate, who shall be a representative of an industry association representing the industries that are using artificial intelligence; (vii) one appointed by the House chairperson of the joint standing committee of the General Assembly having cognizance of matters relating to consumer protection; (viii) one appointed by the Senate chairperson of the joint standing committee of the General Assembly having cognizance of matters relating to consumer protection; (ix) one appointed by the House ranking member of the joint standing committee of the General Assembly having cognizance of matters relating to consumer protection, who shall be a representative of the artificial intelligence industry or a related industry; (x) one appointed by the Senate ranking member of the joint standing committee of the General Assembly having cognizance of matters relating to consumer protection, who shall be a representative of the artificial intelligence industry or a related industry; (xi) one appointed by the House chairperson of the joint standing committee of the General Assembly having cognizance of matters relating to labor, who shall be a representative of a labor organization; (xii) one appointed by the Senate chairperson of the joint standing committee of the General Assembly having cognizance of matters relating to labor, who shall be a representative of a labor organization; (xiii) one appointed by the House ranking member of the joint standing committee of the General Assembly having cognizance of matters relating to labor, who shall be a representative of a small business; (xiv) one appointed by the Senate ranking member of the joint standing committee of the General Assembly having cognizance of matters relating to labor, who shall be a representative of a small business; and (xv) two appointed by the Governor, who shall be members of the Connecticut Academy of Science and Engineering.</p>\n   <p class=\"indent\">(B) All voting members of the working group appointed pursuant to subparagraph (A) of this subdivision shall have professional experience or academic qualifications in matters pertaining to artificial intelligence, automated systems, government policy or another related field.</p>\n   <p class=\"indent\">(C) All initial appointments to the working group shall be made not later than July 31, 2025. Any vacancy shall be filled by the appointing authority.</p>\n   <p class=\"indent\">(D) Any action taken by the working group shall be taken by a majority vote of all members present who are entitled to vote, provided no such action may be taken unless at least fifty per cent of such members are present.</p>\n   <p class=\"indent\">(2) The working group shall include the following nonvoting, ex-officio members: (A) The House chairperson of the joint standing committee of the General Assembly having cognizance of matters relating to consumer protection; (B) the Senate chairperson of the joint standing committee of the General Assembly having cognizance of matters relating to consumer protection; (C) the House chairperson of the joint standing committee of the General Assembly having cognizance of matters relating to labor; (D) the Senate chairperson of the joint standing committee of the General Assembly having cognizance of matters relating to labor; (E) the Attorney General, or the Attorney General&#39;s designee; (F) the Comptroller, or the Comptroller&#39;s designee; (G) the Treasurer, or the Treasurer&#39;s designee; (H) the Commissioner of Administrative Services, or said commissioner&#39;s designee; (I) the Chief Data Officer, or said officer&#39;s designee; (J) the executive director of the Freedom of Information Commission, or said executive director&#39;s designee; (K) the executive director of the Commission on Women, Children, Seniors, Equity and Opportunity, or said executive director&#39;s designee; (L) the Chief Court Administrator, or said administrator&#39;s designee; and (M) the executive director of the Connecticut Academy of Science and Engineering, or said executive director&#39;s designee.</p>\n   <p class=\"indent\">(d) The chairpersons of the joint standing committee of the General Assembly having cognizance of matters relating to consumer protection and the executive director of the Connecticut Academy of Science and Engineering shall serve as chairpersons of the working group. Such chairpersons shall schedule the first meeting of the working group, which shall be held not later than August 31, 2025.</p>\n   <p class=\"indent\">(e) The administrative staff of the joint standing committee of the General Assembly having cognizance of matters relating to consumer protection shall serve as administrative staff of the working group.</p>\n   <p class=\"indent\">(f) Not later than February 1, 2026, the working group shall submit a report on its findings and recommendations to the joint standing committee of the General Assembly having cognizance of matters relating to consumer protection, in accordance with the provisions of section 11-4a of the general statutes. The working group shall terminate on the date that the working group submits such report or February 1, 2026, whichever is later.</p>\n   <p class=\"indent\">Sec. 26. Section 4a-2e of the general statutes is repealed and the following is substituted in lieu thereof (Effective July 1, 2025):</p>\n   <p class=\"indent\">(a) For the purposes of this section:</p>\n   <p class=\"indent\">(1) &quot;Artificial intelligence&quot; means <strike class=\"amendmentDeletedText\">(A) an artificial system that (i) performs tasks under varying and unpredictable circumstances without significant human oversight or can learn from experience and improve such performance when exposed to data sets, (ii) is developed in any context, including, but not limited to, software or physical hardware, and solves tasks requiring human-like perception, cognition, planning, learning, communication or physical action, or (iii) is designed to (I) think or act like a human, including, but not limited to, a cognitive architecture or neural network, or (II) act rationally, including, but not limited to, an intelligent software agent or embodied robot that achieves goals using perception, planning, reasoning, learning, communication, decision-making or action, or (B) a set of techniques, including, but not limited to, machine learning, that is designed to approximate a cognitive task; and</strike>\n    <u class=\"amendmentInsertedText\">artificial intelligence system, as defined in section 1 of this act;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(2) &quot;Generative artificial intelligence&quot; means any form of artificial intelligence, including, but not limited to, a foundation model, that is able to produce synthetic digital content, as defined in section 1 of this act; and</u>\n   </p>\n   <p class=\"indent\">\n    <strike class=\"amendmentDeletedText\">(2)</strike>\n    <u class=\"amendmentInsertedText\">(3)</u> &quot;State agency&quot; has the same meaning as provided in section 4d-1.</p>\n   <p class=\"indent\">(b) (1) Not later than December 31, 2023, and annually thereafter, the <strike class=\"amendmentDeletedText\">Department</strike>\n    <u class=\"amendmentInsertedText\">Commissioner</u> of Administrative Services shall conduct an inventory of all systems that employ artificial intelligence and are in use by any state agency. Each such inventory shall include at least the following information for each such system:</p>\n   <p class=\"indent\">(A) The name of such system and the vendor, if any, that provided such system;</p>\n   <p class=\"indent\">(B) A description of the general capabilities and uses of such system;</p>\n   <p class=\"indent\">(C) Whether such system was used to independently make, inform or materially support a conclusion, decision or judgment; and</p>\n   <p class=\"indent\">(D) Whether such system underwent an impact assessment prior to implementation.</p>\n   <p class=\"indent\">(2) The <strike class=\"amendmentDeletedText\">Department</strike>\n    <u class=\"amendmentInsertedText\">Commissioner</u> of Administrative Services shall make each inventory conducted pursuant to subdivision (1) of this subsection publicly available on the state&#39;s open data portal.</p>\n   <p class=\"indent\">(c) Beginning on February 1, 2024, the <strike class=\"amendmentDeletedText\">Department</strike>\n    <u class=\"amendmentInsertedText\">Commissioner</u> of Administrative Services shall perform ongoing assessments of systems that employ artificial intelligence and are in use by state agencies to ensure that no such system shall result in any unlawful discrimination or disparate impact described in subparagraph (B) of subdivision (1) of subsection (b) of section 4-68jj. The <strike class=\"amendmentDeletedText\">department</strike>\n    <u class=\"amendmentInsertedText\">commissioner</u> shall perform such assessment in accordance with the policies and procedures established by the Office of Policy and Management pursuant to subsection (b) of section 4-68jj.</p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(d) The Commissioner of Administrative Services shall, in consultation with other state agencies, collective bargaining units that represent state agency employees and industry experts, develop trainings for state agency employees on (1) the use of generative artificial intelligence tools that are determined by the commissioner, pursuant to the assessment performed under subsection (c) of this section, to achieve equitable outcomes, and (2) methods for identifying and mitigating potential output inaccuracies, fabricated text, hallucinations and biases of generative artificial intelligence while respecting the privacy of the public and complying with all applicable state laws and policies. Beginning on July 1, 2026, the commissioner shall make such trainings available to state agency employees not less frequently than annually.</u>\n   </p>\n   <p class=\"indent\">Sec. 27. (NEW) (Effective July 1, 2025) The Department of Economic and Community Development shall, within available appropriations, design an algorithmic computer model for the purpose of simulating and assessing various public policy decisions, proposed public policy decisions and the actual or potential effects of such policy decisions. The department shall design such model in collaboration with public and private institutions of higher education in this state, the Department of Energy and Environmental Protection and any other state agency the Commissioner of Economic and Community Development, in the commissioner&#39;s discretion, deems relevant for the purposes of this section. Such model shall, at a minimum, be designed to (1) function as a digital twin of the population of the state, (2) algorithmically model (A) the actual or potential effects of planning and development decisions or proposed planning and development decisions, and (B) the actual or potential socioeconomic effects of macroeconomic shocks on businesses and families in the state, (3) utilize large quantities of data to support the development of public policies concerning coastline resiliency, family assistance and workforce development, and (4) enable data-driven governance by optimizing resource allocation and policy efficiency for the purpose of furthering economic resilience and social equity.</p>\n   <p class=\"indent\">Sec. 28. Section 53a-189c of the general statutes is repealed and the following is substituted in lieu thereof (Effective October 1, 2025):</p>\n   <p class=\"indent\">(a) A person is guilty of unlawful dissemination of an intimate image when (1) such person intentionally disseminates by electronic or other means a photograph, film, videotape or other recorded image <u class=\"amendmentInsertedText\">or synthetic image</u> of (A) the genitals, pubic area or buttocks of another person with less than a fully opaque covering of such body part, or the breast of such other person who is female with less than a fully opaque covering of any portion of such breast below the top of the nipple, or (B) another person engaged in sexual intercourse, as defined in section 53a-193, (2) such person disseminates such image <strike class=\"amendmentDeletedText\">without the consent of such other person,</strike> knowing that such other person <strike class=\"amendmentDeletedText\">understood that the image would not be so disseminated</strike>\n    <u class=\"amendmentInsertedText\">did not consent to such dissemination</u>, and (3) such other person suffers harm as a result of such dissemination.</p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b)</u> For purposes of this <strike class=\"amendmentDeletedText\">subsection, &quot;disseminate&quot;</strike>\n    <u class=\"amendmentInsertedText\">section:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(1) &quot;Disseminate&quot;</u> means to sell, give, provide, lend, trade, mail, deliver, transfer, publish, distribute, circulate, present, exhibit, advertise or otherwise offer<u class=\"amendmentInsertedText\">;</u>\n    <strike class=\"amendmentDeletedText\">, and &quot;harm&quot;</strike>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(2) &quot;Harm&quot;</u> includes, but is not limited to, subjecting such other person to hatred, contempt, ridicule, physical injury, financial injury, psychological harm or serious emotional distress<u class=\"amendmentInsertedText\">; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(3) &quot;Synthetic image&quot; means any photograph, film, videotape or other image that (A) is not wholly recorded by a camera, (B) is either partially or wholly generated by a computer system, and (C) depicts, and is virtually indistinguishable from an actual representation of, an identifiable person</u>.</p>\n   <p class=\"indent\">\n    <strike class=\"amendmentDeletedText\">(b)</strike>\n    <u class=\"amendmentInsertedText\">(c)</u> The provisions of subsection (a) of this <strike class=\"amendmentDeletedText\">subsection</strike>\n    <u class=\"amendmentInsertedText\">section</u> shall not apply to:</p>\n   <p class=\"indent\">(1) Any image described in subsection (a) of this section of such other person if such image resulted from voluntary exposure or engagement in sexual intercourse by such other person, in a public place, as defined in section 53a-181, or in a commercial setting;</p>\n   <p class=\"indent\">(2) Any image described in subsection (a) of this section of such other person, if such other person is not clearly identifiable, unless other personally identifying information is associated with or accompanies the image; or</p>\n   <p class=\"indent\">(3) Any image described in subsection (a) of this section of such other person, if the dissemination of such image serves the public interest.</p>\n   <p class=\"indent\">\n    <strike class=\"amendmentDeletedText\">(c)</strike>\n    <u class=\"amendmentInsertedText\">(d)</u> Unlawful dissemination of an intimate image to (1) a person by any means is a class A misdemeanor, and (2) more than one person by means of an interactive computer service, as defined in 47 USC 230, an information service, as defined in 47 USC 153, or a telecommunications service, as defined in section 16-247a, is a class D felony.</p>\n   <p class=\"indent\">\n    <strike class=\"amendmentDeletedText\">(d)</strike>\n    <u class=\"amendmentInsertedText\">(e)</u> Nothing in this section shall be construed to impose liability on the provider of an interactive computer service, as defined in 47 USC 230, an information service, as defined in 47 USC 153, or a telecommunications service, as defined in section 16-247a, for content provided by another person.</p>\n   <table>\n    <tr>\n     <td colspan=\"3\">This act shall take effect as follows and shall amend the following sections:<br/>\n     </td>\n    </tr>\n    <tr>\n     <td>Section 1</td>\n     <td>October 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 2</td>\n     <td>October 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 3</td>\n     <td>October 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 4</td>\n     <td>October 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 5</td>\n     <td>October 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 6</td>\n     <td>October 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 7</td>\n     <td>October 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 8</td>\n     <td>October 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 9</td>\n     <td>October 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 10</td>\n     <td>October 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 11</td>\n     <td>October 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 12</td>\n     <td>October 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 13</td>\n     <td>July 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 14</td>\n     <td>July 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 15</td>\n     <td>July 1, 2025</td>\n     <td>17b-751b(b)</td>\n    </tr>\n    <tr>\n     <td>Sec. 16</td>\n     <td>July 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 17</td>\n     <td>July 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 18</td>\n     <td>July 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 19</td>\n     <td>July 1, 2025</td>\n     <td>10-21l</td>\n    </tr>\n    <tr>\n     <td>Sec. 20</td>\n     <td>July 1, 2025</td>\n     <td>32-7p</td>\n    </tr>\n    <tr>\n     <td>Sec. 21</td>\n     <td>July 1, 2025</td>\n     <td>32-235(b)</td>\n    </tr>\n    <tr>\n     <td>Sec. 22</td>\n     <td>July 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 23</td>\n     <td>July 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 24</td>\n     <td>July 1, 2025</td>\n     <td>32-39e</td>\n    </tr>\n    <tr>\n     <td>Sec. 25</td>\n     <td>July 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 26</td>\n     <td>July 1, 2025</td>\n     <td>4a-2e</td>\n    </tr>\n    <tr>\n     <td>Sec. 27</td>\n     <td>July 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 28</td>\n     <td>October 1, 2025</td>\n     <td>53a-189c</td>\n    </tr>\n   </table>\n   <p class=\"indent\">\n    <b>Statement of Legislative Commissioners: </b>\n   </p>\n   <p class=\"indent\">In Section 1(9)(B), &quot;or system&quot; was added after &quot;unless the technology&quot; and &quot;does not include&quot; was added before &quot;(i)&quot; for internal consistency; in Section 1(13), &quot;identify&quot; was added before &quot;how&quot; for internal consistency; in Section 3(d)(2)(B), &quot;any intentional&quot; was changed to &quot;an intentional&quot; for consistency; in Section 4(e)(1)(B)(ii), &quot;said subparagraph (C)&quot; was changed to &quot;said subparagraph&quot; for consistency with standard drafting conventions; in Section 12(b)(3), &quot;being&quot; was added before &quot;exempt&quot; for clarity; in Section 12(d), &quot;subparagraph (B) of&quot; was added before &quot;subdivision (2)&quot; for accuracy; and in Sections 12(g), 16(e)(3), 17(b), 23(d) and 25(f), &quot;the provisions of&quot; was added before &quot;section 11-4a&quot; for consistency with standard drafting conventions.</p>\n  </div>\n </div>\n    </div>\t\n<table cellpadding=0 cellspacing=0 width=\"100%\">\n   <tr>\n      <td>\n          Copyright &copy; 2025 State Net\n      </td>\n<BR>\n<!--???MOVED INTO resources.cgi      <td align=\"right\">\n          <img src=\"https://custom.statenet.com/network/poweredby.gif\" alt=\"Powered by State Net\">\n      </td>-->\n\n    </tr>\n</table>\n</body></html>\n",
      "markdown": "The following has special meaning: _green underline denotes added text_ ~~red struck out text denotes deleted text~~ | [![Powered by State Net](https://custom.statenet.com/network/poweredby.gif)](https://www.lexisnexis.com/statenet/)  \n---|---  \n  \n2025 CT S 2 | | Author: | Looney  \n---|---  \nVersion: | Reissued  \nVersion Date: | 04/09/2025  \n  \n**STATE OF CONNECTICUT**\n\nGeneral Assembly\n\nFile No. 603\n\n**January Session, 2025**\n\nSubstitute Senate Bill No. 2\n\nSenate, April 9, 2025\n\nThe Committee on General Law reported through SEN. MARONEY of the 14th Dist.,\nChairperson of the Committee on the part of the Senate, that the substitute\nbill ought to pass.\n\nAN ACT CONCERNING ARTIFICIAL INTELLIGENCE.\n\nBe it enacted by the Senate and House of Representatives in General Assembly\nconvened:\n\nSection 1. (NEW) (Effective October 1, 2025) For the purposes of this section\nand sections 2 to 10, inclusive, of this act, unless the context otherwise\nrequires:\n\n(1) \"Algorithmic discrimination\" (A) means any use of an artificial\nintelligence system that results in any unlawful differential treatment or\nimpact that disfavors any individual or group of individuals on the basis of\none or more classifications protected under the laws of this state or federal\nlaw, and (B) does not include (i) the offer, license or use of a high-risk\nartificial intelligence system by a developer, integrator or deployer for the\nsole purpose of (I) the developer's, integrator's or deployer's testing to\nidentify, mitigate or prevent discrimination or otherwise ensure compliance\nwith state and federal law, or (II) expanding an applicant, customer or\nparticipant pool to increase diversity or redress historic discrimination, or\n(ii) an act or omission by or on behalf of a private club or other\nestablishment not in fact open to the public, as set forth in Title II of the\nCivil Rights Act of 1964, 42 USC 2000a(e), as amended from time to time;\n\n(2) \"Artificial intelligence system\" means any machine-based system that, for\nany explicit or implicit objective, infers from the inputs such system\nreceives how to generate outputs, including, but not limited to, content,\ndecisions, predictions or recommendations, that can influence physical or\nvirtual environments;\n\n(3) \"Consequential decision\" means any decision or judgment that has a\nmaterial legal or similarly significant effect on a consumer with respect to\n(A) access to employment, including, but not limited to, any such decision or\njudgment made concerning hiring, termination, compensation or promotion, (B)\naccess to education or vocational training, including, but not limited to, any\nsuch decision or judgment made concerning admissions, financial aid or\nscholarships, (C) the provision or denial, or terms and conditions, of (i)\nfinancial lending or credit services, (ii) housing or lodging, including, but\nnot limited to, rentals or short-term housing or lodging, (iii) insurance, or\n(iv) legal services, or (D) access to (i) essential government services, or\n(ii) health care services;\n\n(4) \"Consumer\" means any individual who is a resident of this state;\n\n(5) \"Deploy\" means to put a high-risk artificial intelligence system into use;\n\n(6) \"Deployer\" means any person doing business in this state that deploys a\nhigh-risk artificial intelligence system in this state;\n\n(7) \"Developer\" means any person doing business in this state that develops,\nor intentionally and substantially modifies, an artificial intelligence\nsystem;\n\n(8) \"General-purpose artificial intelligence model\" (A) means a model used by\nan artificial intelligence system that (i) displays significant generality,\n(ii) is capable of competently performing a wide range of distinct tasks, and\n(iii) can be integrated into a variety of downstream applications or systems,\nand (B) does not include any artificial intelligence model that is used for\ndevelopment, prototyping and research activities before such artificial\nintelligence model is released on the market;\n\n(9) \"High-risk artificial intelligence system\" (A) means any artificial\nintelligence system that is intended, when deployed, to make, or be a\nsubstantial factor in making, a consequential decision, and (B) unless the\ntechnology or system, when deployed, makes, or is a substantial factor in\nmaking, a consequential decision, does not include (i) any anti-fraud\ntechnology that does not make use of facial recognition technology, (ii) any\nartificial intelligence-enabled video game technology, (iii) any anti-malware,\nanti-virus, calculator, cybersecurity, database, data storage, firewall,\nInternet domain registration, Internet-web-site loading, networking, robocall-\nfiltering, spam-filtering, spellchecking, spreadsheet, web-caching, web-\nhosting or similar technology, (iv) any technology that performs tasks\nexclusively related to an entity's internal management affairs, including, but\nnot limited to, ordering office supplies or processing payments, (v) any\nsystem that classifies incoming documents into categories, is used to detect\nduplicate applications among a large number of applications or otherwise\nperforms narrow tasks of such a limited nature that performance of such tasks\nposes a limited risk of algorithmic discrimination, (vi) any technology that\nmerely detects decision-making patterns or deviations from prior decision-\nmaking patterns following a previously completed human assessment that such\ntechnology is not meant to replace or influence without sufficient human\nreview, including, but not limited to, any technology that analyzes a\nparticular decision-maker's prior pattern of decisions and flags potential\ninconsistencies or anomalies, or (vii) any technology that communicates with\nconsumers in natural language for the purpose of providing users with\ninformation, making referrals or recommendations and answering questions, and\nis subject to an acceptable use policy that prohibits generating content that\nis discriminatory or harmful;\n\n(10) \"Integrator\" means any person doing business in this state that, with\nrespect to a given high-risk artificial intelligence system, (A) neither\ndevelops nor intentionally and substantially modifies the high-risk artificial\nintelligence system, and (B) integrates the high-risk artificial intelligence\nsystem into a product or service such person offers to any other person;\n\n(11) \"Intentional and substantial modification\" (A) means any deliberate\nmaterial change made to (i) an artificial intelligence system that was not\npredetermined by a developer and materially increases the risk of algorithmic\ndiscrimination, or (ii) a general-purpose artificial intelligence model that\n(I) affects compliance of the general-purpose artificial intelligence model,\n(II) materially changes the purpose of the general-purpose artificial\nintelligence model, or (III) materially increases the risk of algorithmic\ndiscrimination, and (B) does not include any change made to a high-risk\nartificial intelligence system, or the performance of a high-risk artificial\nintelligence system, if (i) the high-risk artificial intelligence system\ncontinues to learn after such high-risk artificial intelligence system is (I)\noffered, sold, leased, licensed, given or otherwise made available to a\ndeployer, or (II) deployed, and (ii) such change (I) is made to such high-risk\nartificial intelligence system as a result of any learning described in\nsubparagraph (B)(i) of this subdivision, (II) was predetermined by the\ndeployer, or the third party contracted by the deployer, when such deployer or\nthird party completed the initial impact assessment of such high-risk\nartificial intelligence system pursuant to subsection (c) of section 4 of this\nact, and (III) is included in the technical documentation for such high-risk\nartificial intelligence system;\n\n(12) \"Person\" means any individual, association, corporation, limited\nliability company, partnership, trust or other legal entity;\n\n(13) \"Red-teaming\" means an adversarial exercise that is conducted to identify\nthe potential adverse behaviors or outcomes of an artificial intelligence\nsystem, identify how such behaviors or outcomes occur and stress test the\nsafeguards against such behaviors or outcomes;\n\n(14) \"Substantial factor\" (A) means a factor that (i) alters the outcome of a\nconsequential decision, and (ii) is generated by an artificial intelligence\nsystem, (B) includes, but is not limited to, any use of an artificial\nintelligence system to generate any content, decision, prediction or\nrecommendation concerning a consumer that is used as a basis to make a\nconsequential decision concerning the consumer, and (C) does not include any\noutput produced by an artificial intelligence system where an individual was\ninvolved in the data processing that produced such output and such individual\n(i) meaningfully considered such data as part of such data processing, and\n(ii) had the authority to change or influence the output produced by such data\nprocessing;\n\n(15) \"Synthetic digital content\" means any digital content, including, but not\nlimited to, any audio, image, text or video, that is produced or manipulated\nby an artificial intelligence system, including, but not limited to, a\ngeneral-purpose artificial intelligence model; and\n\n(16) \"Trade secret\" has the same meaning as provided in section 35-51 of the\ngeneral statutes.\n\nSec. 2. (NEW) (Effective October 1, 2025) (a) Beginning on October 1, 2026, a\ndeveloper of a high-risk artificial intelligence system shall use reasonable\ncare to protect consumers from any known or reasonably foreseeable risks of\nalgorithmic discrimination arising from the intended and contracted uses of\nthe high-risk artificial intelligence system. In any enforcement action\nbrought on or after said date by the Attorney General pursuant to section 10\nof this act, there shall be a rebuttable presumption that a developer used\nreasonable care as required under this subsection if the developer complied\nwith the provisions of this section or, if the developer enters into a\ncontract with an integrator as set forth in subsection (b) of section 3 of\nthis act, the developer and integrator complied with the provisions of this\nsection and section 3 of this act.\n\n(b) Except as provided in subsection (c) of section 3 of this act, a developer\nof a high-risk artificial intelligence system shall, beginning on October 1,\n2026, make available to each deployer, or other developer, of the high-risk\nartificial intelligence system:\n\n(1) A general statement describing the intended uses, and the known harmful or\ninappropriate uses, of such high-risk artificial intelligence system;\n\n(2) (A) Documentation disclosing (i) high-level summaries of the type of data\nused to train such high-risk artificial intelligence system, (ii) the known or\nreasonably foreseeable limitations of such high-risk artificial intelligence\nsystem, including, but not limited to, the known or reasonably foreseeable\nrisks of algorithmic discrimination arising from the intended uses of such\nhigh-risk artificial intelligence system, (iii) the purpose of such high-risk\nartificial intelligence system, and (iv) the intended benefits and uses of\nsuch high-risk artificial intelligence system, and (B) any additional\ndocumentation that is reasonably necessary to assist such deployer or other\ndeveloper to understand the outputs, and monitor the performance, of such\nhigh-risk artificial intelligence system to enable such deployer or other\ndeveloper to comply with the provisions of sections 1 to 10, inclusive, of\nthis act; and\n\n(3) Documentation describing (A) how such high-risk artificial intelligence\nsystem was evaluated for performance, and mitigation of algorithmic\ndiscrimination, before such high-risk artificial intelligence system was\noffered, sold, leased, licensed, given or otherwise made available to such\ndeployer, (B) the data governance measures used to cover the training datasets\nand the measures used to examine the suitability of data sources, possible\nbiases and appropriate mitigation, (C) the intended outputs of such high-risk\nartificial intelligence system, (D) the measures the developer has taken to\nmitigate any known or reasonably foreseeable risks of algorithmic\ndiscrimination that may arise from deployment of such high-risk artificial\nintelligence system, and (E) how such high-risk artificial intelligence system\nis intended to be used, based on known or reasonably foreseeable harmful or\ninappropriate applications, and be monitored by an individual when such high-\nrisk artificial intelligence system is used to make, or as a substantial\nfactor in making, a consequential decision.\n\n(c) (1) Except as provided in subsection (c) of section 3 of this act, any\ndeveloper that, on or after October 1, 2026, offers, sells, leases, licenses,\ngives or otherwise makes available to a deployer or another developer a high-\nrisk artificial intelligence system shall, to the extent feasible, make\navailable to the deployers and other developers of such high-risk artificial\nintelligence system the documentation and information necessary for a\ndeployer, or the third party contracted by a deployer, to complete an impact\nassessment pursuant to subsection (c) of section 4 of this act. The developer\nshall make such documentation and information available through artifacts such\nas system cards or other impact assessments.\n\n(2) A developer that also serves as a deployer for any high-risk artificial\nintelligence system shall not be required to generate the documentation\nrequired by this section unless such high-risk artificial intelligence system\nis provided to another person that serves as a deployer for such high-risk\nartificial intelligence system.\n\n(d) (1) Beginning on October 1, 2026, each developer shall make available, in\na manner that is clear and readily available on such developer's Internet web\nsite or in a public use case inventory, a statement summarizing:\n\n(A) The types of high-risk artificial intelligence systems that such developer\n(i) has developed or intentionally and substantially modified, and (ii)\ncurrently makes available to a deployer or another developer; and\n\n(B) How such developer manages any known or reasonably foreseeable risks of\nalgorithmic discrimination that may arise from the intended uses of the types\nof high-risk artificial intelligence systems described in subparagraph (A) of\nthis subdivision.\n\n(2) Each developer shall update the statement made available pursuant to\nsubdivision (1) of this subsection (A) as necessary to ensure that such\nstatement remains accurate, and (B) not later than ninety days after the\ndeveloper intentionally and substantially modifies any high-risk artificial\nintelligence system described in subparagraph (A) of subdivision (1) of this\nsubsection.\n\n(3) Where multiple developers contribute to the development of a high-risk\nartificial intelligence system, each developer shall be subject to the\nobligations applicable to developers under sections 1 to 10, inclusive, of\nthis act solely with respect to the activities the developer performed in\ncontributing to the development of such high-risk artificial intelligence\nsystem.\n\n(e) Beginning on October 1, 2026, a developer of a high-risk artificial\nintelligence system shall disclose to the Attorney General, in a form and\nmanner prescribed by the Attorney General, and to all known deployers or other\ndevelopers of the high-risk artificial intelligence system, any previously\ndisclosed known or reasonably foreseeable risks of algorithmic discrimination\narising from the intended uses of such high-risk artificial intelligence\nsystem. The developer shall make such disclosures without unreasonable delay\nbut in no event later than ninety days after the date on which:\n\n(1) The developer discovers, through the developer's ongoing testing and\nanalysis, that the high-risk artificial intelligence system has (A) been\ndeployed, and (B) caused, or is reasonably likely to have caused, algorithmic\ndiscrimination to at least one thousand consumers; or\n\n(2) The developer receives, from a deployer of the high-risk artificial\nintelligence system, a credible report disclosing that such high-risk\nartificial intelligence system has (A) been deployed, and (B) caused\nalgorithmic discrimination to at least one thousand consumers.\n\n(f) The provisions of subsections (b) to (e), inclusive, of this section shall\nnot be construed to require a developer to disclose any information (1) that\nis a trade secret or otherwise protected from disclosure under state or\nfederal law, or (2) the disclosure of which would present a security risk to\nthe developer.\n\n(g) Notwithstanding the provisions of subsections (a) to (f), inclusive, of\nthis section, (1) any documentation a developer completes for the purpose of\ncomplying with another applicable law or regulation shall be deemed to satisfy\nthe requirements established in this section if such documentation is\nreasonably similar in scope and effect to the documentation the developer\nwould otherwise be required to complete pursuant to this section, and (2) a\ndeveloper may contract with a third party to fulfill the developer's duties\nunder this section.\n\n(h) Beginning on October 1, 2026, the Attorney General may require that a\ndeveloper disclose to the Attorney General, as part of an investigation\nconducted by the Attorney General regarding a suspected violation of any\nprovision of sections 1 to 10, inclusive, of this act and in a form and manner\nprescribed by the Attorney General, the general statement or documentation\ndescribed in subsection (b) of this section. The Attorney General may evaluate\nsuch general statement or documentation to ensure compliance with the\nprovisions of this section. In disclosing such general statement or\ndocumentation to the Attorney General pursuant to this subsection, the\ndeveloper may designate such general statement or documentation as including\nany information that is exempt from disclosure under subsection (f) of this\nsection or the Freedom of Information Act, as defined in section 1-200 of the\ngeneral statutes. To the extent such general statement or documentation\nincludes such information, such general statement or documentation shall be\nexempt from disclosure under subsection (f) of this section or said act. To\nthe extent any information contained in such general statement or\ndocumentation is subject to the attorney-client privilege or work product\nprotection, such disclosure shall not constitute a waiver of such privilege or\nprotection.\n\nSec. 3. (NEW) (Effective October 1, 2025) (a) Beginning on October 1, 2026, if\nan integrator integrates a high-risk artificial intelligence system into a\nproduct or service the integrator offers to any other person, such integrator\nshall use reasonable care to protect consumers from any known or reasonably\nforeseeable risks of algorithmic discrimination arising from the intended and\ncontracted uses of such integrated high-risk artificial intelligence system.\nIn any enforcement action brought on or after said date by the Attorney\nGeneral pursuant to section 10 of this act, there shall be a rebuttable\npresumption that the integrator used reasonable care as required under this\nsubsection if the integrator complied with the provisions of this section.\n\n(b) Beginning on October 1, 2026, no integrator shall integrate a high-risk\nartificial intelligence system into a product or service the integrator offers\nto any other person unless the integrator has entered into a contract with the\ndeveloper of the high-risk artificial intelligence system. The contract shall\nbe binding and clearly set forth the duties of the developer and integrator\nwith respect to the integrated high-risk artificial intelligence system,\nincluding, but not limited to, whether the developer or integrator shall be\nresponsible for performing the developer's duties under subsections (b) and\n(c) of section 2 of this act.\n\n(c) The provisions of subsections (b) and (c) of section 2 of this act shall\nnot apply to a developer of an integrated high-risk artificial intelligence\nsystem if, at all times while the integrated high-risk artificial intelligence\nsystem is integrated into a product or service an integrator offers to any\nother person, the developer has entered into a contract with the integrator in\nwhich such integrator has agreed to assume the developer's duties under\nsubsections (b) and (c) of section 2 of this act.\n\n(d) (1) Beginning on October 1, 2026, each integrator shall make available, in\na manner that is clear and readily available on such integrator's Internet web\nsite or in a public use case inventory, a statement summarizing:\n\n(A) The types of high-risk artificial intelligence systems that such\nintegrator has integrated into products or services such integrator currently\noffers to any other person; and\n\n(B) How such integrator manages any known or reasonably foreseeable risks of\nalgorithmic discrimination that may arise from the types of high-risk\nartificial intelligence systems described in subparagraph (A) of this\nsubdivision.\n\n(2) Each integrator shall update the statement made available pursuant to\nsubdivision (1) of this subsection (A) as necessary to ensure that such\nstatement remains accurate, and (B) not later than ninety days after an\nintentional and substantial modification is made to any high-risk artificial\nintelligence system described in subparagraph (A) of subdivision (1) of this\nsubsection.\n\n(e) The provisions of subsections (b) to (d), inclusive, of this section shall\nnot be construed to require a developer or integrator to disclose any\ninformation (1) that is a trade secret or otherwise protected from disclosure\nunder state or federal law, or (2) the disclosure of which would present a\nsecurity risk to the developer or integrator.\n\n(f) Beginning on October 1, 2026, the Attorney General may require that an\nintegrator which has assumed a developer's duties under subsection (c) of\nsection 2 of this act disclose to the Attorney General, as part of an\ninvestigation conducted by the Attorney General regarding a suspected\nviolation of any provision of sections 1 to 10, inclusive, of this act and in\na form and manner prescribed by the Attorney General, the general statement or\ndocumentation described in said subsection. The Attorney General may evaluate\nsuch general statement or documentation to ensure compliance with the\nprovisions of this section and section 2 of this act. In disclosing such\ngeneral statement or documentation to the Attorney General pursuant to this\nsubsection, the integrator may designate such general statement or\ndocumentation as including any information that is exempt from disclosure\nunder subsection (e) of this section or the Freedom of Information Act, as\ndefined in section 1-200 of the general statutes. To the extent such general\nstatement or documentation includes such information, such general statement\nor documentation shall be exempt from disclosure under subsection (e) of this\nsection or said act. To the extent any information contained in such general\nstatement or documentation is subject to the attorney-client privilege or work\nproduct protection, such disclosure shall not constitute a waiver of such\nprivilege or protection.\n\nSec. 4. (NEW) (Effective October 1, 2025) (a) Beginning on October 1, 2026,\neach deployer of a high-risk artificial intelligence system shall use\nreasonable care to protect consumers from any known or reasonably foreseeable\nrisks of algorithmic discrimination. In any enforcement action brought on or\nafter said date by the Attorney General pursuant to section 10 of this act,\nthere shall be a rebuttable presumption that a deployer of a high-risk\nartificial intelligence system used reasonable care as required under this\nsubsection if the deployer complied with the provisions of this section.\n\n(b) (1) Beginning on October 1, 2026, and except as provided in subsection (g)\nof this section, each deployer of a high-risk artificial intelligence system\nshall implement and maintain a risk management policy and program to govern\nsuch deployer's deployment of the high-risk artificial intelligence system.\nThe risk management policy and program shall specify and incorporate the\nprinciples, processes and personnel that the deployer shall use to identify,\ndocument and mitigate any known or reasonably foreseeable risks of algorithmic\ndiscrimination. The risk management policy shall be the product of an\niterative process, the risk management program shall be an iterative process\nand both the risk management policy and program shall be planned, implemented\nand regularly and systematically reviewed and updated over the lifecycle of\nthe high-risk artificial intelligence system. Each risk management policy and\nprogram implemented and maintained pursuant to this subsection shall be\nreasonable, considering:\n\n(A) The guidance and standards set forth in the latest version of (i) the\n\"Artificial Intelligence Risk Management Framework\" published by the National\nInstitute of Standards and Technology, (ii) ISO or IEC 42001 of the\nInternational Organization for Standardization, or (iii) a nationally or\ninternationally recognized risk management framework for artificial\nintelligence systems, other than the guidance and standards specified in\nsubparagraphs (A)(i) and (A)(ii) of this subdivision, that imposes\nrequirements that are substantially equivalent to, and at least as stringent\nas, the requirements set forth in this section for risk management policies\nand programs;\n\n(B) The size and complexity of the deployer;\n\n(C) The nature and scope of the high-risk artificial intelligence systems\ndeployed by the deployer, including, but not limited to, the intended uses of\nsuch high-risk artificial intelligence systems; and\n\n(D) The sensitivity and volume of data processed in connection with the high-\nrisk artificial intelligence systems deployed by the deployer.\n\n(2) A risk management policy and program implemented and maintained pursuant\nto subdivision (1) of this subsection may cover multiple high-risk artificial\nintelligence systems deployed by the deployer.\n\n(c) (1) Except as provided in subdivisions (3) and (4) of this subsection and\nsubsection (g) of this section:\n\n(A) A deployer that deploys a high-risk artificial intelligence system on or\nafter October 1, 2026, or a third party contracted by the deployer, shall\ncomplete an impact assessment of the high-risk artificial intelligence system;\nand\n\n(B) Beginning on October 1, 2026, a deployer, or a third party contracted by\nthe deployer, shall complete an impact assessment of a deployed high-risk\nartificial intelligence system (i) at least annually, and (ii) not later than\nninety days after an intentional and substantial modification to such high-\nrisk artificial intelligence system is made available.\n\n(2) (A) Each impact assessment completed pursuant to this subsection shall\ninclude, at a minimum and to the extent reasonably known by, or available to,\nthe deployer:\n\n(i) A statement by the deployer disclosing the purpose, intended use cases and\ndeployment context of, and benefits afforded by, the high-risk artificial\nintelligence system;\n\n(ii) An analysis of whether the deployment of the high-risk artificial\nintelligence system poses any known or reasonably foreseeable risks of\nalgorithmic discrimination and, if so, the nature of such algorithmic\ndiscrimination and the steps that have been taken to mitigate such risks;\n\n(iii) A description of (I) the categories of data the high-risk artificial\nintelligence system processes as inputs, and (II) the outputs such high-risk\nartificial intelligence system produces;\n\n(iv) If the deployer used data to customize the high-risk artificial\nintelligence system, an overview of the categories of data the deployer used\nto customize such high-risk artificial intelligence system;\n\n(v) Any metrics used to evaluate the performance and known limitations of the\nhigh-risk artificial intelligence system;\n\n(vi) A high-level description of any transparency measures taken concerning\nthe high-risk artificial intelligence system, including, but not limited to,\nany measures taken to disclose to a consumer that such high-risk artificial\nintelligence system is in use when such high-risk artificial intelligence\nsystem is in use; and\n\n(vii) A high-level description of the post-deployment monitoring and user\nsafeguards provided concerning such high-risk artificial intelligence system,\nincluding, but not limited to, the oversight, use and learning process\nestablished by the deployer to address issues arising from deployment of such\nhigh-risk artificial intelligence system.\n\n(B) In addition to the statement, analysis, descriptions, overview and metrics\nrequired under subparagraph (A) of this subdivision, an impact assessment\ncompleted pursuant to this subsection following an intentional and substantial\nmodification made to a high-risk artificial intelligence system on or after\nOctober 1, 2026, shall include a high-level statement disclosing the extent to\nwhich the high-risk artificial intelligence system was used in a manner that\nwas consistent with, or varied from, the developer's intended uses of such\nhigh-risk artificial intelligence system.\n\n(3) A single impact assessment may address a comparable set of high-risk\nartificial intelligence systems deployed by a deployer.\n\n(4) If a deployer, or a third party contracted by the deployer, completes an\nimpact assessment for the purpose of complying with another applicable law or\nregulation, such impact assessment shall be deemed to satisfy the requirements\nestablished in this subsection if such impact assessment is reasonably similar\nin scope and effect to the impact assessment that would otherwise be completed\npursuant to this subsection.\n\n(5) A deployer shall maintain the most recently completed impact assessment of\na high-risk artificial intelligence system as required under this subsection,\nall records concerning each such impact assessment and all prior impact\nassessments, if any, for a period of at least three years following the final\ndeployment of the high-risk artificial intelligence system.\n\n(d) Except as provided in subsection (g) of this section, a deployer, or a\nthird party contracted by the deployer, shall review, not later than October\n1, 2026, and at least annually thereafter, the deployment of each high-risk\nartificial intelligence system deployed by the deployer to ensure that such\nhigh-risk artificial intelligence system is not causing algorithmic\ndiscrimination.\n\n(e) (1) Beginning on October 1, 2026, and before a deployer deploys a high-\nrisk artificial intelligence system to make, or be a substantial factor in\nmaking, a consequential decision concerning a consumer, the deployer shall:\n\n(A) Notify the consumer that the deployer has deployed a high-risk artificial\nintelligence system to make, or be a substantial factor in making, such\nconsequential decision; and\n\n(B) Provide to the consumer (i) a statement disclosing (I) the purpose of such\nhigh-risk artificial intelligence system, and (II) the nature of such\nconsequential decision, (ii) if applicable, information concerning the\nconsumer's right, under subparagraph (C) of subdivision (5) of subsection (a)\nof section 42-518 of the general statutes, to opt-out of the processing of the\nconsumer's personal data for the purposes set forth in said subparagraph,\n(iii) contact information for such deployer, (iv) a description, in plain\nlanguage, of such high-risk artificial intelligence system, and (v)\ninstructions on how to access the statement made available pursuant to\nsubdivision (1) of subsection (f) of this section.\n\n(2) Beginning on October 1, 2026, a deployer that has deployed a high-risk\nartificial intelligence system to make, or as a substantial factor in making,\na consequential decision concerning a consumer shall, if such consequential\ndecision is adverse to the consumer, provide to such consumer:\n\n(A) A high-level statement disclosing the principal reason or reasons for such\nadverse consequential decision, including, but not limited to, (i) the degree\nto which, and manner in which, the high-risk artificial intelligence system\ncontributed to such adverse consequential decision, (ii) the type of data that\nwere processed by such high-risk artificial intelligence system in making such\nadverse consequential decision, and (iii) the source of the data described in\nsubparagraph (A)(ii) of this subdivision;\n\n(B) An opportunity to (i) examine the personal data that the high-risk\nartificial intelligence system processed in making, or as a substantial factor\nin making, such adverse consequential decision, and (ii) correct any incorrect\npersonal data described in subparagraph (B)(i) of this subdivision; and\n\n(C) (i) Except as provided in subparagraph (C)(ii) of this subdivision, an\nopportunity to appeal such adverse consequential decision if such adverse\nconsequential decision is based upon inaccurate personal data, taking into\naccount both the nature of such personal data and the purpose for which such\npersonal data was processed. Such appeal shall, if technically feasible, allow\nfor human review.\n\n(ii) No deployer shall be required to provide an opportunity to appeal\npursuant to subparagraph (C)(i) of this subdivision in any instance in which\nproviding such opportunity to appeal is not in the best interest of the\nconsumer, including, but not limited to, in any instance in which any delay\nmight pose a risk to the life or safety of the consumer.\n\n(3) The deployer shall provide the notice, statements, information,\ndescription and instructions required under subdivisions (1) and (2) of this\nsubsection:\n\n(A) Directly to the consumer;\n\n(B) In plain language;\n\n(C) In all languages in which such deployer, in the ordinary course of such\ndeployer's business, provides contracts, disclaimers, sale announcements and\nother information to consumers; and\n\n(D) In a format that is accessible to consumers with disabilities.\n\n(f) (1) Beginning on October 1, 2026, and except as provided in subsection (g)\nof this section, each deployer shall make available, in a manner that is clear\nand readily available on such deployer's Internet web site, a statement\nsummarizing:\n\n(A) The types of high-risk artificial intelligence systems that are currently\ndeployed by such deployer;\n\n(B) How such deployer manages any known or reasonably foreseeable risks of\nalgorithmic discrimination that may arise from deployment of each high-risk\nartificial intelligence system described in subparagraph (A) of this\nsubdivision;\n\n(C) In detail, the nature, source and extent of the information collected and\nused by such deployer; and\n\n(D) How the consumer may exercise rights under section 42-518 of the general\nstatutes by the secure and reliable means established and described pursuant\nto subsection (b) of section 42-518 of the general statutes.\n\n(2) Each deployer shall periodically update the statement made available\npursuant to subdivision (1) of this subsection.\n\n(g) The provisions of subsections (b) to (d), inclusive, of this section and\nsubsection (f) of this section shall not apply to a deployer if, at the time\nthe deployer deploys a high-risk artificial intelligence system and at all\ntimes while the high-risk artificial intelligence system is deployed:\n\n(1) The deployer (A) has entered into a contract with the developer in which\nthe developer has agreed to assume the deployer's duties under subsections (b)\nto (d), inclusive, of this section and subsection (f) of this section, and (B)\ndoes not exclusively use such deployer's own data to train such high-risk\nartificial intelligence system;\n\n(2) Such high-risk artificial intelligence system (A) is used for the intended\nuses that are disclosed to such deployer as set forth in subparagraph (A)(iv)\nof subdivision (2) of subsection (b) of section 2 of this act, and (B)\ncontinues learning based on a broad range of data sources and not solely based\non the deployer's own data; and\n\n(3) Such deployer makes available to consumers any impact assessment that (A)\nthe developer of such high-risk artificial intelligence system has completed\nand provided to such deployer, and (B) includes information that is\nsubstantially similar to the information included in the statement, analysis,\ndescriptions, overview and metrics required under subparagraph (A) of\nsubdivision (2) of subsection (c) of this section.\n\n(h) If a deployer deploys a high-risk artificial intelligence system on or\nafter October 1, 2026, and subsequently discovers that the high-risk\nartificial intelligence system has caused algorithmic discrimination to at\nleast one thousand consumers, the deployer shall send to the Attorney General,\nin a form and manner prescribed by the Attorney General, a notice disclosing\nsuch discovery. The deployer shall send such notice to the Attorney General\nwithout unreasonable delay but in no event later than ninety days after the\ndate on which the deployer discovered such algorithmic discrimination.\n\n(i) Nothing in subsections (b) to (h), inclusive, of this section shall be\nconstrued to require a deployer to disclose any information that is a trade\nsecret or otherwise protected from disclosure under state or federal law. If a\ndeployer withholds any information from a consumer under this subsection, the\ndeployer shall send notice to the consumer disclosing (1) that the deployer is\nwithholding such information from such consumer, and (2) the basis for the\ndeployer's decision to withhold such information from such consumer.\n\n(j) Beginning on October 1, 2026, the Attorney General may require that a\ndeployer, or a third party contracted by the deployer as set forth in\nsubsection (c) of this section, as applicable, disclose to the Attorney\nGeneral, as part of an investigation conducted by the Attorney General\nregarding a suspected violation of any provision of sections 1 to 10,\ninclusive, of this act, not later than ninety days after a request by the\nAttorney General and in a form and manner prescribed by the Attorney General,\nthe risk management policy implemented pursuant to subsection (b) of this\nsection, impact assessment completed pursuant to subsection (c) of this\nsection or records maintained pursuant to subdivision (5) of subsection (c) of\nthis section. The Attorney General may evaluate such risk management policy,\nimpact assessment or records to ensure compliance with the provisions of this\nsection. In disclosing such risk management policy, impact assessment or\nrecords to the Attorney General pursuant to this subsection, the deployer or\nthird-party contractor, as applicable, may designate such risk management\npolicy, impact assessment or records as including any information that is\nexempt from disclosure under subsection (i) of this section or the Freedom of\nInformation Act, as defined in section 1-200 of the general statutes. To the\nextent such risk management policy, impact assessment or records include such\ninformation, such risk management policy, impact assessment or records shall\nbe exempt from disclosure under subsection (i) of this section or said act. To\nthe extent any information contained in such risk management policy, impact\nassessment or record is subject to the attorney-client privilege or work\nproduct protection, such disclosure shall not constitute a waiver of such\nprivilege or protection.\n\nSec. 5. (NEW) (Effective October 1, 2025) (a) Beginning on October 1, 2026,\neach developer of a general-purpose artificial intelligence model that is\ncapable of being used by a high-risk artificial intelligence system shall, to\nthe extent feasible and except as provided in subsection (b) of this section,\nmake available to:\n\n(1) Each deployer of such general-purpose artificial intelligence model,\nthrough artifacts such as system cards or other impact assessments, the\ndocumentation and information necessary for such deployer, or a third party\ncontracted by such deployer, to complete an impact assessment pursuant to\nsubsection (c) of section 4 of this act; and\n\n(2) Each deployer or other developer of such general-purpose artificial\nintelligence model any additional documentation that is reasonably necessary\nto assist such deployer or other developer to understand the outputs, and\nmonitor the performance, of the general-purpose artificial intelligence model\nto enable such deployer or other developer to comply with the provisions of\nsections 1 to 10, inclusive, of this act.\n\n(b) (1) The provisions of subsection (a) of this section shall not apply to a\ndeveloper that develops, or intentionally and substantially modifies, a\ngeneral-purpose artificial intelligence model on or after October 1, 2026, if:\n\n(A) (i) The developer releases such general-purpose artificial intelligence\nmodel under a free and open-source license that allows for (I) access to, and\nmodification, distribution and usage of, such general-purpose artificial\nintelligence model, and (II) the parameters of such general-purpose artificial\nintelligence model to be made publicly available as set forth in subparagraph\n(A)(ii) of this subdivision; and\n\n(ii) Unless such general-purpose artificial intelligence model is deployed as\na high-risk artificial intelligence system, the parameters of such general-\npurpose artificial intelligence model, including, but not limited to, the\nweights and information concerning the model architecture and model usage for\nsuch general-purpose artificial intelligence model, are made publicly\navailable; or\n\n(B) The general-purpose artificial intelligence model is (i) not offered for\nsale in the market, (ii) not intended to interact with consumers, and (iii)\nsolely utilized (I) for an entity's internal purposes, or (II) under an\nagreement between multiple entities for such entities' internal purposes.\n\n(2) The provisions of this section shall not apply to a developer that\ndevelops, or intentionally and substantially modifies, a general-purpose\nartificial intelligence model on or after October 1, 2026, if such general-\npurpose artificial intelligence model performs tasks exclusively related to an\nentity's internal management affairs, including, but not limited to, ordering\noffice supplies or processing payments.\n\n(3) A developer that takes any action under an exemption established in\nsubdivision (1) or (2) of this subsection shall bear the burden of\ndemonstrating that such action qualifies for such exemption.\n\n(4) A developer that is exempt under subparagraph (B) of subdivision (1) of\nthis subsection shall establish and maintain an artificial intelligence risk\nmanagement framework, which framework shall (A) be the product of an iterative\nprocess and ongoing efforts, and (B) include, at a minimum, (i) an internal\ngovernance function, (ii) a map function that shall establish the context to\nframe risks, (iii) a risk management function, and (iv) a function to measure\nidentified risks by assessing, analyzing and tracking such risks.\n\n(c) Nothing in subsection (a) of this section shall be construed to require a\ndeveloper to disclose any information that is a trade secret or otherwise\nprotected from disclosure under state or federal law.\n\n(d) Beginning on October 1, 2026, the Attorney General may require that a\ndeveloper disclose to the Attorney General, as part of an investigation\nconducted by the Attorney General regarding a suspected violation of any\nprovision of sections 1 to 10, inclusive, of this act, not later than ninety\ndays after a request by the Attorney General and in a form and manner\nprescribed by the Attorney General, any documentation maintained pursuant to\nthis section. The Attorney General may evaluate such documentation to ensure\ncompliance with the provisions of this section. In disclosing any\ndocumentation to the Attorney General pursuant to this subsection, the\ndeveloper may designate such documentation as including any information that\nis exempt from disclosure under subsection (c) of this section or the Freedom\nof Information Act, as defined in section 1-200 of the general statutes. To\nthe extent such documentation includes such information, such documentation\nshall be exempt from disclosure under subsection (c) of this section or said\nact. To the extent any information contained in such documentation is subject\nto the attorney-client privilege or work product protection, such disclosure\nshall not constitute a waiver of such privilege or protection.\n\nSec. 6. (NEW) (Effective October 1, 2025) (a) Beginning on October 1, 2026,\nand except as provided in subsection (b) of this section, each person doing\nbusiness in this state, including, but not limited to, each deployer that\ndeploys, offers, sells, leases, licenses, gives or otherwise makes available,\nas applicable, any artificial intelligence system that is intended to interact\nwith consumers shall ensure that it is disclosed to each consumer who\ninteracts with such artificial intelligence system that such consumer is\ninteracting with an artificial intelligence system.\n\n(b) No disclosure shall be required under subsection (a) of this section under\ncircumstances in which a reasonable person would deem it obvious that such\nperson is interacting with an artificial intelligence system.\n\nSec. 7. (NEW) (Effective October 1, 2025) (a) Beginning on October 1, 2026,\nand except as provided in subsections (b) and (c) of this section, the\ndeveloper of an artificial intelligence system, including, but not limited to,\na general-purpose artificial intelligence model, that is capable of generating\nsynthetic digital content shall:\n\n(1) Ensure that the outputs of such artificial intelligence system are marked\nand detectable as synthetic digital content, and that such outputs are so\nmarked and detectable (A) not later than the time that consumers who did not\ncreate such outputs first interact with, or are exposed to, such outputs, and\n(B) in a manner that (i) is detectable by consumers, and (ii) complies with\nany applicable accessibility requirements; and\n\n(2) As far as technically feasible and in a manner that is consistent with any\nnationally or internationally recognized technical standards, ensure that such\ndeveloper's technical solutions are effective, interoperable, robust and\nreliable, considering (A) the specificities and limitations of different types\nof synthetic digital content, (B) the implementation costs, and (C) the\ngenerally acknowledged state of the art.\n\n(b) If the synthetic digital content described in subsection (a) of this\nsection is in an audio, image or video format, and such synthetic digital\ncontent forms part of an evidently artistic, creative, satirical, fictional\nanalogous work or program, the disclosure required under said subsection shall\nbe limited to a disclosure that does not hinder the display or enjoyment of\nsuch work or program.\n\n(c) The provisions of subsection (a) of this section shall not apply:\n\n(1) To any synthetic digital content that (A) consists exclusively of text,\n(B) is published to inform the public on any matter of public interest, or (C)\nis unlikely to mislead a reasonable person consuming such synthetic digital\ncontent; or\n\n(2) To the extent that any artificial intelligence system described in\nsubsection (a) of this section (A) performs an assistive function for standard\nediting, (B) does not substantially alter the input data provided by the\ndeveloper or the semantics thereof, or (C) is used to detect, prevent,\ninvestigate or prosecute any crime where authorized by law.\n\nSec. 8. (NEW) (Effective October 1, 2025) (a) Nothing in sections 1 to 10,\ninclusive, of this act shall be construed to restrict a developer's,\nintegrator's, deployer's or other person's ability to:\n\n(1) Comply with any federal, state or municipal law, ordinance or regulation;\n\n(2) Comply with a civil, criminal or regulatory inquiry, investigation,\nsubpoena or summons by a federal, state, municipal or other governmental\nauthority;\n\n(3) Cooperate with a law enforcement agency concerning conduct or activity\nthat the developer, integrator, deployer or other person reasonably and in\ngood faith believes may violate federal, state or municipal law;\n\n(4) Investigate, establish, exercise, prepare for or defend a legal claim;\n\n(5) Take immediate steps to protect an interest that is essential for the life\nor physical safety of a consumer or another individual;\n\n(6) (A) By any means other than facial recognition technology, prevent,\ndetect, protect against or respond to (i) a security incident, (ii) a\nmalicious or deceptive activity, or (iii) identity theft, fraud, harassment or\nany other illegal activity, (B) investigate, report or prosecute the persons\nresponsible for any action described in subparagraph (A) of this subdivision,\nor (C) preserve the integrity or security of systems;\n\n(7) Engage in public or peer-reviewed scientific or statistical research in\nthe public interest that (A) adheres to all other applicable ethics and\nprivacy laws, and (B) is conducted in accordance with (i) 45 CFR Part 46, as\namended from time to time, or (ii) relevant requirements established by the\nfederal Food and Drug Administration;\n\n(8) Conduct research, testing, development and integration activities\nregarding an artificial intelligence system or model, other than testing\nconducted under real world conditions, before such artificial intelligence\nsystem or model is placed on the market, deployed or put into service, as\napplicable;\n\n(9) Effectuate a product recall;\n\n(10) Identify and repair technical errors that impair existing or intended\nfunctionality; or\n\n(11) Assist another developer, integrator, deployer or person with any of the\nobligations imposed under sections 1 to 10, inclusive, of this act.\n\n(b) The obligations imposed on developers, integrators, deployers or other\npersons under sections 1 to 10, inclusive, of this act shall not apply where\ncompliance by the developer, integrator, deployer or other person with said\nsections would violate an evidentiary privilege under the laws of this state.\n\n(c) Nothing in sections 1 to 10, inclusive, of this act shall be construed to\nimpose any obligation on a developer, integrator, deployer or other person\nthat adversely affects the rights or freedoms of any person, including, but\nnot limited to, the rights of any person (1) to freedom of speech or freedom\nof the press guaranteed in (A) the First Amendment to the United States\nConstitution, and (B) section 5 of article first of the Constitution of the\nstate, or (2) under section 52-146t of the general statutes.\n\n(d) Nothing in sections 1 to 10, inclusive, of this act shall be construed to\napply to any developer, integrator, deployer or other person:\n\n(1) Insofar as such developer, integrator, deployer or other person develops,\nintegrates, deploys, puts into service or intentionally and substantially\nmodifies, as applicable, a high-risk artificial intelligence system (A) that\nhas been approved, authorized, certified, cleared, developed, integrated or\ngranted by (i) a federal agency, such as the federal Food and Drug\nAdministration or the Federal Aviation Administration, acting within the scope\nof such federal agency's authority, or (ii) a regulated entity subject to\nsupervision and regulation by the Federal Housing Finance Agency, or (B) in\ncompliance with standards that are (i) established by (I) any federal agency,\nincluding, but not limited to, the federal Office of the National Coordinator\nfor Health Information Technology, or (II) a regulated entity subject to\nsupervision and regulation by the Federal Housing Finance Agency, and (ii)\nsubstantially equivalent to, and at least as stringent as, the standards\nestablished in sections 1 to 10, inclusive, of this act;\n\n(2) Conducting research to support an application (A) for approval or\ncertification from any federal agency, including, but not limited to, the\nFederal Aviation Administration, the Federal Communications Commission or the\nfederal Food and Drug Administration, or (B) that is otherwise subject to\nreview by any federal agency;\n\n(3) Performing work under, or in connection with, a contract with the United\nStates Department of Commerce, the United States Department of Defense or the\nNational Aeronautics and Space Administration, unless such developer,\nintegrator, deployer or other person is performing such work on a high-risk\nartificial intelligence system that is used to make, or as a substantial\nfactor in making, a decision concerning employment or housing;\n\n(4) That facilitates or engages in the provision of telehealth services or is\na covered entity within the meaning of the Health Insurance Portability and\nAccountability Act of 1996, P.L. 104-191, and the regulations promulgated\nthereunder, as both may be amended from time to time, and providing health\ncare recommendations that (A) are generated by an artificial intelligence\nsystem, (B) require a health care provider to take action to implement such\nrecommendations, and (C) are not considered to be high risk; or\n\n(5) Who is an active participant in the artificial intelligence regulatory\nsandbox program designed, established and administered under section 12 of\nthis act, and is engaged in activities within the scope of such program in\naccordance with the provisions of section 12 of this act.\n\n(e) Nothing in sections 1 to 10, inclusive, of this act shall be construed to\napply to any artificial intelligence system that is acquired by or for the\nfederal government or any federal agency or department, including, but not\nlimited to, the United States Department of Commerce, the United States\nDepartment of Defense or the National Aeronautics and Space Administration,\nunless such artificial intelligence system is a high-risk artificial\nintelligence system that is used to make, or as a substantial factor in\nmaking, a decision concerning employment or housing.\n\n(f) Any insurer, as defined in section 38a-1 of the general statutes,\nfraternal benefit society, as described in section 38a-595 of the general\nstatutes, or health carrier, as defined in section 38a-591a of the general\nstatutes, shall be deemed to be in full compliance with the provisions of\nsections 1 to 10, inclusive, of this act if such insurer, fraternal benefit\nsociety or health carrier has implemented and maintains a written artificial\nintelligence systems program in accordance with all requirements established\nby the Insurance Commissioner.\n\n(g) (1) Any bank, out-of-state bank, Connecticut credit union, federal credit\nunion, mortgage lender or out-of-state credit union, or any affiliate,\nsubsidiary or service provider thereof, shall be deemed to be in full\ncompliance with the provisions of sections 1 to 10, inclusive, of this act if\nsuch bank, out-of-state bank, Connecticut credit union, federal credit union,\nmortgage lender, out-of-state credit union, affiliate, subsidiary or service\nprovider is subject to examination by any state or federal prudential\nregulator under any published guidance or regulations that apply to the use of\nhigh-risk artificial intelligence systems and such guidance or regulations (A)\nimpose requirements that are substantially equivalent to, and at least as\nstringent as, the requirements set forth in sections 1 to 10, inclusive, of\nthis act, and (B) at a minimum, require such bank, out-of-state bank,\nConnecticut credit union, federal credit union, mortgage lender, out-of-state\ncredit union, affiliate, subsidiary or service provider to (i) regularly audit\nsuch bank's, out-of-state bank's, Connecticut credit union's, federal credit\nunion's, mortgage lender's, out-of-state credit union's, affiliate's,\nsubsidiary's or service provider's use of high-risk artificial intelligence\nsystems for compliance with state and federal anti-discrimination laws and\nregulations applicable to such bank, out-of-state bank, Connecticut credit\nunion, federal credit union, mortgage lender, out-of-state credit union,\naffiliate, subsidiary or service provider, and (ii) mitigate any algorithmic\ndiscrimination caused by the use of a high-risk artificial intelligence system\nor any risk of algorithmic discrimination that is reasonably foreseeable as a\nresult of the use of a high-risk artificial intelligence system.\n\n(2) For the purposes of this subsection, (A) \"affiliate\", \"bank\", \"Connecticut\ncredit union\", \"federal credit union\", \"out-of-state bank\", \"out-of-state\ncredit union\" and \"subsidiary\" have the same meanings as provided in section\n36a-2 of the general statutes, and (B) \"mortgage lender\" has the same meaning\nas provided in section 36a-705 of the general statutes.\n\n(h) If a developer, integrator, deployer or other person engages in any action\npursuant to an exemption set forth in subsections (a) to (g), inclusive, of\nthis section, the developer, integrator, deployer or other person bears the\nburden of demonstrating that such action qualifies for such exemption.\n\nSec. 9. (NEW) (Effective October 1, 2025) Not later than January 1, 2026, the\nAttorney General shall, within available appropriations, develop and implement\na comprehensive public education, outreach and assistance program for\ndevelopers, integrators and deployers that are small businesses, as defined in\nsection 4-168a of the general statutes. Such program shall, at a minimum,\ndisseminate educational materials concerning (1) the requirements established\nin sections 1 to 10, inclusive, of this act, including, but not limited to,\nthe duties of developers, integrators and deployers under sections 1 to 10,\ninclusive, of this act, (2) the impact assessments required under subsection\n(c) of section 4 of this act, (3) the Attorney General's powers under sections\n1 to 10, inclusive, of this act, and (4) any other matters the Attorney\nGeneral, in the Attorney General's discretion, deems relevant for the purposes\nof such program.\n\nSec. 10. (NEW) (Effective October 1, 2025) (a) The Attorney General shall have\nexclusive authority to enforce the provisions of sections 1 to 9, inclusive,\nof this act.\n\n(b) Except as provided in subsection (f) of this section, during the period\nbeginning on October 1, 2026, and ending on September 30, 2027, the Attorney\nGeneral shall, prior to initiating any action for a violation of any provision\nof sections 1 to 9, inclusive, of this act, issue a notice of violation to the\ndeveloper, integrator, deployer or other person if the Attorney General\ndetermines that it is possible to cure such violation. If the developer,\nintegrator, deployer or other person fails to cure such violation not later\nthan sixty days after receipt of the notice of violation, the Attorney General\nmay bring an action pursuant to this section.\n\n(c) Except as provided in subsection (f) of this section, beginning on October\n1, 2027, the Attorney General may, in determining whether to grant a\ndeveloper, integrator, deployer or other person the opportunity to cure a\nviolation described in subsection (b) of this section, consider: (1) The\nnumber of violations; (2) the size and complexity of the developer,\nintegrator, deployer or other person; (3) the nature and extent of the\ndeveloper's, integrator's, deployer's or other person's business; (4) the\nsubstantial likelihood of injury to the public; (5) the safety of persons or\nproperty; and (6) whether such violation was likely caused by human or\ntechnical error.\n\n(d) Nothing in sections 1 to 9, inclusive, of this act shall be construed as\nproviding the basis for a private right of action for violations of said\nsections.\n\n(e) Except as provided in subsections (a) to (d), inclusive, of this section\nand subsection (f) of this section, a violation of the requirements\nestablished in sections 1 to 9, inclusive, of this act shall constitute an\nunfair trade practice for purposes of section 42-110b of the general statutes\nand shall be enforced solely by the Attorney General. The provisions of\nsection 42-110g of the general statutes shall not apply to any such violation.\n\n(f) (1) In any action commenced by the Attorney General for any violation of\nsections 1 to 9, inclusive, of this act, it shall be an affirmative defense\nthat the developer, integrator, deployer or other person:\n\n(A) Discovers a violation of any provision of sections 1 to 9, inclusive, of\nthis act through red-teaming;\n\n(B) Not later than sixty days after discovering the violation as set forth in\nsubparagraph (A) of this subdivision: (i) Cures such violation; and (ii)\nprovides to the Attorney General, in a form and manner prescribed by the\nAttorney General, notice that such violation has been cured and evidence that\nany harm caused by such violation has been mitigated; and\n\n(C) Is otherwise in compliance with the latest version of: (i) The \"Artificial\nIntelligence Risk Management Framework\" published by the National Institute of\nStandards and Technology; (ii) ISO or IEC 42001 of the International\nOrganization for Standardization; (iii) a nationally or internationally\nrecognized risk management framework for artificial intelligence systems,\nother than the risk management frameworks specified in subparagraphs (C)(i)\nand (C)(ii) of this subdivision, that imposes requirements that are\nsubstantially equivalent to, and at least as stringent as, the requirements\nset forth in sections 1 to 9, inclusive, of this act; or (iv) any risk\nmanagement framework for artificial intelligence systems that is substantially\nequivalent to, and at least as stringent as, the risk management frameworks\ndescribed in subparagraphs (C)(i) to (C)(iii), inclusive, of this subdivision.\n\n(2) The developer, integrator, deployer or other person bears the burden of\ndemonstrating to the Attorney General that the requirements established in\nsubdivision (1) of this subsection have been satisfied.\n\n(3) Nothing in this section or sections 1 to 9, inclusive, of this act,\nincluding, but not limited to, the enforcement authority granted to the\nAttorney General under this section, shall be construed to preempt or\notherwise affect any right, claim, remedy, presumption or defense available at\nlaw or in equity. Any rebuttable presumption or affirmative defense\nestablished under this section or sections 1 to 9, inclusive, of this act\nshall apply only to an enforcement action brought by the Attorney General\npursuant to this section and shall not apply to any right, claim, remedy,\npresumption or defense available at law or in equity.\n\nSec. 11. (NEW) (Effective October 1, 2025) (a) For the purposes of this\nsection, \"legislative leader\" has the same meaning as provided in subsection\n(b) of section 4-9d of the general statutes.\n\n(b) Each legislative leader may request that the executive director of the\nConnecticut Academy of Science and Engineering designate a member of said\nacademy to serve as such legislative leader's liaison with said academy, the\nOffice of the Attorney General and the Department of Economic and Community\nDevelopment for the purpose of:\n\n(1) Designing a tool to enable any person to determine whether such person is\nin compliance with the provisions of sections 1 to 10, inclusive, of this act;\n\n(2) Designing a tool to assist a deployer, or a third party contracted by a\ndeployer, to complete an impact assessment pursuant to subsection (c) of\nsection 4 of this act;\n\n(3) Conducting meetings with relevant stakeholders to formulate a plan to\nutilize The University of Connecticut School of Law's Intellectual Property\nand Entrepreneurship Law Clinic to assist small businesses and startups in\ntheir efforts to comply with the provisions of sections 1 to 10, inclusive, of\nthis act;\n\n(4) Making recommendations concerning establishing a framework to provide a\ncontrolled and supervised environment in which artificial intelligence systems\nmay be tested, which recommendations shall include, at a minimum,\nrecommendations concerning the establishment of (A) an office to oversee such\nframework and environment, and (B) a program that would enable consultations\nbetween the state, businesses and other stakeholders concerning such framework\nand environment;\n\n(5) Evaluating (A) the adoption of artificial intelligence systems by\nbusinesses, (B) the challenges posed to, and needs of, businesses in (i)\nadopting artificial intelligence systems, and (ii) understanding laws and\nregulations concerning artificial intelligence systems, and (C) how businesses\nthat use artificial intelligence systems hire employees with necessary skills\nconcerning artificial intelligence systems;\n\n(6) Creating a plan for the state to provide high-performance computing\nservices to businesses and researchers in the state;\n\n(7) Evaluating the benefits of creating a state-wide research collaborative\namong health care providers to enable the development of advanced analytics,\nethical and trustworthy artificial intelligence systems and hands-on workforce\neducation while using methods that protect patient privacy; and\n\n(8) Evaluating, and making recommendations concerning, (A) the establishment\nof testbeds to support safeguards and systems to prevent the misuse of\nartificial intelligence systems, (B) risk assessments for the misuse of\nartificial intelligence systems, (C) evaluation strategies for artificial\nintelligence systems, and (D) the development, testing and evaluation of\nresources to support state oversight of artificial intelligence systems.\n\n(c) No member of the Connecticut Academy of Science and Engineering designated\npursuant to subsection (b) of this section shall be deemed a state employee,\nor receive any compensation from the state, for performing such member's\nduties under said subsection.\n\nSec. 12. (NEW) (Effective October 1, 2025) (a) As used in this section:\n\n(1) \"Active participant\" means a person participating in the artificial\nintelligence regulatory sandbox program designed, established and administered\nin accordance with the provisions of this section;\n\n(2) \"Artificial intelligence system\" has the same meaning as provided in\nsection 1 of this act;\n\n(3) \"Consumer\" has the same meaning as provided in section 1 of this act;\n\n(4) \"Deployer\" means any person doing business in this state that deploys an\nartificial intelligence system;\n\n(5) \"Developer\" has the same meaning as provided in section 1 of this act;\n\n(6) \"Person\" has the same meaning as provided in section 1 of this act; and\n\n(7) \"State agency\" has the same meaning as provided in section 1-79 of the\ngeneral statutes.\n\n(b) The Department of Economic and Community Development, in coordination with\nthe Chief Data Officer and the Connecticut Technology Advisory Board\nestablished under section 16 of this act, shall design, establish and\nadminister an artificial intelligence regulatory sandbox program to facilitate\nthe development, testing and deployment of innovative artificial intelligence\nsystems in the state. The program shall be designed to (1) promote the safe\nand innovative use of artificial intelligence systems across various sectors,\nincluding, but not limited to, education, finance, health care and public\nservice, (2) encourage the responsible deployment of artificial intelligence\nsystems while balancing the need for consumer protection, privacy and public\nsafety, and (3) provide clear guidelines for developers to test artificial\nintelligence systems while being exempt from certain regulatory requirements\nduring the period set forth in subsection (d) of this section.\n\n(c) (1) A person seeking to participate in the artificial intelligence\nregulatory sandbox program shall submit an application to the Department of\nEconomic and Community Development in a form and manner prescribed by the\nCommissioner of Economic and Community Development. Each application shall\ninclude (A) a detailed description of the applicant's artificial intelligence\nsystem and its intended uses, (B) a risk assessment that addresses the\npotential impact of the applicant's artificial intelligence system on\nconsumers, privacy and public safety, (C) a plan for mitigating any adverse\nconsequences that may arise from the applicant's artificial intelligence\nsystem during the period set forth in subsection (d) of this section, (D)\nproof that the applicant and the applicant's artificial intelligence system\nare in compliance with all applicable federal laws and regulations concerning\nartificial intelligence systems, and (E) any other information the\ncommissioner deems relevant for the purposes of this section or the program.\n\n(2) Not later than thirty days after the Department of Economic and Community\nDevelopment receives an application submitted pursuant to subdivision (1) of\nthis subsection, the department shall (A) approve or deny the application, and\n(B) send a notice to the applicant, in a form and manner prescribed by the\nCommissioner of Economic and Community Development, disclosing whether the\ndepartment has approved or denied such application.\n\n(d) An active participant in the artificial intelligence regulatory sandbox\nprogram may test the applicant's artificial intelligence system as part of the\nprogram for a period not to exceed eighteen months from the date on which the\nDepartment of Economic and Community Development sent notice approving the\nactive participant's application pursuant to subparagraph (B) of subdivision\n(2) of subsection (c) of this section, except the department may extend such\nperiod for good cause shown.\n\n(e) The Department of Economic and Community Development shall coordinate with\nall relevant state agencies to oversee the operations of active participants\nin the artificial intelligence regulatory sandbox program. Any state agency\nmay recommend to the department that an active participant's participation in\nthe program be revoked if the active participant's artificial intelligence\nsystem (1) poses an undue risk to the public health, safety or welfare, or (2)\nviolates any federal law or regulation.\n\n(f) For the calendar quarter ending December 31, 2025, and for each calendar\nquarter thereafter, each active participant in the artificial intelligence\nregulatory sandbox program shall, not later than thirty days after the end of\nsuch calendar quarter, submit a report to the Department of Economic and\nCommunity Development disclosing (1) system performance metrics for such\nactive participant's artificial intelligence system, (2) information\nconcerning the manner in which such active participant's artificial\nintelligence system mitigated any risks associated with such artificial\nintelligence system, and (3) any feedback such active participant received\nfrom deployers, consumers and other users of such artificial intelligence\nsystem.\n\n(g) For the calendar year ending December 31, 2025, and for each calendar year\nthereafter, the Department of Economic and Community Development shall, not\nlater than thirty days after the end of such calendar year, submit a report,\nin accordance with the provisions of section 11-4a of the general statutes, to\nthe joint standing committee of the General Assembly having cognizance of\nmatters relating to consumer protection. Each report shall disclose (1) the\nnumber of persons who were active participants in the artificial intelligence\nregulatory sandbox program for the calendar year that is the subject of such\nreport or any portion of such calendar year, (2) the overall performance and\nimpact of artificial intelligence systems tested as part of the program, and\n(3) any recommendations regarding the adoption of legislation for the purposes\nof the program.\n\nSec. 13. (NEW) (Effective July 1, 2025) (a) As used in this section,\n\"artificial intelligence\" means artificial intelligence system, as defined in\nsection 1 of this act.\n\n(b) Not later than December 31, 2025, the Board of Regents for Higher\nEducation shall establish, on behalf of Charter Oak State College and in\nconsultation with the Labor Department, the State Board of Education,\nWorkforce Investment Boards, employers and institutions of higher education in\nthis state, a \"Connecticut AI Academy\". The academy shall, at a minimum:\n\n(1) Curate and offer online courses concerning artificial intelligence and the\nresponsible use of artificial intelligence;\n\n(2) Promote digital literacy;\n\n(3) Prepare students for careers in fields involving artificial intelligence;\n\n(4) Offer courses directed at individuals between thirteen and twenty years of\nage;\n\n(5) Offer courses that prepare small businesses and nonprofit organizations to\nutilize artificial intelligence to improve marketing and management\nefficiency;\n\n(6) Develop courses concerning artificial intelligence that the Labor\nDepartment and Workforce Investment Boards may incorporate into workforce\ntraining programs; and\n\n(7) Enable persons providing free or discounted public Internet access to\ndistribute information and provide mentorship concerning artificial\nintelligence, the academy and methods available for the public to obtain free\nor discounted devices capable of accessing the Internet and utilizing\nartificial intelligence.\n\n(c) The Board of Regents for Higher Education shall, in consultation with\nCharter Oak State College, develop certificates and badges to be awarded to\npersons who successfully complete courses offered by the Connecticut AI\nAcademy.\n\nSec. 14. (NEW) (Effective July 1, 2025) The Labor Department shall provide a\nnotice, in a form and manner prescribed by the Labor Commissioner, to each\nindividual who makes a claim for unemployment compensation disclosing the\nexistence of, and courses and services offered by, the Connecticut AI Academy\nestablished pursuant to section 13 of this act.\n\nSec. 15. Subsection (b) of section 17b-751b of the general statutes is\nrepealed and the following is substituted in lieu thereof (Effective July 1,\n2025):\n\n(b) The commissioner shall: (1) Ensure that all home visiting programs _(A)_\nare one or more of the evidence-based home visiting models that meet the\ncriteria for evidence of effectiveness developed by the federal Department of\nHealth and Human Services _, and (B) provide information to parents regarding\nthe Connecticut AI Academy established pursuant to section 13 of this act_ ;\n(2) provide oversight of home visiting programs to insure model fidelity; and\n(3) develop, issue and evaluate requests for proposals to procure the services\nrequired by this section. In evaluating the proposals, the commissioner shall\ntake into consideration the most effective and consistent service delivery\nsystem allowing for the continuation of current public and private programs.\n\nSec. 16. (NEW) (Effective July 1, 2025) (a) As used in this section,\n\"artificial intelligence\" means artificial intelligence system, as defined in\nsection 1 of this act.\n\n(b) There is established, within available appropriations, a Connecticut\nTechnology Advisory Board, which shall be part of the Legislative Department.\n\n(c) (1) The board shall consist of the following members: (A) Two appointed by\nthe speaker of the House of Representatives; (B) two appointed by the\npresident pro tempore of the Senate; (C) two appointed by the minority leader\nof the House of Representatives; and (D) two appointed by the minority leader\nof the Senate. All appointed members shall have professional experience or\nacademic qualifications in the field of artificial intelligence or the field\nof technology, or another related field, and no such member shall be a member\nof the General Assembly.\n\n(2) The following persons or their designees shall serve as ex-officio,\nnonvoting members and chairpersons of the board: (A) The Commissioner of\nEconomic and Community Development; (B) the executive director of the\nConnecticut Academy of Science and Engineering; and (C) the president of\nCharter Oak State College.\n\n(3) All initial appointments to the board shall be made not later than October\n1, 2025. The term of an appointed member shall be coterminous with the term of\nthe appointing authority for the appointed member. Any vacancy shall be filled\nby the appointing authority. Any vacancy occurring other than by expiration of\na term shall be filled for the balance of the unexpired term. A member of the\nboard may serve more than one term. The chairpersons shall schedule the first\nmeeting of the board, which shall be held not later than November 1, 2025.\n\n(d) The administrative staff of the joint standing committees of the General\nAssembly having cognizance of matters relating to consumer protection and\ngovernment administration shall serve as administrative staff of the board.\n\n(e) The board shall have the following powers and duties: (1) To develop and\nadopt a state technology strategy (A) for the purpose of promoting education,\nworkforce development, economic development and consumer protection, and (B)\nthat accounts for the rapid pace of technological development, including, but\nnot limited to, in the field of artificial intelligence; (2) to update the\nstate technology strategy developed and adopted pursuant to subdivision (1) of\nthis subsection at least once every two years; (3) to issue reports and\nrecommendations in accordance with the provisions of section 11-4a of the\ngeneral statutes; (4) upon the vote of a majority of the members of the board,\nto request any state agency data officer or state agency head to (A) appear\nbefore the board to answer questions, or (B) provide such assistance and data\nas may be necessary for the purpose of enabling the board to perform its\nduties; (5) to make recommendations to the Legislative Department, Executive\nDepartment or Judicial Department in accordance with the state technology\nstrategy; and (6) to establish bylaws to govern the board's procedures.\n\n(f) The board shall meet at least twice annually and may meet at such other\ntimes as deemed necessary by the chairpersons or a majority of the members of\nthe board.\n\nSec. 17. (Effective July 1, 2025) (a) Not later than December 31, 2025, the\nDepartment of Economic and Community Development shall, within available\nappropriations and in collaboration with Charter Oak State College, develop a\nplan to establish a technology transfer program within Connecticut\nInnovations, Incorporated, for the purpose of supporting technology transfers\nby and among public and private institutions of higher education in this\nstate.\n\n(b) Not later than January 1, 2026, the Commissioner of Economic and Community\nDevelopment shall submit a report, in accordance with the provisions of\nsection 11-4a of the general statutes, to the joint standing committees of the\nGeneral Assembly having cognizance of matters relating to consumer protection,\ncommerce and higher education. Such report shall, at a minimum, include the\nplan developed pursuant to subsection (a) of this section.\n\nSec. 18. (NEW) (Effective July 1, 2025) (a) Not later than December 31, 2025,\nthe Department of Economic and Community Development shall, within available\nappropriations and in collaboration with the Office of Health Strategy,\nestablish a confidential computing cluster for the purpose of fostering the\nexchange of health information in order to support academic and medical\nresearch.\n\n(b) (1) The confidential computing cluster established pursuant to subsection\n(a) of this section shall be overseen by a Connecticut Confidential Computing\nCluster Policy Board, which shall be within the Department of Economic and\nCommunity Development for administrative purposes only. Said policy board\nshall consist of:\n\n(A) The chairperson of The University of Connecticut Health Center Board of\nDirectors, or said chairperson's designee; and\n\n(B) A representative of the State-wide Health Information Exchange established\npursuant to section 17b-59d of the general statutes, who shall be appointed by\nthe Commissioner of Health Strategy.\n\n(2) The Connecticut Confidential Computing Cluster Policy Board shall direct\nthe formulation of policies and operating procedures for the confidential\ncomputing cluster established pursuant to subsection (a) of this section.\n\n(3) The Connecticut Confidential Computing Cluster Policy Board may apply for\nand administer any federal, state, local or private appropriations or grant\nfunds made available for the operation of the confidential computing cluster\nestablished pursuant to subsection (a) of this section.\n\nSec. 19. Section 10-21l of the general statutes is repealed and the following\nis substituted in lieu thereof (Effective July 1, 2025):\n\nThere is established an account to be known as the ~~\" computer science\neducation account\"~~ _\" computer science education and workforce development\naccount\"_, which shall be a separate, nonlapsing account within the General\nFund. The account shall contain any moneys required or permitted by law to be\ndeposited in the account and any funds received from any public or private\ncontributions, gifts, grants, donations, bequests or devises to the account.\nThe Department of Education may make expenditures from the account _(1)_ to\nsupport curriculum development, teacher professional development, capacity\ndevelopment for school districts ~~,~~ and other programs for the purposes of\nsupporting computer science education _, and (2) in coordination with the\nOffice of Workforce Strategy and the Board of Regents for Higher Education for\nthe purpose of supporting workforce development initiatives in accordance with\nthe state technology strategy adopted pursuant to subsection (e) of section 16\nof this act_.\n\nSec. 20. Section 32-7p of the general statutes is repealed and the following\nis substituted in lieu thereof (Effective July 1, 2025):\n\n_(a) As used in this section:_\n\n_(1) \"Artificial intelligence\" means artificial intelligence system, as\ndefined in section 1 of this act;_\n\n_(2) \"Generative artificial intelligence\" means any form of artificial\nintelligence, including, but not limited to, a foundation model, that is able\nto produce synthetic digital content, as defined in section 1 of this act;\nand_\n\n_(3) \"Prompt engineering\" means the process of guiding generative artificial\nintelligence to generate a desired output._\n\n~~(a)~~ _(b)_ There shall be a Technology Talent _and Innovation Fund_\nAdvisory Committee within the Department of Economic and Community\nDevelopment. Such committee shall consist of members appointed by the\nCommissioner of Economic and Community Development, including, but not limited\nto, representatives of The University of Connecticut, the Board of Regents for\nHigher Education, independent institutions of higher education, the Office of\nWorkforce Strategy and private industry. Such members shall be subject to term\nlimits prescribed by the commissioner. Each member shall hold office until a\nsuccessor is appointed.\n\n~~(b)~~ _(c)_ The commissioner shall call the first meeting of the advisory\ncommittee not later than October 15, 2016. The advisory committee shall meet\nnot less than quarterly thereafter and at such other times as the chairperson\ndeems necessary. The Technology Talent _and Innovation Fund_ Advisory\nCommittee shall designate the chairperson of the committee from among its\nmembers.\n\n~~(c)~~ _(d)_ No member of the advisory committee shall receive compensation\nfor such member's service, except that each member shall be entitled to\nreimbursement for actual and necessary expenses incurred during the\nperformance of such member's official duties.\n\n~~(d)~~ _(e)_ A majority of members of the advisory committee shall constitute\na quorum for the transaction of any business or the exercise of any power of\nthe advisory committee. The advisory committee may act by a majority of the\nmembers present at any meeting at which a quorum is in attendance, for the\ntransaction of any business or the exercise of any power of the advisory\ncommittee, except as otherwise provided in this section.\n\n~~(e)~~ _(f)_ Notwithstanding any provision of the general statutes, it shall\nnot constitute a conflict of interest for a trustee, director, partner or\nofficer of any person, firm or corporation, or any individual having a\nfinancial interest in a person, firm or corporation, to serve as a member of\nthe advisory committee, provided such trustee, director, partner, officer or\nindividual complies with all applicable provisions of chapter 10. All members\nof the advisory committee shall be deemed public officials and shall adhere to\nthe code of ethics for public officials set forth in chapter 10, except that\nno member shall be required to file a statement of financial interest as\ndescribed in section 1-83.\n\n~~(f) The Technology Talent Advisory Committee shall, in the following order\nof priority, (1) calculate the number of software developers and other persons\n(A) employed in technology-based fields where there is a shortage of qualified\nemployees in this state for businesses to hire, including, but not limited to,\ndata mining, data analysis and cybersecurity, and (B) employed by businesses\nlocated in Connecticut as of December 31, 2016; (2) develop pilot programs to\nrecruit software developers to Connecticut and train residents of the state in\nsoftware development and such other technology fields, with the goal of\nincreasing the number of software developers and persons employed in such\nother technology fields residing in Connecticut and employed by businesses in\nConnecticut by at least double the number calculated pursuant to subdivision\n(1) of this subsection by January 1, 2026; and (3) identify other technology\nindustries where there is a shortage of qualified employees in this state for\ngrowth stage businesses to hire.~~\n\n(g) The Technology Talent _and Innovation Fund_ Advisory Committee may\n_partner with institutions of higher education and other nonprofit\norganizations to_ develop ~~pilot~~ programs ~~for (1) marketing and publicity\ncampaigns designed to recruit technology talent to the state; (2) student loan\ndeferral or forgiveness for students who start businesses in the state; and\n(3) training, apprenticeship and gap-year initiatives~~ _to expand the\ntechnology talent pipeline in the state, including, but not limited to, in the\nfields of artificial intelligence and quantum computing_.\n\n~~(h) The Technology Talent Advisory Committee shall report, in accordance\nwith the provisions of section 11-4a, and present such report to the joint\nstanding committees of the General Assembly having cognizance of matters\nrelating to commerce, education, higher education and finance, revenue and\nbonding on or before January 1, 2017, concerning the (1) pilot programs\ndeveloped pursuant to subsections (f) and (g) of this section, (2) number of\nsoftware developers and persons employed in technology-based fields described\nin subsection (f) of this section targeted for recruitment pursuant to\nsubsection (f) of this section, and (3) timeline and measures for reaching the\nrecruitment target.~~\n\n_(h) Not later than July 1, 2026, the Technology Talent and Innovation Fund\nAdvisory Committee shall partner with public and private institutions of\nhigher education in the state and other training providers to develop programs\nin the field of artificial intelligence, including, but not limited to, in\nareas such as prompt engineering, artificial intelligence marketing for small\nbusinesses and artificial intelligence for small business operations._\n\nSec. 21. Subsection (b) of section 32-235 of the general statutes is repealed\nand the following is substituted in lieu thereof (Effective July 1, 2025):\n\n(b) The proceeds of the sale of said bonds, to the extent of the amount stated\nin subsection (a) of this section, shall be used by the Department of Economic\nand Community Development (1) for the purposes of sections 32-220 to 32-234,\ninclusive, including economic cluster-related programs and activities, and for\nthe Connecticut job training finance demonstration program pursuant to\nsections 32-23uu and 32-23vv, provided (A) three million dollars shall be used\nby said department solely for the purposes of section 32-23uu, (B) not less\nthan one million dollars shall be used for an educational technology grant to\nthe deployment center program and the nonprofit business consortium deployment\ncenter approved pursuant to section 32-41l, (C) not less than two million\ndollars shall be used by said department for the establishment of a pilot\nprogram to make grants to businesses in designated areas of the state for\nconstruction, renovation or improvement of small manufacturing facilities,\nprovided such grants are matched by the business, a municipality or another\nfinancing entity. The Commissioner of Economic and Community Development shall\ndesignate areas of the state where manufacturing is a substantial part of the\nlocal economy and shall make grants under such pilot program which are likely\nto produce a significant economic development benefit for the designated area,\n(D) five million dollars may be used by said department for the manufacturing\ncompetitiveness grants program, (E) one million dollars shall be used by said\ndepartment for the purpose of a grant to the Connecticut Center for Advanced\nTechnology, for the purposes of subdivision (5) of subsection (a) of section\n32-7f, (F) fifty million dollars shall be used by said department for the\npurpose of grants to the United States Department of the Navy, the United\nStates Department of Defense or eligible applicants for projects related to\nthe enhancement of infrastructure for long-term, on-going naval operations at\nthe United States Naval Submarine Base-New London, located in Groton, which\nwill increase the military value of said base. Such projects shall not be\nsubject to the provisions of sections 4a-60 and 4a-60a, (G) two million\ndollars shall be used by said department for the purpose of a grant to the\nConnecticut Center for Advanced Technology, Inc., for manufacturing\ninitiatives, including aerospace and defense, and (H) four million dollars\nshall be used by said department for the purpose of a grant to companies\nadversely impacted by the construction at the Quinnipiac Bridge, where such\ngrant may be used to offset the increase in costs of commercial overland\ntransportation of goods or materials brought to the port of New Haven by ship\nor vessel, (2) for the purposes of the small business assistance program\nestablished pursuant to section 32-9yy, provided fifteen million dollars shall\nbe deposited in the small business assistance account established pursuant to\nsaid section 32-9yy, (3) to deposit twenty million dollars in the small\nbusiness express assistance account established pursuant to section 32-7h, (4)\nto deposit four million nine hundred thousand dollars per year in each of the\nfiscal years ending June 30, 2017, to June 30, 2019, inclusive, and June 30,\n2021, and nine million nine hundred thousand dollars in the fiscal year ending\nJune 30, 2020, in the CTNext Fund established pursuant to section 32-39i,\nwhich shall be used by the Department of Economic and Community Development to\nprovide grants-in-aid to designated innovation places, as defined in section\n32-39f, planning grants-in-aid pursuant to section 32-39l, and grants-in-aid\nfor projects that network innovation places pursuant to subsection (b) of\nsection 32-39m, provided not more than three million dollars be used for\ngrants-in-aid for such projects, and further provided any portion of any such\ndeposit that remains unexpended in a fiscal year subsequent to the date of\nsuch deposit may be used by the Department of Economic and Community\nDevelopment for any purpose described in subsection (e) of section 32-39i, (5)\nto deposit two million dollars per year in each of the fiscal years ending\nJune 30, 2019, to June 30, 2021, inclusive, in the CTNext Fund established\npursuant to section 32-39i, which shall be used by the Department of Economic\nand Community Development for the purpose of providing higher education\nentrepreneurship grants-in-aid pursuant to section 32-39g, provided any\nportion of any such deposit that remains unexpended in a fiscal year\nsubsequent to the date of such deposit may be used by the Department of\nEconomic and Community Development for any purpose described in subsection (e)\nof section 32-39i, (6) for the purpose of funding the costs of the Technology\nTalent _and Innovation Fund_ Advisory Committee established pursuant to\nsection 32-7p _, as amended by this act_ , provided not more than ten million\ndollars may be used on or after July 1, 2023, for such purpose, (7) to provide\n(A) a grant-in-aid to the Connecticut Supplier Connection in an amount equal\nto two hundred fifty thousand dollars in each of the fiscal years ending June\n30, 2017, to June 30, 2021, inclusive, and (B) a grant-in-aid to the\nConnecticut Procurement Technical Assistance Program in an amount equal to\nthree hundred thousand dollars in each of the fiscal years ending June 30,\n2017, to June 30, 2021, inclusive, (8) to deposit four hundred fifty thousand\ndollars per year, in each of the fiscal years ending June 30, 2017, to June\n30, 2021, inclusive, in the CTNext Fund established pursuant to section\n32-39i, which shall be used by the Department of Economic and Community\nDevelopment to provide growth grants-in-aid pursuant to section 32-39g,\nprovided any portion of any such deposit that remains unexpended in a fiscal\nyear subsequent to the date of such deposit may be used by the Department of\nEconomic and Community Development for any purpose described in subsection (e)\nof section 32-39i, (9) to transfer fifty million dollars to the Labor\nDepartment which shall be used by said department for the purpose of funding\nworkforce pipeline programs selected pursuant to section 31-11rr, provided,\nnotwithstanding the provisions of section 31-11rr, (A) not less than five\nmillion dollars shall be provided to the workforce development board in\nBridgeport serving the southwest region, for purposes of such program, and the\nboard shall distribute such money in proportion to population and need, and\n(B) not less than five million dollars shall be provided to the workforce\ndevelopment board in Hartford serving the north central region, for purposes\nof such program, (10) to transfer twenty million dollars to Connecticut\nInnovations, Incorporated, provided ten million dollars shall be used by\nConnecticut Innovations, Incorporated for the purpose of the proof of concept\nfund established pursuant to subsection (b) of section 32-39x and ten million\ndollars shall be used by Connecticut Innovations, Incorporated for the purpose\nof the venture capital fund program established pursuant to section 32-41oo,\n(11) to provide a grant to The University of Connecticut of eight million\ndollars for the establishment, development and operation of a center for\nsustainable aviation pursuant to subsection (a) of section 10a-110o, and (12)\nfor up to twenty million dollars in investments in federally designated\nopportunity zones through an impact investment firm including, subject to the\napproval of the Governor, funding from the Economic Assistance Revolving Fund,\nestablished pursuant to section 32-231.\n\nSec. 22. (Effective July 1, 2025) Not later than December 31, 2025, the\nDepartment of Economic and Community Development shall, within available\nappropriations, in partnership with public and private institutions of higher\neducation in the state and in coordination with the artificial intelligence\nindustry, conduct a \"CT AI Symposium\" to foster collaboration between\nacademia, government and the artificial intelligence industry for the purpose\nof promoting the establishment and growth of artificial intelligence\nbusinesses in this state.\n\nSec. 23. (Effective July 1, 2025) (a) As used in this section:\n\n(1) \"Artificial intelligence\" means artificial intelligence system, as defined\nin section 1 of this act;\n\n(2) \"Generative artificial intelligence\" means any form of artificial\nintelligence, including, but not limited to, a foundation model, that is able\nto produce synthetic digital content, as defined in section 1 of this act; and\n\n(3) \"State agency\" means any department, board, council, commission,\ninstitution or other executive branch agency of state government, including,\nbut not limited to, each constituent unit and each public institution of\nhigher education.\n\n(b) Each state agency shall, in consultation with the labor unions\nrepresenting the employees of such state agency, study how generative\nartificial intelligence may be incorporated in its processes to improve\nefficiencies. Each state agency shall prepare for any such incorporation with\ninput from the state agency's employees, including, but not limited to, any\napplicable collective bargaining unit that represents its employees, and\nappropriate experts from civil society organizations, academia and industry.\n\n(c) Not later than January 1, 2026, each state agency shall submit the results\nof such study to the Department of Administrative Services, including a\nrequest for approval of any potential pilot project utilizing generative\nartificial intelligence that the state agency intends to establish, provided\nsuch use is in accordance with the policies and procedures established by the\nOffice of Policy and Management pursuant to subsection (b) of section 4-68jj\nof the general statutes. Any such pilot project shall measure how generative\nartificial intelligence (1) improves Connecticut residents' experience with\nand access to government services, and (2) supports state agency employees in\nthe performance of their duties in addition to any domain-specific impacts to\nbe measured by the state agency. The Commissioner of Administrative Services\nshall assess any such proposed pilot project in accordance with the provisions\nof section 4a-2e of the general statutes, as amended by this act, and may\ndisapprove any pilot project that fails such assessment or requires additional\nlegislative authorization.\n\n(d) Not later than February 1, 2026, the Commissioner of Administrative\nServices shall submit a report, in accordance with the provisions of section\n11-4a of the general statutes, to the joint standing committees of the General\nAssembly having cognizance of matters relating to consumer protection and\ngovernment administration. Such report shall include a summary of all pilot\nprojects approved by the commissioner under this section and any\nrecommendations for legislation necessary to implement additional pilot\nprojects.\n\nSec. 24. Section 32-39e of the general statutes is repealed and the following\nis substituted in lieu thereof (Effective July 1, 2025):\n\n(a) If, in the exercise of its powers under section 32-39, Connecticut\nInnovations, Incorporated (1) finds that the use of a certain technology,\nproduct or process _, including, but not limited to, an artificial\nintelligence system, as defined in section 1 of this act,_ (A) would promote\npublic health and safety, environmental protection or economic development, or\n(B) with regard to state services, would promote efficiency, reduce\nadministrative burdens or otherwise improve such services, and (2) determines\nsuch technology, product or process was developed by a business (A) domiciled\nin this state to which the corporation has provided financial assistance or in\nwhich the corporation has invested, or (B) which has been certified as a small\ncontractor or minority business enterprise by the Commissioner of\nAdministrative Services under section 4a-60g, the corporation, upon\napplication of such business, may recommend to the Secretary of the Office of\nPolicy and Management that an agency of the state, including, but not limited\nto, any constituent unit of the state system of higher education, be\nauthorized to test such technology, product or process by employing ~~it~~\n_such technology, product or process_ in the operations of such agency on a\ntrial basis. The purpose of such test program shall be to validate the\ncommercial viability of such technology, product or process provided no\nbusiness in which Connecticut Innovations, Incorporated has invested shall be\nrequired to participate in such program.\n\n(b) Connecticut Innovations, Incorporated shall make no such recommendation\nunless such business has submitted a viable business plan to Connecticut\nInnovations, Incorporated for manufacturing and marketing such technology,\nproduct or process and such business demonstrates that (1) the usage of such\ntechnology, product or process by the state agency will not adversely affect\nsafety, (2) sufficient research and development has occurred to warrant\nparticipation in the test program, (3) the technology, product or process has\npotential for commercialization not later than two years following the\ncompletion of any test program involving a state agency under this section,\nand (4) such technology, product or process will have a positive economic\nimpact in the state, including the prospective addition of jobs and economic\nactivity upon such commercialization.\n\n(c) If the Secretary of the Office of Policy and Management finds that\nemploying such technology, product or process would be feasible in the\noperations of a state agency and would not have any detrimental effect on such\noperations, said secretary, notwithstanding the requirement of chapter 58, may\ndirect an agency of the state to accept delivery of such technology, product\nor process and to undertake such a test program. The Secretary of the Office\nof Policy and Management, in consultation with the Commissioner of\nAdministrative Services, the chief executive officer of Connecticut\nInnovations, Incorporated and the department head of the testing agency, shall\ndetermine, on a case-by-case basis, whether the costs associated with the\nacquisition and use of such technology, product or process by the testing\nagency shall be borne by Connecticut Innovations, Incorporated, the business\nor by any investor or participant in such business. The acquisition of any\ntechnology, product or process for purposes of the test program established\npursuant to this section shall not be deemed to be a purchase under the\nprovisions of the state procurement policy. The testing agency, on behalf of\nConnecticut Innovations, Incorporated shall maintain records related to such\ntest program, as requested by Connecticut Innovations, Incorporated and shall\nmake such records and any other information derived from such test program\navailable to Connecticut Innovations, Incorporated and the business. Any\nproprietary information derived from such test program shall be exempt from\nthe provisions of subsection (a) of section 1-210.\n\n(d) If the Secretary of the Office of Policy and Management, in consultation\nwith the Commissioner of Administrative Services, the chief executive officer\nof Connecticut Innovations, Incorporated and the department head of the\ntesting agency, determines that the test program sufficiently demonstrates\nthat the technology, product or process promotes public health and safety,\nenvironmental protection, economic development or efficiency, reduces\nadministrative burdens or otherwise improves state services, the Commissioner\nof Administrative Services may procure such technology, product or process for\nuse by any or all state agencies pursuant to subsection (b) of section 4a-58.\n\n(e) The Secretary of the Office of Policy and Management, the Commissioner of\nAdministrative Services and Connecticut Innovations, Incorporated may develop\na program to recognize state agencies that help to promote public health and\nsafety, environmental protection, economic development or efficiency, reduce\nadministrative burdens or improve state services by participating in a testing\nprogram under this section. Such program may include the creation of a fund\nestablished with savings accrued by the testing agency during its\nparticipation in the testing program established under this section. Such fund\nshall only be used to implement the program of recognition established by the\nSecretary of the Office of Policy and Management, the Commissioner of\nAdministrative Services and Connecticut Innovations, Incorporated, under the\nprovisions of this subsection.\n\n_(f) The Secretary of the Office of Policy and Management, the Commissioner of\nAdministrative Services, Connecticut Innovations, Incorporated, and the Chief\nInformation Officer shall, within available appropriations, establish an\nartificial intelligence systems fellowship program for the purpose of\nassisting the Chief Information Officer and state agencies to implement\nartificial intelligence systems procured pursuant to subsection (b) of section\n4a-58. The program shall be within the Office of Policy and Management for\nadministrative purposes only. Not later than January 1, 2026, the Governor\nshall appoint three artificial intelligence technology fellows in consultation\nwith the Chief Information Officer. Each artificial intelligence technology\nfellow shall have professional experience or academic qualifications in the\nfield of artificial intelligence, and shall perform such artificial\nintelligence technology fellow 's duties under the supervision of the Chief\nInformation Officer. The initial term for each artificial intelligence\ntechnology fellow shall expire on January 31, 2029. Terms following initial\nterms shall be for two years, and any artificial intelligence technology\nfellow may serve more than one term. The Governor shall fill any vacancy in\nconsultation with the Chief Information Officer not later than thirty days\nafter the appointment becomes vacant. For the purposes of this subsection,\n\"artificial intelligence system\" has the same meaning as provided in section 1\nof this act._\n\nSec. 25. (Effective July 1, 2025) (a) For the purposes of this section:\n\n(1) \"Artificial intelligence\" means artificial intelligence system, as defined\nin section 1 of this act;\n\n(2) \"General-purpose artificial intelligence\" means general-purpose artificial\nintelligence model, as defined in section 1 of this act; and\n\n(3) \"Synthetic digital content\" has the same meaning as provided in section 1\nof this act.\n\n(b) There is established a working group to engage stakeholders and experts\nto:\n\n(1) Make recommendations concerning:\n\n(A) The best practices to avoid the negative impacts, and to maximize the\npositive impacts, on services and state employees in connection with the\nimplementation of new digital technologies and artificial intelligence;\n\n(B) The collection of reports, recommendations and plans from state agencies\nconsidering the implementation of artificial intelligence, and the assessment\nof such reports, recommendations and plans against the best practices\ndescribed in subparagraph (A) of this subdivision; and\n\n(C) Any other matters that the working group may deem relevant for the\npurposes of avoiding the negative impacts, and maximizing the positive\nimpacts, described in subparagraph (A) of this subdivision;\n\n(2) Make recommendations concerning methods to create resources for the\npurpose of assisting small businesses to adopt artificial intelligence to\nimprove their efficiency and operations;\n\n(3) Propose legislation to (A) regulate the use of general-purpose artificial\nintelligence, and (B) require social media platforms to provide a signal when\nsuch social media platforms are displaying synthetic digital content;\n\n(4) After reviewing the laws and regulations, and any proposed legislation or\nregulations, of other states concerning artificial intelligence, propose\nlegislation concerning artificial intelligence;\n\n(5) Develop an outreach plan for the purpose of bridging the digital divide\nand providing workforce training to persons who do not have high-speed\nInternet access;\n\n(6) Evaluate and make recommendations concerning:\n\n(A) The establishment of testbeds to support safeguards and systems to prevent\nthe misuse of artificial intelligence;\n\n(B) Risk assessments for the misuse of artificial intelligence;\n\n(C) Evaluation strategies for artificial intelligence; and\n\n(D) The development, testing and evaluation of resources to support state\noversight of artificial intelligence;\n\n(7) Review the protections afforded to trade secrets and other proprietary\ninformation under existing state law and make recommendations concerning such\nprotections;\n\n(8) Study definitions concerning artificial intelligence, including, but not\nlimited to, the definition of high-risk artificial intelligence system set\nforth in section 1 of this act, and make recommendations concerning the\ninclusion of language providing that no artificial intelligence system shall\nbe considered to be a high-risk artificial intelligence system if such\nartificial intelligence system does not pose a significant risk of harm to the\nhealth, safety or fundamental rights of individuals, including, but not\nlimited to, by not materially influencing the outcome of any decision-making;\n\n(9) Make recommendations concerning the establishment and membership of a\npermanent artificial intelligence advisory council; and\n\n(10) Make such other recommendations concerning artificial intelligence that\nthe working group may deem appropriate.\n\n(c) (1) (A) The working group shall be part of the Legislative Department and\nconsist of the following voting members: (i) One appointed by the speaker of\nthe House of Representatives, who shall be a representative of the industries\nthat are developing artificial intelligence; (ii) one appointed by the\npresident pro tempore of the Senate, who shall be a representative of the\nindustries that are using artificial intelligence; (iii) one appointed by the\nmajority leader of the House of Representatives, who shall be an academic with\na concentration in the study of technology and technology policy; (iv) one\nappointed by the majority leader of the Senate, who shall be an academic with\na concentration in the study of government and public policy; (v) one\nappointed by the minority leader of the House of Representatives, who shall be\na representative of an industry association representing the industries that\nare developing artificial intelligence; (vi) one appointed by the minority\nleader of the Senate, who shall be a representative of an industry association\nrepresenting the industries that are using artificial intelligence; (vii) one\nappointed by the House chairperson of the joint standing committee of the\nGeneral Assembly having cognizance of matters relating to consumer protection;\n(viii) one appointed by the Senate chairperson of the joint standing committee\nof the General Assembly having cognizance of matters relating to consumer\nprotection; (ix) one appointed by the House ranking member of the joint\nstanding committee of the General Assembly having cognizance of matters\nrelating to consumer protection, who shall be a representative of the\nartificial intelligence industry or a related industry; (x) one appointed by\nthe Senate ranking member of the joint standing committee of the General\nAssembly having cognizance of matters relating to consumer protection, who\nshall be a representative of the artificial intelligence industry or a related\nindustry; (xi) one appointed by the House chairperson of the joint standing\ncommittee of the General Assembly having cognizance of matters relating to\nlabor, who shall be a representative of a labor organization; (xii) one\nappointed by the Senate chairperson of the joint standing committee of the\nGeneral Assembly having cognizance of matters relating to labor, who shall be\na representative of a labor organization; (xiii) one appointed by the House\nranking member of the joint standing committee of the General Assembly having\ncognizance of matters relating to labor, who shall be a representative of a\nsmall business; (xiv) one appointed by the Senate ranking member of the joint\nstanding committee of the General Assembly having cognizance of matters\nrelating to labor, who shall be a representative of a small business; and (xv)\ntwo appointed by the Governor, who shall be members of the Connecticut Academy\nof Science and Engineering.\n\n(B) All voting members of the working group appointed pursuant to subparagraph\n(A) of this subdivision shall have professional experience or academic\nqualifications in matters pertaining to artificial intelligence, automated\nsystems, government policy or another related field.\n\n(C) All initial appointments to the working group shall be made not later than\nJuly 31, 2025. Any vacancy shall be filled by the appointing authority.\n\n(D) Any action taken by the working group shall be taken by a majority vote of\nall members present who are entitled to vote, provided no such action may be\ntaken unless at least fifty per cent of such members are present.\n\n(2) The working group shall include the following nonvoting, ex-officio\nmembers: (A) The House chairperson of the joint standing committee of the\nGeneral Assembly having cognizance of matters relating to consumer protection;\n(B) the Senate chairperson of the joint standing committee of the General\nAssembly having cognizance of matters relating to consumer protection; (C) the\nHouse chairperson of the joint standing committee of the General Assembly\nhaving cognizance of matters relating to labor; (D) the Senate chairperson of\nthe joint standing committee of the General Assembly having cognizance of\nmatters relating to labor; (E) the Attorney General, or the Attorney General's\ndesignee; (F) the Comptroller, or the Comptroller's designee; (G) the\nTreasurer, or the Treasurer's designee; (H) the Commissioner of Administrative\nServices, or said commissioner's designee; (I) the Chief Data Officer, or said\nofficer's designee; (J) the executive director of the Freedom of Information\nCommission, or said executive director's designee; (K) the executive director\nof the Commission on Women, Children, Seniors, Equity and Opportunity, or said\nexecutive director's designee; (L) the Chief Court Administrator, or said\nadministrator's designee; and (M) the executive director of the Connecticut\nAcademy of Science and Engineering, or said executive director's designee.\n\n(d) The chairpersons of the joint standing committee of the General Assembly\nhaving cognizance of matters relating to consumer protection and the executive\ndirector of the Connecticut Academy of Science and Engineering shall serve as\nchairpersons of the working group. Such chairpersons shall schedule the first\nmeeting of the working group, which shall be held not later than August 31,\n2025.\n\n(e) The administrative staff of the joint standing committee of the General\nAssembly having cognizance of matters relating to consumer protection shall\nserve as administrative staff of the working group.\n\n(f) Not later than February 1, 2026, the working group shall submit a report\non its findings and recommendations to the joint standing committee of the\nGeneral Assembly having cognizance of matters relating to consumer protection,\nin accordance with the provisions of section 11-4a of the general statutes.\nThe working group shall terminate on the date that the working group submits\nsuch report or February 1, 2026, whichever is later.\n\nSec. 26. Section 4a-2e of the general statutes is repealed and the following\nis substituted in lieu thereof (Effective July 1, 2025):\n\n(a) For the purposes of this section:\n\n(1) \"Artificial intelligence\" means ~~(A) an artificial system that (i)\nperforms tasks under varying and unpredictable circumstances without\nsignificant human oversight or can learn from experience and improve such\nperformance when exposed to data sets, (ii) is developed in any context,\nincluding, but not limited to, software or physical hardware, and solves tasks\nrequiring human-like perception, cognition, planning, learning, communication\nor physical action, or (iii) is designed to (I) think or act like a human,\nincluding, but not limited to, a cognitive architecture or neural network, or\n(II) act rationally, including, but not limited to, an intelligent software\nagent or embodied robot that achieves goals using perception, planning,\nreasoning, learning, communication, decision-making or action, or (B) a set of\ntechniques, including, but not limited to, machine learning, that is designed\nto approximate a cognitive task; and~~ _artificial intelligence system, as\ndefined in section 1 of this act;_\n\n_(2) \"Generative artificial intelligence\" means any form of artificial\nintelligence, including, but not limited to, a foundation model, that is able\nto produce synthetic digital content, as defined in section 1 of this act;\nand_\n\n~~(2)~~ _(3)_ \"State agency\" has the same meaning as provided in section 4d-1.\n\n(b) (1) Not later than December 31, 2023, and annually thereafter, the\n~~Department~~ _Commissioner_ of Administrative Services shall conduct an\ninventory of all systems that employ artificial intelligence and are in use by\nany state agency. Each such inventory shall include at least the following\ninformation for each such system:\n\n(A) The name of such system and the vendor, if any, that provided such system;\n\n(B) A description of the general capabilities and uses of such system;\n\n(C) Whether such system was used to independently make, inform or materially\nsupport a conclusion, decision or judgment; and\n\n(D) Whether such system underwent an impact assessment prior to\nimplementation.\n\n(2) The ~~Department~~ _Commissioner_ of Administrative Services shall make\neach inventory conducted pursuant to subdivision (1) of this subsection\npublicly available on the state's open data portal.\n\n(c) Beginning on February 1, 2024, the ~~Department~~ _Commissioner_ of\nAdministrative Services shall perform ongoing assessments of systems that\nemploy artificial intelligence and are in use by state agencies to ensure that\nno such system shall result in any unlawful discrimination or disparate impact\ndescribed in subparagraph (B) of subdivision (1) of subsection (b) of section\n4-68jj. The ~~department~~ _commissioner_ shall perform such assessment in\naccordance with the policies and procedures established by the Office of\nPolicy and Management pursuant to subsection (b) of section 4-68jj.\n\n_(d) The Commissioner of Administrative Services shall, in consultation with\nother state agencies, collective bargaining units that represent state agency\nemployees and industry experts, develop trainings for state agency employees\non (1) the use of generative artificial intelligence tools that are determined\nby the commissioner, pursuant to the assessment performed under subsection (c)\nof this section, to achieve equitable outcomes, and (2) methods for\nidentifying and mitigating potential output inaccuracies, fabricated text,\nhallucinations and biases of generative artificial intelligence while\nrespecting the privacy of the public and complying with all applicable state\nlaws and policies. Beginning on July 1, 2026, the commissioner shall make such\ntrainings available to state agency employees not less frequently than\nannually._\n\nSec. 27. (NEW) (Effective July 1, 2025) The Department of Economic and\nCommunity Development shall, within available appropriations, design an\nalgorithmic computer model for the purpose of simulating and assessing various\npublic policy decisions, proposed public policy decisions and the actual or\npotential effects of such policy decisions. The department shall design such\nmodel in collaboration with public and private institutions of higher\neducation in this state, the Department of Energy and Environmental Protection\nand any other state agency the Commissioner of Economic and Community\nDevelopment, in the commissioner's discretion, deems relevant for the purposes\nof this section. Such model shall, at a minimum, be designed to (1) function\nas a digital twin of the population of the state, (2) algorithmically model\n(A) the actual or potential effects of planning and development decisions or\nproposed planning and development decisions, and (B) the actual or potential\nsocioeconomic effects of macroeconomic shocks on businesses and families in\nthe state, (3) utilize large quantities of data to support the development of\npublic policies concerning coastline resiliency, family assistance and\nworkforce development, and (4) enable data-driven governance by optimizing\nresource allocation and policy efficiency for the purpose of furthering\neconomic resilience and social equity.\n\nSec. 28. Section 53a-189c of the general statutes is repealed and the\nfollowing is substituted in lieu thereof (Effective October 1, 2025):\n\n(a) A person is guilty of unlawful dissemination of an intimate image when (1)\nsuch person intentionally disseminates by electronic or other means a\nphotograph, film, videotape or other recorded image _or synthetic image_ of\n(A) the genitals, pubic area or buttocks of another person with less than a\nfully opaque covering of such body part, or the breast of such other person\nwho is female with less than a fully opaque covering of any portion of such\nbreast below the top of the nipple, or (B) another person engaged in sexual\nintercourse, as defined in section 53a-193, (2) such person disseminates such\nimage ~~without the consent of such other person,~~ knowing that such other\nperson ~~understood that the image would not be so disseminated~~ _did not\nconsent to such dissemination_ , and (3) such other person suffers harm as a\nresult of such dissemination.\n\n_(b)_ For purposes of this ~~subsection, \"disseminate\"~~ _section:_\n\n_(1) \"Disseminate\"_ means to sell, give, provide, lend, trade, mail, deliver,\ntransfer, publish, distribute, circulate, present, exhibit, advertise or\notherwise offer _;_ ~~, and \"harm\"~~\n\n_(2) \"Harm\"_ includes, but is not limited to, subjecting such other person to\nhatred, contempt, ridicule, physical injury, financial injury, psychological\nharm or serious emotional distress _; and_\n\n_(3) \"Synthetic image\" means any photograph, film, videotape or other image\nthat (A) is not wholly recorded by a camera, (B) is either partially or wholly\ngenerated by a computer system, and (C) depicts, and is virtually\nindistinguishable from an actual representation of, an identifiable person_.\n\n~~(b)~~ _(c)_ The provisions of subsection (a) of this ~~subsection~~\n_section_ shall not apply to:\n\n(1) Any image described in subsection (a) of this section of such other person\nif such image resulted from voluntary exposure or engagement in sexual\nintercourse by such other person, in a public place, as defined in section\n53a-181, or in a commercial setting;\n\n(2) Any image described in subsection (a) of this section of such other\nperson, if such other person is not clearly identifiable, unless other\npersonally identifying information is associated with or accompanies the\nimage; or\n\n(3) Any image described in subsection (a) of this section of such other\nperson, if the dissemination of such image serves the public interest.\n\n~~(c)~~ _(d)_ Unlawful dissemination of an intimate image to (1) a person by\nany means is a class A misdemeanor, and (2) more than one person by means of\nan interactive computer service, as defined in 47 USC 230, an information\nservice, as defined in 47 USC 153, or a telecommunications service, as defined\nin section 16-247a, is a class D felony.\n\n~~(d)~~ _(e)_ Nothing in this section shall be construed to impose liability\non the provider of an interactive computer service, as defined in 47 USC 230,\nan information service, as defined in 47 USC 153, or a telecommunications\nservice, as defined in section 16-247a, for content provided by another\nperson.\n\nThis act shall take effect as follows and shall amend the following sections:  \n  \n---  \nSection 1 | October 1, 2025 | New section  \nSec. 2 | October 1, 2025 | New section  \nSec. 3 | October 1, 2025 | New section  \nSec. 4 | October 1, 2025 | New section  \nSec. 5 | October 1, 2025 | New section  \nSec. 6 | October 1, 2025 | New section  \nSec. 7 | October 1, 2025 | New section  \nSec. 8 | October 1, 2025 | New section  \nSec. 9 | October 1, 2025 | New section  \nSec. 10 | October 1, 2025 | New section  \nSec. 11 | October 1, 2025 | New section  \nSec. 12 | October 1, 2025 | New section  \nSec. 13 | July 1, 2025 | New section  \nSec. 14 | July 1, 2025 | New section  \nSec. 15 | July 1, 2025 | 17b-751b(b)  \nSec. 16 | July 1, 2025 | New section  \nSec. 17 | July 1, 2025 | New section  \nSec. 18 | July 1, 2025 | New section  \nSec. 19 | July 1, 2025 | 10-21l  \nSec. 20 | July 1, 2025 | 32-7p  \nSec. 21 | July 1, 2025 | 32-235(b)  \nSec. 22 | July 1, 2025 | New section  \nSec. 23 | July 1, 2025 | New section  \nSec. 24 | July 1, 2025 | 32-39e  \nSec. 25 | July 1, 2025 | New section  \nSec. 26 | July 1, 2025 | 4a-2e  \nSec. 27 | July 1, 2025 | New section  \nSec. 28 | October 1, 2025 | 53a-189c  \n  \n**Statement of Legislative Commissioners:**\n\nIn Section 1(9)(B), \"or system\" was added after \"unless the technology\" and\n\"does not include\" was added before \"(i)\" for internal consistency; in Section\n1(13), \"identify\" was added before \"how\" for internal consistency; in Section\n3(d)(2)(B), \"any intentional\" was changed to \"an intentional\" for consistency;\nin Section 4(e)(1)(B)(ii), \"said subparagraph (C)\" was changed to \"said\nsubparagraph\" for consistency with standard drafting conventions; in Section\n12(b)(3), \"being\" was added before \"exempt\" for clarity; in Section 12(d),\n\"subparagraph (B) of\" was added before \"subdivision (2)\" for accuracy; and in\nSections 12(g), 16(e)(3), 17(b), 23(d) and 25(f), \"the provisions of\" was\nadded before \"section 11-4a\" for consistency with standard drafting\nconventions.\n\nCopyright (C) 2025 State Net  \n  \n---\n\n",
      "latest_version": true
    },
    {
      "date": "04/09/2025",
      "label": "Substituted",
      "url": "https://custom.statenet.com/public/resources.cgi?mode=show_text&id=ID:bill:CT2025000S2&verid=CT2025000S2_20250409_0_S&",
      "raw_html": "<html>\n<head>\n<title>Bill Resource</title>\n\n<!--   <link href=\"https://custom.statenet.com/network/Common/css/extregtext.css\" rel=\"stylesheet\" type=\"text/css\" />-->\n   <link href=\"https://custom.statenet.com/network/Common/css/xmltext-2.0.css\" rel=\"stylesheet\" type=\"text/css\" />\n   <link href=\"https://custom.statenet.com/network/Common/css/additional-text.css\" rel=\"stylesheet\" type=\"text/css\" />\n\n\t<style type=\"text/css\">\n<!--\n\ntd, body {\n     background-color: white;\n\tfont-family: Verdana, Arial, Helvetica, sans-serif;\n\tfont-size: 12px;\n}\n\n.resourceContainer {\n   border: 1px solid black;\n}\n-->\n</style>\n</head>\n<body>\n\n    <div style=\"width: 750px; margin: auto\">\n       <div style=\"font-size: .8em;margin-bottom: 10px\"><table width=\"100%\"><tr><td align=\"left\" style=\"font-size: .8em;\"><div>The following has special meaning:</div>\n<div><u class=\"amendmentInsertedText\">green underline denotes added text</u></div>\n<div><strike class=\"amendmentDeletedText\">red struck out text denotes deleted text</strike></div></td> <td align=\"right\"><a href=\"https://www.lexisnexis.com/statenet/\"><img alt=\"Powered by State Net\" src=\"https://custom.statenet.com/network/poweredby.gif\" /></a></td></tr></table></div><table id=\"text-identifier\"><tr><td class=\"key\">2025 CT S 2</td> <td><table><tr><td class=\"label\">Author:</td> <td>Looney</td></tr> <tr><td class=\"label\">Version:</td> <td>Substituted</td></tr> <tr><td class=\"label\">Version Date:</td> <td>04/09/2025</td></tr></table></td></tr></table><div class=\"documentBody\">\n  <a name=\"head_document_section\"></a><div class=\"head\">\n   <p class=\"center\">\n    <b>STATE OF CONNECTICUT</b>\n   </p>\n   <p class=\"center\">\n    <b>General Assembly</b>\n   </p>\n   <p class=\"center\">\n    <b>Substitute Bill No. 2</b>\n   </p>\n   <p class=\"center\">\n    <b>January Session, 2025</b>\n   </p>\n  </div>\n  <a name=\"title_document_section\"></a><div class=\"title\">\n   <p class=\"indent\">AN ACT CONCERNING ARTIFICIAL INTELLIGENCE.</p>\n  </div>\n  <a name=\"text_document_section\"></a><div class=\"text\">\n   <span>\n    <p class=\"indent\">Be it enacted by the Senate and House of Representatives in General Assembly convened:</p>\n   </span>\n   <p class=\"indent\">Section 1. (NEW) (Effective October 1, 2025) For the purposes of this section and sections 2 to 10, inclusive, of this act, unless the context otherwise requires:</p>\n   <p class=\"indent\">(1) &quot;Algorithmic discrimination&quot; (A) means any use of an artificial intelligence system that results in any unlawful differential treatment or impact that disfavors any individual or group of individuals on the basis of one or more classifications protected under the laws of this state or federal law, and (B) does not include (i) the offer, license or use of a high-risk artificial intelligence system by a developer, integrator or deployer for the sole purpose of (I) the developer&#39;s, integrator&#39;s or deployer&#39;s testing to identify, mitigate or prevent discrimination or otherwise ensure compliance with state and federal law, or (II) expanding an applicant, customer or participant pool to increase diversity or redress historic discrimination, or (ii) an act or omission by or on behalf of a private club or other establishment not in fact open to the public, as set forth in Title II of the Civil Rights Act of 1964, 42 USC 2000a(e), as amended from time to time;</p>\n   <p class=\"indent\">(2) &quot;Artificial intelligence system&quot; means any machine-based system that, for any explicit or implicit objective, infers from the inputs such system receives how to generate outputs, including, but not limited to, content, decisions, predictions or recommendations, that can influence physical or virtual environments;</p>\n   <p class=\"indent\">(3) &quot;Consequential decision&quot; means any decision or judgment that has a material legal or similarly significant effect on a consumer with respect to (A) access to employment, including, but not limited to, any such decision or judgment made concerning hiring, termination, compensation or promotion, (B) access to education or vocational training, including, but not limited to, any such decision or judgment made concerning admissions, financial aid or scholarships, (C) the provision or denial, or terms and conditions, of (i) financial lending or credit services, (ii) housing or lodging, including, but not limited to, rentals or short-term housing or lodging, (iii) insurance, or (iv) legal services, or (D) access to (i) essential government services, or (ii) health care services;</p>\n   <p class=\"indent\">(4) &quot;Consumer&quot; means any individual who is a resident of this state;</p>\n   <p class=\"indent\">(5) &quot;Deploy&quot; means to put a high-risk artificial intelligence system into use;</p>\n   <p class=\"indent\">(6) &quot;Deployer&quot; means any person doing business in this state that deploys a high-risk artificial intelligence system in this state;</p>\n   <p class=\"indent\">(7) &quot;Developer&quot; means any person doing business in this state that develops, or intentionally and substantially modifies, an artificial intelligence system;</p>\n   <p class=\"indent\">(8) &quot;General-purpose artificial intelligence model&quot; (A) means a model used by an artificial intelligence system that (i) displays significant generality, (ii) is capable of competently performing a wide range of distinct tasks, and (iii) can be integrated into a variety of downstream applications or systems, and (B) does not include any artificial intelligence model that is used for development, prototyping and research activities before such artificial intelligence model is released on the market;</p>\n   <p class=\"indent\">(9) &quot;High-risk artificial intelligence system&quot; (A) means any artificial intelligence system that is intended, when deployed, to make, or be a substantial factor in making, a consequential decision, and (B) unless the technology or system, when deployed, makes, or is a substantial factor in making, a consequential decision, does not include (i) any anti-fraud technology that does not make use of facial recognition technology, (ii) any artificial intelligence-enabled video game technology, (iii) any anti-malware, anti-virus, calculator, cybersecurity, database, data storage, firewall, Internet domain registration, Internet-web-site loading, networking, robocall-filtering, spam-filtering, spellchecking, spreadsheet, web-caching, web-hosting or similar technology, (iv) any technology that performs tasks exclusively related to an entity&#39;s internal management affairs, including, but not limited to, ordering office supplies or processing payments, (v) any system that classifies incoming documents into categories, is used to detect duplicate applications among a large number of applications or otherwise performs narrow tasks of such a limited nature that performance of such tasks poses a limited risk of algorithmic discrimination, (vi) any technology that merely detects decision-making patterns or deviations from prior decision-making patterns following a previously completed human assessment that such technology is not meant to replace or influence without sufficient human review, including, but not limited to, any technology that analyzes a particular decision-maker&#39;s prior pattern of decisions and flags potential inconsistencies or anomalies, or (vii) any technology that communicates with consumers in natural language for the purpose of providing users with information, making referrals or recommendations and answering questions, and is subject to an acceptable use policy that prohibits generating content that is discriminatory or harmful;</p>\n   <p class=\"indent\">(10) &quot;Integrator&quot; means any person doing business in this state that, with respect to a given high-risk artificial intelligence system, (A) neither develops nor intentionally and substantially modifies the high-risk artificial intelligence system, and (B) integrates the high-risk artificial intelligence system into a product or service such person offers to any other person;</p>\n   <p class=\"indent\">(11) &quot;Intentional and substantial modification&quot; (A) means any deliberate material change made to (i) an artificial intelligence system that was not predetermined by a developer and materially increases the risk of algorithmic discrimination, or (ii) a general-purpose artificial intelligence model that (I) affects compliance of the general-purpose artificial intelligence model, (II) materially changes the purpose of the general-purpose artificial intelligence model, or (III) materially increases the risk of algorithmic discrimination, and (B) does not include any change made to a high-risk artificial intelligence system, or the performance of a high-risk artificial intelligence system, if (i) the high-risk artificial intelligence system continues to learn after such high-risk artificial intelligence system is (I) offered, sold, leased, licensed, given or otherwise made available to a deployer, or (II) deployed, and (ii) such change (I) is made to such high-risk artificial intelligence system as a result of any learning described in subparagraph (B)(i) of this subdivision, (II) was predetermined by the deployer, or the third party contracted by the deployer, when such deployer or third party completed the initial impact assessment of such high-risk artificial intelligence system pursuant to subsection (c) of section 4 of this act, and (III) is included in the technical documentation for such high-risk artificial intelligence system;</p>\n   <p class=\"indent\">(12) &quot;Person&quot; means any individual, association, corporation, limited liability company, partnership, trust or other legal entity;</p>\n   <p class=\"indent\">(13) &quot;Red-teaming&quot; means an adversarial exercise that is conducted to identify the potential adverse behaviors or outcomes of an artificial intelligence system, identify how such behaviors or outcomes occur and stress test the safeguards against such behaviors or outcomes;</p>\n   <p class=\"indent\">(14) &quot;Substantial factor&quot; (A) means a factor that (i) alters the outcome of a consequential decision, and (ii) is generated by an artificial intelligence system, (B) includes, but is not limited to, any use of an artificial intelligence system to generate any content, decision, prediction or recommendation concerning a consumer that is used as a basis to make a consequential decision concerning the consumer, and (C) does not include any output produced by an artificial intelligence system where an individual was involved in the data processing that produced such output and such individual (i) meaningfully considered such data as part of such data processing, and (ii) had the authority to change or influence the output produced by such data processing;</p>\n   <p class=\"indent\">(15) &quot;Synthetic digital content&quot; means any digital content, including, but not limited to, any audio, image, text or video, that is produced or manipulated by an artificial intelligence system, including, but not limited to, a general-purpose artificial intelligence model; and</p>\n   <p class=\"indent\">(16) &quot;Trade secret&quot; has the same meaning as provided in section 35-51 of the general statutes.</p>\n   <p class=\"indent\">Sec. 2. (NEW) (Effective October 1, 2025) (a) Beginning on October 1, 2026, a developer of a high-risk artificial intelligence system shall use reasonable care to protect consumers from any known or reasonably foreseeable risks of algorithmic discrimination arising from the intended and contracted uses of the high-risk artificial intelligence system. In any enforcement action brought on or after said date by the Attorney General pursuant to section 10 of this act, there shall be a rebuttable presumption that a developer used reasonable care as required under this subsection if the developer complied with the provisions of this section or, if the developer enters into a contract with an integrator as set forth in subsection (b) of section 3 of this act, the developer and integrator complied with the provisions of this section and section 3 of this act.</p>\n   <p class=\"indent\">(b) Except as provided in subsection (c) of section 3 of this act, a developer of a high-risk artificial intelligence system shall, beginning on October 1, 2026, make available to each deployer, or other developer, of the high-risk artificial intelligence system:</p>\n   <p class=\"indent\">(1) A general statement describing the intended uses, and the known harmful or inappropriate uses, of such high-risk artificial intelligence system;</p>\n   <p class=\"indent\">(2) (A) Documentation disclosing (i) high-level summaries of the type of data used to train such high-risk artificial intelligence system, (ii) the known or reasonably foreseeable limitations of such high-risk artificial intelligence system, including, but not limited to, the known or reasonably foreseeable risks of algorithmic discrimination arising from the intended uses of such high-risk artificial intelligence system, (iii) the purpose of such high-risk artificial intelligence system, and (iv) the intended benefits and uses of such high-risk artificial intelligence system, and (B) any additional documentation that is reasonably necessary to assist such deployer or other developer to understand the outputs, and monitor the performance, of such high-risk artificial intelligence system to enable such deployer or other developer to comply with the provisions of sections 1 to 10, inclusive, of this act; and</p>\n   <p class=\"indent\">(3) Documentation describing (A) how such high-risk artificial intelligence system was evaluated for performance, and mitigation of algorithmic discrimination, before such high-risk artificial intelligence system was offered, sold, leased, licensed, given or otherwise made available to such deployer, (B) the data governance measures used to cover the training datasets and the measures used to examine the suitability of data sources, possible biases and appropriate mitigation, (C) the intended outputs of such high-risk artificial intelligence system, (D) the measures the developer has taken to mitigate any known or reasonably foreseeable risks of algorithmic discrimination that may arise from deployment of such high-risk artificial intelligence system, and (E) how such high-risk artificial intelligence system is intended to be used, based on known or reasonably foreseeable harmful or inappropriate applications, and be monitored by an individual when such high-risk artificial intelligence system is used to make, or as a substantial factor in making, a consequential decision.</p>\n   <p class=\"indent\">(c) (1) Except as provided in subsection (c) of section 3 of this act, any developer that, on or after October 1, 2026, offers, sells, leases, licenses, gives or otherwise makes available to a deployer or another developer a high-risk artificial intelligence system shall, to the extent feasible, make available to the deployers and other developers of such high-risk artificial intelligence system the documentation and information necessary for a deployer, or the third party contracted by a deployer, to complete an impact assessment pursuant to subsection (c) of section 4 of this act. The developer shall make such documentation and information available through artifacts such as system cards or other impact assessments.</p>\n   <p class=\"indent\">(2) A developer that also serves as a deployer for any high-risk artificial intelligence system shall not be required to generate the documentation required by this section unless such high-risk artificial intelligence system is provided to another person that serves as a deployer for such high-risk artificial intelligence system.</p>\n   <p class=\"indent\">(d) (1) Beginning on October 1, 2026, each developer shall make available, in a manner that is clear and readily available on such developer&#39;s Internet web site or in a public use case inventory, a statement summarizing:</p>\n   <p class=\"indent\">(A) The types of high-risk artificial intelligence systems that such developer (i) has developed or intentionally and substantially modified, and (ii) currently makes available to a deployer or another developer; and</p>\n   <p class=\"indent\">(B) How such developer manages any known or reasonably foreseeable risks of algorithmic discrimination that may arise from the intended uses of the types of high-risk artificial intelligence systems described in subparagraph (A) of this subdivision.</p>\n   <p class=\"indent\">(2) Each developer shall update the statement made available pursuant to subdivision (1) of this subsection (A) as necessary to ensure that such statement remains accurate, and (B) not later than ninety days after the developer intentionally and substantially modifies any high-risk artificial intelligence system described in subparagraph (A) of subdivision (1) of this subsection.</p>\n   <p class=\"indent\">(3) Where multiple developers contribute to the development of a high-risk artificial intelligence system, each developer shall be subject to the obligations applicable to developers under sections 1 to 10, inclusive, of this act solely with respect to the activities the developer performed in contributing to the development of such high-risk artificial intelligence system.</p>\n   <p class=\"indent\">(e) Beginning on October 1, 2026, a developer of a high-risk artificial intelligence system shall disclose to the Attorney General, in a form and manner prescribed by the Attorney General, and to all known deployers or other developers of the high-risk artificial intelligence system, any previously disclosed known or reasonably foreseeable risks of algorithmic discrimination arising from the intended uses of such high-risk artificial intelligence system. The developer shall make such disclosures without unreasonable delay but in no event later than ninety days after the date on which:</p>\n   <p class=\"indent\">(1) The developer discovers, through the developer&#39;s ongoing testing and analysis, that the high-risk artificial intelligence system has (A) been deployed, and (B) caused, or is reasonably likely to have caused, algorithmic discrimination to at least one thousand consumers; or</p>\n   <p class=\"indent\">(2) The developer receives, from a deployer of the high-risk artificial intelligence system, a credible report disclosing that such high-risk artificial intelligence system has (A) been deployed, and (B) caused algorithmic discrimination to at least one thousand consumers.</p>\n   <p class=\"indent\">(f) The provisions of subsections (b) to (e), inclusive, of this section shall not be construed to require a developer to disclose any information (1) that is a trade secret or otherwise protected from disclosure under state or federal law, or (2) the disclosure of which would present a security risk to the developer.</p>\n   <p class=\"indent\">(g) Notwithstanding the provisions of subsections (a) to (f), inclusive, of this section, (1) any documentation a developer completes for the purpose of complying with another applicable law or regulation shall be deemed to satisfy the requirements established in this section if such documentation is reasonably similar in scope and effect to the documentation the developer would otherwise be required to complete pursuant to this section, and (2) a developer may contract with a third party to fulfill the developer&#39;s duties under this section.</p>\n   <p class=\"indent\">(h) Beginning on October 1, 2026, the Attorney General may require that a developer disclose to the Attorney General, as part of an investigation conducted by the Attorney General regarding a suspected violation of any provision of sections 1 to 10, inclusive, of this act and in a form and manner prescribed by the Attorney General, the general statement or documentation described in subsection (b) of this section. The Attorney General may evaluate such general statement or documentation to ensure compliance with the provisions of this section. In disclosing such general statement or documentation to the Attorney General pursuant to this subsection, the developer may designate such general statement or documentation as including any information that is exempt from disclosure under subsection (f) of this section or the Freedom of Information Act, as defined in section 1-200 of the general statutes. To the extent such general statement or documentation includes such information, such general statement or documentation shall be exempt from disclosure under subsection (f) of this section or said act. To the extent any information contained in such general statement or documentation is subject to the attorney-client privilege or work product protection, such disclosure shall not constitute a waiver of such privilege or protection.</p>\n   <p class=\"indent\">Sec. 3. (NEW) (Effective October 1, 2025) (a) Beginning on October 1, 2026, if an integrator integrates a high-risk artificial intelligence system into a product or service the integrator offers to any other person, such integrator shall use reasonable care to protect consumers from any known or reasonably foreseeable risks of algorithmic discrimination arising from the intended and contracted uses of such integrated high-risk artificial intelligence system. In any enforcement action brought on or after said date by the Attorney General pursuant to section 10 of this act, there shall be a rebuttable presumption that the integrator used reasonable care as required under this subsection if the integrator complied with the provisions of this section.</p>\n   <p class=\"indent\">(b) Beginning on October 1, 2026, no integrator shall integrate a high-risk artificial intelligence system into a product or service the integrator offers to any other person unless the integrator has entered into a contract with the developer of the high-risk artificial intelligence system. The contract shall be binding and clearly set forth the duties of the developer and integrator with respect to the integrated high-risk artificial intelligence system, including, but not limited to, whether the developer or integrator shall be responsible for performing the developer&#39;s duties under subsections (b) and (c) of section 2 of this act.</p>\n   <p class=\"indent\">(c) The provisions of subsections (b) and (c) of section 2 of this act shall not apply to a developer of an integrated high-risk artificial intelligence system if, at all times while the integrated high-risk artificial intelligence system is integrated into a product or service an integrator offers to any other person, the developer has entered into a contract with the integrator in which such integrator has agreed to assume the developer&#39;s duties under subsections (b) and (c) of section 2 of this act.</p>\n   <p class=\"indent\">(d) (1) Beginning on October 1, 2026, each integrator shall make available, in a manner that is clear and readily available on such integrator&#39;s Internet web site or in a public use case inventory, a statement summarizing:</p>\n   <p class=\"indent\">(A) The types of high-risk artificial intelligence systems that such integrator has integrated into products or services such integrator currently offers to any other person; and</p>\n   <p class=\"indent\">(B) How such integrator manages any known or reasonably foreseeable risks of algorithmic discrimination that may arise from the types of high-risk artificial intelligence systems described in subparagraph (A) of this subdivision.</p>\n   <p class=\"indent\">(2) Each integrator shall update the statement made available pursuant to subdivision (1) of this subsection (A) as necessary to ensure that such statement remains accurate, and (B) not later than ninety days after an intentional and substantial modification is made to any high-risk artificial intelligence system described in subparagraph (A) of subdivision (1) of this subsection.</p>\n   <p class=\"indent\">(e) The provisions of subsections (b) to (d), inclusive, of this section shall not be construed to require a developer or integrator to disclose any information (1) that is a trade secret or otherwise protected from disclosure under state or federal law, or (2) the disclosure of which would present a security risk to the developer or integrator.</p>\n   <p class=\"indent\">(f) Beginning on October 1, 2026, the Attorney General may require that an integrator which has assumed a developer&#39;s duties under subsection (c) of section 2 of this act disclose to the Attorney General, as part of an investigation conducted by the Attorney General regarding a suspected violation of any provision of sections 1 to 10, inclusive, of this act and in a form and manner prescribed by the Attorney General, the general statement or documentation described in said subsection. The Attorney General may evaluate such general statement or documentation to ensure compliance with the provisions of this section and section 2 of this act. In disclosing such general statement or documentation to the Attorney General pursuant to this subsection, the integrator may designate such general statement or documentation as including any information that is exempt from disclosure under subsection (e) of this section or the Freedom of Information Act, as defined in section 1-200 of the general statutes. To the extent such general statement or documentation includes such information, such general statement or documentation shall be exempt from disclosure under subsection (e) of this section or said act. To the extent any information contained in such general statement or documentation is subject to the attorney-client privilege or work product protection, such disclosure shall not constitute a waiver of such privilege or protection.</p>\n   <p class=\"indent\">Sec. 4. (NEW) (Effective October 1, 2025) (a) Beginning on October 1, 2026, each deployer of a high-risk artificial intelligence system shall use reasonable care to protect consumers from any known or reasonably foreseeable risks of algorithmic discrimination. In any enforcement action brought on or after said date by the Attorney General pursuant to section 10 of this act, there shall be a rebuttable presumption that a deployer of a high-risk artificial intelligence system used reasonable care as required under this subsection if the deployer complied with the provisions of this section.</p>\n   <p class=\"indent\">(b) (1) Beginning on October 1, 2026, and except as provided in subsection (g) of this section, each deployer of a high-risk artificial intelligence system shall implement and maintain a risk management policy and program to govern such deployer&#39;s deployment of the high-risk artificial intelligence system. The risk management policy and program shall specify and incorporate the principles, processes and personnel that the deployer shall use to identify, document and mitigate any known or reasonably foreseeable risks of algorithmic discrimination. The risk management policy shall be the product of an iterative process, the risk management program shall be an iterative process and both the risk management policy and program shall be planned, implemented and regularly and systematically reviewed and updated over the lifecycle of the high-risk artificial intelligence system. Each risk management policy and program implemented and maintained pursuant to this subsection shall be reasonable, considering:</p>\n   <p class=\"indent\">(A) The guidance and standards set forth in the latest version of (i) the &quot;Artificial Intelligence Risk Management Framework&quot; published by the National Institute of Standards and Technology, (ii) ISO or IEC 42001 of the International Organization for Standardization, or (iii) a nationally or internationally recognized risk management framework for artificial intelligence systems, other than the guidance and standards specified in subparagraphs (A)(i) and (A)(ii) of this subdivision, that imposes requirements that are substantially equivalent to, and at least as stringent as, the requirements set forth in this section for risk management policies and programs;</p>\n   <p class=\"indent\">(B) The size and complexity of the deployer;</p>\n   <p class=\"indent\">(C) The nature and scope of the high-risk artificial intelligence systems deployed by the deployer, including, but not limited to, the intended uses of such high-risk artificial intelligence systems; and</p>\n   <p class=\"indent\">(D) The sensitivity and volume of data processed in connection with the high-risk artificial intelligence systems deployed by the deployer.</p>\n   <p class=\"indent\">(2) A risk management policy and program implemented and maintained pursuant to subdivision (1) of this subsection may cover multiple high-risk artificial intelligence systems deployed by the deployer.</p>\n   <p class=\"indent\">(c) (1) Except as provided in subdivisions (3) and (4) of this subsection and subsection (g) of this section:</p>\n   <p class=\"indent\">(A) A deployer that deploys a high-risk artificial intelligence system on or after October 1, 2026, or a third party contracted by the deployer, shall complete an impact assessment of the high-risk artificial intelligence system; and</p>\n   <p class=\"indent\">(B) Beginning on October 1, 2026, a deployer, or a third party contracted by the deployer, shall complete an impact assessment of a deployed high-risk artificial intelligence system (i) at least annually, and (ii) not later than ninety days after an intentional and substantial modification to such high-risk artificial intelligence system is made available.</p>\n   <p class=\"indent\">(2) (A) Each impact assessment completed pursuant to this subsection shall include, at a minimum and to the extent reasonably known by, or available to, the deployer:</p>\n   <p class=\"indent\">(i) A statement by the deployer disclosing the purpose, intended use cases and deployment context of, and benefits afforded by, the high-risk artificial intelligence system;</p>\n   <p class=\"indent\">(ii) An analysis of whether the deployment of the high-risk artificial intelligence system poses any known or reasonably foreseeable risks of algorithmic discrimination and, if so, the nature of such algorithmic discrimination and the steps that have been taken to mitigate such risks;</p>\n   <p class=\"indent\">(iii) A description of (I) the categories of data the high-risk artificial intelligence system processes as inputs, and (II) the outputs such high-risk artificial intelligence system produces;</p>\n   <p class=\"indent\">(iv) If the deployer used data to customize the high-risk artificial intelligence system, an overview of the categories of data the deployer used to customize such high-risk artificial intelligence system;</p>\n   <p class=\"indent\">(v) Any metrics used to evaluate the performance and known limitations of the high-risk artificial intelligence system;</p>\n   <p class=\"indent\">(vi) A high-level description of any transparency measures taken concerning the high-risk artificial intelligence system, including, but not limited to, any measures taken to disclose to a consumer that such high-risk artificial intelligence system is in use when such high-risk artificial intelligence system is in use; and</p>\n   <p class=\"indent\">(vii) A high-level description of the post-deployment monitoring and user safeguards provided concerning such high-risk artificial intelligence system, including, but not limited to, the oversight, use and learning process established by the deployer to address issues arising from deployment of such high-risk artificial intelligence system.</p>\n   <p class=\"indent\">(B) In addition to the statement, analysis, descriptions, overview and metrics required under subparagraph (A) of this subdivision, an impact assessment completed pursuant to this subsection following an intentional and substantial modification made to a high-risk artificial intelligence system on or after October 1, 2026, shall include a high-level statement disclosing the extent to which the high-risk artificial intelligence system was used in a manner that was consistent with, or varied from, the developer&#39;s intended uses of such high-risk artificial intelligence system.</p>\n   <p class=\"indent\">(3) A single impact assessment may address a comparable set of high-risk artificial intelligence systems deployed by a deployer.</p>\n   <p class=\"indent\">(4) If a deployer, or a third party contracted by the deployer, completes an impact assessment for the purpose of complying with another applicable law or regulation, such impact assessment shall be deemed to satisfy the requirements established in this subsection if such impact assessment is reasonably similar in scope and effect to the impact assessment that would otherwise be completed pursuant to this subsection.</p>\n   <p class=\"indent\">(5) A deployer shall maintain the most recently completed impact assessment of a high-risk artificial intelligence system as required under this subsection, all records concerning each such impact assessment and all prior impact assessments, if any, for a period of at least three years following the final deployment of the high-risk artificial intelligence system.</p>\n   <p class=\"indent\">(d) Except as provided in subsection (g) of this section, a deployer, or a third party contracted by the deployer, shall review, not later than October 1, 2026, and at least annually thereafter, the deployment of each high-risk artificial intelligence system deployed by the deployer to ensure that such high-risk artificial intelligence system is not causing algorithmic discrimination.</p>\n   <p class=\"indent\">(e) (1) Beginning on October 1, 2026, and before a deployer deploys a high-risk artificial intelligence system to make, or be a substantial factor in making, a consequential decision concerning a consumer, the deployer shall:</p>\n   <p class=\"indent\">(A) Notify the consumer that the deployer has deployed a high-risk artificial intelligence system to make, or be a substantial factor in making, such consequential decision; and</p>\n   <p class=\"indent\">(B) Provide to the consumer (i) a statement disclosing (I) the purpose of such high-risk artificial intelligence system, and (II) the nature of such consequential decision, (ii) if applicable, information concerning the consumer&#39;s right, under subparagraph (C) of subdivision (5) of subsection (a) of section 42-518 of the general statutes, to opt-out of the processing of the consumer&#39;s personal data for the purposes set forth in said subparagraph, (iii) contact information for such deployer, (iv) a description, in plain language, of such high-risk artificial intelligence system, and (v) instructions on how to access the statement made available pursuant to subdivision (1) of subsection (f) of this section.</p>\n   <p class=\"indent\">(2) Beginning on October 1, 2026, a deployer that has deployed a high-risk artificial intelligence system to make, or as a substantial factor in making, a consequential decision concerning a consumer shall, if such consequential decision is adverse to the consumer, provide to such consumer:</p>\n   <p class=\"indent\">(A) A high-level statement disclosing the principal reason or reasons for such adverse consequential decision, including, but not limited to, (i) the degree to which, and manner in which, the high-risk artificial intelligence system contributed to such adverse consequential decision, (ii) the type of data that were processed by such high-risk artificial intelligence system in making such adverse consequential decision, and (iii) the source of the data described in subparagraph (A)(ii) of this subdivision;</p>\n   <p class=\"indent\">(B) An opportunity to (i) examine the personal data that the high-risk artificial intelligence system processed in making, or as a substantial factor in making, such adverse consequential decision, and (ii) correct any incorrect personal data described in subparagraph (B)(i) of this subdivision; and</p>\n   <p class=\"indent\">(C) (i) Except as provided in subparagraph (C)(ii) of this subdivision, an opportunity to appeal such adverse consequential decision if such adverse consequential decision is based upon inaccurate personal data, taking into account both the nature of such personal data and the purpose for which such personal data was processed. Such appeal shall, if technically feasible, allow for human review.</p>\n   <p class=\"indent\">(ii) No deployer shall be required to provide an opportunity to appeal pursuant to subparagraph (C)(i) of this subdivision in any instance in which providing such opportunity to appeal is not in the best interest of the consumer, including, but not limited to, in any instance in which any delay might pose a risk to the life or safety of the consumer.</p>\n   <p class=\"indent\">(3) The deployer shall provide the notice, statements, information, description and instructions required under subdivisions (1) and (2) of this subsection:</p>\n   <p class=\"indent\">(A) Directly to the consumer;</p>\n   <p class=\"indent\">(B) In plain language;</p>\n   <p class=\"indent\">(C) In all languages in which such deployer, in the ordinary course of such deployer&#39;s business, provides contracts, disclaimers, sale announcements and other information to consumers; and</p>\n   <p class=\"indent\">(D) In a format that is accessible to consumers with disabilities.</p>\n   <p class=\"indent\">(f) (1) Beginning on October 1, 2026, and except as provided in subsection (g) of this section, each deployer shall make available, in a manner that is clear and readily available on such deployer&#39;s Internet web site, a statement summarizing:</p>\n   <p class=\"indent\">(A) The types of high-risk artificial intelligence systems that are currently deployed by such deployer;</p>\n   <p class=\"indent\">(B) How such deployer manages any known or reasonably foreseeable risks of algorithmic discrimination that may arise from deployment of each high-risk artificial intelligence system described in subparagraph (A) of this subdivision;</p>\n   <p class=\"indent\">(C) In detail, the nature, source and extent of the information collected and used by such deployer; and</p>\n   <p class=\"indent\">(D) How the consumer may exercise rights under section 42-518 of the general statutes by the secure and reliable means established and described pursuant to subsection (b) of section 42-518 of the general statutes.</p>\n   <p class=\"indent\">(2) Each deployer shall periodically update the statement made available pursuant to subdivision (1) of this subsection.</p>\n   <p class=\"indent\">(g) The provisions of subsections (b) to (d), inclusive, of this section and subsection (f) of this section shall not apply to a deployer if, at the time the deployer deploys a high-risk artificial intelligence system and at all times while the high-risk artificial intelligence system is deployed:</p>\n   <p class=\"indent\">(1) The deployer (A) has entered into a contract with the developer in which the developer has agreed to assume the deployer&#39;s duties under subsections (b) to (d), inclusive, of this section and subsection (f) of this section, and (B) does not exclusively use such deployer&#39;s own data to train such high-risk artificial intelligence system;</p>\n   <p class=\"indent\">(2) Such high-risk artificial intelligence system (A) is used for the intended uses that are disclosed to such deployer as set forth in subparagraph (A)(iv) of subdivision (2) of subsection (b) of section 2 of this act, and (B) continues learning based on a broad range of data sources and not solely based on the deployer&#39;s own data; and</p>\n   <p class=\"indent\">(3) Such deployer makes available to consumers any impact assessment that (A) the developer of such high-risk artificial intelligence system has completed and provided to such deployer, and (B) includes information that is substantially similar to the information included in the statement, analysis, descriptions, overview and metrics required under subparagraph (A) of subdivision (2) of subsection (c) of this section.</p>\n   <p class=\"indent\">(h) If a deployer deploys a high-risk artificial intelligence system on or after October 1, 2026, and subsequently discovers that the high-risk artificial intelligence system has caused algorithmic discrimination to at least one thousand consumers, the deployer shall send to the Attorney General, in a form and manner prescribed by the Attorney General, a notice disclosing such discovery. The deployer shall send such notice to the Attorney General without unreasonable delay but in no event later than ninety days after the date on which the deployer discovered such algorithmic discrimination.</p>\n   <p class=\"indent\">(i) Nothing in subsections (b) to (h), inclusive, of this section shall be construed to require a deployer to disclose any information that is a trade secret or otherwise protected from disclosure under state or federal law. If a deployer withholds any information from a consumer under this subsection, the deployer shall send notice to the consumer disclosing (1) that the deployer is withholding such information from such consumer, and (2) the basis for the deployer&#39;s decision to withhold such information from such consumer.</p>\n   <p class=\"indent\">(j) Beginning on October 1, 2026, the Attorney General may require that a deployer, or a third party contracted by the deployer as set forth in subsection (c) of this section, as applicable, disclose to the Attorney General, as part of an investigation conducted by the Attorney General regarding a suspected violation of any provision of sections 1 to 10, inclusive, of this act, not later than ninety days after a request by the Attorney General and in a form and manner prescribed by the Attorney General, the risk management policy implemented pursuant to subsection (b) of this section, impact assessment completed pursuant to subsection (c) of this section or records maintained pursuant to subdivision (5) of subsection (c) of this section. The Attorney General may evaluate such risk management policy, impact assessment or records to ensure compliance with the provisions of this section. In disclosing such risk management policy, impact assessment or records to the Attorney General pursuant to this subsection, the deployer or third-party contractor, as applicable, may designate such risk management policy, impact assessment or records as including any information that is exempt from disclosure under subsection (i) of this section or the Freedom of Information Act, as defined in section 1-200 of the general statutes. To the extent such risk management policy, impact assessment or records include such information, such risk management policy, impact assessment or records shall be exempt from disclosure under subsection (i) of this section or said act. To the extent any information contained in such risk management policy, impact assessment or record is subject to the attorney-client privilege or work product protection, such disclosure shall not constitute a waiver of such privilege or protection.</p>\n   <p class=\"indent\">Sec. 5. (NEW) (Effective October 1, 2025) (a) Beginning on October 1, 2026, each developer of a general-purpose artificial intelligence model that is capable of being used by a high-risk artificial intelligence system shall, to the extent feasible and except as provided in subsection (b) of this section, make available to:</p>\n   <p class=\"indent\">(1) Each deployer of such general-purpose artificial intelligence model, through artifacts such as system cards or other impact assessments, the documentation and information necessary for such deployer, or a third party contracted by such deployer, to complete an impact assessment pursuant to subsection (c) of section 4 of this act; and</p>\n   <p class=\"indent\">(2) Each deployer or other developer of such general-purpose artificial intelligence model any additional documentation that is reasonably necessary to assist such deployer or other developer to understand the outputs, and monitor the performance, of the general-purpose artificial intelligence model to enable such deployer or other developer to comply with the provisions of sections 1 to 10, inclusive, of this act.</p>\n   <p class=\"indent\">(b) (1) The provisions of subsection (a) of this section shall not apply to a developer that develops, or intentionally and substantially modifies, a general-purpose artificial intelligence model on or after October 1, 2026, if:</p>\n   <p class=\"indent\">(A) (i) The developer releases such general-purpose artificial intelligence model under a free and open-source license that allows for (I) access to, and modification, distribution and usage of, such general-purpose artificial intelligence model, and (II) the parameters of such general-purpose artificial intelligence model to be made publicly available as set forth in subparagraph (A)(ii) of this subdivision; and</p>\n   <p class=\"indent\">(ii) Unless such general-purpose artificial intelligence model is deployed as a high-risk artificial intelligence system, the parameters of such general-purpose artificial intelligence model, including, but not limited to, the weights and information concerning the model architecture and model usage for such general-purpose artificial intelligence model, are made publicly available; or</p>\n   <p class=\"indent\">(B) The general-purpose artificial intelligence model is (i) not offered for sale in the market, (ii) not intended to interact with consumers, and (iii) solely utilized (I) for an entity&#39;s internal purposes, or (II) under an agreement between multiple entities for such entities&#39; internal purposes.</p>\n   <p class=\"indent\">(2) The provisions of this section shall not apply to a developer that develops, or intentionally and substantially modifies, a general-purpose artificial intelligence model on or after October 1, 2026, if such general-purpose artificial intelligence model performs tasks exclusively related to an entity&#39;s internal management affairs, including, but not limited to, ordering office supplies or processing payments.</p>\n   <p class=\"indent\">(3) A developer that takes any action under an exemption established in subdivision (1) or (2) of this subsection shall bear the burden of demonstrating that such action qualifies for such exemption.</p>\n   <p class=\"indent\">(4) A developer that is exempt under subparagraph (B) of subdivision (1) of this subsection shall establish and maintain an artificial intelligence risk management framework, which framework shall (A) be the product of an iterative process and ongoing efforts, and (B) include, at a minimum, (i) an internal governance function, (ii) a map function that shall establish the context to frame risks, (iii) a risk management function, and (iv) a function to measure identified risks by assessing, analyzing and tracking such risks.</p>\n   <p class=\"indent\">(c) Nothing in subsection (a) of this section shall be construed to require a developer to disclose any information that is a trade secret or otherwise protected from disclosure under state or federal law.</p>\n   <p class=\"indent\">(d) Beginning on October 1, 2026, the Attorney General may require that a developer disclose to the Attorney General, as part of an investigation conducted by the Attorney General regarding a suspected violation of any provision of sections 1 to 10, inclusive, of this act, not later than ninety days after a request by the Attorney General and in a form and manner prescribed by the Attorney General, any documentation maintained pursuant to this section. The Attorney General may evaluate such documentation to ensure compliance with the provisions of this section. In disclosing any documentation to the Attorney General pursuant to this subsection, the developer may designate such documentation as including any information that is exempt from disclosure under subsection (c) of this section or the Freedom of Information Act, as defined in section 1-200 of the general statutes. To the extent such documentation includes such information, such documentation shall be exempt from disclosure under subsection (c) of this section or said act. To the extent any information contained in such documentation is subject to the attorney-client privilege or work product protection, such disclosure shall not constitute a waiver of such privilege or protection.</p>\n   <p class=\"indent\">Sec. 6. (NEW) (Effective October 1, 2025) (a) Beginning on October 1, 2026, and except as provided in subsection (b) of this section, each person doing business in this state, including, but not limited to, each deployer that deploys, offers, sells, leases, licenses, gives or otherwise makes available, as applicable, any artificial intelligence system that is intended to interact with consumers shall ensure that it is disclosed to each consumer who interacts with such artificial intelligence system that such consumer is interacting with an artificial intelligence system.</p>\n   <p class=\"indent\">(b) No disclosure shall be required under subsection (a) of this section under circumstances in which a reasonable person would deem it obvious that such person is interacting with an artificial intelligence system.</p>\n   <p class=\"indent\">Sec. 7. (NEW) (Effective October 1, 2025) (a) Beginning on October 1, 2026, and except as provided in subsections (b) and (c) of this section, the developer of an artificial intelligence system, including, but not limited to, a general-purpose artificial intelligence model, that is capable of generating synthetic digital content shall:</p>\n   <p class=\"indent\">(1) Ensure that the outputs of such artificial intelligence system are marked and detectable as synthetic digital content, and that such outputs are so marked and detectable (A) not later than the time that consumers who did not create such outputs first interact with, or are exposed to, such outputs, and (B) in a manner that (i) is detectable by consumers, and (ii) complies with any applicable accessibility requirements; and</p>\n   <p class=\"indent\">(2) As far as technically feasible and in a manner that is consistent with any nationally or internationally recognized technical standards, ensure that such developer&#39;s technical solutions are effective, interoperable, robust and reliable, considering (A) the specificities and limitations of different types of synthetic digital content, (B) the implementation costs, and (C) the generally acknowledged state of the art.</p>\n   <p class=\"indent\">(b) If the synthetic digital content described in subsection (a) of this section is in an audio, image or video format, and such synthetic digital content forms part of an evidently artistic, creative, satirical, fictional analogous work or program, the disclosure required under said subsection shall be limited to a disclosure that does not hinder the display or enjoyment of such work or program.</p>\n   <p class=\"indent\">(c) The provisions of subsection (a) of this section shall not apply:</p>\n   <p class=\"indent\">(1) To any synthetic digital content that (A) consists exclusively of text, (B) is published to inform the public on any matter of public interest, or (C) is unlikely to mislead a reasonable person consuming such synthetic digital content; or</p>\n   <p class=\"indent\">(2) To the extent that any artificial intelligence system described in subsection (a) of this section (A) performs an assistive function for standard editing, (B) does not substantially alter the input data provided by the developer or the semantics thereof, or (C) is used to detect, prevent, investigate or prosecute any crime where authorized by law.</p>\n   <p class=\"indent\">Sec. 8. (NEW) (Effective October 1, 2025) (a) Nothing in sections 1 to 10, inclusive, of this act shall be construed to restrict a developer&#39;s, integrator&#39;s, deployer&#39;s or other person&#39;s ability to:</p>\n   <p class=\"indent\">(1) Comply with any federal, state or municipal law, ordinance or regulation;</p>\n   <p class=\"indent\">(2) Comply with a civil, criminal or regulatory inquiry, investigation, subpoena or summons by a federal, state, municipal or other governmental authority;</p>\n   <p class=\"indent\">(3) Cooperate with a law enforcement agency concerning conduct or activity that the developer, integrator, deployer or other person reasonably and in good faith believes may violate federal, state or municipal law;</p>\n   <p class=\"indent\">(4) Investigate, establish, exercise, prepare for or defend a legal claim;</p>\n   <p class=\"indent\">(5) Take immediate steps to protect an interest that is essential for the life or physical safety of a consumer or another individual;</p>\n   <p class=\"indent\">(6) (A) By any means other than facial recognition technology, prevent, detect, protect against or respond to (i) a security incident, (ii) a malicious or deceptive activity, or (iii) identity theft, fraud, harassment or any other illegal activity, (B) investigate, report or prosecute the persons responsible for any action described in subparagraph (A) of this subdivision, or (C) preserve the integrity or security of systems;</p>\n   <p class=\"indent\">(7) Engage in public or peer-reviewed scientific or statistical research in the public interest that (A) adheres to all other applicable ethics and privacy laws, and (B) is conducted in accordance with (i) 45 CFR Part 46, as amended from time to time, or (ii) relevant requirements established by the federal Food and Drug Administration;</p>\n   <p class=\"indent\">(8) Conduct research, testing, development and integration activities regarding an artificial intelligence system or model, other than testing conducted under real world conditions, before such artificial intelligence system or model is placed on the market, deployed or put into service, as applicable;</p>\n   <p class=\"indent\">(9) Effectuate a product recall;</p>\n   <p class=\"indent\">(10) Identify and repair technical errors that impair existing or intended functionality; or</p>\n   <p class=\"indent\">(11) Assist another developer, integrator, deployer or person with any of the obligations imposed under sections 1 to 10, inclusive, of this act.</p>\n   <p class=\"indent\">(b) The obligations imposed on developers, integrators, deployers or other persons under sections 1 to 10, inclusive, of this act shall not apply where compliance by the developer, integrator, deployer or other person with said sections would violate an evidentiary privilege under the laws of this state.</p>\n   <p class=\"indent\">(c) Nothing in sections 1 to 10, inclusive, of this act shall be construed to impose any obligation on a developer, integrator, deployer or other person that adversely affects the rights or freedoms of any person, including, but not limited to, the rights of any person (1) to freedom of speech or freedom of the press guaranteed in (A) the First Amendment to the United States Constitution, and (B) section 5 of article first of the Constitution of the state, or (2) under section 52-146t of the general statutes.</p>\n   <p class=\"indent\">(d) Nothing in sections 1 to 10, inclusive, of this act shall be construed to apply to any developer, integrator, deployer or other person:</p>\n   <p class=\"indent\">(1) Insofar as such developer, integrator, deployer or other person develops, integrates, deploys, puts into service or intentionally and substantially modifies, as applicable, a high-risk artificial intelligence system (A) that has been approved, authorized, certified, cleared, developed, integrated or granted by (i) a federal agency, such as the federal Food and Drug Administration or the Federal Aviation Administration, acting within the scope of such federal agency&#39;s authority, or (ii) a regulated entity subject to supervision and regulation by the Federal Housing Finance Agency, or (B) in compliance with standards that are (i) established by (I) any federal agency, including, but not limited to, the federal Office of the National Coordinator for Health Information Technology, or (II) a regulated entity subject to supervision and regulation by the Federal Housing Finance Agency, and (ii) substantially equivalent to, and at least as stringent as, the standards established in sections 1 to 10, inclusive, of this act;</p>\n   <p class=\"indent\">(2) Conducting research to support an application (A) for approval or certification from any federal agency, including, but not limited to, the Federal Aviation Administration, the Federal Communications Commission or the federal Food and Drug Administration, or (B) that is otherwise subject to review by any federal agency;</p>\n   <p class=\"indent\">(3) Performing work under, or in connection with, a contract with the United States Department of Commerce, the United States Department of Defense or the National Aeronautics and Space Administration, unless such developer, integrator, deployer or other person is performing such work on a high-risk artificial intelligence system that is used to make, or as a substantial factor in making, a decision concerning employment or housing;</p>\n   <p class=\"indent\">(4) That facilitates or engages in the provision of telehealth services or is a covered entity within the meaning of the Health Insurance Portability and Accountability Act of 1996, P.L. 104-191, and the regulations promulgated thereunder, as both may be amended from time to time, and providing health care recommendations that (A) are generated by an artificial intelligence system, (B) require a health care provider to take action to implement such recommendations, and (C) are not considered to be high risk; or</p>\n   <p class=\"indent\">(5) Who is an active participant in the artificial intelligence regulatory sandbox program designed, established and administered under section 12 of this act, and is engaged in activities within the scope of such program in accordance with the provisions of section 12 of this act.</p>\n   <p class=\"indent\">(e) Nothing in sections 1 to 10, inclusive, of this act shall be construed to apply to any artificial intelligence system that is acquired by or for the federal government or any federal agency or department, including, but not limited to, the United States Department of Commerce, the United States Department of Defense or the National Aeronautics and Space Administration, unless such artificial intelligence system is a high-risk artificial intelligence system that is used to make, or as a substantial factor in making, a decision concerning employment or housing.</p>\n   <p class=\"indent\">(f) Any insurer, as defined in section 38a-1 of the general statutes, fraternal benefit society, as described in section 38a-595 of the general statutes, or health carrier, as defined in section 38a-591a of the general statutes, shall be deemed to be in full compliance with the provisions of sections 1 to 10, inclusive, of this act if such insurer, fraternal benefit society or health carrier has implemented and maintains a written artificial intelligence systems program in accordance with all requirements established by the Insurance Commissioner.</p>\n   <p class=\"indent\">(g) (1) Any bank, out-of-state bank, Connecticut credit union, federal credit union, mortgage lender or out-of-state credit union, or any affiliate, subsidiary or service provider thereof, shall be deemed to be in full compliance with the provisions of sections 1 to 10, inclusive, of this act if such bank, out-of-state bank, Connecticut credit union, federal credit union, mortgage lender, out-of-state credit union, affiliate, subsidiary or service provider is subject to examination by any state or federal prudential regulator under any published guidance or regulations that apply to the use of high-risk artificial intelligence systems and such guidance or regulations (A) impose requirements that are substantially equivalent to, and at least as stringent as, the requirements set forth in sections 1 to 10, inclusive, of this act, and (B) at a minimum, require such bank, out-of-state bank, Connecticut credit union, federal credit union, mortgage lender, out-of-state credit union, affiliate, subsidiary or service provider to (i) regularly audit such bank&#39;s, out-of-state bank&#39;s, Connecticut credit union&#39;s, federal credit union&#39;s, mortgage lender&#39;s, out-of-state credit union&#39;s, affiliate&#39;s, subsidiary&#39;s or service provider&#39;s use of high-risk artificial intelligence systems for compliance with state and federal anti-discrimination laws and regulations applicable to such bank, out-of-state bank, Connecticut credit union, federal credit union, mortgage lender, out-of-state credit union, affiliate, subsidiary or service provider, and (ii) mitigate any algorithmic discrimination caused by the use of a high-risk artificial intelligence system or any risk of algorithmic discrimination that is reasonably foreseeable as a result of the use of a high-risk artificial intelligence system.</p>\n   <p class=\"indent\">(2) For the purposes of this subsection, (A) &quot;affiliate&quot;, &quot;bank&quot;, &quot;Connecticut credit union&quot;, &quot;federal credit union&quot;, &quot;out-of-state bank&quot;, &quot;out-of-state credit union&quot; and &quot;subsidiary&quot; have the same meanings as provided in section 36a-2 of the general statutes, and (B) &quot;mortgage lender&quot; has the same meaning as provided in section 36a-705 of the general statutes.</p>\n   <p class=\"indent\">(h) If a developer, integrator, deployer or other person engages in any action pursuant to an exemption set forth in subsections (a) to (g), inclusive, of this section, the developer, integrator, deployer or other person bears the burden of demonstrating that such action qualifies for such exemption.</p>\n   <p class=\"indent\">Sec. 9. (NEW) (Effective October 1, 2025) Not later than January 1, 2026, the Attorney General shall, within available appropriations, develop and implement a comprehensive public education, outreach and assistance program for developers, integrators and deployers that are small businesses, as defined in section 4-168a of the general statutes. Such program shall, at a minimum, disseminate educational materials concerning (1) the requirements established in sections 1 to 10, inclusive, of this act, including, but not limited to, the duties of developers, integrators and deployers under sections 1 to 10, inclusive, of this act, (2) the impact assessments required under subsection (c) of section 4 of this act, (3) the Attorney General&#39;s powers under sections 1 to 10, inclusive, of this act, and (4) any other matters the Attorney General, in the Attorney General&#39;s discretion, deems relevant for the purposes of such program.</p>\n   <p class=\"indent\">Sec. 10. (NEW) (Effective October 1, 2025) (a) The Attorney General shall have exclusive authority to enforce the provisions of sections 1 to 9, inclusive, of this act.</p>\n   <p class=\"indent\">(b) Except as provided in subsection (f) of this section, during the period beginning on October 1, 2026, and ending on September 30, 2027, the Attorney General shall, prior to initiating any action for a violation of any provision of sections 1 to 9, inclusive, of this act, issue a notice of violation to the developer, integrator, deployer or other person if the Attorney General determines that it is possible to cure such violation. If the developer, integrator, deployer or other person fails to cure such violation not later than sixty days after receipt of the notice of violation, the Attorney General may bring an action pursuant to this section.</p>\n   <p class=\"indent\">(c) Except as provided in subsection (f) of this section, beginning on October 1, 2027, the Attorney General may, in determining whether to grant a developer, integrator, deployer or other person the opportunity to cure a violation described in subsection (b) of this section, consider: (1) The number of violations; (2) the size and complexity of the developer, integrator, deployer or other person; (3) the nature and extent of the developer&#39;s, integrator&#39;s, deployer&#39;s or other person&#39;s business; (4) the substantial likelihood of injury to the public; (5) the safety of persons or property; and (6) whether such violation was likely caused by human or technical error.</p>\n   <p class=\"indent\">(d) Nothing in sections 1 to 9, inclusive, of this act shall be construed as providing the basis for a private right of action for violations of said sections.</p>\n   <p class=\"indent\">(e) Except as provided in subsections (a) to (d), inclusive, of this section and subsection (f) of this section, a violation of the requirements established in sections 1 to 9, inclusive, of this act shall constitute an unfair trade practice for purposes of section 42-110b of the general statutes and shall be enforced solely by the Attorney General. The provisions of section 42-110g of the general statutes shall not apply to any such violation.</p>\n   <p class=\"indent\">(f) (1) In any action commenced by the Attorney General for any violation of sections 1 to 9, inclusive, of this act, it shall be an affirmative defense that the developer, integrator, deployer or other person:</p>\n   <p class=\"indent\">(A) Discovers a violation of any provision of sections 1 to 9, inclusive, of this act through red-teaming;</p>\n   <p class=\"indent\">(B) Not later than sixty days after discovering the violation as set forth in subparagraph (A) of this subdivision: (i) Cures such violation; and (ii) provides to the Attorney General, in a form and manner prescribed by the Attorney General, notice that such violation has been cured and evidence that any harm caused by such violation has been mitigated; and</p>\n   <p class=\"indent\">(C) Is otherwise in compliance with the latest version of: (i) The &quot;Artificial Intelligence Risk Management Framework&quot; published by the National Institute of Standards and Technology; (ii) ISO or IEC 42001 of the International Organization for Standardization; (iii) a nationally or internationally recognized risk management framework for artificial intelligence systems, other than the risk management frameworks specified in subparagraphs (C)(i) and (C)(ii) of this subdivision, that imposes requirements that are substantially equivalent to, and at least as stringent as, the requirements set forth in sections 1 to 9, inclusive, of this act; or (iv) any risk management framework for artificial intelligence systems that is substantially equivalent to, and at least as stringent as, the risk management frameworks described in subparagraphs (C)(i) to (C)(iii), inclusive, of this subdivision.</p>\n   <p class=\"indent\">(2) The developer, integrator, deployer or other person bears the burden of demonstrating to the Attorney General that the requirements established in subdivision (1) of this subsection have been satisfied.</p>\n   <p class=\"indent\">(3) Nothing in this section or sections 1 to 9, inclusive, of this act, including, but not limited to, the enforcement authority granted to the Attorney General under this section, shall be construed to preempt or otherwise affect any right, claim, remedy, presumption or defense available at law or in equity. Any rebuttable presumption or affirmative defense established under this section or sections 1 to 9, inclusive, of this act shall apply only to an enforcement action brought by the Attorney General pursuant to this section and shall not apply to any right, claim, remedy, presumption or defense available at law or in equity.</p>\n   <p class=\"indent\">Sec. 11. (NEW) (Effective October 1, 2025) (a) For the purposes of this section, &quot;legislative leader&quot; has the same meaning as provided in subsection (b) of section 4-9d of the general statutes.</p>\n   <p class=\"indent\">(b) Each legislative leader may request that the executive director of the Connecticut Academy of Science and Engineering designate a member of said academy to serve as such legislative leader&#39;s liaison with said academy, the Office of the Attorney General and the Department of Economic and Community Development for the purpose of:</p>\n   <p class=\"indent\">(1) Designing a tool to enable any person to determine whether such person is in compliance with the provisions of sections 1 to 10, inclusive, of this act;</p>\n   <p class=\"indent\">(2) Designing a tool to assist a deployer, or a third party contracted by a deployer, to complete an impact assessment pursuant to subsection (c) of section 4 of this act;</p>\n   <p class=\"indent\">(3) Conducting meetings with relevant stakeholders to formulate a plan to utilize The University of Connecticut School of Law&#39;s Intellectual Property and Entrepreneurship Law Clinic to assist small businesses and startups in their efforts to comply with the provisions of sections 1 to 10, inclusive, of this act;</p>\n   <p class=\"indent\">(4) Making recommendations concerning establishing a framework to provide a controlled and supervised environment in which artificial intelligence systems may be tested, which recommendations shall include, at a minimum, recommendations concerning the establishment of (A) an office to oversee such framework and environment, and (B) a program that would enable consultations between the state, businesses and other stakeholders concerning such framework and environment;</p>\n   <p class=\"indent\">(5) Evaluating (A) the adoption of artificial intelligence systems by businesses, (B) the challenges posed to, and needs of, businesses in (i) adopting artificial intelligence systems, and (ii) understanding laws and regulations concerning artificial intelligence systems, and (C) how businesses that use artificial intelligence systems hire employees with necessary skills concerning artificial intelligence systems;</p>\n   <p class=\"indent\">(6) Creating a plan for the state to provide high-performance computing services to businesses and researchers in the state;</p>\n   <p class=\"indent\">(7) Evaluating the benefits of creating a state-wide research collaborative among health care providers to enable the development of advanced analytics, ethical and trustworthy artificial intelligence systems and hands-on workforce education while using methods that protect patient privacy; and</p>\n   <p class=\"indent\">(8) Evaluating, and making recommendations concerning, (A) the establishment of testbeds to support safeguards and systems to prevent the misuse of artificial intelligence systems, (B) risk assessments for the misuse of artificial intelligence systems, (C) evaluation strategies for artificial intelligence systems, and (D) the development, testing and evaluation of resources to support state oversight of artificial intelligence systems.</p>\n   <p class=\"indent\">(c) No member of the Connecticut Academy of Science and Engineering designated pursuant to subsection (b) of this section shall be deemed a state employee, or receive any compensation from the state, for performing such member&#39;s duties under said subsection.</p>\n   <p class=\"indent\">Sec. 12. (NEW) (Effective October 1, 2025) (a) As used in this section:</p>\n   <p class=\"indent\">(1) &quot;Active participant&quot; means a person participating in the artificial intelligence regulatory sandbox program designed, established and administered in accordance with the provisions of this section;</p>\n   <p class=\"indent\">(2) &quot;Artificial intelligence system&quot; has the same meaning as provided in section 1 of this act;</p>\n   <p class=\"indent\">(3) &quot;Consumer&quot; has the same meaning as provided in section 1 of this act;</p>\n   <p class=\"indent\">(4) &quot;Deployer&quot; means any person doing business in this state that deploys an artificial intelligence system;</p>\n   <p class=\"indent\">(5) &quot;Developer&quot; has the same meaning as provided in section 1 of this act;</p>\n   <p class=\"indent\">(6) &quot;Person&quot; has the same meaning as provided in section 1 of this act; and</p>\n   <p class=\"indent\">(7) &quot;State agency&quot; has the same meaning as provided in section 1-79 of the general statutes.</p>\n   <p class=\"indent\">(b) The Department of Economic and Community Development, in coordination with the Chief Data Officer and the Connecticut Technology Advisory Board established under section 16 of this act, shall design, establish and administer an artificial intelligence regulatory sandbox program to facilitate the development, testing and deployment of innovative artificial intelligence systems in the state. The program shall be designed to (1) promote the safe and innovative use of artificial intelligence systems across various sectors, including, but not limited to, education, finance, health care and public service, (2) encourage the responsible deployment of artificial intelligence systems while balancing the need for consumer protection, privacy and public safety, and (3) provide clear guidelines for developers to test artificial intelligence systems while being exempt from certain regulatory requirements during the period set forth in subsection (d) of this section.</p>\n   <p class=\"indent\">(c) (1) A person seeking to participate in the artificial intelligence regulatory sandbox program shall submit an application to the Department of Economic and Community Development in a form and manner prescribed by the Commissioner of Economic and Community Development. Each application shall include (A) a detailed description of the applicant&#39;s artificial intelligence system and its intended uses, (B) a risk assessment that addresses the potential impact of the applicant&#39;s artificial intelligence system on consumers, privacy and public safety, (C) a plan for mitigating any adverse consequences that may arise from the applicant&#39;s artificial intelligence system during the period set forth in subsection (d) of this section, (D) proof that the applicant and the applicant&#39;s artificial intelligence system are in compliance with all applicable federal laws and regulations concerning artificial intelligence systems, and (E) any other information the commissioner deems relevant for the purposes of this section or the program.</p>\n   <p class=\"indent\">(2) Not later than thirty days after the Department of Economic and Community Development receives an application submitted pursuant to subdivision (1) of this subsection, the department shall (A) approve or deny the application, and (B) send a notice to the applicant, in a form and manner prescribed by the Commissioner of Economic and Community Development, disclosing whether the department has approved or denied such application.</p>\n   <p class=\"indent\">(d) An active participant in the artificial intelligence regulatory sandbox program may test the applicant&#39;s artificial intelligence system as part of the program for a period not to exceed eighteen months from the date on which the Department of Economic and Community Development sent notice approving the active participant&#39;s application pursuant to subparagraph (B) of subdivision (2) of subsection (c) of this section, except the department may extend such period for good cause shown.</p>\n   <p class=\"indent\">(e) The Department of Economic and Community Development shall coordinate with all relevant state agencies to oversee the operations of active participants in the artificial intelligence regulatory sandbox program. Any state agency may recommend to the department that an active participant&#39;s participation in the program be revoked if the active participant&#39;s artificial intelligence system (1) poses an undue risk to the public health, safety or welfare, or (2) violates any federal law or regulation.</p>\n   <p class=\"indent\">(f) For the calendar quarter ending December 31, 2025, and for each calendar quarter thereafter, each active participant in the artificial intelligence regulatory sandbox program shall, not later than thirty days after the end of such calendar quarter, submit a report to the Department of Economic and Community Development disclosing (1) system performance metrics for such active participant&#39;s artificial intelligence system, (2) information concerning the manner in which such active participant&#39;s artificial intelligence system mitigated any risks associated with such artificial intelligence system, and (3) any feedback such active participant received from deployers, consumers and other users of such artificial intelligence system.</p>\n   <p class=\"indent\">(g) For the calendar year ending December 31, 2025, and for each calendar year thereafter, the Department of Economic and Community Development shall, not later than thirty days after the end of such calendar year, submit a report, in accordance with the provisions of section 11-4a of the general statutes, to the joint standing committee of the General Assembly having cognizance of matters relating to consumer protection. Each report shall disclose (1) the number of persons who were active participants in the artificial intelligence regulatory sandbox program for the calendar year that is the subject of such report or any portion of such calendar year, (2) the overall performance and impact of artificial intelligence systems tested as part of the program, and (3) any recommendations regarding the adoption of legislation for the purposes of the program.</p>\n   <p class=\"indent\">Sec. 13. (NEW) (Effective July 1, 2025) (a) As used in this section, &quot;artificial intelligence&quot; means artificial intelligence system, as defined in section 1 of this act.</p>\n   <p class=\"indent\">(b) Not later than December 31, 2025, the Board of Regents for Higher Education shall establish, on behalf of Charter Oak State College and in consultation with the Labor Department, the State Board of Education, Workforce Investment Boards, employers and institutions of higher education in this state, a &quot;Connecticut AI Academy&quot;. The academy shall, at a minimum:</p>\n   <p class=\"indent\">(1) Curate and offer online courses concerning artificial intelligence and the responsible use of artificial intelligence;</p>\n   <p class=\"indent\">(2) Promote digital literacy;</p>\n   <p class=\"indent\">(3) Prepare students for careers in fields involving artificial intelligence;</p>\n   <p class=\"indent\">(4) Offer courses directed at individuals between thirteen and twenty years of age;</p>\n   <p class=\"indent\">(5) Offer courses that prepare small businesses and nonprofit organizations to utilize artificial intelligence to improve marketing and management efficiency;</p>\n   <p class=\"indent\">(6) Develop courses concerning artificial intelligence that the Labor Department and Workforce Investment Boards may incorporate into workforce training programs; and</p>\n   <p class=\"indent\">(7) Enable persons providing free or discounted public Internet access to distribute information and provide mentorship concerning artificial intelligence, the academy and methods available for the public to obtain free or discounted devices capable of accessing the Internet and utilizing artificial intelligence.</p>\n   <p class=\"indent\">(c) The Board of Regents for Higher Education shall, in consultation with Charter Oak State College, develop certificates and badges to be awarded to persons who successfully complete courses offered by the Connecticut AI Academy.</p>\n   <p class=\"indent\">Sec. 14. (NEW) (Effective July 1, 2025) The Labor Department shall provide a notice, in a form and manner prescribed by the Labor Commissioner, to each individual who makes a claim for unemployment compensation disclosing the existence of, and courses and services offered by, the Connecticut AI Academy established pursuant to section 13 of this act.</p>\n   <p class=\"indent\">Sec. 15. Subsection (b) of section 17b-751b of the general statutes is repealed and the following is substituted in lieu thereof (Effective July 1, 2025):</p>\n   <p class=\"indent\">(b) The commissioner shall: (1) Ensure that all home visiting programs <u class=\"amendmentInsertedText\">(A)</u> are one or more of the evidence-based home visiting models that meet the criteria for evidence of effectiveness developed by the federal Department of Health and Human Services<u class=\"amendmentInsertedText\">, and (B) provide information to parents regarding the Connecticut AI Academy established pursuant to section 13 of this act</u>; (2) provide oversight of home visiting programs to insure model fidelity; and (3) develop, issue and evaluate requests for proposals to procure the services required by this section. In evaluating the proposals, the commissioner shall take into consideration the most effective and consistent service delivery system allowing for the continuation of current public and private programs.</p>\n   <p class=\"indent\">Sec. 16. (NEW) (Effective July 1, 2025) (a) As used in this section, &quot;artificial intelligence&quot; means artificial intelligence system, as defined in section 1 of this act.</p>\n   <p class=\"indent\">(b) There is established, within available appropriations, a Connecticut Technology Advisory Board, which shall be part of the Legislative Department.</p>\n   <p class=\"indent\">(c) (1) The board shall consist of the following members: (A) Two appointed by the speaker of the House of Representatives; (B) two appointed by the president pro tempore of the Senate; (C) two appointed by the minority leader of the House of Representatives; and (D) two appointed by the minority leader of the Senate. All appointed members shall have professional experience or academic qualifications in the field of artificial intelligence or the field of technology, or another related field, and no such member shall be a member of the General Assembly.</p>\n   <p class=\"indent\">(2) The following persons or their designees shall serve as ex-officio, nonvoting members and chairpersons of the board: (A) The Commissioner of Economic and Community Development; (B) the executive director of the Connecticut Academy of Science and Engineering; and (C) the president of Charter Oak State College.</p>\n   <p class=\"indent\">(3) All initial appointments to the board shall be made not later than October 1, 2025. The term of an appointed member shall be coterminous with the term of the appointing authority for the appointed member. Any vacancy shall be filled by the appointing authority. Any vacancy occurring other than by expiration of a term shall be filled for the balance of the unexpired term. A member of the board may serve more than one term. The chairpersons shall schedule the first meeting of the board, which shall be held not later than November 1, 2025.</p>\n   <p class=\"indent\">(d) The administrative staff of the joint standing committees of the General Assembly having cognizance of matters relating to consumer protection and government administration shall serve as administrative staff of the board.</p>\n   <p class=\"indent\">(e) The board shall have the following powers and duties: (1) To develop and adopt a state technology strategy (A) for the purpose of promoting education, workforce development, economic development and consumer protection, and (B) that accounts for the rapid pace of technological development, including, but not limited to, in the field of artificial intelligence; (2) to update the state technology strategy developed and adopted pursuant to subdivision (1) of this subsection at least once every two years; (3) to issue reports and recommendations in accordance with the provisions of section 11-4a of the general statutes; (4) upon the vote of a majority of the members of the board, to request any state agency data officer or state agency head to (A) appear before the board to answer questions, or (B) provide such assistance and data as may be necessary for the purpose of enabling the board to perform its duties; (5) to make recommendations to the Legislative Department, Executive Department or Judicial Department in accordance with the state technology strategy; and (6) to establish bylaws to govern the board&#39;s procedures.</p>\n   <p class=\"indent\">(f) The board shall meet at least twice annually and may meet at such other times as deemed necessary by the chairpersons or a majority of the members of the board.</p>\n   <p class=\"indent\">Sec. 17. (Effective July 1, 2025) (a) Not later than December 31, 2025, the Department of Economic and Community Development shall, within available appropriations and in collaboration with Charter Oak State College, develop a plan to establish a technology transfer program within Connecticut Innovations, Incorporated, for the purpose of supporting technology transfers by and among public and private institutions of higher education in this state.</p>\n   <p class=\"indent\">(b) Not later than January 1, 2026, the Commissioner of Economic and Community Development shall submit a report, in accordance with the provisions of section 11-4a of the general statutes, to the joint standing committees of the General Assembly having cognizance of matters relating to consumer protection, commerce and higher education. Such report shall, at a minimum, include the plan developed pursuant to subsection (a) of this section.</p>\n   <p class=\"indent\">Sec. 18. (NEW) (Effective July 1, 2025) (a) Not later than December 31, 2025, the Department of Economic and Community Development shall, within available appropriations and in collaboration with the Office of Health Strategy, establish a confidential computing cluster for the purpose of fostering the exchange of health information in order to support academic and medical research.</p>\n   <p class=\"indent\">(b) (1) The confidential computing cluster established pursuant to subsection (a) of this section shall be overseen by a Connecticut Confidential Computing Cluster Policy Board, which shall be within the Department of Economic and Community Development for administrative purposes only. Said policy board shall consist of:</p>\n   <p class=\"indent\">(A) The chairperson of The University of Connecticut Health Center Board of Directors, or said chairperson&#39;s designee; and</p>\n   <p class=\"indent\">(B) A representative of the State-wide Health Information Exchange established pursuant to section 17b-59d of the general statutes, who shall be appointed by the Commissioner of Health Strategy.</p>\n   <p class=\"indent\">(2) The Connecticut Confidential Computing Cluster Policy Board shall direct the formulation of policies and operating procedures for the confidential computing cluster established pursuant to subsection (a) of this section.</p>\n   <p class=\"indent\">(3) The Connecticut Confidential Computing Cluster Policy Board may apply for and administer any federal, state, local or private appropriations or grant funds made available for the operation of the confidential computing cluster established pursuant to subsection (a) of this section.</p>\n   <p class=\"indent\">Sec. 19. Section 10-21l of the general statutes is repealed and the following is substituted in lieu thereof (Effective July 1, 2025):</p>\n   <p class=\"indent\">There is established an account to be known as the <strike class=\"amendmentDeletedText\">&quot;computer science education account&quot;</strike>\n    <u class=\"amendmentInsertedText\">&quot;computer science education and workforce development account&quot;</u>, which shall be a separate, nonlapsing account within the General Fund. The account shall contain any moneys required or permitted by law to be deposited in the account and any funds received from any public or private contributions, gifts, grants, donations, bequests or devises to the account. The Department of Education may make expenditures from the account <u class=\"amendmentInsertedText\">(1)</u> to support curriculum development, teacher professional development, capacity development for school districts <strike class=\"amendmentDeletedText\">,</strike> and other programs for the purposes of supporting computer science education<u class=\"amendmentInsertedText\">, and (2) in coordination with the Office of Workforce Strategy and the Board of Regents for Higher Education for the purpose of supporting workforce development initiatives in accordance with the state technology strategy adopted pursuant to subsection (e) of section 16 of this act</u>.</p>\n   <p class=\"indent\">Sec. 20. Section 32-7p of the general statutes is repealed and the following is substituted in lieu thereof (Effective July 1, 2025):</p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(a) As used in this section:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(1) &quot;Artificial intelligence&quot; means artificial intelligence system, as defined in section 1 of this act;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(2) &quot;Generative artificial intelligence&quot; means any form of artificial intelligence, including, but not limited to, a foundation model, that is able to produce synthetic digital content, as defined in section 1 of this act; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(3) &quot;Prompt engineering&quot; means the process of guiding generative artificial intelligence to generate a desired output.</u>\n   </p>\n   <p class=\"indent\">\n    <strike class=\"amendmentDeletedText\">(a)</strike>\n    <u class=\"amendmentInsertedText\">(b)</u> There shall be a Technology Talent <u class=\"amendmentInsertedText\">and Innovation Fund</u> Advisory Committee within the Department of Economic and Community Development. Such committee shall consist of members appointed by the Commissioner of Economic and Community Development, including, but not limited to, representatives of The University of Connecticut, the Board of Regents for Higher Education, independent institutions of higher education, the Office of Workforce Strategy and private industry. Such members shall be subject to term limits prescribed by the commissioner. Each member shall hold office until a successor is appointed.</p>\n   <p class=\"indent\">\n    <strike class=\"amendmentDeletedText\">(b)</strike>\n    <u class=\"amendmentInsertedText\">(c)</u> The commissioner shall call the first meeting of the advisory committee not later than October 15, 2016. The advisory committee shall meet not less than quarterly thereafter and at such other times as the chairperson deems necessary. The Technology Talent <u class=\"amendmentInsertedText\">and Innovation Fund</u> Advisory Committee shall designate the chairperson of the committee from among its members.</p>\n   <p class=\"indent\">\n    <strike class=\"amendmentDeletedText\">(c)</strike>\n    <u class=\"amendmentInsertedText\">(d)</u> No member of the advisory committee shall receive compensation for such member&#39;s service, except that each member shall be entitled to reimbursement for actual and necessary expenses incurred during the performance of such member&#39;s official duties.</p>\n   <p class=\"indent\">\n    <strike class=\"amendmentDeletedText\">(d)</strike>\n    <u class=\"amendmentInsertedText\">(e)</u> A majority of members of the advisory committee shall constitute a quorum for the transaction of any business or the exercise of any power of the advisory committee. The advisory committee may act by a majority of the members present at any meeting at which a quorum is in attendance, for the transaction of any business or the exercise of any power of the advisory committee, except as otherwise provided in this section.</p>\n   <p class=\"indent\">\n    <strike class=\"amendmentDeletedText\">(e)</strike>\n    <u class=\"amendmentInsertedText\">(f)</u> Notwithstanding any provision of the general statutes, it shall not constitute a conflict of interest for a trustee, director, partner or officer of any person, firm or corporation, or any individual having a financial interest in a person, firm or corporation, to serve as a member of the advisory committee, provided such trustee, director, partner, officer or individual complies with all applicable provisions of chapter 10. All members of the advisory committee shall be deemed public officials and shall adhere to the code of ethics for public officials set forth in chapter 10, except that no member shall be required to file a statement of financial interest as described in section 1-83.</p>\n   <p class=\"indent\">\n    <strike class=\"amendmentDeletedText\">(f) The Technology Talent Advisory Committee shall, in the following order of priority, (1) calculate the number of software developers and other persons (A) employed in technology-based fields where there is a shortage of qualified employees in this state for businesses to hire, including, but not limited to, data mining, data analysis and cybersecurity, and (B) employed by businesses located in Connecticut as of December 31, 2016; (2) develop pilot programs to recruit software developers to Connecticut and train residents of the state in software development and such other technology fields, with the goal of increasing the number of software developers and persons employed in such other technology fields residing in Connecticut and employed by businesses in Connecticut by at least double the number calculated pursuant to subdivision (1) of this subsection by January 1, 2026; and (3) identify other technology industries where there is a shortage of qualified employees in this state for growth stage businesses to hire.</strike>\n   </p>\n   <p class=\"indent\">(g) The Technology Talent <u class=\"amendmentInsertedText\">and Innovation Fund</u> Advisory Committee may <u class=\"amendmentInsertedText\">partner with institutions of higher education and other nonprofit organizations to</u> develop <strike class=\"amendmentDeletedText\">pilot</strike> programs <strike class=\"amendmentDeletedText\">for (1) marketing and publicity campaigns designed to recruit technology talent to the state; (2) student loan deferral or forgiveness for students who start businesses in the state; and (3) training, apprenticeship and gap-year initiatives</strike>\n    <u class=\"amendmentInsertedText\">to expand the technology talent pipeline in the state, including, but not limited to, in the fields of artificial intelligence and quantum computing</u>.</p>\n   <p class=\"indent\">\n    <strike class=\"amendmentDeletedText\">(h) The Technology Talent Advisory Committee shall report, in accordance with the provisions of section 11-4a, and present such report to the joint standing committees of the General Assembly having cognizance of matters relating to commerce, education, higher education and finance, revenue and bonding on or before January 1, 2017, concerning the (1) pilot programs developed pursuant to subsections (f) and (g) of this section, (2) number of software developers and persons employed in technology-based fields described in subsection (f) of this section targeted for recruitment pursuant to subsection (f) of this section, and (3) timeline and measures for reaching the recruitment target.</strike>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(h) Not later than July 1, 2026, the Technology Talent and Innovation Fund Advisory Committee shall partner with public and private institutions of higher education in the state and other training providers to develop programs in the field of artificial intelligence, including, but not limited to, in areas such as prompt engineering, artificial intelligence marketing for small businesses and artificial intelligence for small business operations.</u>\n   </p>\n   <p class=\"indent\">Sec. 21. Subsection (b) of section 32-235 of the general statutes is repealed and the following is substituted in lieu thereof (Effective July 1, 2025):</p>\n   <p class=\"indent\">(b) The proceeds of the sale of said bonds, to the extent of the amount stated in subsection (a) of this section, shall be used by the Department of Economic and Community Development (1) for the purposes of sections 32-220 to 32-234, inclusive, including economic cluster-related programs and activities, and for the Connecticut job training finance demonstration program pursuant to sections 32-23uu and 32-23vv, provided (A) three million dollars shall be used by said department solely for the purposes of section 32-23uu, (B) not less than one million dollars shall be used for an educational technology grant to the deployment center program and the nonprofit business consortium deployment center approved pursuant to section 32-41l, (C) not less than two million dollars shall be used by said department for the establishment of a pilot program to make grants to businesses in designated areas of the state for construction, renovation or improvement of small manufacturing facilities, provided such grants are matched by the business, a municipality or another financing entity. The Commissioner of Economic and Community Development shall designate areas of the state where manufacturing is a substantial part of the local economy and shall make grants under such pilot program which are likely to produce a significant economic development benefit for the designated area, (D) five million dollars may be used by said department for the manufacturing competitiveness grants program, (E) one million dollars shall be used by said department for the purpose of a grant to the Connecticut Center for Advanced Technology, for the purposes of subdivision (5) of subsection (a) of section 32-7f, (F) fifty million dollars shall be used by said department for the purpose of grants to the United States Department of the Navy, the United States Department of Defense or eligible applicants for projects related to the enhancement of infrastructure for long-term, on-going naval operations at the United States Naval Submarine Base-New London, located in Groton, which will increase the military value of said base. Such projects shall not be subject to the provisions of sections 4a-60 and 4a-60a, (G) two million dollars shall be used by said department for the purpose of a grant to the Connecticut Center for Advanced Technology, Inc., for manufacturing initiatives, including aerospace and defense, and (H) four million dollars shall be used by said department for the purpose of a grant to companies adversely impacted by the construction at the Quinnipiac Bridge, where such grant may be used to offset the increase in costs of commercial overland transportation of goods or materials brought to the port of New Haven by ship or vessel, (2) for the purposes of the small business assistance program established pursuant to section 32-9yy, provided fifteen million dollars shall be deposited in the small business assistance account established pursuant to said section 32-9yy, (3) to deposit twenty million dollars in the small business express assistance account established pursuant to section 32-7h, (4) to deposit four million nine hundred thousand dollars per year in each of the fiscal years ending June 30, 2017, to June 30, 2019, inclusive, and June 30, 2021, and nine million nine hundred thousand dollars in the fiscal year ending June 30, 2020, in the CTNext Fund established pursuant to section 32-39i, which shall be used by the Department of Economic and Community Development to provide grants-in-aid to designated innovation places, as defined in section 32-39f, planning grants-in-aid pursuant to section 32-39l, and grants-in-aid for projects that network innovation places pursuant to subsection (b) of section 32-39m, provided not more than three million dollars be used for grants-in-aid for such projects, and further provided any portion of any such deposit that remains unexpended in a fiscal year subsequent to the date of such deposit may be used by the Department of Economic and Community Development for any purpose described in subsection (e) of section 32-39i, (5) to deposit two million dollars per year in each of the fiscal years ending June 30, 2019, to June 30, 2021, inclusive, in the CTNext Fund established pursuant to section 32-39i, which shall be used by the Department of Economic and Community Development for the purpose of providing higher education entrepreneurship grants-in-aid pursuant to section 32-39g, provided any portion of any such deposit that remains unexpended in a fiscal year subsequent to the date of such deposit may be used by the Department of Economic and Community Development for any purpose described in subsection (e) of section 32-39i, (6) for the purpose of funding the costs of the Technology Talent <u class=\"amendmentInsertedText\">and Innovation Fund</u> Advisory Committee established pursuant to section 32-7p<u class=\"amendmentInsertedText\">, as amended by this act</u>, provided not more than ten million dollars may be used on or after July 1, 2023, for such purpose, (7) to provide (A) a grant-in-aid to the Connecticut Supplier Connection in an amount equal to two hundred fifty thousand dollars in each of the fiscal years ending June 30, 2017, to June 30, 2021, inclusive, and (B) a grant-in-aid to the Connecticut Procurement Technical Assistance Program in an amount equal to three hundred thousand dollars in each of the fiscal years ending June 30, 2017, to June 30, 2021, inclusive, (8) to deposit four hundred fifty thousand dollars per year, in each of the fiscal years ending June 30, 2017, to June 30, 2021, inclusive, in the CTNext Fund established pursuant to section 32-39i, which shall be used by the Department of Economic and Community Development to provide growth grants-in-aid pursuant to section 32-39g, provided any portion of any such deposit that remains unexpended in a fiscal year subsequent to the date of such deposit may be used by the Department of Economic and Community Development for any purpose described in subsection (e) of section 32-39i, (9) to transfer fifty million dollars to the Labor Department which shall be used by said department for the purpose of funding workforce pipeline programs selected pursuant to section 31-11rr, provided, notwithstanding the provisions of section 31-11rr, (A) not less than five million dollars shall be provided to the workforce development board in Bridgeport serving the southwest region, for purposes of such program, and the board shall distribute such money in proportion to population and need, and (B) not less than five million dollars shall be provided to the workforce development board in Hartford serving the north central region, for purposes of such program, (10) to transfer twenty million dollars to Connecticut Innovations, Incorporated, provided ten million dollars shall be used by Connecticut Innovations, Incorporated for the purpose of the proof of concept fund established pursuant to subsection (b) of section 32-39x and ten million dollars shall be used by Connecticut Innovations, Incorporated for the purpose of the venture capital fund program established pursuant to section 32-41oo, (11) to provide a grant to The University of Connecticut of eight million dollars for the establishment, development and operation of a center for sustainable aviation pursuant to subsection (a) of section 10a-110o, and (12) for up to twenty million dollars in investments in federally designated opportunity zones through an impact investment firm including, subject to the approval of the Governor, funding from the Economic Assistance Revolving Fund, established pursuant to section 32-231.</p>\n   <p class=\"indent\">Sec. 22. (Effective July 1, 2025) Not later than December 31, 2025, the Department of Economic and Community Development shall, within available appropriations, in partnership with public and private institutions of higher education in the state and in coordination with the artificial intelligence industry, conduct a &quot;CT AI Symposium&quot; to foster collaboration between academia, government and the artificial intelligence industry for the purpose of promoting the establishment and growth of artificial intelligence businesses in this state.</p>\n   <p class=\"indent\">Sec. 23. (Effective July 1, 2025) (a) As used in this section:</p>\n   <p class=\"indent\">(1) &quot;Artificial intelligence&quot; means artificial intelligence system, as defined in section 1 of this act;</p>\n   <p class=\"indent\">(2) &quot;Generative artificial intelligence&quot; means any form of artificial intelligence, including, but not limited to, a foundation model, that is able to produce synthetic digital content, as defined in section 1 of this act; and</p>\n   <p class=\"indent\">(3) &quot;State agency&quot; means any department, board, council, commission, institution or other executive branch agency of state government, including, but not limited to, each constituent unit and each public institution of higher education.</p>\n   <p class=\"indent\">(b) Each state agency shall, in consultation with the labor unions representing the employees of such state agency, study how generative artificial intelligence may be incorporated in its processes to improve efficiencies. Each state agency shall prepare for any such incorporation with input from the state agency&#39;s employees, including, but not limited to, any applicable collective bargaining unit that represents its employees, and appropriate experts from civil society organizations, academia and industry.</p>\n   <p class=\"indent\">(c) Not later than January 1, 2026, each state agency shall submit the results of such study to the Department of Administrative Services, including a request for approval of any potential pilot project utilizing generative artificial intelligence that the state agency intends to establish, provided such use is in accordance with the policies and procedures established by the Office of Policy and Management pursuant to subsection (b) of section 4-68jj of the general statutes. Any such pilot project shall measure how generative artificial intelligence (1) improves Connecticut residents&#39; experience with and access to government services, and (2) supports state agency employees in the performance of their duties in addition to any domain-specific impacts to be measured by the state agency. The Commissioner of Administrative Services shall assess any such proposed pilot project in accordance with the provisions of section 4a-2e of the general statutes, as amended by this act, and may disapprove any pilot project that fails such assessment or requires additional legislative authorization.</p>\n   <p class=\"indent\">(d) Not later than February 1, 2026, the Commissioner of Administrative Services shall submit a report, in accordance with the provisions of section 11-4a of the general statutes, to the joint standing committees of the General Assembly having cognizance of matters relating to consumer protection and government administration. Such report shall include a summary of all pilot projects approved by the commissioner under this section and any recommendations for legislation necessary to implement additional pilot projects.</p>\n   <p class=\"indent\">Sec. 24. Section 32-39e of the general statutes is repealed and the following is substituted in lieu thereof (Effective July 1, 2025):</p>\n   <p class=\"indent\">(a) If, in the exercise of its powers under section 32-39, Connecticut Innovations, Incorporated (1) finds that the use of a certain technology, product or process<u class=\"amendmentInsertedText\">, including, but not limited to, an artificial intelligence system, as defined in section 1 of this act,</u> (A) would promote public health and safety, environmental protection or economic development, or (B) with regard to state services, would promote efficiency, reduce administrative burdens or otherwise improve such services, and (2) determines such technology, product or process was developed by a business (A) domiciled in this state to which the corporation has provided financial assistance or in which the corporation has invested, or (B) which has been certified as a small contractor or minority business enterprise by the Commissioner of Administrative Services under section 4a-60g, the corporation, upon application of such business, may recommend to the Secretary of the Office of Policy and Management that an agency of the state, including, but not limited to, any constituent unit of the state system of higher education, be authorized to test such technology, product or process by employing <strike class=\"amendmentDeletedText\">it</strike>\n    <u class=\"amendmentInsertedText\">such technology, product or process</u> in the operations of such agency on a trial basis. The purpose of such test program shall be to validate the commercial viability of such technology, product or process provided no business in which Connecticut Innovations, Incorporated has invested shall be required to participate in such program.</p>\n   <p class=\"indent\">(b) Connecticut Innovations, Incorporated shall make no such recommendation unless such business has submitted a viable business plan to Connecticut Innovations, Incorporated for manufacturing and marketing such technology, product or process and such business demonstrates that (1) the usage of such technology, product or process by the state agency will not adversely affect safety, (2) sufficient research and development has occurred to warrant participation in the test program, (3) the technology, product or process has potential for commercialization not later than two years following the completion of any test program involving a state agency under this section, and (4) such technology, product or process will have a positive economic impact in the state, including the prospective addition of jobs and economic activity upon such commercialization.</p>\n   <p class=\"indent\">(c) If the Secretary of the Office of Policy and Management finds that employing such technology, product or process would be feasible in the operations of a state agency and would not have any detrimental effect on such operations, said secretary, notwithstanding the requirement of chapter 58, may direct an agency of the state to accept delivery of such technology, product or process and to undertake such a test program. The Secretary of the Office of Policy and Management, in consultation with the Commissioner of Administrative Services, the chief executive officer of Connecticut Innovations, Incorporated and the department head of the testing agency, shall determine, on a case-by-case basis, whether the costs associated with the acquisition and use of such technology, product or process by the testing agency shall be borne by Connecticut Innovations, Incorporated, the business or by any investor or participant in such business. The acquisition of any technology, product or process for purposes of the test program established pursuant to this section shall not be deemed to be a purchase under the provisions of the state procurement policy. The testing agency, on behalf of Connecticut Innovations, Incorporated shall maintain records related to such test program, as requested by Connecticut Innovations, Incorporated and shall make such records and any other information derived from such test program available to Connecticut Innovations, Incorporated and the business. Any proprietary information derived from such test program shall be exempt from the provisions of subsection (a) of section 1-210.</p>\n   <p class=\"indent\">(d) If the Secretary of the Office of Policy and Management, in consultation with the Commissioner of Administrative Services, the chief executive officer of Connecticut Innovations, Incorporated and the department head of the testing agency, determines that the test program sufficiently demonstrates that the technology, product or process promotes public health and safety, environmental protection, economic development or efficiency, reduces administrative burdens or otherwise improves state services, the Commissioner of Administrative Services may procure such technology, product or process for use by any or all state agencies pursuant to subsection (b) of section 4a-58.</p>\n   <p class=\"indent\">(e) The Secretary of the Office of Policy and Management, the Commissioner of Administrative Services and Connecticut Innovations, Incorporated may develop a program to recognize state agencies that help to promote public health and safety, environmental protection, economic development or efficiency, reduce administrative burdens or improve state services by participating in a testing program under this section. Such program may include the creation of a fund established with savings accrued by the testing agency during its participation in the testing program established under this section. Such fund shall only be used to implement the program of recognition established by the Secretary of the Office of Policy and Management, the Commissioner of Administrative Services and Connecticut Innovations, Incorporated, under the provisions of this subsection.</p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(f) The Secretary of the Office of Policy and Management, the Commissioner of Administrative Services, Connecticut Innovations, Incorporated, and the Chief Information Officer shall, within available appropriations, establish an artificial intelligence systems fellowship program for the purpose of assisting the Chief Information Officer and state agencies to implement artificial intelligence systems procured pursuant to subsection (b) of section 4a-58. The program shall be within the Office of Policy and Management for administrative purposes only. Not later than January 1, 2026, the Governor shall appoint three artificial intelligence technology fellows in consultation with the Chief Information Officer. Each artificial intelligence technology fellow shall have professional experience or academic qualifications in the field of artificial intelligence, and shall perform such artificial intelligence technology fellow&#39;s duties under the supervision of the Chief Information Officer. The initial term for each artificial intelligence technology fellow shall expire on January 31, 2029. Terms following initial terms shall be for two years, and any artificial intelligence technology fellow may serve more than one term. The Governor shall fill any vacancy in consultation with the Chief Information Officer not later than thirty days after the appointment becomes vacant. For the purposes of this subsection, &quot;artificial intelligence system&quot; has the same meaning as provided in section 1 of this act.</u>\n   </p>\n   <p class=\"indent\">Sec. 25. (Effective July 1, 2025) (a) For the purposes of this section:</p>\n   <p class=\"indent\">(1) &quot;Artificial intelligence&quot; means artificial intelligence system, as defined in section 1 of this act;</p>\n   <p class=\"indent\">(2) &quot;General-purpose artificial intelligence&quot; means general-purpose artificial intelligence model, as defined in section 1 of this act; and</p>\n   <p class=\"indent\">(3) &quot;Synthetic digital content&quot; has the same meaning as provided in section 1 of this act.</p>\n   <p class=\"indent\">(b) There is established a working group to engage stakeholders and experts to:</p>\n   <p class=\"indent\">(1) Make recommendations concerning:</p>\n   <p class=\"indent\">(A) The best practices to avoid the negative impacts, and to maximize the positive impacts, on services and state employees in connection with the implementation of new digital technologies and artificial intelligence;</p>\n   <p class=\"indent\">(B) The collection of reports, recommendations and plans from state agencies considering the implementation of artificial intelligence, and the assessment of such reports, recommendations and plans against the best practices described in subparagraph (A) of this subdivision; and</p>\n   <p class=\"indent\">(C) Any other matters that the working group may deem relevant for the purposes of avoiding the negative impacts, and maximizing the positive impacts, described in subparagraph (A) of this subdivision;</p>\n   <p class=\"indent\">(2) Make recommendations concerning methods to create resources for the purpose of assisting small businesses to adopt artificial intelligence to improve their efficiency and operations;</p>\n   <p class=\"indent\">(3) Propose legislation to (A) regulate the use of general-purpose artificial intelligence, and (B) require social media platforms to provide a signal when such social media platforms are displaying synthetic digital content;</p>\n   <p class=\"indent\">(4) After reviewing the laws and regulations, and any proposed legislation or regulations, of other states concerning artificial intelligence, propose legislation concerning artificial intelligence;</p>\n   <p class=\"indent\">(5) Develop an outreach plan for the purpose of bridging the digital divide and providing workforce training to persons who do not have high-speed Internet access;</p>\n   <p class=\"indent\">(6) Evaluate and make recommendations concerning:</p>\n   <p class=\"indent\">(A) The establishment of testbeds to support safeguards and systems to prevent the misuse of artificial intelligence;</p>\n   <p class=\"indent\">(B) Risk assessments for the misuse of artificial intelligence;</p>\n   <p class=\"indent\">(C) Evaluation strategies for artificial intelligence; and</p>\n   <p class=\"indent\">(D) The development, testing and evaluation of resources to support state oversight of artificial intelligence;</p>\n   <p class=\"indent\">(7) Review the protections afforded to trade secrets and other proprietary information under existing state law and make recommendations concerning such protections;</p>\n   <p class=\"indent\">(8) Study definitions concerning artificial intelligence, including, but not limited to, the definition of high-risk artificial intelligence system set forth in section 1 of this act, and make recommendations concerning the inclusion of language providing that no artificial intelligence system shall be considered to be a high-risk artificial intelligence system if such artificial intelligence system does not pose a significant risk of harm to the health, safety or fundamental rights of individuals, including, but not limited to, by not materially influencing the outcome of any decision-making;</p>\n   <p class=\"indent\">(9) Make recommendations concerning the establishment and membership of a permanent artificial intelligence advisory council; and</p>\n   <p class=\"indent\">(10) Make such other recommendations concerning artificial intelligence that the working group may deem appropriate.</p>\n   <p class=\"indent\">(c) (1) (A) The working group shall be part of the Legislative Department and consist of the following voting members: (i) One appointed by the speaker of the House of Representatives, who shall be a representative of the industries that are developing artificial intelligence; (ii) one appointed by the president pro tempore of the Senate, who shall be a representative of the industries that are using artificial intelligence; (iii) one appointed by the majority leader of the House of Representatives, who shall be an academic with a concentration in the study of technology and technology policy; (iv) one appointed by the majority leader of the Senate, who shall be an academic with a concentration in the study of government and public policy; (v) one appointed by the minority leader of the House of Representatives, who shall be a representative of an industry association representing the industries that are developing artificial intelligence; (vi) one appointed by the minority leader of the Senate, who shall be a representative of an industry association representing the industries that are using artificial intelligence; (vii) one appointed by the House chairperson of the joint standing committee of the General Assembly having cognizance of matters relating to consumer protection; (viii) one appointed by the Senate chairperson of the joint standing committee of the General Assembly having cognizance of matters relating to consumer protection; (ix) one appointed by the House ranking member of the joint standing committee of the General Assembly having cognizance of matters relating to consumer protection, who shall be a representative of the artificial intelligence industry or a related industry; (x) one appointed by the Senate ranking member of the joint standing committee of the General Assembly having cognizance of matters relating to consumer protection, who shall be a representative of the artificial intelligence industry or a related industry; (xi) one appointed by the House chairperson of the joint standing committee of the General Assembly having cognizance of matters relating to labor, who shall be a representative of a labor organization; (xii) one appointed by the Senate chairperson of the joint standing committee of the General Assembly having cognizance of matters relating to labor, who shall be a representative of a labor organization; (xiii) one appointed by the House ranking member of the joint standing committee of the General Assembly having cognizance of matters relating to labor, who shall be a representative of a small business; (xiv) one appointed by the Senate ranking member of the joint standing committee of the General Assembly having cognizance of matters relating to labor, who shall be a representative of a small business; and (xv) two appointed by the Governor, who shall be members of the Connecticut Academy of Science and Engineering.</p>\n   <p class=\"indent\">(B) All voting members of the working group appointed pursuant to subparagraph (A) of this subdivision shall have professional experience or academic qualifications in matters pertaining to artificial intelligence, automated systems, government policy or another related field.</p>\n   <p class=\"indent\">(C) All initial appointments to the working group shall be made not later than July 31, 2025. Any vacancy shall be filled by the appointing authority.</p>\n   <p class=\"indent\">(D) Any action taken by the working group shall be taken by a majority vote of all members present who are entitled to vote, provided no such action may be taken unless at least fifty per cent of such members are present.</p>\n   <p class=\"indent\">(2) The working group shall include the following nonvoting, ex-officio members: (A) The House chairperson of the joint standing committee of the General Assembly having cognizance of matters relating to consumer protection; (B) the Senate chairperson of the joint standing committee of the General Assembly having cognizance of matters relating to consumer protection; (C) the House chairperson of the joint standing committee of the General Assembly having cognizance of matters relating to labor; (D) the Senate chairperson of the joint standing committee of the General Assembly having cognizance of matters relating to labor; (E) the Attorney General, or the Attorney General&#39;s designee; (F) the Comptroller, or the Comptroller&#39;s designee; (G) the Treasurer, or the Treasurer&#39;s designee; (H) the Commissioner of Administrative Services, or said commissioner&#39;s designee; (I) the Chief Data Officer, or said officer&#39;s designee; (J) the executive director of the Freedom of Information Commission, or said executive director&#39;s designee; (K) the executive director of the Commission on Women, Children, Seniors, Equity and Opportunity, or said executive director&#39;s designee; (L) the Chief Court Administrator, or said administrator&#39;s designee; and (M) the executive director of the Connecticut Academy of Science and Engineering, or said executive director&#39;s designee.</p>\n   <p class=\"indent\">(d) The chairpersons of the joint standing committee of the General Assembly having cognizance of matters relating to consumer protection and the executive director of the Connecticut Academy of Science and Engineering shall serve as chairpersons of the working group. Such chairpersons shall schedule the first meeting of the working group, which shall be held not later than August 31, 2025.</p>\n   <p class=\"indent\">(e) The administrative staff of the joint standing committee of the General Assembly having cognizance of matters relating to consumer protection shall serve as administrative staff of the working group.</p>\n   <p class=\"indent\">(f) Not later than February 1, 2026, the working group shall submit a report on its findings and recommendations to the joint standing committee of the General Assembly having cognizance of matters relating to consumer protection, in accordance with the provisions of section 11-4a of the general statutes. The working group shall terminate on the date that the working group submits such report or February 1, 2026, whichever is later.</p>\n   <p class=\"indent\">Sec. 26. Section 4a-2e of the general statutes is repealed and the following is substituted in lieu thereof (Effective July 1, 2025):</p>\n   <p class=\"indent\">(a) For the purposes of this section:</p>\n   <p class=\"indent\">(1) &quot;Artificial intelligence&quot; means <strike class=\"amendmentDeletedText\">(A) an artificial system that (i) performs tasks under varying and unpredictable circumstances without significant human oversight or can learn from experience and improve such performance when exposed to data sets, (ii) is developed in any context, including, but not limited to, software or physical hardware, and solves tasks requiring human-like perception, cognition, planning, learning, communication or physical action, or (iii) is designed to (I) think or act like a human, including, but not limited to, a cognitive architecture or neural network, or (II) act rationally, including, but not limited to, an intelligent software agent or embodied robot that achieves goals using perception, planning, reasoning, learning, communication, decision-making or action, or (B) a set of techniques, including, but not limited to, machine learning, that is designed to approximate a cognitive task; and</strike>\n    <u class=\"amendmentInsertedText\">artificial intelligence system, as defined in section 1 of this act;</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(2) &quot;Generative artificial intelligence&quot; means any form of artificial intelligence, including, but not limited to, a foundation model, that is able to produce synthetic digital content, as defined in section 1 of this act; and</u>\n   </p>\n   <p class=\"indent\">\n    <strike class=\"amendmentDeletedText\">(2)</strike>\n    <u class=\"amendmentInsertedText\">(3)</u> &quot;State agency&quot; has the same meaning as provided in section 4d-1.</p>\n   <p class=\"indent\">(b) (1) Not later than December 31, 2023, and annually thereafter, the <strike class=\"amendmentDeletedText\">Department</strike>\n    <u class=\"amendmentInsertedText\">Commissioner</u> of Administrative Services shall conduct an inventory of all systems that employ artificial intelligence and are in use by any state agency. Each such inventory shall include at least the following information for each such system:</p>\n   <p class=\"indent\">(A) The name of such system and the vendor, if any, that provided such system;</p>\n   <p class=\"indent\">(B) A description of the general capabilities and uses of such system;</p>\n   <p class=\"indent\">(C) Whether such system was used to independently make, inform or materially support a conclusion, decision or judgment; and</p>\n   <p class=\"indent\">(D) Whether such system underwent an impact assessment prior to implementation.</p>\n   <p class=\"indent\">(2) The <strike class=\"amendmentDeletedText\">Department</strike>\n    <u class=\"amendmentInsertedText\">Commissioner</u> of Administrative Services shall make each inventory conducted pursuant to subdivision (1) of this subsection publicly available on the state&#39;s open data portal.</p>\n   <p class=\"indent\">(c) Beginning on February 1, 2024, the <strike class=\"amendmentDeletedText\">Department</strike>\n    <u class=\"amendmentInsertedText\">Commissioner</u> of Administrative Services shall perform ongoing assessments of systems that employ artificial intelligence and are in use by state agencies to ensure that no such system shall result in any unlawful discrimination or disparate impact described in subparagraph (B) of subdivision (1) of subsection (b) of section 4-68jj. The <strike class=\"amendmentDeletedText\">department</strike>\n    <u class=\"amendmentInsertedText\">commissioner</u> shall perform such assessment in accordance with the policies and procedures established by the Office of Policy and Management pursuant to subsection (b) of section 4-68jj.</p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(d) The Commissioner of Administrative Services shall, in consultation with other state agencies, collective bargaining units that represent state agency employees and industry experts, develop trainings for state agency employees on (1) the use of generative artificial intelligence tools that are determined by the commissioner, pursuant to the assessment performed under subsection (c) of this section, to achieve equitable outcomes, and (2) methods for identifying and mitigating potential output inaccuracies, fabricated text, hallucinations and biases of generative artificial intelligence while respecting the privacy of the public and complying with all applicable state laws and policies. Beginning on July 1, 2026, the commissioner shall make such trainings available to state agency employees not less frequently than annually.</u>\n   </p>\n   <p class=\"indent\">Sec. 27. (NEW) (Effective July 1, 2025) The Department of Economic and Community Development shall, within available appropriations, design an algorithmic computer model for the purpose of simulating and assessing various public policy decisions, proposed public policy decisions and the actual or potential effects of such policy decisions. The department shall design such model in collaboration with public and private institutions of higher education in this state, the Department of Energy and Environmental Protection and any other state agency the Commissioner of Economic and Community Development, in the commissioner&#39;s discretion, deems relevant for the purposes of this section. Such model shall, at a minimum, be designed to (1) function as a digital twin of the population of the state, (2) algorithmically model (A) the actual or potential effects of planning and development decisions or proposed planning and development decisions, and (B) the actual or potential socioeconomic effects of macroeconomic shocks on businesses and families in the state, (3) utilize large quantities of data to support the development of public policies concerning coastline resiliency, family assistance and workforce development, and (4) enable data-driven governance by optimizing resource allocation and policy efficiency for the purpose of furthering economic resilience and social equity.</p>\n   <p class=\"indent\">Sec. 28. Section 53a-189c of the general statutes is repealed and the following is substituted in lieu thereof (Effective October 1, 2025):</p>\n   <p class=\"indent\">(a) A person is guilty of unlawful dissemination of an intimate image when (1) such person intentionally disseminates by electronic or other means a photograph, film, videotape or other recorded image <u class=\"amendmentInsertedText\">or synthetic image</u> of (A) the genitals, pubic area or buttocks of another person with less than a fully opaque covering of such body part, or the breast of such other person who is female with less than a fully opaque covering of any portion of such breast below the top of the nipple, or (B) another person engaged in sexual intercourse, as defined in section 53a-193, (2) such person disseminates such image <strike class=\"amendmentDeletedText\">without the consent of such other person,</strike> knowing that such other person <strike class=\"amendmentDeletedText\">understood that the image would not be so disseminated</strike>\n    <u class=\"amendmentInsertedText\">did not consent to such dissemination</u>, and (3) such other person suffers harm as a result of such dissemination.</p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(b)</u> For purposes of this <strike class=\"amendmentDeletedText\">subsection, &quot;disseminate&quot;</strike>\n    <u class=\"amendmentInsertedText\">section:</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(1) &quot;Disseminate&quot;</u> means to sell, give, provide, lend, trade, mail, deliver, transfer, publish, distribute, circulate, present, exhibit, advertise or otherwise offer<u class=\"amendmentInsertedText\">;</u>\n    <strike class=\"amendmentDeletedText\">, and &quot;harm&quot;</strike>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(2) &quot;Harm&quot;</u> includes, but is not limited to, subjecting such other person to hatred, contempt, ridicule, physical injury, financial injury, psychological harm or serious emotional distress<u class=\"amendmentInsertedText\">; and</u>\n   </p>\n   <p class=\"indent\">\n    <u class=\"amendmentInsertedText\">(3) &quot;Synthetic image&quot; means any photograph, film, videotape or other image that (A) is not wholly recorded by a camera, (B) is either partially or wholly generated by a computer system, and (C) depicts, and is virtually indistinguishable from an actual representation of, an identifiable person</u>.</p>\n   <p class=\"indent\">\n    <strike class=\"amendmentDeletedText\">(b)</strike>\n    <u class=\"amendmentInsertedText\">(c)</u> The provisions of subsection (a) of this <strike class=\"amendmentDeletedText\">subsection</strike>\n    <u class=\"amendmentInsertedText\">section</u> shall not apply to:</p>\n   <p class=\"indent\">(1) Any image described in subsection (a) of this section of such other person if such image resulted from voluntary exposure or engagement in sexual intercourse by such other person, in a public place, as defined in section 53a-181, or in a commercial setting;</p>\n   <p class=\"indent\">(2) Any image described in subsection (a) of this section of such other person, if such other person is not clearly identifiable, unless other personally identifying information is associated with or accompanies the image; or</p>\n   <p class=\"indent\">(3) Any image described in subsection (a) of this section of such other person, if the dissemination of such image serves the public interest.</p>\n   <p class=\"indent\">\n    <strike class=\"amendmentDeletedText\">(c)</strike>\n    <u class=\"amendmentInsertedText\">(d)</u> Unlawful dissemination of an intimate image to (1) a person by any means is a class A misdemeanor, and (2) more than one person by means of an interactive computer service, as defined in 47 USC 230, an information service, as defined in 47 USC 153, or a telecommunications service, as defined in section 16-247a, is a class D felony.</p>\n   <p class=\"indent\">\n    <strike class=\"amendmentDeletedText\">(d)</strike>\n    <u class=\"amendmentInsertedText\">(e)</u> Nothing in this section shall be construed to impose liability on the provider of an interactive computer service, as defined in 47 USC 230, an information service, as defined in 47 USC 153, or a telecommunications service, as defined in section 16-247a, for content provided by another person.</p>\n   <p class=\"indent\">This act shall take effect as follows and shall amend the following sections:</p>\n   <table>\n    <tr>\n     <td>Section 1</td>\n     <td>October 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 2</td>\n     <td>October 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 3</td>\n     <td>October 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 4</td>\n     <td>October 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 5</td>\n     <td>October 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 6</td>\n     <td>October 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 7</td>\n     <td>October 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 8</td>\n     <td>October 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 9</td>\n     <td>October 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 10</td>\n     <td>October 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 11</td>\n     <td>October 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 12</td>\n     <td>October 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 13</td>\n     <td>July 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 14</td>\n     <td>July 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 15</td>\n     <td>July 1, 2025</td>\n     <td>17b-751b(b)</td>\n    </tr>\n    <tr>\n     <td>Sec. 16</td>\n     <td>July 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 17</td>\n     <td>July 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 18</td>\n     <td>July 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 19</td>\n     <td>July 1, 2025</td>\n     <td>10-21l</td>\n    </tr>\n    <tr>\n     <td>Sec. 20</td>\n     <td>July 1, 2025</td>\n     <td>32-7p</td>\n    </tr>\n    <tr>\n     <td>Sec. 21</td>\n     <td>July 1, 2025</td>\n     <td>32-235(b)</td>\n    </tr>\n    <tr>\n     <td>Sec. 22</td>\n     <td>July 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 23</td>\n     <td>July 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 24</td>\n     <td>July 1, 2025</td>\n     <td>32-39e</td>\n    </tr>\n    <tr>\n     <td>Sec. 25</td>\n     <td>July 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 26</td>\n     <td>July 1, 2025</td>\n     <td>4a-2e</td>\n    </tr>\n    <tr>\n     <td>Sec. 27</td>\n     <td>July 1, 2025</td>\n     <td>New section</td>\n    </tr>\n    <tr>\n     <td>Sec. 28</td>\n     <td>October 1, 2025</td>\n     <td>53a-189c</td>\n    </tr>\n   </table>\n   <p class=\"indent\">\n    <b>Statement of Legislative Commissioners: </b>\n   </p>\n   <p class=\"indent\">In Section 1(9)(B), &quot;or system&quot; was added after &quot;unless the technology&quot; and &quot;does not include&quot; was added before &quot;(i)&quot; for internal consistency; in Section 1(13), &quot;identify&quot; was added before &quot;how&quot; for internal consistency; in Section 3(d)(2)(B), &quot;any intentional&quot; was changed to &quot;an intentional&quot; for consistency; in Section 4(e)(1)(B)(ii), &quot;said subparagraph (C)&quot; was changed to &quot;said subparagraph&quot; for consistency with standard drafting conventions; in Section 12(b)(3), &quot;being&quot; was added before &quot;exempt&quot; for clarity; in Section 12(d), &quot;subparagraph (B) of&quot; was added before &quot;subdivision (2)&quot; for accuracy; and in Sections 12(g), 16(e)(3), 17(b), 23(d) and 25(f), &quot;the provisions of&quot; was added before &quot;section 11-4a&quot; for consistency with standard drafting conventions.</p>\n  </div>\n </div>\n    </div>\t\n<table cellpadding=0 cellspacing=0 width=\"100%\">\n   <tr>\n      <td>\n          Copyright &copy; 2025 State Net\n      </td>\n<BR>\n<!--???MOVED INTO resources.cgi      <td align=\"right\">\n          <img src=\"https://custom.statenet.com/network/poweredby.gif\" alt=\"Powered by State Net\">\n      </td>-->\n\n    </tr>\n</table>\n</body></html>\n",
      "markdown": "The following has special meaning: _green underline denotes added text_ ~~red struck out text denotes deleted text~~ | [![Powered by State Net](https://custom.statenet.com/network/poweredby.gif)](https://www.lexisnexis.com/statenet/)  \n---|---  \n  \n2025 CT S 2 | | Author: | Looney  \n---|---  \nVersion: | Substituted  \nVersion Date: | 04/09/2025  \n  \n**STATE OF CONNECTICUT**\n\n**General Assembly**\n\n**Substitute Bill No. 2**\n\n**January Session, 2025**\n\nAN ACT CONCERNING ARTIFICIAL INTELLIGENCE.\n\nBe it enacted by the Senate and House of Representatives in General Assembly\nconvened:\n\nSection 1. (NEW) (Effective October 1, 2025) For the purposes of this section\nand sections 2 to 10, inclusive, of this act, unless the context otherwise\nrequires:\n\n(1) \"Algorithmic discrimination\" (A) means any use of an artificial\nintelligence system that results in any unlawful differential treatment or\nimpact that disfavors any individual or group of individuals on the basis of\none or more classifications protected under the laws of this state or federal\nlaw, and (B) does not include (i) the offer, license or use of a high-risk\nartificial intelligence system by a developer, integrator or deployer for the\nsole purpose of (I) the developer's, integrator's or deployer's testing to\nidentify, mitigate or prevent discrimination or otherwise ensure compliance\nwith state and federal law, or (II) expanding an applicant, customer or\nparticipant pool to increase diversity or redress historic discrimination, or\n(ii) an act or omission by or on behalf of a private club or other\nestablishment not in fact open to the public, as set forth in Title II of the\nCivil Rights Act of 1964, 42 USC 2000a(e), as amended from time to time;\n\n(2) \"Artificial intelligence system\" means any machine-based system that, for\nany explicit or implicit objective, infers from the inputs such system\nreceives how to generate outputs, including, but not limited to, content,\ndecisions, predictions or recommendations, that can influence physical or\nvirtual environments;\n\n(3) \"Consequential decision\" means any decision or judgment that has a\nmaterial legal or similarly significant effect on a consumer with respect to\n(A) access to employment, including, but not limited to, any such decision or\njudgment made concerning hiring, termination, compensation or promotion, (B)\naccess to education or vocational training, including, but not limited to, any\nsuch decision or judgment made concerning admissions, financial aid or\nscholarships, (C) the provision or denial, or terms and conditions, of (i)\nfinancial lending or credit services, (ii) housing or lodging, including, but\nnot limited to, rentals or short-term housing or lodging, (iii) insurance, or\n(iv) legal services, or (D) access to (i) essential government services, or\n(ii) health care services;\n\n(4) \"Consumer\" means any individual who is a resident of this state;\n\n(5) \"Deploy\" means to put a high-risk artificial intelligence system into use;\n\n(6) \"Deployer\" means any person doing business in this state that deploys a\nhigh-risk artificial intelligence system in this state;\n\n(7) \"Developer\" means any person doing business in this state that develops,\nor intentionally and substantially modifies, an artificial intelligence\nsystem;\n\n(8) \"General-purpose artificial intelligence model\" (A) means a model used by\nan artificial intelligence system that (i) displays significant generality,\n(ii) is capable of competently performing a wide range of distinct tasks, and\n(iii) can be integrated into a variety of downstream applications or systems,\nand (B) does not include any artificial intelligence model that is used for\ndevelopment, prototyping and research activities before such artificial\nintelligence model is released on the market;\n\n(9) \"High-risk artificial intelligence system\" (A) means any artificial\nintelligence system that is intended, when deployed, to make, or be a\nsubstantial factor in making, a consequential decision, and (B) unless the\ntechnology or system, when deployed, makes, or is a substantial factor in\nmaking, a consequential decision, does not include (i) any anti-fraud\ntechnology that does not make use of facial recognition technology, (ii) any\nartificial intelligence-enabled video game technology, (iii) any anti-malware,\nanti-virus, calculator, cybersecurity, database, data storage, firewall,\nInternet domain registration, Internet-web-site loading, networking, robocall-\nfiltering, spam-filtering, spellchecking, spreadsheet, web-caching, web-\nhosting or similar technology, (iv) any technology that performs tasks\nexclusively related to an entity's internal management affairs, including, but\nnot limited to, ordering office supplies or processing payments, (v) any\nsystem that classifies incoming documents into categories, is used to detect\nduplicate applications among a large number of applications or otherwise\nperforms narrow tasks of such a limited nature that performance of such tasks\nposes a limited risk of algorithmic discrimination, (vi) any technology that\nmerely detects decision-making patterns or deviations from prior decision-\nmaking patterns following a previously completed human assessment that such\ntechnology is not meant to replace or influence without sufficient human\nreview, including, but not limited to, any technology that analyzes a\nparticular decision-maker's prior pattern of decisions and flags potential\ninconsistencies or anomalies, or (vii) any technology that communicates with\nconsumers in natural language for the purpose of providing users with\ninformation, making referrals or recommendations and answering questions, and\nis subject to an acceptable use policy that prohibits generating content that\nis discriminatory or harmful;\n\n(10) \"Integrator\" means any person doing business in this state that, with\nrespect to a given high-risk artificial intelligence system, (A) neither\ndevelops nor intentionally and substantially modifies the high-risk artificial\nintelligence system, and (B) integrates the high-risk artificial intelligence\nsystem into a product or service such person offers to any other person;\n\n(11) \"Intentional and substantial modification\" (A) means any deliberate\nmaterial change made to (i) an artificial intelligence system that was not\npredetermined by a developer and materially increases the risk of algorithmic\ndiscrimination, or (ii) a general-purpose artificial intelligence model that\n(I) affects compliance of the general-purpose artificial intelligence model,\n(II) materially changes the purpose of the general-purpose artificial\nintelligence model, or (III) materially increases the risk of algorithmic\ndiscrimination, and (B) does not include any change made to a high-risk\nartificial intelligence system, or the performance of a high-risk artificial\nintelligence system, if (i) the high-risk artificial intelligence system\ncontinues to learn after such high-risk artificial intelligence system is (I)\noffered, sold, leased, licensed, given or otherwise made available to a\ndeployer, or (II) deployed, and (ii) such change (I) is made to such high-risk\nartificial intelligence system as a result of any learning described in\nsubparagraph (B)(i) of this subdivision, (II) was predetermined by the\ndeployer, or the third party contracted by the deployer, when such deployer or\nthird party completed the initial impact assessment of such high-risk\nartificial intelligence system pursuant to subsection (c) of section 4 of this\nact, and (III) is included in the technical documentation for such high-risk\nartificial intelligence system;\n\n(12) \"Person\" means any individual, association, corporation, limited\nliability company, partnership, trust or other legal entity;\n\n(13) \"Red-teaming\" means an adversarial exercise that is conducted to identify\nthe potential adverse behaviors or outcomes of an artificial intelligence\nsystem, identify how such behaviors or outcomes occur and stress test the\nsafeguards against such behaviors or outcomes;\n\n(14) \"Substantial factor\" (A) means a factor that (i) alters the outcome of a\nconsequential decision, and (ii) is generated by an artificial intelligence\nsystem, (B) includes, but is not limited to, any use of an artificial\nintelligence system to generate any content, decision, prediction or\nrecommendation concerning a consumer that is used as a basis to make a\nconsequential decision concerning the consumer, and (C) does not include any\noutput produced by an artificial intelligence system where an individual was\ninvolved in the data processing that produced such output and such individual\n(i) meaningfully considered such data as part of such data processing, and\n(ii) had the authority to change or influence the output produced by such data\nprocessing;\n\n(15) \"Synthetic digital content\" means any digital content, including, but not\nlimited to, any audio, image, text or video, that is produced or manipulated\nby an artificial intelligence system, including, but not limited to, a\ngeneral-purpose artificial intelligence model; and\n\n(16) \"Trade secret\" has the same meaning as provided in section 35-51 of the\ngeneral statutes.\n\nSec. 2. (NEW) (Effective October 1, 2025) (a) Beginning on October 1, 2026, a\ndeveloper of a high-risk artificial intelligence system shall use reasonable\ncare to protect consumers from any known or reasonably foreseeable risks of\nalgorithmic discrimination arising from the intended and contracted uses of\nthe high-risk artificial intelligence system. In any enforcement action\nbrought on or after said date by the Attorney General pursuant to section 10\nof this act, there shall be a rebuttable presumption that a developer used\nreasonable care as required under this subsection if the developer complied\nwith the provisions of this section or, if the developer enters into a\ncontract with an integrator as set forth in subsection (b) of section 3 of\nthis act, the developer and integrator complied with the provisions of this\nsection and section 3 of this act.\n\n(b) Except as provided in subsection (c) of section 3 of this act, a developer\nof a high-risk artificial intelligence system shall, beginning on October 1,\n2026, make available to each deployer, or other developer, of the high-risk\nartificial intelligence system:\n\n(1) A general statement describing the intended uses, and the known harmful or\ninappropriate uses, of such high-risk artificial intelligence system;\n\n(2) (A) Documentation disclosing (i) high-level summaries of the type of data\nused to train such high-risk artificial intelligence system, (ii) the known or\nreasonably foreseeable limitations of such high-risk artificial intelligence\nsystem, including, but not limited to, the known or reasonably foreseeable\nrisks of algorithmic discrimination arising from the intended uses of such\nhigh-risk artificial intelligence system, (iii) the purpose of such high-risk\nartificial intelligence system, and (iv) the intended benefits and uses of\nsuch high-risk artificial intelligence system, and (B) any additional\ndocumentation that is reasonably necessary to assist such deployer or other\ndeveloper to understand the outputs, and monitor the performance, of such\nhigh-risk artificial intelligence system to enable such deployer or other\ndeveloper to comply with the provisions of sections 1 to 10, inclusive, of\nthis act; and\n\n(3) Documentation describing (A) how such high-risk artificial intelligence\nsystem was evaluated for performance, and mitigation of algorithmic\ndiscrimination, before such high-risk artificial intelligence system was\noffered, sold, leased, licensed, given or otherwise made available to such\ndeployer, (B) the data governance measures used to cover the training datasets\nand the measures used to examine the suitability of data sources, possible\nbiases and appropriate mitigation, (C) the intended outputs of such high-risk\nartificial intelligence system, (D) the measures the developer has taken to\nmitigate any known or reasonably foreseeable risks of algorithmic\ndiscrimination that may arise from deployment of such high-risk artificial\nintelligence system, and (E) how such high-risk artificial intelligence system\nis intended to be used, based on known or reasonably foreseeable harmful or\ninappropriate applications, and be monitored by an individual when such high-\nrisk artificial intelligence system is used to make, or as a substantial\nfactor in making, a consequential decision.\n\n(c) (1) Except as provided in subsection (c) of section 3 of this act, any\ndeveloper that, on or after October 1, 2026, offers, sells, leases, licenses,\ngives or otherwise makes available to a deployer or another developer a high-\nrisk artificial intelligence system shall, to the extent feasible, make\navailable to the deployers and other developers of such high-risk artificial\nintelligence system the documentation and information necessary for a\ndeployer, or the third party contracted by a deployer, to complete an impact\nassessment pursuant to subsection (c) of section 4 of this act. The developer\nshall make such documentation and information available through artifacts such\nas system cards or other impact assessments.\n\n(2) A developer that also serves as a deployer for any high-risk artificial\nintelligence system shall not be required to generate the documentation\nrequired by this section unless such high-risk artificial intelligence system\nis provided to another person that serves as a deployer for such high-risk\nartificial intelligence system.\n\n(d) (1) Beginning on October 1, 2026, each developer shall make available, in\na manner that is clear and readily available on such developer's Internet web\nsite or in a public use case inventory, a statement summarizing:\n\n(A) The types of high-risk artificial intelligence systems that such developer\n(i) has developed or intentionally and substantially modified, and (ii)\ncurrently makes available to a deployer or another developer; and\n\n(B) How such developer manages any known or reasonably foreseeable risks of\nalgorithmic discrimination that may arise from the intended uses of the types\nof high-risk artificial intelligence systems described in subparagraph (A) of\nthis subdivision.\n\n(2) Each developer shall update the statement made available pursuant to\nsubdivision (1) of this subsection (A) as necessary to ensure that such\nstatement remains accurate, and (B) not later than ninety days after the\ndeveloper intentionally and substantially modifies any high-risk artificial\nintelligence system described in subparagraph (A) of subdivision (1) of this\nsubsection.\n\n(3) Where multiple developers contribute to the development of a high-risk\nartificial intelligence system, each developer shall be subject to the\nobligations applicable to developers under sections 1 to 10, inclusive, of\nthis act solely with respect to the activities the developer performed in\ncontributing to the development of such high-risk artificial intelligence\nsystem.\n\n(e) Beginning on October 1, 2026, a developer of a high-risk artificial\nintelligence system shall disclose to the Attorney General, in a form and\nmanner prescribed by the Attorney General, and to all known deployers or other\ndevelopers of the high-risk artificial intelligence system, any previously\ndisclosed known or reasonably foreseeable risks of algorithmic discrimination\narising from the intended uses of such high-risk artificial intelligence\nsystem. The developer shall make such disclosures without unreasonable delay\nbut in no event later than ninety days after the date on which:\n\n(1) The developer discovers, through the developer's ongoing testing and\nanalysis, that the high-risk artificial intelligence system has (A) been\ndeployed, and (B) caused, or is reasonably likely to have caused, algorithmic\ndiscrimination to at least one thousand consumers; or\n\n(2) The developer receives, from a deployer of the high-risk artificial\nintelligence system, a credible report disclosing that such high-risk\nartificial intelligence system has (A) been deployed, and (B) caused\nalgorithmic discrimination to at least one thousand consumers.\n\n(f) The provisions of subsections (b) to (e), inclusive, of this section shall\nnot be construed to require a developer to disclose any information (1) that\nis a trade secret or otherwise protected from disclosure under state or\nfederal law, or (2) the disclosure of which would present a security risk to\nthe developer.\n\n(g) Notwithstanding the provisions of subsections (a) to (f), inclusive, of\nthis section, (1) any documentation a developer completes for the purpose of\ncomplying with another applicable law or regulation shall be deemed to satisfy\nthe requirements established in this section if such documentation is\nreasonably similar in scope and effect to the documentation the developer\nwould otherwise be required to complete pursuant to this section, and (2) a\ndeveloper may contract with a third party to fulfill the developer's duties\nunder this section.\n\n(h) Beginning on October 1, 2026, the Attorney General may require that a\ndeveloper disclose to the Attorney General, as part of an investigation\nconducted by the Attorney General regarding a suspected violation of any\nprovision of sections 1 to 10, inclusive, of this act and in a form and manner\nprescribed by the Attorney General, the general statement or documentation\ndescribed in subsection (b) of this section. The Attorney General may evaluate\nsuch general statement or documentation to ensure compliance with the\nprovisions of this section. In disclosing such general statement or\ndocumentation to the Attorney General pursuant to this subsection, the\ndeveloper may designate such general statement or documentation as including\nany information that is exempt from disclosure under subsection (f) of this\nsection or the Freedom of Information Act, as defined in section 1-200 of the\ngeneral statutes. To the extent such general statement or documentation\nincludes such information, such general statement or documentation shall be\nexempt from disclosure under subsection (f) of this section or said act. To\nthe extent any information contained in such general statement or\ndocumentation is subject to the attorney-client privilege or work product\nprotection, such disclosure shall not constitute a waiver of such privilege or\nprotection.\n\nSec. 3. (NEW) (Effective October 1, 2025) (a) Beginning on October 1, 2026, if\nan integrator integrates a high-risk artificial intelligence system into a\nproduct or service the integrator offers to any other person, such integrator\nshall use reasonable care to protect consumers from any known or reasonably\nforeseeable risks of algorithmic discrimination arising from the intended and\ncontracted uses of such integrated high-risk artificial intelligence system.\nIn any enforcement action brought on or after said date by the Attorney\nGeneral pursuant to section 10 of this act, there shall be a rebuttable\npresumption that the integrator used reasonable care as required under this\nsubsection if the integrator complied with the provisions of this section.\n\n(b) Beginning on October 1, 2026, no integrator shall integrate a high-risk\nartificial intelligence system into a product or service the integrator offers\nto any other person unless the integrator has entered into a contract with the\ndeveloper of the high-risk artificial intelligence system. The contract shall\nbe binding and clearly set forth the duties of the developer and integrator\nwith respect to the integrated high-risk artificial intelligence system,\nincluding, but not limited to, whether the developer or integrator shall be\nresponsible for performing the developer's duties under subsections (b) and\n(c) of section 2 of this act.\n\n(c) The provisions of subsections (b) and (c) of section 2 of this act shall\nnot apply to a developer of an integrated high-risk artificial intelligence\nsystem if, at all times while the integrated high-risk artificial intelligence\nsystem is integrated into a product or service an integrator offers to any\nother person, the developer has entered into a contract with the integrator in\nwhich such integrator has agreed to assume the developer's duties under\nsubsections (b) and (c) of section 2 of this act.\n\n(d) (1) Beginning on October 1, 2026, each integrator shall make available, in\na manner that is clear and readily available on such integrator's Internet web\nsite or in a public use case inventory, a statement summarizing:\n\n(A) The types of high-risk artificial intelligence systems that such\nintegrator has integrated into products or services such integrator currently\noffers to any other person; and\n\n(B) How such integrator manages any known or reasonably foreseeable risks of\nalgorithmic discrimination that may arise from the types of high-risk\nartificial intelligence systems described in subparagraph (A) of this\nsubdivision.\n\n(2) Each integrator shall update the statement made available pursuant to\nsubdivision (1) of this subsection (A) as necessary to ensure that such\nstatement remains accurate, and (B) not later than ninety days after an\nintentional and substantial modification is made to any high-risk artificial\nintelligence system described in subparagraph (A) of subdivision (1) of this\nsubsection.\n\n(e) The provisions of subsections (b) to (d), inclusive, of this section shall\nnot be construed to require a developer or integrator to disclose any\ninformation (1) that is a trade secret or otherwise protected from disclosure\nunder state or federal law, or (2) the disclosure of which would present a\nsecurity risk to the developer or integrator.\n\n(f) Beginning on October 1, 2026, the Attorney General may require that an\nintegrator which has assumed a developer's duties under subsection (c) of\nsection 2 of this act disclose to the Attorney General, as part of an\ninvestigation conducted by the Attorney General regarding a suspected\nviolation of any provision of sections 1 to 10, inclusive, of this act and in\na form and manner prescribed by the Attorney General, the general statement or\ndocumentation described in said subsection. The Attorney General may evaluate\nsuch general statement or documentation to ensure compliance with the\nprovisions of this section and section 2 of this act. In disclosing such\ngeneral statement or documentation to the Attorney General pursuant to this\nsubsection, the integrator may designate such general statement or\ndocumentation as including any information that is exempt from disclosure\nunder subsection (e) of this section or the Freedom of Information Act, as\ndefined in section 1-200 of the general statutes. To the extent such general\nstatement or documentation includes such information, such general statement\nor documentation shall be exempt from disclosure under subsection (e) of this\nsection or said act. To the extent any information contained in such general\nstatement or documentation is subject to the attorney-client privilege or work\nproduct protection, such disclosure shall not constitute a waiver of such\nprivilege or protection.\n\nSec. 4. (NEW) (Effective October 1, 2025) (a) Beginning on October 1, 2026,\neach deployer of a high-risk artificial intelligence system shall use\nreasonable care to protect consumers from any known or reasonably foreseeable\nrisks of algorithmic discrimination. In any enforcement action brought on or\nafter said date by the Attorney General pursuant to section 10 of this act,\nthere shall be a rebuttable presumption that a deployer of a high-risk\nartificial intelligence system used reasonable care as required under this\nsubsection if the deployer complied with the provisions of this section.\n\n(b) (1) Beginning on October 1, 2026, and except as provided in subsection (g)\nof this section, each deployer of a high-risk artificial intelligence system\nshall implement and maintain a risk management policy and program to govern\nsuch deployer's deployment of the high-risk artificial intelligence system.\nThe risk management policy and program shall specify and incorporate the\nprinciples, processes and personnel that the deployer shall use to identify,\ndocument and mitigate any known or reasonably foreseeable risks of algorithmic\ndiscrimination. The risk management policy shall be the product of an\niterative process, the risk management program shall be an iterative process\nand both the risk management policy and program shall be planned, implemented\nand regularly and systematically reviewed and updated over the lifecycle of\nthe high-risk artificial intelligence system. Each risk management policy and\nprogram implemented and maintained pursuant to this subsection shall be\nreasonable, considering:\n\n(A) The guidance and standards set forth in the latest version of (i) the\n\"Artificial Intelligence Risk Management Framework\" published by the National\nInstitute of Standards and Technology, (ii) ISO or IEC 42001 of the\nInternational Organization for Standardization, or (iii) a nationally or\ninternationally recognized risk management framework for artificial\nintelligence systems, other than the guidance and standards specified in\nsubparagraphs (A)(i) and (A)(ii) of this subdivision, that imposes\nrequirements that are substantially equivalent to, and at least as stringent\nas, the requirements set forth in this section for risk management policies\nand programs;\n\n(B) The size and complexity of the deployer;\n\n(C) The nature and scope of the high-risk artificial intelligence systems\ndeployed by the deployer, including, but not limited to, the intended uses of\nsuch high-risk artificial intelligence systems; and\n\n(D) The sensitivity and volume of data processed in connection with the high-\nrisk artificial intelligence systems deployed by the deployer.\n\n(2) A risk management policy and program implemented and maintained pursuant\nto subdivision (1) of this subsection may cover multiple high-risk artificial\nintelligence systems deployed by the deployer.\n\n(c) (1) Except as provided in subdivisions (3) and (4) of this subsection and\nsubsection (g) of this section:\n\n(A) A deployer that deploys a high-risk artificial intelligence system on or\nafter October 1, 2026, or a third party contracted by the deployer, shall\ncomplete an impact assessment of the high-risk artificial intelligence system;\nand\n\n(B) Beginning on October 1, 2026, a deployer, or a third party contracted by\nthe deployer, shall complete an impact assessment of a deployed high-risk\nartificial intelligence system (i) at least annually, and (ii) not later than\nninety days after an intentional and substantial modification to such high-\nrisk artificial intelligence system is made available.\n\n(2) (A) Each impact assessment completed pursuant to this subsection shall\ninclude, at a minimum and to the extent reasonably known by, or available to,\nthe deployer:\n\n(i) A statement by the deployer disclosing the purpose, intended use cases and\ndeployment context of, and benefits afforded by, the high-risk artificial\nintelligence system;\n\n(ii) An analysis of whether the deployment of the high-risk artificial\nintelligence system poses any known or reasonably foreseeable risks of\nalgorithmic discrimination and, if so, the nature of such algorithmic\ndiscrimination and the steps that have been taken to mitigate such risks;\n\n(iii) A description of (I) the categories of data the high-risk artificial\nintelligence system processes as inputs, and (II) the outputs such high-risk\nartificial intelligence system produces;\n\n(iv) If the deployer used data to customize the high-risk artificial\nintelligence system, an overview of the categories of data the deployer used\nto customize such high-risk artificial intelligence system;\n\n(v) Any metrics used to evaluate the performance and known limitations of the\nhigh-risk artificial intelligence system;\n\n(vi) A high-level description of any transparency measures taken concerning\nthe high-risk artificial intelligence system, including, but not limited to,\nany measures taken to disclose to a consumer that such high-risk artificial\nintelligence system is in use when such high-risk artificial intelligence\nsystem is in use; and\n\n(vii) A high-level description of the post-deployment monitoring and user\nsafeguards provided concerning such high-risk artificial intelligence system,\nincluding, but not limited to, the oversight, use and learning process\nestablished by the deployer to address issues arising from deployment of such\nhigh-risk artificial intelligence system.\n\n(B) In addition to the statement, analysis, descriptions, overview and metrics\nrequired under subparagraph (A) of this subdivision, an impact assessment\ncompleted pursuant to this subsection following an intentional and substantial\nmodification made to a high-risk artificial intelligence system on or after\nOctober 1, 2026, shall include a high-level statement disclosing the extent to\nwhich the high-risk artificial intelligence system was used in a manner that\nwas consistent with, or varied from, the developer's intended uses of such\nhigh-risk artificial intelligence system.\n\n(3) A single impact assessment may address a comparable set of high-risk\nartificial intelligence systems deployed by a deployer.\n\n(4) If a deployer, or a third party contracted by the deployer, completes an\nimpact assessment for the purpose of complying with another applicable law or\nregulation, such impact assessment shall be deemed to satisfy the requirements\nestablished in this subsection if such impact assessment is reasonably similar\nin scope and effect to the impact assessment that would otherwise be completed\npursuant to this subsection.\n\n(5) A deployer shall maintain the most recently completed impact assessment of\na high-risk artificial intelligence system as required under this subsection,\nall records concerning each such impact assessment and all prior impact\nassessments, if any, for a period of at least three years following the final\ndeployment of the high-risk artificial intelligence system.\n\n(d) Except as provided in subsection (g) of this section, a deployer, or a\nthird party contracted by the deployer, shall review, not later than October\n1, 2026, and at least annually thereafter, the deployment of each high-risk\nartificial intelligence system deployed by the deployer to ensure that such\nhigh-risk artificial intelligence system is not causing algorithmic\ndiscrimination.\n\n(e) (1) Beginning on October 1, 2026, and before a deployer deploys a high-\nrisk artificial intelligence system to make, or be a substantial factor in\nmaking, a consequential decision concerning a consumer, the deployer shall:\n\n(A) Notify the consumer that the deployer has deployed a high-risk artificial\nintelligence system to make, or be a substantial factor in making, such\nconsequential decision; and\n\n(B) Provide to the consumer (i) a statement disclosing (I) the purpose of such\nhigh-risk artificial intelligence system, and (II) the nature of such\nconsequential decision, (ii) if applicable, information concerning the\nconsumer's right, under subparagraph (C) of subdivision (5) of subsection (a)\nof section 42-518 of the general statutes, to opt-out of the processing of the\nconsumer's personal data for the purposes set forth in said subparagraph,\n(iii) contact information for such deployer, (iv) a description, in plain\nlanguage, of such high-risk artificial intelligence system, and (v)\ninstructions on how to access the statement made available pursuant to\nsubdivision (1) of subsection (f) of this section.\n\n(2) Beginning on October 1, 2026, a deployer that has deployed a high-risk\nartificial intelligence system to make, or as a substantial factor in making,\na consequential decision concerning a consumer shall, if such consequential\ndecision is adverse to the consumer, provide to such consumer:\n\n(A) A high-level statement disclosing the principal reason or reasons for such\nadverse consequential decision, including, but not limited to, (i) the degree\nto which, and manner in which, the high-risk artificial intelligence system\ncontributed to such adverse consequential decision, (ii) the type of data that\nwere processed by such high-risk artificial intelligence system in making such\nadverse consequential decision, and (iii) the source of the data described in\nsubparagraph (A)(ii) of this subdivision;\n\n(B) An opportunity to (i) examine the personal data that the high-risk\nartificial intelligence system processed in making, or as a substantial factor\nin making, such adverse consequential decision, and (ii) correct any incorrect\npersonal data described in subparagraph (B)(i) of this subdivision; and\n\n(C) (i) Except as provided in subparagraph (C)(ii) of this subdivision, an\nopportunity to appeal such adverse consequential decision if such adverse\nconsequential decision is based upon inaccurate personal data, taking into\naccount both the nature of such personal data and the purpose for which such\npersonal data was processed. Such appeal shall, if technically feasible, allow\nfor human review.\n\n(ii) No deployer shall be required to provide an opportunity to appeal\npursuant to subparagraph (C)(i) of this subdivision in any instance in which\nproviding such opportunity to appeal is not in the best interest of the\nconsumer, including, but not limited to, in any instance in which any delay\nmight pose a risk to the life or safety of the consumer.\n\n(3) The deployer shall provide the notice, statements, information,\ndescription and instructions required under subdivisions (1) and (2) of this\nsubsection:\n\n(A) Directly to the consumer;\n\n(B) In plain language;\n\n(C) In all languages in which such deployer, in the ordinary course of such\ndeployer's business, provides contracts, disclaimers, sale announcements and\nother information to consumers; and\n\n(D) In a format that is accessible to consumers with disabilities.\n\n(f) (1) Beginning on October 1, 2026, and except as provided in subsection (g)\nof this section, each deployer shall make available, in a manner that is clear\nand readily available on such deployer's Internet web site, a statement\nsummarizing:\n\n(A) The types of high-risk artificial intelligence systems that are currently\ndeployed by such deployer;\n\n(B) How such deployer manages any known or reasonably foreseeable risks of\nalgorithmic discrimination that may arise from deployment of each high-risk\nartificial intelligence system described in subparagraph (A) of this\nsubdivision;\n\n(C) In detail, the nature, source and extent of the information collected and\nused by such deployer; and\n\n(D) How the consumer may exercise rights under section 42-518 of the general\nstatutes by the secure and reliable means established and described pursuant\nto subsection (b) of section 42-518 of the general statutes.\n\n(2) Each deployer shall periodically update the statement made available\npursuant to subdivision (1) of this subsection.\n\n(g) The provisions of subsections (b) to (d), inclusive, of this section and\nsubsection (f) of this section shall not apply to a deployer if, at the time\nthe deployer deploys a high-risk artificial intelligence system and at all\ntimes while the high-risk artificial intelligence system is deployed:\n\n(1) The deployer (A) has entered into a contract with the developer in which\nthe developer has agreed to assume the deployer's duties under subsections (b)\nto (d), inclusive, of this section and subsection (f) of this section, and (B)\ndoes not exclusively use such deployer's own data to train such high-risk\nartificial intelligence system;\n\n(2) Such high-risk artificial intelligence system (A) is used for the intended\nuses that are disclosed to such deployer as set forth in subparagraph (A)(iv)\nof subdivision (2) of subsection (b) of section 2 of this act, and (B)\ncontinues learning based on a broad range of data sources and not solely based\non the deployer's own data; and\n\n(3) Such deployer makes available to consumers any impact assessment that (A)\nthe developer of such high-risk artificial intelligence system has completed\nand provided to such deployer, and (B) includes information that is\nsubstantially similar to the information included in the statement, analysis,\ndescriptions, overview and metrics required under subparagraph (A) of\nsubdivision (2) of subsection (c) of this section.\n\n(h) If a deployer deploys a high-risk artificial intelligence system on or\nafter October 1, 2026, and subsequently discovers that the high-risk\nartificial intelligence system has caused algorithmic discrimination to at\nleast one thousand consumers, the deployer shall send to the Attorney General,\nin a form and manner prescribed by the Attorney General, a notice disclosing\nsuch discovery. The deployer shall send such notice to the Attorney General\nwithout unreasonable delay but in no event later than ninety days after the\ndate on which the deployer discovered such algorithmic discrimination.\n\n(i) Nothing in subsections (b) to (h), inclusive, of this section shall be\nconstrued to require a deployer to disclose any information that is a trade\nsecret or otherwise protected from disclosure under state or federal law. If a\ndeployer withholds any information from a consumer under this subsection, the\ndeployer shall send notice to the consumer disclosing (1) that the deployer is\nwithholding such information from such consumer, and (2) the basis for the\ndeployer's decision to withhold such information from such consumer.\n\n(j) Beginning on October 1, 2026, the Attorney General may require that a\ndeployer, or a third party contracted by the deployer as set forth in\nsubsection (c) of this section, as applicable, disclose to the Attorney\nGeneral, as part of an investigation conducted by the Attorney General\nregarding a suspected violation of any provision of sections 1 to 10,\ninclusive, of this act, not later than ninety days after a request by the\nAttorney General and in a form and manner prescribed by the Attorney General,\nthe risk management policy implemented pursuant to subsection (b) of this\nsection, impact assessment completed pursuant to subsection (c) of this\nsection or records maintained pursuant to subdivision (5) of subsection (c) of\nthis section. The Attorney General may evaluate such risk management policy,\nimpact assessment or records to ensure compliance with the provisions of this\nsection. In disclosing such risk management policy, impact assessment or\nrecords to the Attorney General pursuant to this subsection, the deployer or\nthird-party contractor, as applicable, may designate such risk management\npolicy, impact assessment or records as including any information that is\nexempt from disclosure under subsection (i) of this section or the Freedom of\nInformation Act, as defined in section 1-200 of the general statutes. To the\nextent such risk management policy, impact assessment or records include such\ninformation, such risk management policy, impact assessment or records shall\nbe exempt from disclosure under subsection (i) of this section or said act. To\nthe extent any information contained in such risk management policy, impact\nassessment or record is subject to the attorney-client privilege or work\nproduct protection, such disclosure shall not constitute a waiver of such\nprivilege or protection.\n\nSec. 5. (NEW) (Effective October 1, 2025) (a) Beginning on October 1, 2026,\neach developer of a general-purpose artificial intelligence model that is\ncapable of being used by a high-risk artificial intelligence system shall, to\nthe extent feasible and except as provided in subsection (b) of this section,\nmake available to:\n\n(1) Each deployer of such general-purpose artificial intelligence model,\nthrough artifacts such as system cards or other impact assessments, the\ndocumentation and information necessary for such deployer, or a third party\ncontracted by such deployer, to complete an impact assessment pursuant to\nsubsection (c) of section 4 of this act; and\n\n(2) Each deployer or other developer of such general-purpose artificial\nintelligence model any additional documentation that is reasonably necessary\nto assist such deployer or other developer to understand the outputs, and\nmonitor the performance, of the general-purpose artificial intelligence model\nto enable such deployer or other developer to comply with the provisions of\nsections 1 to 10, inclusive, of this act.\n\n(b) (1) The provisions of subsection (a) of this section shall not apply to a\ndeveloper that develops, or intentionally and substantially modifies, a\ngeneral-purpose artificial intelligence model on or after October 1, 2026, if:\n\n(A) (i) The developer releases such general-purpose artificial intelligence\nmodel under a free and open-source license that allows for (I) access to, and\nmodification, distribution and usage of, such general-purpose artificial\nintelligence model, and (II) the parameters of such general-purpose artificial\nintelligence model to be made publicly available as set forth in subparagraph\n(A)(ii) of this subdivision; and\n\n(ii) Unless such general-purpose artificial intelligence model is deployed as\na high-risk artificial intelligence system, the parameters of such general-\npurpose artificial intelligence model, including, but not limited to, the\nweights and information concerning the model architecture and model usage for\nsuch general-purpose artificial intelligence model, are made publicly\navailable; or\n\n(B) The general-purpose artificial intelligence model is (i) not offered for\nsale in the market, (ii) not intended to interact with consumers, and (iii)\nsolely utilized (I) for an entity's internal purposes, or (II) under an\nagreement between multiple entities for such entities' internal purposes.\n\n(2) The provisions of this section shall not apply to a developer that\ndevelops, or intentionally and substantially modifies, a general-purpose\nartificial intelligence model on or after October 1, 2026, if such general-\npurpose artificial intelligence model performs tasks exclusively related to an\nentity's internal management affairs, including, but not limited to, ordering\noffice supplies or processing payments.\n\n(3) A developer that takes any action under an exemption established in\nsubdivision (1) or (2) of this subsection shall bear the burden of\ndemonstrating that such action qualifies for such exemption.\n\n(4) A developer that is exempt under subparagraph (B) of subdivision (1) of\nthis subsection shall establish and maintain an artificial intelligence risk\nmanagement framework, which framework shall (A) be the product of an iterative\nprocess and ongoing efforts, and (B) include, at a minimum, (i) an internal\ngovernance function, (ii) a map function that shall establish the context to\nframe risks, (iii) a risk management function, and (iv) a function to measure\nidentified risks by assessing, analyzing and tracking such risks.\n\n(c) Nothing in subsection (a) of this section shall be construed to require a\ndeveloper to disclose any information that is a trade secret or otherwise\nprotected from disclosure under state or federal law.\n\n(d) Beginning on October 1, 2026, the Attorney General may require that a\ndeveloper disclose to the Attorney General, as part of an investigation\nconducted by the Attorney General regarding a suspected violation of any\nprovision of sections 1 to 10, inclusive, of this act, not later than ninety\ndays after a request by the Attorney General and in a form and manner\nprescribed by the Attorney General, any documentation maintained pursuant to\nthis section. The Attorney General may evaluate such documentation to ensure\ncompliance with the provisions of this section. In disclosing any\ndocumentation to the Attorney General pursuant to this subsection, the\ndeveloper may designate such documentation as including any information that\nis exempt from disclosure under subsection (c) of this section or the Freedom\nof Information Act, as defined in section 1-200 of the general statutes. To\nthe extent such documentation includes such information, such documentation\nshall be exempt from disclosure under subsection (c) of this section or said\nact. To the extent any information contained in such documentation is subject\nto the attorney-client privilege or work product protection, such disclosure\nshall not constitute a waiver of such privilege or protection.\n\nSec. 6. (NEW) (Effective October 1, 2025) (a) Beginning on October 1, 2026,\nand except as provided in subsection (b) of this section, each person doing\nbusiness in this state, including, but not limited to, each deployer that\ndeploys, offers, sells, leases, licenses, gives or otherwise makes available,\nas applicable, any artificial intelligence system that is intended to interact\nwith consumers shall ensure that it is disclosed to each consumer who\ninteracts with such artificial intelligence system that such consumer is\ninteracting with an artificial intelligence system.\n\n(b) No disclosure shall be required under subsection (a) of this section under\ncircumstances in which a reasonable person would deem it obvious that such\nperson is interacting with an artificial intelligence system.\n\nSec. 7. (NEW) (Effective October 1, 2025) (a) Beginning on October 1, 2026,\nand except as provided in subsections (b) and (c) of this section, the\ndeveloper of an artificial intelligence system, including, but not limited to,\na general-purpose artificial intelligence model, that is capable of generating\nsynthetic digital content shall:\n\n(1) Ensure that the outputs of such artificial intelligence system are marked\nand detectable as synthetic digital content, and that such outputs are so\nmarked and detectable (A) not later than the time that consumers who did not\ncreate such outputs first interact with, or are exposed to, such outputs, and\n(B) in a manner that (i) is detectable by consumers, and (ii) complies with\nany applicable accessibility requirements; and\n\n(2) As far as technically feasible and in a manner that is consistent with any\nnationally or internationally recognized technical standards, ensure that such\ndeveloper's technical solutions are effective, interoperable, robust and\nreliable, considering (A) the specificities and limitations of different types\nof synthetic digital content, (B) the implementation costs, and (C) the\ngenerally acknowledged state of the art.\n\n(b) If the synthetic digital content described in subsection (a) of this\nsection is in an audio, image or video format, and such synthetic digital\ncontent forms part of an evidently artistic, creative, satirical, fictional\nanalogous work or program, the disclosure required under said subsection shall\nbe limited to a disclosure that does not hinder the display or enjoyment of\nsuch work or program.\n\n(c) The provisions of subsection (a) of this section shall not apply:\n\n(1) To any synthetic digital content that (A) consists exclusively of text,\n(B) is published to inform the public on any matter of public interest, or (C)\nis unlikely to mislead a reasonable person consuming such synthetic digital\ncontent; or\n\n(2) To the extent that any artificial intelligence system described in\nsubsection (a) of this section (A) performs an assistive function for standard\nediting, (B) does not substantially alter the input data provided by the\ndeveloper or the semantics thereof, or (C) is used to detect, prevent,\ninvestigate or prosecute any crime where authorized by law.\n\nSec. 8. (NEW) (Effective October 1, 2025) (a) Nothing in sections 1 to 10,\ninclusive, of this act shall be construed to restrict a developer's,\nintegrator's, deployer's or other person's ability to:\n\n(1) Comply with any federal, state or municipal law, ordinance or regulation;\n\n(2) Comply with a civil, criminal or regulatory inquiry, investigation,\nsubpoena or summons by a federal, state, municipal or other governmental\nauthority;\n\n(3) Cooperate with a law enforcement agency concerning conduct or activity\nthat the developer, integrator, deployer or other person reasonably and in\ngood faith believes may violate federal, state or municipal law;\n\n(4) Investigate, establish, exercise, prepare for or defend a legal claim;\n\n(5) Take immediate steps to protect an interest that is essential for the life\nor physical safety of a consumer or another individual;\n\n(6) (A) By any means other than facial recognition technology, prevent,\ndetect, protect against or respond to (i) a security incident, (ii) a\nmalicious or deceptive activity, or (iii) identity theft, fraud, harassment or\nany other illegal activity, (B) investigate, report or prosecute the persons\nresponsible for any action described in subparagraph (A) of this subdivision,\nor (C) preserve the integrity or security of systems;\n\n(7) Engage in public or peer-reviewed scientific or statistical research in\nthe public interest that (A) adheres to all other applicable ethics and\nprivacy laws, and (B) is conducted in accordance with (i) 45 CFR Part 46, as\namended from time to time, or (ii) relevant requirements established by the\nfederal Food and Drug Administration;\n\n(8) Conduct research, testing, development and integration activities\nregarding an artificial intelligence system or model, other than testing\nconducted under real world conditions, before such artificial intelligence\nsystem or model is placed on the market, deployed or put into service, as\napplicable;\n\n(9) Effectuate a product recall;\n\n(10) Identify and repair technical errors that impair existing or intended\nfunctionality; or\n\n(11) Assist another developer, integrator, deployer or person with any of the\nobligations imposed under sections 1 to 10, inclusive, of this act.\n\n(b) The obligations imposed on developers, integrators, deployers or other\npersons under sections 1 to 10, inclusive, of this act shall not apply where\ncompliance by the developer, integrator, deployer or other person with said\nsections would violate an evidentiary privilege under the laws of this state.\n\n(c) Nothing in sections 1 to 10, inclusive, of this act shall be construed to\nimpose any obligation on a developer, integrator, deployer or other person\nthat adversely affects the rights or freedoms of any person, including, but\nnot limited to, the rights of any person (1) to freedom of speech or freedom\nof the press guaranteed in (A) the First Amendment to the United States\nConstitution, and (B) section 5 of article first of the Constitution of the\nstate, or (2) under section 52-146t of the general statutes.\n\n(d) Nothing in sections 1 to 10, inclusive, of this act shall be construed to\napply to any developer, integrator, deployer or other person:\n\n(1) Insofar as such developer, integrator, deployer or other person develops,\nintegrates, deploys, puts into service or intentionally and substantially\nmodifies, as applicable, a high-risk artificial intelligence system (A) that\nhas been approved, authorized, certified, cleared, developed, integrated or\ngranted by (i) a federal agency, such as the federal Food and Drug\nAdministration or the Federal Aviation Administration, acting within the scope\nof such federal agency's authority, or (ii) a regulated entity subject to\nsupervision and regulation by the Federal Housing Finance Agency, or (B) in\ncompliance with standards that are (i) established by (I) any federal agency,\nincluding, but not limited to, the federal Office of the National Coordinator\nfor Health Information Technology, or (II) a regulated entity subject to\nsupervision and regulation by the Federal Housing Finance Agency, and (ii)\nsubstantially equivalent to, and at least as stringent as, the standards\nestablished in sections 1 to 10, inclusive, of this act;\n\n(2) Conducting research to support an application (A) for approval or\ncertification from any federal agency, including, but not limited to, the\nFederal Aviation Administration, the Federal Communications Commission or the\nfederal Food and Drug Administration, or (B) that is otherwise subject to\nreview by any federal agency;\n\n(3) Performing work under, or in connection with, a contract with the United\nStates Department of Commerce, the United States Department of Defense or the\nNational Aeronautics and Space Administration, unless such developer,\nintegrator, deployer or other person is performing such work on a high-risk\nartificial intelligence system that is used to make, or as a substantial\nfactor in making, a decision concerning employment or housing;\n\n(4) That facilitates or engages in the provision of telehealth services or is\na covered entity within the meaning of the Health Insurance Portability and\nAccountability Act of 1996, P.L. 104-191, and the regulations promulgated\nthereunder, as both may be amended from time to time, and providing health\ncare recommendations that (A) are generated by an artificial intelligence\nsystem, (B) require a health care provider to take action to implement such\nrecommendations, and (C) are not considered to be high risk; or\n\n(5) Who is an active participant in the artificial intelligence regulatory\nsandbox program designed, established and administered under section 12 of\nthis act, and is engaged in activities within the scope of such program in\naccordance with the provisions of section 12 of this act.\n\n(e) Nothing in sections 1 to 10, inclusive, of this act shall be construed to\napply to any artificial intelligence system that is acquired by or for the\nfederal government or any federal agency or department, including, but not\nlimited to, the United States Department of Commerce, the United States\nDepartment of Defense or the National Aeronautics and Space Administration,\nunless such artificial intelligence system is a high-risk artificial\nintelligence system that is used to make, or as a substantial factor in\nmaking, a decision concerning employment or housing.\n\n(f) Any insurer, as defined in section 38a-1 of the general statutes,\nfraternal benefit society, as described in section 38a-595 of the general\nstatutes, or health carrier, as defined in section 38a-591a of the general\nstatutes, shall be deemed to be in full compliance with the provisions of\nsections 1 to 10, inclusive, of this act if such insurer, fraternal benefit\nsociety or health carrier has implemented and maintains a written artificial\nintelligence systems program in accordance with all requirements established\nby the Insurance Commissioner.\n\n(g) (1) Any bank, out-of-state bank, Connecticut credit union, federal credit\nunion, mortgage lender or out-of-state credit union, or any affiliate,\nsubsidiary or service provider thereof, shall be deemed to be in full\ncompliance with the provisions of sections 1 to 10, inclusive, of this act if\nsuch bank, out-of-state bank, Connecticut credit union, federal credit union,\nmortgage lender, out-of-state credit union, affiliate, subsidiary or service\nprovider is subject to examination by any state or federal prudential\nregulator under any published guidance or regulations that apply to the use of\nhigh-risk artificial intelligence systems and such guidance or regulations (A)\nimpose requirements that are substantially equivalent to, and at least as\nstringent as, the requirements set forth in sections 1 to 10, inclusive, of\nthis act, and (B) at a minimum, require such bank, out-of-state bank,\nConnecticut credit union, federal credit union, mortgage lender, out-of-state\ncredit union, affiliate, subsidiary or service provider to (i) regularly audit\nsuch bank's, out-of-state bank's, Connecticut credit union's, federal credit\nunion's, mortgage lender's, out-of-state credit union's, affiliate's,\nsubsidiary's or service provider's use of high-risk artificial intelligence\nsystems for compliance with state and federal anti-discrimination laws and\nregulations applicable to such bank, out-of-state bank, Connecticut credit\nunion, federal credit union, mortgage lender, out-of-state credit union,\naffiliate, subsidiary or service provider, and (ii) mitigate any algorithmic\ndiscrimination caused by the use of a high-risk artificial intelligence system\nor any risk of algorithmic discrimination that is reasonably foreseeable as a\nresult of the use of a high-risk artificial intelligence system.\n\n(2) For the purposes of this subsection, (A) \"affiliate\", \"bank\", \"Connecticut\ncredit union\", \"federal credit union\", \"out-of-state bank\", \"out-of-state\ncredit union\" and \"subsidiary\" have the same meanings as provided in section\n36a-2 of the general statutes, and (B) \"mortgage lender\" has the same meaning\nas provided in section 36a-705 of the general statutes.\n\n(h) If a developer, integrator, deployer or other person engages in any action\npursuant to an exemption set forth in subsections (a) to (g), inclusive, of\nthis section, the developer, integrator, deployer or other person bears the\nburden of demonstrating that such action qualifies for such exemption.\n\nSec. 9. (NEW) (Effective October 1, 2025) Not later than January 1, 2026, the\nAttorney General shall, within available appropriations, develop and implement\na comprehensive public education, outreach and assistance program for\ndevelopers, integrators and deployers that are small businesses, as defined in\nsection 4-168a of the general statutes. Such program shall, at a minimum,\ndisseminate educational materials concerning (1) the requirements established\nin sections 1 to 10, inclusive, of this act, including, but not limited to,\nthe duties of developers, integrators and deployers under sections 1 to 10,\ninclusive, of this act, (2) the impact assessments required under subsection\n(c) of section 4 of this act, (3) the Attorney General's powers under sections\n1 to 10, inclusive, of this act, and (4) any other matters the Attorney\nGeneral, in the Attorney General's discretion, deems relevant for the purposes\nof such program.\n\nSec. 10. (NEW) (Effective October 1, 2025) (a) The Attorney General shall have\nexclusive authority to enforce the provisions of sections 1 to 9, inclusive,\nof this act.\n\n(b) Except as provided in subsection (f) of this section, during the period\nbeginning on October 1, 2026, and ending on September 30, 2027, the Attorney\nGeneral shall, prior to initiating any action for a violation of any provision\nof sections 1 to 9, inclusive, of this act, issue a notice of violation to the\ndeveloper, integrator, deployer or other person if the Attorney General\ndetermines that it is possible to cure such violation. If the developer,\nintegrator, deployer or other person fails to cure such violation not later\nthan sixty days after receipt of the notice of violation, the Attorney General\nmay bring an action pursuant to this section.\n\n(c) Except as provided in subsection (f) of this section, beginning on October\n1, 2027, the Attorney General may, in determining whether to grant a\ndeveloper, integrator, deployer or other person the opportunity to cure a\nviolation described in subsection (b) of this section, consider: (1) The\nnumber of violations; (2) the size and complexity of the developer,\nintegrator, deployer or other person; (3) the nature and extent of the\ndeveloper's, integrator's, deployer's or other person's business; (4) the\nsubstantial likelihood of injury to the public; (5) the safety of persons or\nproperty; and (6) whether such violation was likely caused by human or\ntechnical error.\n\n(d) Nothing in sections 1 to 9, inclusive, of this act shall be construed as\nproviding the basis for a private right of action for violations of said\nsections.\n\n(e) Except as provided in subsections (a) to (d), inclusive, of this section\nand subsection (f) of this section, a violation of the requirements\nestablished in sections 1 to 9, inclusive, of this act shall constitute an\nunfair trade practice for purposes of section 42-110b of the general statutes\nand shall be enforced solely by the Attorney General. The provisions of\nsection 42-110g of the general statutes shall not apply to any such violation.\n\n(f) (1) In any action commenced by the Attorney General for any violation of\nsections 1 to 9, inclusive, of this act, it shall be an affirmative defense\nthat the developer, integrator, deployer or other person:\n\n(A) Discovers a violation of any provision of sections 1 to 9, inclusive, of\nthis act through red-teaming;\n\n(B) Not later than sixty days after discovering the violation as set forth in\nsubparagraph (A) of this subdivision: (i) Cures such violation; and (ii)\nprovides to the Attorney General, in a form and manner prescribed by the\nAttorney General, notice that such violation has been cured and evidence that\nany harm caused by such violation has been mitigated; and\n\n(C) Is otherwise in compliance with the latest version of: (i) The \"Artificial\nIntelligence Risk Management Framework\" published by the National Institute of\nStandards and Technology; (ii) ISO or IEC 42001 of the International\nOrganization for Standardization; (iii) a nationally or internationally\nrecognized risk management framework for artificial intelligence systems,\nother than the risk management frameworks specified in subparagraphs (C)(i)\nand (C)(ii) of this subdivision, that imposes requirements that are\nsubstantially equivalent to, and at least as stringent as, the requirements\nset forth in sections 1 to 9, inclusive, of this act; or (iv) any risk\nmanagement framework for artificial intelligence systems that is substantially\nequivalent to, and at least as stringent as, the risk management frameworks\ndescribed in subparagraphs (C)(i) to (C)(iii), inclusive, of this subdivision.\n\n(2) The developer, integrator, deployer or other person bears the burden of\ndemonstrating to the Attorney General that the requirements established in\nsubdivision (1) of this subsection have been satisfied.\n\n(3) Nothing in this section or sections 1 to 9, inclusive, of this act,\nincluding, but not limited to, the enforcement authority granted to the\nAttorney General under this section, shall be construed to preempt or\notherwise affect any right, claim, remedy, presumption or defense available at\nlaw or in equity. Any rebuttable presumption or affirmative defense\nestablished under this section or sections 1 to 9, inclusive, of this act\nshall apply only to an enforcement action brought by the Attorney General\npursuant to this section and shall not apply to any right, claim, remedy,\npresumption or defense available at law or in equity.\n\nSec. 11. (NEW) (Effective October 1, 2025) (a) For the purposes of this\nsection, \"legislative leader\" has the same meaning as provided in subsection\n(b) of section 4-9d of the general statutes.\n\n(b) Each legislative leader may request that the executive director of the\nConnecticut Academy of Science and Engineering designate a member of said\nacademy to serve as such legislative leader's liaison with said academy, the\nOffice of the Attorney General and the Department of Economic and Community\nDevelopment for the purpose of:\n\n(1) Designing a tool to enable any person to determine whether such person is\nin compliance with the provisions of sections 1 to 10, inclusive, of this act;\n\n(2) Designing a tool to assist a deployer, or a third party contracted by a\ndeployer, to complete an impact assessment pursuant to subsection (c) of\nsection 4 of this act;\n\n(3) Conducting meetings with relevant stakeholders to formulate a plan to\nutilize The University of Connecticut School of Law's Intellectual Property\nand Entrepreneurship Law Clinic to assist small businesses and startups in\ntheir efforts to comply with the provisions of sections 1 to 10, inclusive, of\nthis act;\n\n(4) Making recommendations concerning establishing a framework to provide a\ncontrolled and supervised environment in which artificial intelligence systems\nmay be tested, which recommendations shall include, at a minimum,\nrecommendations concerning the establishment of (A) an office to oversee such\nframework and environment, and (B) a program that would enable consultations\nbetween the state, businesses and other stakeholders concerning such framework\nand environment;\n\n(5) Evaluating (A) the adoption of artificial intelligence systems by\nbusinesses, (B) the challenges posed to, and needs of, businesses in (i)\nadopting artificial intelligence systems, and (ii) understanding laws and\nregulations concerning artificial intelligence systems, and (C) how businesses\nthat use artificial intelligence systems hire employees with necessary skills\nconcerning artificial intelligence systems;\n\n(6) Creating a plan for the state to provide high-performance computing\nservices to businesses and researchers in the state;\n\n(7) Evaluating the benefits of creating a state-wide research collaborative\namong health care providers to enable the development of advanced analytics,\nethical and trustworthy artificial intelligence systems and hands-on workforce\neducation while using methods that protect patient privacy; and\n\n(8) Evaluating, and making recommendations concerning, (A) the establishment\nof testbeds to support safeguards and systems to prevent the misuse of\nartificial intelligence systems, (B) risk assessments for the misuse of\nartificial intelligence systems, (C) evaluation strategies for artificial\nintelligence systems, and (D) the development, testing and evaluation of\nresources to support state oversight of artificial intelligence systems.\n\n(c) No member of the Connecticut Academy of Science and Engineering designated\npursuant to subsection (b) of this section shall be deemed a state employee,\nor receive any compensation from the state, for performing such member's\nduties under said subsection.\n\nSec. 12. (NEW) (Effective October 1, 2025) (a) As used in this section:\n\n(1) \"Active participant\" means a person participating in the artificial\nintelligence regulatory sandbox program designed, established and administered\nin accordance with the provisions of this section;\n\n(2) \"Artificial intelligence system\" has the same meaning as provided in\nsection 1 of this act;\n\n(3) \"Consumer\" has the same meaning as provided in section 1 of this act;\n\n(4) \"Deployer\" means any person doing business in this state that deploys an\nartificial intelligence system;\n\n(5) \"Developer\" has the same meaning as provided in section 1 of this act;\n\n(6) \"Person\" has the same meaning as provided in section 1 of this act; and\n\n(7) \"State agency\" has the same meaning as provided in section 1-79 of the\ngeneral statutes.\n\n(b) The Department of Economic and Community Development, in coordination with\nthe Chief Data Officer and the Connecticut Technology Advisory Board\nestablished under section 16 of this act, shall design, establish and\nadminister an artificial intelligence regulatory sandbox program to facilitate\nthe development, testing and deployment of innovative artificial intelligence\nsystems in the state. The program shall be designed to (1) promote the safe\nand innovative use of artificial intelligence systems across various sectors,\nincluding, but not limited to, education, finance, health care and public\nservice, (2) encourage the responsible deployment of artificial intelligence\nsystems while balancing the need for consumer protection, privacy and public\nsafety, and (3) provide clear guidelines for developers to test artificial\nintelligence systems while being exempt from certain regulatory requirements\nduring the period set forth in subsection (d) of this section.\n\n(c) (1) A person seeking to participate in the artificial intelligence\nregulatory sandbox program shall submit an application to the Department of\nEconomic and Community Development in a form and manner prescribed by the\nCommissioner of Economic and Community Development. Each application shall\ninclude (A) a detailed description of the applicant's artificial intelligence\nsystem and its intended uses, (B) a risk assessment that addresses the\npotential impact of the applicant's artificial intelligence system on\nconsumers, privacy and public safety, (C) a plan for mitigating any adverse\nconsequences that may arise from the applicant's artificial intelligence\nsystem during the period set forth in subsection (d) of this section, (D)\nproof that the applicant and the applicant's artificial intelligence system\nare in compliance with all applicable federal laws and regulations concerning\nartificial intelligence systems, and (E) any other information the\ncommissioner deems relevant for the purposes of this section or the program.\n\n(2) Not later than thirty days after the Department of Economic and Community\nDevelopment receives an application submitted pursuant to subdivision (1) of\nthis subsection, the department shall (A) approve or deny the application, and\n(B) send a notice to the applicant, in a form and manner prescribed by the\nCommissioner of Economic and Community Development, disclosing whether the\ndepartment has approved or denied such application.\n\n(d) An active participant in the artificial intelligence regulatory sandbox\nprogram may test the applicant's artificial intelligence system as part of the\nprogram for a period not to exceed eighteen months from the date on which the\nDepartment of Economic and Community Development sent notice approving the\nactive participant's application pursuant to subparagraph (B) of subdivision\n(2) of subsection (c) of this section, except the department may extend such\nperiod for good cause shown.\n\n(e) The Department of Economic and Community Development shall coordinate with\nall relevant state agencies to oversee the operations of active participants\nin the artificial intelligence regulatory sandbox program. Any state agency\nmay recommend to the department that an active participant's participation in\nthe program be revoked if the active participant's artificial intelligence\nsystem (1) poses an undue risk to the public health, safety or welfare, or (2)\nviolates any federal law or regulation.\n\n(f) For the calendar quarter ending December 31, 2025, and for each calendar\nquarter thereafter, each active participant in the artificial intelligence\nregulatory sandbox program shall, not later than thirty days after the end of\nsuch calendar quarter, submit a report to the Department of Economic and\nCommunity Development disclosing (1) system performance metrics for such\nactive participant's artificial intelligence system, (2) information\nconcerning the manner in which such active participant's artificial\nintelligence system mitigated any risks associated with such artificial\nintelligence system, and (3) any feedback such active participant received\nfrom deployers, consumers and other users of such artificial intelligence\nsystem.\n\n(g) For the calendar year ending December 31, 2025, and for each calendar year\nthereafter, the Department of Economic and Community Development shall, not\nlater than thirty days after the end of such calendar year, submit a report,\nin accordance with the provisions of section 11-4a of the general statutes, to\nthe joint standing committee of the General Assembly having cognizance of\nmatters relating to consumer protection. Each report shall disclose (1) the\nnumber of persons who were active participants in the artificial intelligence\nregulatory sandbox program for the calendar year that is the subject of such\nreport or any portion of such calendar year, (2) the overall performance and\nimpact of artificial intelligence systems tested as part of the program, and\n(3) any recommendations regarding the adoption of legislation for the purposes\nof the program.\n\nSec. 13. (NEW) (Effective July 1, 2025) (a) As used in this section,\n\"artificial intelligence\" means artificial intelligence system, as defined in\nsection 1 of this act.\n\n(b) Not later than December 31, 2025, the Board of Regents for Higher\nEducation shall establish, on behalf of Charter Oak State College and in\nconsultation with the Labor Department, the State Board of Education,\nWorkforce Investment Boards, employers and institutions of higher education in\nthis state, a \"Connecticut AI Academy\". The academy shall, at a minimum:\n\n(1) Curate and offer online courses concerning artificial intelligence and the\nresponsible use of artificial intelligence;\n\n(2) Promote digital literacy;\n\n(3) Prepare students for careers in fields involving artificial intelligence;\n\n(4) Offer courses directed at individuals between thirteen and twenty years of\nage;\n\n(5) Offer courses that prepare small businesses and nonprofit organizations to\nutilize artificial intelligence to improve marketing and management\nefficiency;\n\n(6) Develop courses concerning artificial intelligence that the Labor\nDepartment and Workforce Investment Boards may incorporate into workforce\ntraining programs; and\n\n(7) Enable persons providing free or discounted public Internet access to\ndistribute information and provide mentorship concerning artificial\nintelligence, the academy and methods available for the public to obtain free\nor discounted devices capable of accessing the Internet and utilizing\nartificial intelligence.\n\n(c) The Board of Regents for Higher Education shall, in consultation with\nCharter Oak State College, develop certificates and badges to be awarded to\npersons who successfully complete courses offered by the Connecticut AI\nAcademy.\n\nSec. 14. (NEW) (Effective July 1, 2025) The Labor Department shall provide a\nnotice, in a form and manner prescribed by the Labor Commissioner, to each\nindividual who makes a claim for unemployment compensation disclosing the\nexistence of, and courses and services offered by, the Connecticut AI Academy\nestablished pursuant to section 13 of this act.\n\nSec. 15. Subsection (b) of section 17b-751b of the general statutes is\nrepealed and the following is substituted in lieu thereof (Effective July 1,\n2025):\n\n(b) The commissioner shall: (1) Ensure that all home visiting programs _(A)_\nare one or more of the evidence-based home visiting models that meet the\ncriteria for evidence of effectiveness developed by the federal Department of\nHealth and Human Services _, and (B) provide information to parents regarding\nthe Connecticut AI Academy established pursuant to section 13 of this act_ ;\n(2) provide oversight of home visiting programs to insure model fidelity; and\n(3) develop, issue and evaluate requests for proposals to procure the services\nrequired by this section. In evaluating the proposals, the commissioner shall\ntake into consideration the most effective and consistent service delivery\nsystem allowing for the continuation of current public and private programs.\n\nSec. 16. (NEW) (Effective July 1, 2025) (a) As used in this section,\n\"artificial intelligence\" means artificial intelligence system, as defined in\nsection 1 of this act.\n\n(b) There is established, within available appropriations, a Connecticut\nTechnology Advisory Board, which shall be part of the Legislative Department.\n\n(c) (1) The board shall consist of the following members: (A) Two appointed by\nthe speaker of the House of Representatives; (B) two appointed by the\npresident pro tempore of the Senate; (C) two appointed by the minority leader\nof the House of Representatives; and (D) two appointed by the minority leader\nof the Senate. All appointed members shall have professional experience or\nacademic qualifications in the field of artificial intelligence or the field\nof technology, or another related field, and no such member shall be a member\nof the General Assembly.\n\n(2) The following persons or their designees shall serve as ex-officio,\nnonvoting members and chairpersons of the board: (A) The Commissioner of\nEconomic and Community Development; (B) the executive director of the\nConnecticut Academy of Science and Engineering; and (C) the president of\nCharter Oak State College.\n\n(3) All initial appointments to the board shall be made not later than October\n1, 2025. The term of an appointed member shall be coterminous with the term of\nthe appointing authority for the appointed member. Any vacancy shall be filled\nby the appointing authority. Any vacancy occurring other than by expiration of\na term shall be filled for the balance of the unexpired term. A member of the\nboard may serve more than one term. The chairpersons shall schedule the first\nmeeting of the board, which shall be held not later than November 1, 2025.\n\n(d) The administrative staff of the joint standing committees of the General\nAssembly having cognizance of matters relating to consumer protection and\ngovernment administration shall serve as administrative staff of the board.\n\n(e) The board shall have the following powers and duties: (1) To develop and\nadopt a state technology strategy (A) for the purpose of promoting education,\nworkforce development, economic development and consumer protection, and (B)\nthat accounts for the rapid pace of technological development, including, but\nnot limited to, in the field of artificial intelligence; (2) to update the\nstate technology strategy developed and adopted pursuant to subdivision (1) of\nthis subsection at least once every two years; (3) to issue reports and\nrecommendations in accordance with the provisions of section 11-4a of the\ngeneral statutes; (4) upon the vote of a majority of the members of the board,\nto request any state agency data officer or state agency head to (A) appear\nbefore the board to answer questions, or (B) provide such assistance and data\nas may be necessary for the purpose of enabling the board to perform its\nduties; (5) to make recommendations to the Legislative Department, Executive\nDepartment or Judicial Department in accordance with the state technology\nstrategy; and (6) to establish bylaws to govern the board's procedures.\n\n(f) The board shall meet at least twice annually and may meet at such other\ntimes as deemed necessary by the chairpersons or a majority of the members of\nthe board.\n\nSec. 17. (Effective July 1, 2025) (a) Not later than December 31, 2025, the\nDepartment of Economic and Community Development shall, within available\nappropriations and in collaboration with Charter Oak State College, develop a\nplan to establish a technology transfer program within Connecticut\nInnovations, Incorporated, for the purpose of supporting technology transfers\nby and among public and private institutions of higher education in this\nstate.\n\n(b) Not later than January 1, 2026, the Commissioner of Economic and Community\nDevelopment shall submit a report, in accordance with the provisions of\nsection 11-4a of the general statutes, to the joint standing committees of the\nGeneral Assembly having cognizance of matters relating to consumer protection,\ncommerce and higher education. Such report shall, at a minimum, include the\nplan developed pursuant to subsection (a) of this section.\n\nSec. 18. (NEW) (Effective July 1, 2025) (a) Not later than December 31, 2025,\nthe Department of Economic and Community Development shall, within available\nappropriations and in collaboration with the Office of Health Strategy,\nestablish a confidential computing cluster for the purpose of fostering the\nexchange of health information in order to support academic and medical\nresearch.\n\n(b) (1) The confidential computing cluster established pursuant to subsection\n(a) of this section shall be overseen by a Connecticut Confidential Computing\nCluster Policy Board, which shall be within the Department of Economic and\nCommunity Development for administrative purposes only. Said policy board\nshall consist of:\n\n(A) The chairperson of The University of Connecticut Health Center Board of\nDirectors, or said chairperson's designee; and\n\n(B) A representative of the State-wide Health Information Exchange established\npursuant to section 17b-59d of the general statutes, who shall be appointed by\nthe Commissioner of Health Strategy.\n\n(2) The Connecticut Confidential Computing Cluster Policy Board shall direct\nthe formulation of policies and operating procedures for the confidential\ncomputing cluster established pursuant to subsection (a) of this section.\n\n(3) The Connecticut Confidential Computing Cluster Policy Board may apply for\nand administer any federal, state, local or private appropriations or grant\nfunds made available for the operation of the confidential computing cluster\nestablished pursuant to subsection (a) of this section.\n\nSec. 19. Section 10-21l of the general statutes is repealed and the following\nis substituted in lieu thereof (Effective July 1, 2025):\n\nThere is established an account to be known as the ~~\" computer science\neducation account\"~~ _\" computer science education and workforce development\naccount\"_, which shall be a separate, nonlapsing account within the General\nFund. The account shall contain any moneys required or permitted by law to be\ndeposited in the account and any funds received from any public or private\ncontributions, gifts, grants, donations, bequests or devises to the account.\nThe Department of Education may make expenditures from the account _(1)_ to\nsupport curriculum development, teacher professional development, capacity\ndevelopment for school districts ~~,~~ and other programs for the purposes of\nsupporting computer science education _, and (2) in coordination with the\nOffice of Workforce Strategy and the Board of Regents for Higher Education for\nthe purpose of supporting workforce development initiatives in accordance with\nthe state technology strategy adopted pursuant to subsection (e) of section 16\nof this act_.\n\nSec. 20. Section 32-7p of the general statutes is repealed and the following\nis substituted in lieu thereof (Effective July 1, 2025):\n\n_(a) As used in this section:_\n\n_(1) \"Artificial intelligence\" means artificial intelligence system, as\ndefined in section 1 of this act;_\n\n_(2) \"Generative artificial intelligence\" means any form of artificial\nintelligence, including, but not limited to, a foundation model, that is able\nto produce synthetic digital content, as defined in section 1 of this act;\nand_\n\n_(3) \"Prompt engineering\" means the process of guiding generative artificial\nintelligence to generate a desired output._\n\n~~(a)~~ _(b)_ There shall be a Technology Talent _and Innovation Fund_\nAdvisory Committee within the Department of Economic and Community\nDevelopment. Such committee shall consist of members appointed by the\nCommissioner of Economic and Community Development, including, but not limited\nto, representatives of The University of Connecticut, the Board of Regents for\nHigher Education, independent institutions of higher education, the Office of\nWorkforce Strategy and private industry. Such members shall be subject to term\nlimits prescribed by the commissioner. Each member shall hold office until a\nsuccessor is appointed.\n\n~~(b)~~ _(c)_ The commissioner shall call the first meeting of the advisory\ncommittee not later than October 15, 2016. The advisory committee shall meet\nnot less than quarterly thereafter and at such other times as the chairperson\ndeems necessary. The Technology Talent _and Innovation Fund_ Advisory\nCommittee shall designate the chairperson of the committee from among its\nmembers.\n\n~~(c)~~ _(d)_ No member of the advisory committee shall receive compensation\nfor such member's service, except that each member shall be entitled to\nreimbursement for actual and necessary expenses incurred during the\nperformance of such member's official duties.\n\n~~(d)~~ _(e)_ A majority of members of the advisory committee shall constitute\na quorum for the transaction of any business or the exercise of any power of\nthe advisory committee. The advisory committee may act by a majority of the\nmembers present at any meeting at which a quorum is in attendance, for the\ntransaction of any business or the exercise of any power of the advisory\ncommittee, except as otherwise provided in this section.\n\n~~(e)~~ _(f)_ Notwithstanding any provision of the general statutes, it shall\nnot constitute a conflict of interest for a trustee, director, partner or\nofficer of any person, firm or corporation, or any individual having a\nfinancial interest in a person, firm or corporation, to serve as a member of\nthe advisory committee, provided such trustee, director, partner, officer or\nindividual complies with all applicable provisions of chapter 10. All members\nof the advisory committee shall be deemed public officials and shall adhere to\nthe code of ethics for public officials set forth in chapter 10, except that\nno member shall be required to file a statement of financial interest as\ndescribed in section 1-83.\n\n~~(f) The Technology Talent Advisory Committee shall, in the following order\nof priority, (1) calculate the number of software developers and other persons\n(A) employed in technology-based fields where there is a shortage of qualified\nemployees in this state for businesses to hire, including, but not limited to,\ndata mining, data analysis and cybersecurity, and (B) employed by businesses\nlocated in Connecticut as of December 31, 2016; (2) develop pilot programs to\nrecruit software developers to Connecticut and train residents of the state in\nsoftware development and such other technology fields, with the goal of\nincreasing the number of software developers and persons employed in such\nother technology fields residing in Connecticut and employed by businesses in\nConnecticut by at least double the number calculated pursuant to subdivision\n(1) of this subsection by January 1, 2026; and (3) identify other technology\nindustries where there is a shortage of qualified employees in this state for\ngrowth stage businesses to hire.~~\n\n(g) The Technology Talent _and Innovation Fund_ Advisory Committee may\n_partner with institutions of higher education and other nonprofit\norganizations to_ develop ~~pilot~~ programs ~~for (1) marketing and publicity\ncampaigns designed to recruit technology talent to the state; (2) student loan\ndeferral or forgiveness for students who start businesses in the state; and\n(3) training, apprenticeship and gap-year initiatives~~ _to expand the\ntechnology talent pipeline in the state, including, but not limited to, in the\nfields of artificial intelligence and quantum computing_.\n\n~~(h) The Technology Talent Advisory Committee shall report, in accordance\nwith the provisions of section 11-4a, and present such report to the joint\nstanding committees of the General Assembly having cognizance of matters\nrelating to commerce, education, higher education and finance, revenue and\nbonding on or before January 1, 2017, concerning the (1) pilot programs\ndeveloped pursuant to subsections (f) and (g) of this section, (2) number of\nsoftware developers and persons employed in technology-based fields described\nin subsection (f) of this section targeted for recruitment pursuant to\nsubsection (f) of this section, and (3) timeline and measures for reaching the\nrecruitment target.~~\n\n_(h) Not later than July 1, 2026, the Technology Talent and Innovation Fund\nAdvisory Committee shall partner with public and private institutions of\nhigher education in the state and other training providers to develop programs\nin the field of artificial intelligence, including, but not limited to, in\nareas such as prompt engineering, artificial intelligence marketing for small\nbusinesses and artificial intelligence for small business operations._\n\nSec. 21. Subsection (b) of section 32-235 of the general statutes is repealed\nand the following is substituted in lieu thereof (Effective July 1, 2025):\n\n(b) The proceeds of the sale of said bonds, to the extent of the amount stated\nin subsection (a) of this section, shall be used by the Department of Economic\nand Community Development (1) for the purposes of sections 32-220 to 32-234,\ninclusive, including economic cluster-related programs and activities, and for\nthe Connecticut job training finance demonstration program pursuant to\nsections 32-23uu and 32-23vv, provided (A) three million dollars shall be used\nby said department solely for the purposes of section 32-23uu, (B) not less\nthan one million dollars shall be used for an educational technology grant to\nthe deployment center program and the nonprofit business consortium deployment\ncenter approved pursuant to section 32-41l, (C) not less than two million\ndollars shall be used by said department for the establishment of a pilot\nprogram to make grants to businesses in designated areas of the state for\nconstruction, renovation or improvement of small manufacturing facilities,\nprovided such grants are matched by the business, a municipality or another\nfinancing entity. The Commissioner of Economic and Community Development shall\ndesignate areas of the state where manufacturing is a substantial part of the\nlocal economy and shall make grants under such pilot program which are likely\nto produce a significant economic development benefit for the designated area,\n(D) five million dollars may be used by said department for the manufacturing\ncompetitiveness grants program, (E) one million dollars shall be used by said\ndepartment for the purpose of a grant to the Connecticut Center for Advanced\nTechnology, for the purposes of subdivision (5) of subsection (a) of section\n32-7f, (F) fifty million dollars shall be used by said department for the\npurpose of grants to the United States Department of the Navy, the United\nStates Department of Defense or eligible applicants for projects related to\nthe enhancement of infrastructure for long-term, on-going naval operations at\nthe United States Naval Submarine Base-New London, located in Groton, which\nwill increase the military value of said base. Such projects shall not be\nsubject to the provisions of sections 4a-60 and 4a-60a, (G) two million\ndollars shall be used by said department for the purpose of a grant to the\nConnecticut Center for Advanced Technology, Inc., for manufacturing\ninitiatives, including aerospace and defense, and (H) four million dollars\nshall be used by said department for the purpose of a grant to companies\nadversely impacted by the construction at the Quinnipiac Bridge, where such\ngrant may be used to offset the increase in costs of commercial overland\ntransportation of goods or materials brought to the port of New Haven by ship\nor vessel, (2) for the purposes of the small business assistance program\nestablished pursuant to section 32-9yy, provided fifteen million dollars shall\nbe deposited in the small business assistance account established pursuant to\nsaid section 32-9yy, (3) to deposit twenty million dollars in the small\nbusiness express assistance account established pursuant to section 32-7h, (4)\nto deposit four million nine hundred thousand dollars per year in each of the\nfiscal years ending June 30, 2017, to June 30, 2019, inclusive, and June 30,\n2021, and nine million nine hundred thousand dollars in the fiscal year ending\nJune 30, 2020, in the CTNext Fund established pursuant to section 32-39i,\nwhich shall be used by the Department of Economic and Community Development to\nprovide grants-in-aid to designated innovation places, as defined in section\n32-39f, planning grants-in-aid pursuant to section 32-39l, and grants-in-aid\nfor projects that network innovation places pursuant to subsection (b) of\nsection 32-39m, provided not more than three million dollars be used for\ngrants-in-aid for such projects, and further provided any portion of any such\ndeposit that remains unexpended in a fiscal year subsequent to the date of\nsuch deposit may be used by the Department of Economic and Community\nDevelopment for any purpose described in subsection (e) of section 32-39i, (5)\nto deposit two million dollars per year in each of the fiscal years ending\nJune 30, 2019, to June 30, 2021, inclusive, in the CTNext Fund established\npursuant to section 32-39i, which shall be used by the Department of Economic\nand Community Development for the purpose of providing higher education\nentrepreneurship grants-in-aid pursuant to section 32-39g, provided any\nportion of any such deposit that remains unexpended in a fiscal year\nsubsequent to the date of such deposit may be used by the Department of\nEconomic and Community Development for any purpose described in subsection (e)\nof section 32-39i, (6) for the purpose of funding the costs of the Technology\nTalent _and Innovation Fund_ Advisory Committee established pursuant to\nsection 32-7p _, as amended by this act_ , provided not more than ten million\ndollars may be used on or after July 1, 2023, for such purpose, (7) to provide\n(A) a grant-in-aid to the Connecticut Supplier Connection in an amount equal\nto two hundred fifty thousand dollars in each of the fiscal years ending June\n30, 2017, to June 30, 2021, inclusive, and (B) a grant-in-aid to the\nConnecticut Procurement Technical Assistance Program in an amount equal to\nthree hundred thousand dollars in each of the fiscal years ending June 30,\n2017, to June 30, 2021, inclusive, (8) to deposit four hundred fifty thousand\ndollars per year, in each of the fiscal years ending June 30, 2017, to June\n30, 2021, inclusive, in the CTNext Fund established pursuant to section\n32-39i, which shall be used by the Department of Economic and Community\nDevelopment to provide growth grants-in-aid pursuant to section 32-39g,\nprovided any portion of any such deposit that remains unexpended in a fiscal\nyear subsequent to the date of such deposit may be used by the Department of\nEconomic and Community Development for any purpose described in subsection (e)\nof section 32-39i, (9) to transfer fifty million dollars to the Labor\nDepartment which shall be used by said department for the purpose of funding\nworkforce pipeline programs selected pursuant to section 31-11rr, provided,\nnotwithstanding the provisions of section 31-11rr, (A) not less than five\nmillion dollars shall be provided to the workforce development board in\nBridgeport serving the southwest region, for purposes of such program, and the\nboard shall distribute such money in proportion to population and need, and\n(B) not less than five million dollars shall be provided to the workforce\ndevelopment board in Hartford serving the north central region, for purposes\nof such program, (10) to transfer twenty million dollars to Connecticut\nInnovations, Incorporated, provided ten million dollars shall be used by\nConnecticut Innovations, Incorporated for the purpose of the proof of concept\nfund established pursuant to subsection (b) of section 32-39x and ten million\ndollars shall be used by Connecticut Innovations, Incorporated for the purpose\nof the venture capital fund program established pursuant to section 32-41oo,\n(11) to provide a grant to The University of Connecticut of eight million\ndollars for the establishment, development and operation of a center for\nsustainable aviation pursuant to subsection (a) of section 10a-110o, and (12)\nfor up to twenty million dollars in investments in federally designated\nopportunity zones through an impact investment firm including, subject to the\napproval of the Governor, funding from the Economic Assistance Revolving Fund,\nestablished pursuant to section 32-231.\n\nSec. 22. (Effective July 1, 2025) Not later than December 31, 2025, the\nDepartment of Economic and Community Development shall, within available\nappropriations, in partnership with public and private institutions of higher\neducation in the state and in coordination with the artificial intelligence\nindustry, conduct a \"CT AI Symposium\" to foster collaboration between\nacademia, government and the artificial intelligence industry for the purpose\nof promoting the establishment and growth of artificial intelligence\nbusinesses in this state.\n\nSec. 23. (Effective July 1, 2025) (a) As used in this section:\n\n(1) \"Artificial intelligence\" means artificial intelligence system, as defined\nin section 1 of this act;\n\n(2) \"Generative artificial intelligence\" means any form of artificial\nintelligence, including, but not limited to, a foundation model, that is able\nto produce synthetic digital content, as defined in section 1 of this act; and\n\n(3) \"State agency\" means any department, board, council, commission,\ninstitution or other executive branch agency of state government, including,\nbut not limited to, each constituent unit and each public institution of\nhigher education.\n\n(b) Each state agency shall, in consultation with the labor unions\nrepresenting the employees of such state agency, study how generative\nartificial intelligence may be incorporated in its processes to improve\nefficiencies. Each state agency shall prepare for any such incorporation with\ninput from the state agency's employees, including, but not limited to, any\napplicable collective bargaining unit that represents its employees, and\nappropriate experts from civil society organizations, academia and industry.\n\n(c) Not later than January 1, 2026, each state agency shall submit the results\nof such study to the Department of Administrative Services, including a\nrequest for approval of any potential pilot project utilizing generative\nartificial intelligence that the state agency intends to establish, provided\nsuch use is in accordance with the policies and procedures established by the\nOffice of Policy and Management pursuant to subsection (b) of section 4-68jj\nof the general statutes. Any such pilot project shall measure how generative\nartificial intelligence (1) improves Connecticut residents' experience with\nand access to government services, and (2) supports state agency employees in\nthe performance of their duties in addition to any domain-specific impacts to\nbe measured by the state agency. The Commissioner of Administrative Services\nshall assess any such proposed pilot project in accordance with the provisions\nof section 4a-2e of the general statutes, as amended by this act, and may\ndisapprove any pilot project that fails such assessment or requires additional\nlegislative authorization.\n\n(d) Not later than February 1, 2026, the Commissioner of Administrative\nServices shall submit a report, in accordance with the provisions of section\n11-4a of the general statutes, to the joint standing committees of the General\nAssembly having cognizance of matters relating to consumer protection and\ngovernment administration. Such report shall include a summary of all pilot\nprojects approved by the commissioner under this section and any\nrecommendations for legislation necessary to implement additional pilot\nprojects.\n\nSec. 24. Section 32-39e of the general statutes is repealed and the following\nis substituted in lieu thereof (Effective July 1, 2025):\n\n(a) If, in the exercise of its powers under section 32-39, Connecticut\nInnovations, Incorporated (1) finds that the use of a certain technology,\nproduct or process _, including, but not limited to, an artificial\nintelligence system, as defined in section 1 of this act,_ (A) would promote\npublic health and safety, environmental protection or economic development, or\n(B) with regard to state services, would promote efficiency, reduce\nadministrative burdens or otherwise improve such services, and (2) determines\nsuch technology, product or process was developed by a business (A) domiciled\nin this state to which the corporation has provided financial assistance or in\nwhich the corporation has invested, or (B) which has been certified as a small\ncontractor or minority business enterprise by the Commissioner of\nAdministrative Services under section 4a-60g, the corporation, upon\napplication of such business, may recommend to the Secretary of the Office of\nPolicy and Management that an agency of the state, including, but not limited\nto, any constituent unit of the state system of higher education, be\nauthorized to test such technology, product or process by employing ~~it~~\n_such technology, product or process_ in the operations of such agency on a\ntrial basis. The purpose of such test program shall be to validate the\ncommercial viability of such technology, product or process provided no\nbusiness in which Connecticut Innovations, Incorporated has invested shall be\nrequired to participate in such program.\n\n(b) Connecticut Innovations, Incorporated shall make no such recommendation\nunless such business has submitted a viable business plan to Connecticut\nInnovations, Incorporated for manufacturing and marketing such technology,\nproduct or process and such business demonstrates that (1) the usage of such\ntechnology, product or process by the state agency will not adversely affect\nsafety, (2) sufficient research and development has occurred to warrant\nparticipation in the test program, (3) the technology, product or process has\npotential for commercialization not later than two years following the\ncompletion of any test program involving a state agency under this section,\nand (4) such technology, product or process will have a positive economic\nimpact in the state, including the prospective addition of jobs and economic\nactivity upon such commercialization.\n\n(c) If the Secretary of the Office of Policy and Management finds that\nemploying such technology, product or process would be feasible in the\noperations of a state agency and would not have any detrimental effect on such\noperations, said secretary, notwithstanding the requirement of chapter 58, may\ndirect an agency of the state to accept delivery of such technology, product\nor process and to undertake such a test program. The Secretary of the Office\nof Policy and Management, in consultation with the Commissioner of\nAdministrative Services, the chief executive officer of Connecticut\nInnovations, Incorporated and the department head of the testing agency, shall\ndetermine, on a case-by-case basis, whether the costs associated with the\nacquisition and use of such technology, product or process by the testing\nagency shall be borne by Connecticut Innovations, Incorporated, the business\nor by any investor or participant in such business. The acquisition of any\ntechnology, product or process for purposes of the test program established\npursuant to this section shall not be deemed to be a purchase under the\nprovisions of the state procurement policy. The testing agency, on behalf of\nConnecticut Innovations, Incorporated shall maintain records related to such\ntest program, as requested by Connecticut Innovations, Incorporated and shall\nmake such records and any other information derived from such test program\navailable to Connecticut Innovations, Incorporated and the business. Any\nproprietary information derived from such test program shall be exempt from\nthe provisions of subsection (a) of section 1-210.\n\n(d) If the Secretary of the Office of Policy and Management, in consultation\nwith the Commissioner of Administrative Services, the chief executive officer\nof Connecticut Innovations, Incorporated and the department head of the\ntesting agency, determines that the test program sufficiently demonstrates\nthat the technology, product or process promotes public health and safety,\nenvironmental protection, economic development or efficiency, reduces\nadministrative burdens or otherwise improves state services, the Commissioner\nof Administrative Services may procure such technology, product or process for\nuse by any or all state agencies pursuant to subsection (b) of section 4a-58.\n\n(e) The Secretary of the Office of Policy and Management, the Commissioner of\nAdministrative Services and Connecticut Innovations, Incorporated may develop\na program to recognize state agencies that help to promote public health and\nsafety, environmental protection, economic development or efficiency, reduce\nadministrative burdens or improve state services by participating in a testing\nprogram under this section. Such program may include the creation of a fund\nestablished with savings accrued by the testing agency during its\nparticipation in the testing program established under this section. Such fund\nshall only be used to implement the program of recognition established by the\nSecretary of the Office of Policy and Management, the Commissioner of\nAdministrative Services and Connecticut Innovations, Incorporated, under the\nprovisions of this subsection.\n\n_(f) The Secretary of the Office of Policy and Management, the Commissioner of\nAdministrative Services, Connecticut Innovations, Incorporated, and the Chief\nInformation Officer shall, within available appropriations, establish an\nartificial intelligence systems fellowship program for the purpose of\nassisting the Chief Information Officer and state agencies to implement\nartificial intelligence systems procured pursuant to subsection (b) of section\n4a-58. The program shall be within the Office of Policy and Management for\nadministrative purposes only. Not later than January 1, 2026, the Governor\nshall appoint three artificial intelligence technology fellows in consultation\nwith the Chief Information Officer. Each artificial intelligence technology\nfellow shall have professional experience or academic qualifications in the\nfield of artificial intelligence, and shall perform such artificial\nintelligence technology fellow 's duties under the supervision of the Chief\nInformation Officer. The initial term for each artificial intelligence\ntechnology fellow shall expire on January 31, 2029. Terms following initial\nterms shall be for two years, and any artificial intelligence technology\nfellow may serve more than one term. The Governor shall fill any vacancy in\nconsultation with the Chief Information Officer not later than thirty days\nafter the appointment becomes vacant. For the purposes of this subsection,\n\"artificial intelligence system\" has the same meaning as provided in section 1\nof this act._\n\nSec. 25. (Effective July 1, 2025) (a) For the purposes of this section:\n\n(1) \"Artificial intelligence\" means artificial intelligence system, as defined\nin section 1 of this act;\n\n(2) \"General-purpose artificial intelligence\" means general-purpose artificial\nintelligence model, as defined in section 1 of this act; and\n\n(3) \"Synthetic digital content\" has the same meaning as provided in section 1\nof this act.\n\n(b) There is established a working group to engage stakeholders and experts\nto:\n\n(1) Make recommendations concerning:\n\n(A) The best practices to avoid the negative impacts, and to maximize the\npositive impacts, on services and state employees in connection with the\nimplementation of new digital technologies and artificial intelligence;\n\n(B) The collection of reports, recommendations and plans from state agencies\nconsidering the implementation of artificial intelligence, and the assessment\nof such reports, recommendations and plans against the best practices\ndescribed in subparagraph (A) of this subdivision; and\n\n(C) Any other matters that the working group may deem relevant for the\npurposes of avoiding the negative impacts, and maximizing the positive\nimpacts, described in subparagraph (A) of this subdivision;\n\n(2) Make recommendations concerning methods to create resources for the\npurpose of assisting small businesses to adopt artificial intelligence to\nimprove their efficiency and operations;\n\n(3) Propose legislation to (A) regulate the use of general-purpose artificial\nintelligence, and (B) require social media platforms to provide a signal when\nsuch social media platforms are displaying synthetic digital content;\n\n(4) After reviewing the laws and regulations, and any proposed legislation or\nregulations, of other states concerning artificial intelligence, propose\nlegislation concerning artificial intelligence;\n\n(5) Develop an outreach plan for the purpose of bridging the digital divide\nand providing workforce training to persons who do not have high-speed\nInternet access;\n\n(6) Evaluate and make recommendations concerning:\n\n(A) The establishment of testbeds to support safeguards and systems to prevent\nthe misuse of artificial intelligence;\n\n(B) Risk assessments for the misuse of artificial intelligence;\n\n(C) Evaluation strategies for artificial intelligence; and\n\n(D) The development, testing and evaluation of resources to support state\noversight of artificial intelligence;\n\n(7) Review the protections afforded to trade secrets and other proprietary\ninformation under existing state law and make recommendations concerning such\nprotections;\n\n(8) Study definitions concerning artificial intelligence, including, but not\nlimited to, the definition of high-risk artificial intelligence system set\nforth in section 1 of this act, and make recommendations concerning the\ninclusion of language providing that no artificial intelligence system shall\nbe considered to be a high-risk artificial intelligence system if such\nartificial intelligence system does not pose a significant risk of harm to the\nhealth, safety or fundamental rights of individuals, including, but not\nlimited to, by not materially influencing the outcome of any decision-making;\n\n(9) Make recommendations concerning the establishment and membership of a\npermanent artificial intelligence advisory council; and\n\n(10) Make such other recommendations concerning artificial intelligence that\nthe working group may deem appropriate.\n\n(c) (1) (A) The working group shall be part of the Legislative Department and\nconsist of the following voting members: (i) One appointed by the speaker of\nthe House of Representatives, who shall be a representative of the industries\nthat are developing artificial intelligence; (ii) one appointed by the\npresident pro tempore of the Senate, who shall be a representative of the\nindustries that are using artificial intelligence; (iii) one appointed by the\nmajority leader of the House of Representatives, who shall be an academic with\na concentration in the study of technology and technology policy; (iv) one\nappointed by the majority leader of the Senate, who shall be an academic with\na concentration in the study of government and public policy; (v) one\nappointed by the minority leader of the House of Representatives, who shall be\na representative of an industry association representing the industries that\nare developing artificial intelligence; (vi) one appointed by the minority\nleader of the Senate, who shall be a representative of an industry association\nrepresenting the industries that are using artificial intelligence; (vii) one\nappointed by the House chairperson of the joint standing committee of the\nGeneral Assembly having cognizance of matters relating to consumer protection;\n(viii) one appointed by the Senate chairperson of the joint standing committee\nof the General Assembly having cognizance of matters relating to consumer\nprotection; (ix) one appointed by the House ranking member of the joint\nstanding committee of the General Assembly having cognizance of matters\nrelating to consumer protection, who shall be a representative of the\nartificial intelligence industry or a related industry; (x) one appointed by\nthe Senate ranking member of the joint standing committee of the General\nAssembly having cognizance of matters relating to consumer protection, who\nshall be a representative of the artificial intelligence industry or a related\nindustry; (xi) one appointed by the House chairperson of the joint standing\ncommittee of the General Assembly having cognizance of matters relating to\nlabor, who shall be a representative of a labor organization; (xii) one\nappointed by the Senate chairperson of the joint standing committee of the\nGeneral Assembly having cognizance of matters relating to labor, who shall be\na representative of a labor organization; (xiii) one appointed by the House\nranking member of the joint standing committee of the General Assembly having\ncognizance of matters relating to labor, who shall be a representative of a\nsmall business; (xiv) one appointed by the Senate ranking member of the joint\nstanding committee of the General Assembly having cognizance of matters\nrelating to labor, who shall be a representative of a small business; and (xv)\ntwo appointed by the Governor, who shall be members of the Connecticut Academy\nof Science and Engineering.\n\n(B) All voting members of the working group appointed pursuant to subparagraph\n(A) of this subdivision shall have professional experience or academic\nqualifications in matters pertaining to artificial intelligence, automated\nsystems, government policy or another related field.\n\n(C) All initial appointments to the working group shall be made not later than\nJuly 31, 2025. Any vacancy shall be filled by the appointing authority.\n\n(D) Any action taken by the working group shall be taken by a majority vote of\nall members present who are entitled to vote, provided no such action may be\ntaken unless at least fifty per cent of such members are present.\n\n(2) The working group shall include the following nonvoting, ex-officio\nmembers: (A) The House chairperson of the joint standing committee of the\nGeneral Assembly having cognizance of matters relating to consumer protection;\n(B) the Senate chairperson of the joint standing committee of the General\nAssembly having cognizance of matters relating to consumer protection; (C) the\nHouse chairperson of the joint standing committee of the General Assembly\nhaving cognizance of matters relating to labor; (D) the Senate chairperson of\nthe joint standing committee of the General Assembly having cognizance of\nmatters relating to labor; (E) the Attorney General, or the Attorney General's\ndesignee; (F) the Comptroller, or the Comptroller's designee; (G) the\nTreasurer, or the Treasurer's designee; (H) the Commissioner of Administrative\nServices, or said commissioner's designee; (I) the Chief Data Officer, or said\nofficer's designee; (J) the executive director of the Freedom of Information\nCommission, or said executive director's designee; (K) the executive director\nof the Commission on Women, Children, Seniors, Equity and Opportunity, or said\nexecutive director's designee; (L) the Chief Court Administrator, or said\nadministrator's designee; and (M) the executive director of the Connecticut\nAcademy of Science and Engineering, or said executive director's designee.\n\n(d) The chairpersons of the joint standing committee of the General Assembly\nhaving cognizance of matters relating to consumer protection and the executive\ndirector of the Connecticut Academy of Science and Engineering shall serve as\nchairpersons of the working group. Such chairpersons shall schedule the first\nmeeting of the working group, which shall be held not later than August 31,\n2025.\n\n(e) The administrative staff of the joint standing committee of the General\nAssembly having cognizance of matters relating to consumer protection shall\nserve as administrative staff of the working group.\n\n(f) Not later than February 1, 2026, the working group shall submit a report\non its findings and recommendations to the joint standing committee of the\nGeneral Assembly having cognizance of matters relating to consumer protection,\nin accordance with the provisions of section 11-4a of the general statutes.\nThe working group shall terminate on the date that the working group submits\nsuch report or February 1, 2026, whichever is later.\n\nSec. 26. Section 4a-2e of the general statutes is repealed and the following\nis substituted in lieu thereof (Effective July 1, 2025):\n\n(a) For the purposes of this section:\n\n(1) \"Artificial intelligence\" means ~~(A) an artificial system that (i)\nperforms tasks under varying and unpredictable circumstances without\nsignificant human oversight or can learn from experience and improve such\nperformance when exposed to data sets, (ii) is developed in any context,\nincluding, but not limited to, software or physical hardware, and solves tasks\nrequiring human-like perception, cognition, planning, learning, communication\nor physical action, or (iii) is designed to (I) think or act like a human,\nincluding, but not limited to, a cognitive architecture or neural network, or\n(II) act rationally, including, but not limited to, an intelligent software\nagent or embodied robot that achieves goals using perception, planning,\nreasoning, learning, communication, decision-making or action, or (B) a set of\ntechniques, including, but not limited to, machine learning, that is designed\nto approximate a cognitive task; and~~ _artificial intelligence system, as\ndefined in section 1 of this act;_\n\n_(2) \"Generative artificial intelligence\" means any form of artificial\nintelligence, including, but not limited to, a foundation model, that is able\nto produce synthetic digital content, as defined in section 1 of this act;\nand_\n\n~~(2)~~ _(3)_ \"State agency\" has the same meaning as provided in section 4d-1.\n\n(b) (1) Not later than December 31, 2023, and annually thereafter, the\n~~Department~~ _Commissioner_ of Administrative Services shall conduct an\ninventory of all systems that employ artificial intelligence and are in use by\nany state agency. Each such inventory shall include at least the following\ninformation for each such system:\n\n(A) The name of such system and the vendor, if any, that provided such system;\n\n(B) A description of the general capabilities and uses of such system;\n\n(C) Whether such system was used to independently make, inform or materially\nsupport a conclusion, decision or judgment; and\n\n(D) Whether such system underwent an impact assessment prior to\nimplementation.\n\n(2) The ~~Department~~ _Commissioner_ of Administrative Services shall make\neach inventory conducted pursuant to subdivision (1) of this subsection\npublicly available on the state's open data portal.\n\n(c) Beginning on February 1, 2024, the ~~Department~~ _Commissioner_ of\nAdministrative Services shall perform ongoing assessments of systems that\nemploy artificial intelligence and are in use by state agencies to ensure that\nno such system shall result in any unlawful discrimination or disparate impact\ndescribed in subparagraph (B) of subdivision (1) of subsection (b) of section\n4-68jj. The ~~department~~ _commissioner_ shall perform such assessment in\naccordance with the policies and procedures established by the Office of\nPolicy and Management pursuant to subsection (b) of section 4-68jj.\n\n_(d) The Commissioner of Administrative Services shall, in consultation with\nother state agencies, collective bargaining units that represent state agency\nemployees and industry experts, develop trainings for state agency employees\non (1) the use of generative artificial intelligence tools that are determined\nby the commissioner, pursuant to the assessment performed under subsection (c)\nof this section, to achieve equitable outcomes, and (2) methods for\nidentifying and mitigating potential output inaccuracies, fabricated text,\nhallucinations and biases of generative artificial intelligence while\nrespecting the privacy of the public and complying with all applicable state\nlaws and policies. Beginning on July 1, 2026, the commissioner shall make such\ntrainings available to state agency employees not less frequently than\nannually._\n\nSec. 27. (NEW) (Effective July 1, 2025) The Department of Economic and\nCommunity Development shall, within available appropriations, design an\nalgorithmic computer model for the purpose of simulating and assessing various\npublic policy decisions, proposed public policy decisions and the actual or\npotential effects of such policy decisions. The department shall design such\nmodel in collaboration with public and private institutions of higher\neducation in this state, the Department of Energy and Environmental Protection\nand any other state agency the Commissioner of Economic and Community\nDevelopment, in the commissioner's discretion, deems relevant for the purposes\nof this section. Such model shall, at a minimum, be designed to (1) function\nas a digital twin of the population of the state, (2) algorithmically model\n(A) the actual or potential effects of planning and development decisions or\nproposed planning and development decisions, and (B) the actual or potential\nsocioeconomic effects of macroeconomic shocks on businesses and families in\nthe state, (3) utilize large quantities of data to support the development of\npublic policies concerning coastline resiliency, family assistance and\nworkforce development, and (4) enable data-driven governance by optimizing\nresource allocation and policy efficiency for the purpose of furthering\neconomic resilience and social equity.\n\nSec. 28. Section 53a-189c of the general statutes is repealed and the\nfollowing is substituted in lieu thereof (Effective October 1, 2025):\n\n(a) A person is guilty of unlawful dissemination of an intimate image when (1)\nsuch person intentionally disseminates by electronic or other means a\nphotograph, film, videotape or other recorded image _or synthetic image_ of\n(A) the genitals, pubic area or buttocks of another person with less than a\nfully opaque covering of such body part, or the breast of such other person\nwho is female with less than a fully opaque covering of any portion of such\nbreast below the top of the nipple, or (B) another person engaged in sexual\nintercourse, as defined in section 53a-193, (2) such person disseminates such\nimage ~~without the consent of such other person,~~ knowing that such other\nperson ~~understood that the image would not be so disseminated~~ _did not\nconsent to such dissemination_ , and (3) such other person suffers harm as a\nresult of such dissemination.\n\n_(b)_ For purposes of this ~~subsection, \"disseminate\"~~ _section:_\n\n_(1) \"Disseminate\"_ means to sell, give, provide, lend, trade, mail, deliver,\ntransfer, publish, distribute, circulate, present, exhibit, advertise or\notherwise offer _;_ ~~, and \"harm\"~~\n\n_(2) \"Harm\"_ includes, but is not limited to, subjecting such other person to\nhatred, contempt, ridicule, physical injury, financial injury, psychological\nharm or serious emotional distress _; and_\n\n_(3) \"Synthetic image\" means any photograph, film, videotape or other image\nthat (A) is not wholly recorded by a camera, (B) is either partially or wholly\ngenerated by a computer system, and (C) depicts, and is virtually\nindistinguishable from an actual representation of, an identifiable person_.\n\n~~(b)~~ _(c)_ The provisions of subsection (a) of this ~~subsection~~\n_section_ shall not apply to:\n\n(1) Any image described in subsection (a) of this section of such other person\nif such image resulted from voluntary exposure or engagement in sexual\nintercourse by such other person, in a public place, as defined in section\n53a-181, or in a commercial setting;\n\n(2) Any image described in subsection (a) of this section of such other\nperson, if such other person is not clearly identifiable, unless other\npersonally identifying information is associated with or accompanies the\nimage; or\n\n(3) Any image described in subsection (a) of this section of such other\nperson, if the dissemination of such image serves the public interest.\n\n~~(c)~~ _(d)_ Unlawful dissemination of an intimate image to (1) a person by\nany means is a class A misdemeanor, and (2) more than one person by means of\nan interactive computer service, as defined in 47 USC 230, an information\nservice, as defined in 47 USC 153, or a telecommunications service, as defined\nin section 16-247a, is a class D felony.\n\n~~(d)~~ _(e)_ Nothing in this section shall be construed to impose liability\non the provider of an interactive computer service, as defined in 47 USC 230,\nan information service, as defined in 47 USC 153, or a telecommunications\nservice, as defined in section 16-247a, for content provided by another\nperson.\n\nThis act shall take effect as follows and shall amend the following sections:\n\nSection 1 | October 1, 2025 | New section  \n---|---|---  \nSec. 2 | October 1, 2025 | New section  \nSec. 3 | October 1, 2025 | New section  \nSec. 4 | October 1, 2025 | New section  \nSec. 5 | October 1, 2025 | New section  \nSec. 6 | October 1, 2025 | New section  \nSec. 7 | October 1, 2025 | New section  \nSec. 8 | October 1, 2025 | New section  \nSec. 9 | October 1, 2025 | New section  \nSec. 10 | October 1, 2025 | New section  \nSec. 11 | October 1, 2025 | New section  \nSec. 12 | October 1, 2025 | New section  \nSec. 13 | July 1, 2025 | New section  \nSec. 14 | July 1, 2025 | New section  \nSec. 15 | July 1, 2025 | 17b-751b(b)  \nSec. 16 | July 1, 2025 | New section  \nSec. 17 | July 1, 2025 | New section  \nSec. 18 | July 1, 2025 | New section  \nSec. 19 | July 1, 2025 | 10-21l  \nSec. 20 | July 1, 2025 | 32-7p  \nSec. 21 | July 1, 2025 | 32-235(b)  \nSec. 22 | July 1, 2025 | New section  \nSec. 23 | July 1, 2025 | New section  \nSec. 24 | July 1, 2025 | 32-39e  \nSec. 25 | July 1, 2025 | New section  \nSec. 26 | July 1, 2025 | 4a-2e  \nSec. 27 | July 1, 2025 | New section  \nSec. 28 | October 1, 2025 | 53a-189c  \n  \n**Statement of Legislative Commissioners:**\n\nIn Section 1(9)(B), \"or system\" was added after \"unless the technology\" and\n\"does not include\" was added before \"(i)\" for internal consistency; in Section\n1(13), \"identify\" was added before \"how\" for internal consistency; in Section\n3(d)(2)(B), \"any intentional\" was changed to \"an intentional\" for consistency;\nin Section 4(e)(1)(B)(ii), \"said subparagraph (C)\" was changed to \"said\nsubparagraph\" for consistency with standard drafting conventions; in Section\n12(b)(3), \"being\" was added before \"exempt\" for clarity; in Section 12(d),\n\"subparagraph (B) of\" was added before \"subdivision (2)\" for accuracy; and in\nSections 12(g), 16(e)(3), 17(b), 23(d) and 25(f), \"the provisions of\" was\nadded before \"section 11-4a\" for consistency with standard drafting\nconventions.\n\nCopyright (C) 2025 State Net  \n  \n---\n\n",
      "latest_version": true
    }
  ]
}